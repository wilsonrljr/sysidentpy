<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="From Classical Approaches to Neural Networks"><meta name=author content="Wilson Rocha"><link href=https://sysidentpy.org/book/4-Model-Structure-Selection/ rel=canonical><link href=../3-Parameter-Estimation/ rel=prev><link href=../5-Multiobjective-Parameter-Estimation/ rel=next><link rel=icon href=../../en/assets/img/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.6"><title>4. Model Structure Selection - SysIdentPy</title><link rel=stylesheet href=../../assets/stylesheets/main.8608ea7d.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Nunito+Sans:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Nunito Sans";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../assets/_mkdocstrings.css><link rel=stylesheet href=../../overrides/assets/css/extra.css><link rel=stylesheet href=../../overrides/assets/css/feature-grid.css><link rel=stylesheet href=../../overrides/assets/css/fontsize.css><link rel=stylesheet href=../../overrides/assets/css/card-container.css><link rel=stylesheet href=https://unpkg.com/katex@0/dist/katex.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/swiper@11/swiper-bundle.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css><link rel=stylesheet href=../../overrides/assets/vendor/css/prism.css><link rel=stylesheet href=../../overrides/assets/css/style.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-16K3SQT164"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-16K3SQT164",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-16K3SQT164",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script> <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../assets/javascripts/glightbox.min.js"></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=orange> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#introduction class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title=SysIdentPy class="md-header__button md-logo" aria-label=SysIdentPy data-md-component=logo> <img src=../../overrides/assets/img/logotype-sysidentpy.svg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> SysIdentPy </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> 4. Model Structure Selection </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=orange aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=orange aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <div class=md-header__option> <div class=md-select> <button class="md-header__button md-icon" aria-label="Select language"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"/></svg> </button> <div class=md-select__inner> <ul class=md-select__list> <li class=md-select__item> <a href=./ hreflang=en class=md-select__link> English </a> </li> <li class=md-select__item> <a href=../../pt/book/4-Model-Structure-Selection/ hreflang=pt class=md-select__link> Português (Brasil) </a> </li> <li class=md-select__item> <a href=../../es/book/4-Model-Structure-Selection/ hreflang=es class=md-select__link> Español </a> </li> </ul> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/wilsonrljr/sysidentpy title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> wilsonrljr/sysidentpy </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../getting-started/getting-started/ class=md-tabs__link> Getting started </a> </li> <li class=md-tabs__item> <a href=../../user-guide/overview/ class=md-tabs__link> User guide </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../0-Preface/ class=md-tabs__link> Companion Book </a> </li> <li class=md-tabs__item> <a href=../../developer-guide/contribute/ class=md-tabs__link> Developer guide </a> </li> <li class=md-tabs__item> <a href=../../community-support/community-overview/ class=md-tabs__link> Community & Support </a> </li> <li class=md-tabs__item> <a href=../../landing-page/about-us/ class=md-tabs__link> About </a> </li> <li class=md-tabs__item> <a href=../../changelog/changelog/ class=md-tabs__link> Changelog </a> </li> <li class=md-tabs__item> <a href=../../landing-page/sponsor/ class=md-tabs__link> Sponsors </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title=SysIdentPy class="md-nav__button md-logo" aria-label=SysIdentPy data-md-component=logo> <img src=../../overrides/assets/img/logotype-sysidentpy.svg alt=logo> </a> SysIdentPy </label> <div class=md-nav__source> <a href=https://github.com/wilsonrljr/sysidentpy title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> wilsonrljr/sysidentpy </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Getting started </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Getting started </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../getting-started/getting-started/ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../../getting-started/quickstart-guide/ class=md-nav__link> <span class=md-ellipsis> Quickstart Guide </span> </a> </li> <li class=md-nav__item> <a href=../../getting-started/narmax-intro/ class=md-nav__link> <span class=md-ellipsis> Introduction to NARMAX </span> </a> </li> <li class=md-nav__item> <a href=../../getting-started/license/ class=md-nav__link> <span class=md-ellipsis> License </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> User guide </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> User guide </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../user-guide/overview/ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex=0> <span class=md-ellipsis> Tutorials </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> Tutorials </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2_1> <label class=md-nav__link for=__nav_3_2_1 id=__nav_3_2_1_label tabindex=0> <span class=md-ellipsis> Features </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_3_2_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2_1> <span class="md-nav__icon md-icon"></span> Features </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../user-guide/tutorials/your-first-model/ class=md-nav__link> <span class=md-ellipsis> Your First Model </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/model-with-multiple-inputs/ class=md-nav__link> <span class=md-ellipsis> Model with Multiple Inputs </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/parameter-estimation-overview/ class=md-nav__link> <span class=md-ellipsis> Parameter Estimation - Overview </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/basis-function-overview/ class=md-nav__link> <span class=md-ellipsis> Basis Function - Overview </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/information-criteria-overview/ class=md-nav__link> <span class=md-ellipsis> Information Criteria - Overview </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/general-NARX-models/ class=md-nav__link> <span class=md-ellipsis> General NARX Models - Overview </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/fourier-NARX-overview/ class=md-nav__link> <span class=md-ellipsis> Fourier NARX - Overview </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/aols-overview/ class=md-nav__link> <span class=md-ellipsis> AOLS - Overview </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/NFIR-model-overview/ class=md-nav__link> <span class=md-ellipsis> NFIR - Overview </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/importance-of-extended-least-squares/ class=md-nav__link> <span class=md-ellipsis> Importance of Extended Least Squares </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2_2> <label class=md-nav__link for=__nav_3_2_2 id=__nav_3_2_2_label tabindex=0> <span class=md-ellipsis> Electrical and Mechanical Systems </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_3_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2_2> <span class="md-nav__icon md-icon"></span> Electrical and Mechanical Systems </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../user-guide/tutorials/modeling-a-magneto-rheological-damper-device/ class=md-nav__link> <span class=md-ellipsis> Modeling a Magneto-Rheological Damper Device </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/silver-box-system/ class=md-nav__link> <span class=md-ellipsis> Silver Box System </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/coupled-eletric-device/ class=md-nav__link> <span class=md-ellipsis> Coupled Electric Device </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/wiener-hammerstein-system/ class=md-nav__link> <span class=md-ellipsis> Wiener-Hammerstein System </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/f-16-aircraft/ class=md-nav__link> <span class=md-ellipsis> F-16 Aircraft </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/f-16-aircraft-n-steps-ahead-prediction/ class=md-nav__link> <span class=md-ellipsis> F-16 Aircraft - N-Steps Ahead Prediction </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/electromechanical-system-identification-overview/ class=md-nav__link> <span class=md-ellipsis> Electromechanical System Identification - Overview </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/electromechanical-system-identification-metamss/ class=md-nav__link> <span class=md-ellipsis> Electromechanical System Identification - MetaMSS </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/electromechanical-system-identification-entropic-regression/ class=md-nav__link> <span class=md-ellipsis> Electromechanical System Identification - Entropic Regression </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/multiobjective-parameter-estimation-overview/ class=md-nav__link> <span class=md-ellipsis> Multiobjective Parameter Estimation - Overview </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2_3> <label class=md-nav__link for=__nav_3_2_3 id=__nav_3_2_3_label tabindex=0> <span class=md-ellipsis> Industrial and Corporate </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_3_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2_3> <span class="md-nav__icon md-icon"></span> Industrial and Corporate </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../user-guide/tutorials/m4-benchmark/ class=md-nav__link> <span class=md-ellipsis> M4 Benchmark </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/air-passenger-benchmark/ class=md-nav__link> <span class=md-ellipsis> Air Passenger Benchmark </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/load-forecasting-benchmark/ class=md-nav__link> <span class=md-ellipsis> Load Forecasting Benchmark </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/PV-forecasting-benchmark/ class=md-nav__link> <span class=md-ellipsis> PV Forecasting Benchmark </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2_4> <label class=md-nav__link for=__nav_3_2_4 id=__nav_3_2_4_label tabindex=0> <span class=md-ellipsis> Chaotic Systems </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_3_2_4_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2_4> <span class="md-nav__icon md-icon"></span> Chaotic Systems </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../user-guide/tutorials/chaotic-systems/lorenz-system/ class=md-nav__link> <span class=md-ellipsis> Lorenz System </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/tutorials/chaotic-systems/logistic-map/ class=md-nav__link> <span class=md-ellipsis> Logistic Map </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_3> <label class=md-nav__link for=__nav_3_3 id=__nav_3_3_label tabindex=0> <span class=md-ellipsis> How to </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3_3> <span class="md-nav__icon md-icon"></span> How to </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../user-guide/how-to/create-custom-basis-function/ class=md-nav__link> <span class=md-ellipsis> Create a Custom Basis Function </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/how-to/create-a-narx-neural-network/ class=md-nav__link> <span class=md-ellipsis> Create a Neural NARX Network </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/how-to/save-and-load-models/ class=md-nav__link> <span class=md-ellipsis> Save and Load Models </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/how-to/set-specific-lags/ class=md-nav__link> <span class=md-ellipsis> Set Specific Lags </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/how-to/simulating-existing-models/ class=md-nav__link> <span class=md-ellipsis> Simulating Existing Models </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/how-to/use-extended-least-squares/ class=md-nav__link> <span class=md-ellipsis> Use Extended Least Squares </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_4> <label class=md-nav__link for=__nav_3_4 id=__nav_3_4_label tabindex=0> <span class=md-ellipsis> API </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_4_label aria-expanded=false> <label class=md-nav__title for=__nav_3_4> <span class="md-nav__icon md-icon"></span> API </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../user-guide/API/narmax-base/ class=md-nav__link> <span class=md-ellipsis> NARMAX Base </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/API/ofr-base/ class=md-nav__link> <span class=md-ellipsis> OFR Base </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/API/basis-function/ class=md-nav__link> <span class=md-ellipsis> Basis Functions </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/API/frols/ class=md-nav__link> <span class=md-ellipsis> FROLS </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/API/metamss/ class=md-nav__link> <span class=md-ellipsis> MetaMSS </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/API/aols/ class=md-nav__link> <span class=md-ellipsis> AOLS </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/API/uofr/ class=md-nav__link> <span class=md-ellipsis> UOFR </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/API/entropic-regression/ class=md-nav__link> <span class=md-ellipsis> Entropic Regression </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/API/neural-narx/ class=md-nav__link> <span class=md-ellipsis> Neural NARX </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/API/general-estimators/ class=md-nav__link> <span class=md-ellipsis> General Estimators </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/API/parameter-estimation/ class=md-nav__link> <span class=md-ellipsis> Parameter Estimation </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/API/multiobjective-parameter-estimation/ class=md-nav__link> <span class=md-ellipsis> Multiobjective Parameter Estimation </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/API/simulation/ class=md-nav__link> <span class=md-ellipsis> Simulation </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/API/residues/ class=md-nav__link> <span class=md-ellipsis> Residual Analysis </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/API/metaheuristics/ class=md-nav__link> <span class=md-ellipsis> Metaheuristics </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/API/metrics/ class=md-nav__link> <span class=md-ellipsis> Metrics </span> </a> </li> <li class=md-nav__item> <a href=../../user-guide/API/utils/ class=md-nav__link> <span class=md-ellipsis> Utils </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4 checked> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex> <span class=md-ellipsis> Companion Book </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=true> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Companion Book </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../0-Preface/ class=md-nav__link> <span class=md-ellipsis> Preface </span> </a> </li> <li class=md-nav__item> <a href=../0.1-Contents/ class=md-nav__link> <span class=md-ellipsis> Contents </span> </a> </li> <li class=md-nav__item> <a href=../1-Introduction/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../2-NARMAX-Model-Representation/ class=md-nav__link> <span class=md-ellipsis> 2. NARMAX Model Representation </span> </a> </li> <li class=md-nav__item> <a href=../3-Parameter-Estimation/ class=md-nav__link> <span class=md-ellipsis> 3. Parameter Estimation </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> 4. Model Structure Selection </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> 4. Model Structure Selection </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#introduction class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=#the-forward-regression-orthogonal-least-squares-algorithm class=md-nav__link> <span class=md-ellipsis> The Forward Regression Orthogonal Least Squares Algorithm </span> </a> <nav class=md-nav aria-label="The Forward Regression Orthogonal Least Squares Algorithm"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#keep-it-simple class=md-nav__link> <span class=md-ellipsis> Keep it simple </span> </a> <nav class=md-nav aria-label="Keep it simple"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#orthogonal-case class=md-nav__link> <span class=md-ellipsis> Orthogonal case </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#case-study class=md-nav__link> <span class=md-ellipsis> Case Study </span> </a> </li> <li class=md-nav__item> <a href=#information-criteria class=md-nav__link> <span class=md-ellipsis> Information Criteria </span> </a> <nav class=md-nav aria-label="Information Criteria"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#overview-of-the-information-criteria-methods class=md-nav__link> <span class=md-ellipsis> Overview of the Information Criteria Methods </span> </a> <nav class=md-nav aria-label="Overview of the Information Criteria Methods"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#aic class=md-nav__link> <span class=md-ellipsis> AIC </span> </a> </li> <li class=md-nav__item> <a href=#aicc class=md-nav__link> <span class=md-ellipsis> AICc </span> </a> </li> <li class=md-nav__item> <a href=#bic class=md-nav__link> <span class=md-ellipsis> BIC </span> </a> </li> <li class=md-nav__item> <a href=#lilc class=md-nav__link> <span class=md-ellipsis> LILC </span> </a> </li> <li class=md-nav__item> <a href=#fpe class=md-nav__link> <span class=md-ellipsis> FPE </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#meta-model-structure-selection-metamss class=md-nav__link> <span class=md-ellipsis> Meta Model Structure Selection (MetaMSS) </span> </a> <nav class=md-nav aria-label="Meta Model Structure Selection (MetaMSS)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#meta-heuristics class=md-nav__link> <span class=md-ellipsis> Meta-heuristics </span> </a> <nav class=md-nav aria-label=Meta-heuristics> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-binary-hybrid-particle-swarm-optimization-and-gravitational-search-algorithm-bpsogsa-algorithm class=md-nav__link> <span class=md-ellipsis> The Binary hybrid Particle Swarm Optimization and Gravitational Search Algorithm (BPSOGSA) algorithm </span> </a> </li> <li class=md-nav__item> <a href=#standard-particle-swarm-optimization-pso class=md-nav__link> <span class=md-ellipsis> Standard Particle Swarm Optimization (PSO) </span> </a> </li> <li class=md-nav__item> <a href=#standard-gravitational-search-algorithm-gsa class=md-nav__link> <span class=md-ellipsis> Standard Gravitational Search Algorithm (GSA) </span> </a> </li> <li class=md-nav__item> <a href=#the-binary-hybrid-optimization-algorithm class=md-nav__link> <span class=md-ellipsis> The Binary Hybrid Optimization Algorithm </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#meta-model-structure-selection-metamss-building-narx-for-regression class=md-nav__link> <span class=md-ellipsis> Meta-Model Structure Selection (MetaMSS): Building NARX for Regression </span> </a> <nav class=md-nav aria-label="Meta-Model Structure Selection (MetaMSS): Building NARX for Regression"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#encoding-scheme class=md-nav__link> <span class=md-ellipsis> Encoding Scheme </span> </a> </li> <li class=md-nav__item> <a href=#formulation-of-the-objective-function class=md-nav__link> <span class=md-ellipsis> Formulation of the objective function </span> </a> </li> <li class=md-nav__item> <a href=#penalty-value-based-on-the-derivative-of-the-sigmoid-linear-unit-function class=md-nav__link> <span class=md-ellipsis> Penalty value based on the Derivative of the Sigmoid Linear Unit function </span> </a> </li> <li class=md-nav__item> <a href=#case-studies-simulation-results class=md-nav__link> <span class=md-ellipsis> Case Studies: Simulation Results </span> </a> </li> <li class=md-nav__item> <a href=#influence-of-the-max_iter-and-n_agents-parameters class=md-nav__link> <span class=md-ellipsis> Influence of the \(max\_iter\) and \(n\_agents\) parameters </span> </a> </li> <li class=md-nav__item> <a href=#selection-of-over-and-sub-parameterized-models class=md-nav__link> <span class=md-ellipsis> Selection of over and sub-parameterized models </span> </a> </li> <li class=md-nav__item> <a href=#selection-of-over-and-sub-parameterized-models_1 class=md-nav__link> <span class=md-ellipsis> Selection of over and sub-parameterized models </span> </a> </li> <li class=md-nav__item> <a href=#metamss-vs-frols class=md-nav__link> <span class=md-ellipsis> MetaMSS vs FROLS </span> </a> </li> <li class=md-nav__item> <a href=#meta-mss-vs-rjmcmc class=md-nav__link> <span class=md-ellipsis> Meta-MSS vs RJMCMC </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#metamss-algorithm-using-sysidentpy class=md-nav__link> <span class=md-ellipsis> MetaMSS algorithm using SysIdentPy </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#accelerated-orthogonal-least-squares-aols-and-entropic-regression-er class=md-nav__link> <span class=md-ellipsis> Accelerated Orthogonal Least Squares (AOLS) and Entropic Regression (ER) </span> </a> <nav class=md-nav aria-label="Accelerated Orthogonal Least Squares (AOLS) and Entropic Regression (ER)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#accelerated-orthogonal-least-squares class=md-nav__link> <span class=md-ellipsis> Accelerated Orthogonal Least Squares </span> </a> </li> <li class=md-nav__item> <a href=#entropic-regression class=md-nav__link> <span class=md-ellipsis> Entropic Regression </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../5-Multiobjective-Parameter-Estimation/ class=md-nav__link> <span class=md-ellipsis> 5. Multiobjective Parameter Estimation </span> </a> </li> <li class=md-nav__item> <a href=../6-Multiobjective-Model-Structure-Selection/ class=md-nav__link> <span class=md-ellipsis> 6. Multiobjective Model Structure Selection </span> </a> </li> <li class=md-nav__item> <a href=../7-NARX-Neural-Network/ class=md-nav__link> <span class=md-ellipsis> 7. NARX Neural Network </span> </a> </li> <li class=md-nav__item> <a href=../8-Severely-Nonlinear-System-Identification/ class=md-nav__link> <span class=md-ellipsis> 8. Severely Nonlinear System Identification </span> </a> </li> <li class=md-nav__item> <a href=../9-Validation/ class=md-nav__link> <span class=md-ellipsis> 9. Validation </span> </a> </li> <li class=md-nav__item> <a href=../10-Case-Studies/ class=md-nav__link> <span class=md-ellipsis> 10. Case Studies </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> Developer guide </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Developer guide </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../developer-guide/contribute/ class=md-nav__link> <span class=md-ellipsis> How to contribute </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_2> <label class=md-nav__link for=__nav_5_2 id=__nav_5_2_label tabindex=0> <span class=md-ellipsis> Documentation </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_2_label aria-expanded=false> <label class=md-nav__title for=__nav_5_2> <span class="md-nav__icon md-icon"></span> Documentation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../developer-guide/documentation-overview/ class=md-nav__link> <span class=md-ellipsis> Documentation Overview </span> </a> </li> <li class=md-nav__item> <a href=../../developer-guide/how-to-write-a-tutorial/ class=md-nav__link> <span class=md-ellipsis> How To Write a Tutorial </span> </a> </li> <li class=md-nav__item> <a href=../../developer-guide/how-to-write-a-how-to-guide/ class=md-nav__link> <span class=md-ellipsis> How To Write a How-to Guide </span> </a> </li> <li class=md-nav__item> <a href=../../developer-guide/how-to-add-a-translation/ class=md-nav__link> <span class=md-ellipsis> How to Add a Translation </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> Community & Support </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Community & Support </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../community-support/community-overview/ class=md-nav__link> <span class=md-ellipsis> community-overview </span> </a> </li> <li class=md-nav__item> <a href=../../community-support/get-help/ class=md-nav__link> <span class=md-ellipsis> Get Help </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_3> <label class=md-nav__link for=__nav_6_3 id=__nav_6_3_label tabindex=0> <span class=md-ellipsis> Meetups </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_3_label aria-expanded=false> <label class=md-nav__title for=__nav_6_3> <span class="md-nav__icon md-icon"></span> Meetups </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../community-support/meetups/ai-networks-meetup/ class=md-nav__link> <span class=md-ellipsis> AI Networks Meetup </span> </a> </li> <li class=md-nav__item> <a href=../../community-support/meetups/nubank-meetup/ class=md-nav__link> <span class=md-ellipsis> Nubank Timeseries Meetup </span> </a> </li> <li class=md-nav__item> <a href=../../community-support/meetups/nubank-meetup-open-source/ class=md-nav__link> <span class=md-ellipsis> Nubank Open Source Talk </span> </a> </li> <li class=md-nav__item> <a href=../../community-support/meetups/gcom-meetup/ class=md-nav__link> <span class=md-ellipsis> GCoM Meetup </span> </a> </li> <li class=md-nav__item> <a href=../../community-support/meetups/estatidados/ class=md-nav__link> <span class=md-ellipsis> Estatidados Meetup </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../landing-page/about-us/ class=md-nav__link> <span class=md-ellipsis> About </span> </a> </li> <li class=md-nav__item> <a href=../../changelog/changelog/ class=md-nav__link> <span class=md-ellipsis> Changelog </span> </a> </li> <li class=md-nav__item> <a href=../../landing-page/sponsor/ class=md-nav__link> <span class=md-ellipsis> Sponsors </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#introduction class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=#the-forward-regression-orthogonal-least-squares-algorithm class=md-nav__link> <span class=md-ellipsis> The Forward Regression Orthogonal Least Squares Algorithm </span> </a> <nav class=md-nav aria-label="The Forward Regression Orthogonal Least Squares Algorithm"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#keep-it-simple class=md-nav__link> <span class=md-ellipsis> Keep it simple </span> </a> <nav class=md-nav aria-label="Keep it simple"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#orthogonal-case class=md-nav__link> <span class=md-ellipsis> Orthogonal case </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#case-study class=md-nav__link> <span class=md-ellipsis> Case Study </span> </a> </li> <li class=md-nav__item> <a href=#information-criteria class=md-nav__link> <span class=md-ellipsis> Information Criteria </span> </a> <nav class=md-nav aria-label="Information Criteria"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#overview-of-the-information-criteria-methods class=md-nav__link> <span class=md-ellipsis> Overview of the Information Criteria Methods </span> </a> <nav class=md-nav aria-label="Overview of the Information Criteria Methods"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#aic class=md-nav__link> <span class=md-ellipsis> AIC </span> </a> </li> <li class=md-nav__item> <a href=#aicc class=md-nav__link> <span class=md-ellipsis> AICc </span> </a> </li> <li class=md-nav__item> <a href=#bic class=md-nav__link> <span class=md-ellipsis> BIC </span> </a> </li> <li class=md-nav__item> <a href=#lilc class=md-nav__link> <span class=md-ellipsis> LILC </span> </a> </li> <li class=md-nav__item> <a href=#fpe class=md-nav__link> <span class=md-ellipsis> FPE </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#meta-model-structure-selection-metamss class=md-nav__link> <span class=md-ellipsis> Meta Model Structure Selection (MetaMSS) </span> </a> <nav class=md-nav aria-label="Meta Model Structure Selection (MetaMSS)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#meta-heuristics class=md-nav__link> <span class=md-ellipsis> Meta-heuristics </span> </a> <nav class=md-nav aria-label=Meta-heuristics> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-binary-hybrid-particle-swarm-optimization-and-gravitational-search-algorithm-bpsogsa-algorithm class=md-nav__link> <span class=md-ellipsis> The Binary hybrid Particle Swarm Optimization and Gravitational Search Algorithm (BPSOGSA) algorithm </span> </a> </li> <li class=md-nav__item> <a href=#standard-particle-swarm-optimization-pso class=md-nav__link> <span class=md-ellipsis> Standard Particle Swarm Optimization (PSO) </span> </a> </li> <li class=md-nav__item> <a href=#standard-gravitational-search-algorithm-gsa class=md-nav__link> <span class=md-ellipsis> Standard Gravitational Search Algorithm (GSA) </span> </a> </li> <li class=md-nav__item> <a href=#the-binary-hybrid-optimization-algorithm class=md-nav__link> <span class=md-ellipsis> The Binary Hybrid Optimization Algorithm </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#meta-model-structure-selection-metamss-building-narx-for-regression class=md-nav__link> <span class=md-ellipsis> Meta-Model Structure Selection (MetaMSS): Building NARX for Regression </span> </a> <nav class=md-nav aria-label="Meta-Model Structure Selection (MetaMSS): Building NARX for Regression"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#encoding-scheme class=md-nav__link> <span class=md-ellipsis> Encoding Scheme </span> </a> </li> <li class=md-nav__item> <a href=#formulation-of-the-objective-function class=md-nav__link> <span class=md-ellipsis> Formulation of the objective function </span> </a> </li> <li class=md-nav__item> <a href=#penalty-value-based-on-the-derivative-of-the-sigmoid-linear-unit-function class=md-nav__link> <span class=md-ellipsis> Penalty value based on the Derivative of the Sigmoid Linear Unit function </span> </a> </li> <li class=md-nav__item> <a href=#case-studies-simulation-results class=md-nav__link> <span class=md-ellipsis> Case Studies: Simulation Results </span> </a> </li> <li class=md-nav__item> <a href=#influence-of-the-max_iter-and-n_agents-parameters class=md-nav__link> <span class=md-ellipsis> Influence of the \(max\_iter\) and \(n\_agents\) parameters </span> </a> </li> <li class=md-nav__item> <a href=#selection-of-over-and-sub-parameterized-models class=md-nav__link> <span class=md-ellipsis> Selection of over and sub-parameterized models </span> </a> </li> <li class=md-nav__item> <a href=#selection-of-over-and-sub-parameterized-models_1 class=md-nav__link> <span class=md-ellipsis> Selection of over and sub-parameterized models </span> </a> </li> <li class=md-nav__item> <a href=#metamss-vs-frols class=md-nav__link> <span class=md-ellipsis> MetaMSS vs FROLS </span> </a> </li> <li class=md-nav__item> <a href=#meta-mss-vs-rjmcmc class=md-nav__link> <span class=md-ellipsis> Meta-MSS vs RJMCMC </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#metamss-algorithm-using-sysidentpy class=md-nav__link> <span class=md-ellipsis> MetaMSS algorithm using SysIdentPy </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#accelerated-orthogonal-least-squares-aols-and-entropic-regression-er class=md-nav__link> <span class=md-ellipsis> Accelerated Orthogonal Least Squares (AOLS) and Entropic Regression (ER) </span> </a> <nav class=md-nav aria-label="Accelerated Orthogonal Least Squares (AOLS) and Entropic Regression (ER)"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#accelerated-orthogonal-least-squares class=md-nav__link> <span class=md-ellipsis> Accelerated Orthogonal Least Squares </span> </a> </li> <li class=md-nav__item> <a href=#entropic-regression class=md-nav__link> <span class=md-ellipsis> Entropic Regression </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/wilsonrljr/sysidentpy/edit/main/docs/en/book/4-Model-Structure-Selection.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/wilsonrljr/sysidentpy/raw/main/docs/en/book/4-Model-Structure-Selection.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <h1>4. Model Structure Selection</h1> <h2 id=introduction>Introduction<a class=headerlink href=#introduction title="Permanent link">&para;</a></h2> <blockquote> <p>This section is taken mainly from my master thesis, which was based on <a href=https://www.wiley.com/en-us/Nonlinear+System+Identification%3A+NARMAX+Methods+in+the+Time%2C+Frequency%2C+and+Spatio-Temporal+Domains-p-9781119943594>Billings, S. A</a>.</p> </blockquote> <p>Selecting the model structure is crucial to develop models that can correctly reproduce the system behavior. If some prior information about the system are known, e.g., the dynamic order and degree of nonlinearity, determining the terms and then estimate the parameters is trivial. In real life scenarios, however, usually there is no information about what terms should be included in the model and the correct regressors has to be selected in the identification framework. If the MSS is not performed with the necessary concerns, the scientific law that describes the system may will not be revealed and resulting in misleading interpretations about the system. To illustrate this scenario, consider the following example.</p> <p>Let <span class=arithmatex>\(\mathcal{D}\)</span> denote an arbitrary dataset</p> <div class=arithmatex>\[ \begin{equation} \mathcal{D} = \{(x_k, y_k), k = 1, 2, \dotsc, n\}, \end{equation} \tag{1} \]</div> <p>where <span class=arithmatex>\(x_k \in \mathbb{R}^{n_x}\)</span> and <span class=arithmatex>\(y_k\in \mathbb{R}^{n_y}\)</span> are the input and output of an unknown system and <span class=arithmatex>\(n\)</span> is the number of samples in the dataset. The following are two polynomial NARX models built to describe that system:</p> <div class=arithmatex>\[ \begin{align} y_{ak} &amp;= 0.7077y_{ak-1} + 0.1642u_{k-1} + 0.1280u_{k-2} \end{align} \tag{2} \]</div> <div class=arithmatex>\[ \begin{align} y_{bk} &amp;= 0.7103y_{bk-1} + 0.1458u_{k-1} + 0.1631u_{k-2} \\ &amp;\quad - 1467y_{bk-1}^3 + 0.0710y_{bk-2}^3 + 0.0554y_{bk-3}^2u_{k-3}. \end{align} \tag{3} \]</div> <p>Figure 1 shows the predicted values of each model and the real data. As can be observed, the nonlinear model 2 seems to fit the data better than the linear model 1. The original system under consideration is an RLC circuit, consisting of a resistor (R), inductor (L), and capacitor (C) connected in series with a voltage source. It is well known that the behavior of such an RLC series circuit can be accurately described by a linear second-order differential equation that relates the current <span class=arithmatex>\(I(t)\)</span> and the applied voltage <span class=arithmatex>\(V(t)\)</span>:</p> <div class=arithmatex>\[ L\frac{d^2I(t)}{dt^2} + R\frac{dI(t)}{dt} + \frac{1}{C}I(t) = \frac{dV(t)}{dt} \tag{4} \]</div> <p>Given this linear relationship, an adequate model for the RLC circuit should reflect this second-order linearity. While Model 2, which includes nonlinear terms, may provide a closer fit to the data, it is clearly over-parameterized. Such over-parameterization can introduce spurious nonlinear effects, often referred to as "ghost" nonlinearities, which do not correspond to the actual dynamics of the system. Therefore, these models need to be interpreted with caution, as the use of an overly complex model could obscure the true linear nature of the system and lead to incorrect conclusions about its behavior.</p> <p><a class=glightbox href="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/rlc.png?raw=true" data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/rlc.png?raw=true"></a></p> <blockquote> <p>Figure 1.Results for two polynomial NARX models fitted to data from an unknown system. Model 1 (left) is a linear model, while Model 2 (right) includes nonlinear terms. The figure illustrates that Model 2 provides a closer fit to the data compared to Model 1. However, since the original system is a linear RLC circuit known to have a second-order linear behavior, the improved fit of Model 2 may be misleading due to over-parameterization. This highlights the importance of considering the physical characteristics of the system when interpreting model results to avoid misinterpretation of artificial nonlinearities. Reference: <a href=https://ufsj.edu.br/portal2-repositorio/File/ppgel/225-2020-02-17-DissertacaoWilsonLacerda.pdf>Meta Model Structure Selection: An Algorithm For Building Polynomial NARX Models For Regression And Classification</a></p> </blockquote> <p>Correctly identifying the structure of a model is crucial for accurately analyzing the system's dynamics. A well-chosen model structure ensures that the model reflects the true behavior of the system, allowing for consistent and meaningful analysis. In this respect, several algorithms have been developed to select the appropriate terms for constructing a polynomial NARX model. The primary goal of model structure selection (MSS) algorithms is to reveal the system's characteristics by producing the simplest model that adequately describes the data. While some systems may indeed require more complex models, it is essential to strike a balance between simplicity and accuracy. As Einstein aptly put it:</p> <blockquote> <p>A model should be as simple as possible, but not simpler.</p> </blockquote> <p>This principle emphasizes the importance of avoiding unnecessary complexity while ensuring that the model still captures the essential dynamics of the system.</p> <p>We see at chapter 2 that regressors selection, however, is not a simple task. If the nonlinear degree, the order of the model and the number inputs increases, the number of candidate models becomes too large for brute force approach. Considering the MIMO case, this problem is far worse than the SISO one if many inputs and outputs are required. The number of all different models can be calculated as</p> <div class=arithmatex>\[ \begin{align} n_m = \begin{cases} 2^{n_r} &amp; \text{for SISO models}, \\ 2^{n_{{_{m}}r}} &amp; \text{for MIMO models}, \end{cases} \end{align} \tag{5} \]</div> <p>where <span class=arithmatex>\(n_r\)</span> and <span class=arithmatex>\(n_{{_{m}}r}\)</span> are the values computed using the equations presented in Chapter 2.</p> <p>A classical solution to regressors selection problem is the Forward Regression Orthogonal Least Squares (FROLS) algorithm associated with Error Reduction Ratio (ERR) algorithm. This technique is based on the Prediction Error Minimization framework and, one at time, select the most relevant regressor by using a step-wise regression. The FROLS method adapt the set of regressors in the search space into a set of orthogonal vectors, which ERR evaluates the individual contribution to the desired output variance.</p> <h2 id=the-forward-regression-orthogonal-least-squares-algorithm>The Forward Regression Orthogonal Least Squares Algorithm<a class=headerlink href=#the-forward-regression-orthogonal-least-squares-algorithm title="Permanent link">&para;</a></h2> <p>Consider the general NARMAX model defined in Equation 2.23 described in a generic form as</p> <div class=arithmatex>\[ \begin{equation} y_k = \psi^\top_{k-1}\hat{\Theta} + \xi_k, \end{equation} \tag{6} \]</div> <p>where <span class=arithmatex>\(\psi^\top_{k-1} \in \mathbb{R}^{n_r \times n}\)</span> is a vector of some combinations of the regressors and <span class=arithmatex>\(\hat{\Theta} \in \mathbb{R}^{n_{\Theta}}\)</span> the vector of estimated parameters. In a more compact form, the NARMAX model can be represented in a matrix form as:</p> <div class=arithmatex>\[ \begin{equation} y = \Psi\hat{\Theta} + \Xi, \end{equation} \tag{7} \]</div> <p>where</p> <div class=arithmatex>\[ \begin{align} Y = \begin{bmatrix} y_1 \\ y_2 \\ \vdots \\ y_n \end{bmatrix}, \Psi = \begin{bmatrix} \psi_{{_1}} \\ \psi_{{_2}} \\ \vdots \\ \psi_{{_{n_{\Theta}}}} \end{bmatrix}^\top= \begin{bmatrix} \psi_{{_1}1} &amp; \psi_{{_2}1} &amp; \dots &amp; \psi_{{_{n_{\Theta}}}1} \\ \psi_{{_1}2} &amp; \psi_{{_2}2} &amp; \dots &amp; \psi_{{_{n_{\Theta}}}2} \\ \vdots &amp; \vdots &amp; &amp; \vdots \\ \psi_{{_1}n} &amp; \psi_{{_2}n} &amp; \dots &amp; \psi_{{_{n_{\Theta}}}n} \\ \end{bmatrix}, \hat{\Theta} = \begin{bmatrix} \hat{\Theta}_1 \\ \hat{\Theta}_2 \\ \vdots \\ \hat{\Theta}_{n_\Theta} \end{bmatrix}, \Xi = \begin{bmatrix} \xi_1 \\ \xi_2 \\ \vdots \\ \xi_n \end{bmatrix}. \end{align} \tag{8} \]</div> <p>The parameters in equation above could be estimated as a result of a Least Squares-based algorithm, but this would require to optimize all parameters at the same time on account of the fact of interaction between regressors due to non-orthogonality characteristic. Consequently, the computational demand becomes impractical for high number of regressors. In this respect, the FROLS transforms the non-orthogonal model presented in the equation above into a orthogonal one.</p> <p>The regressor matrix <span class=arithmatex>\(\Psi\)</span> can be orthogonally decomposed as</p> <div class=arithmatex>\[ \begin{equation} \Psi = QA, \end{equation} \tag{9} \]</div> <p>where <span class=arithmatex>\(A \in \mathbb{R}^{n_{\Theta}\times n_{\Theta}}\)</span> is an unit upper triangular matrix according to</p> <div class=arithmatex>\[ \begin{align} A = \begin{bmatrix} 1 &amp; a_{12} &amp; a_{13} &amp; \dotsc &amp; a_{1n_{\Theta}} \\ 0 &amp; 1 &amp; a_{23} &amp; \dotsc &amp; a_{2n_{\Theta}} \\ 0 &amp; 0 &amp; 1 &amp; \dotsc &amp; \vdots \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; a_{n_{\Theta}-1n_{\Theta}} \\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix}, \end{align} \tag{10} \]</div> <p>and <span class=arithmatex>\(Q \in \mathbb{R}^{n\times n_{\Theta}}\)</span> is a matrix with orthogonal columns <span class=arithmatex>\(q_i\)</span>, described as</p> <div class=arithmatex>\[ \begin{equation} Q = \begin{bmatrix} q_{{_1}} &amp; q_{{_2}} &amp; q_{{_3}} &amp; \dotsc &amp; q_{{_{n_{\Theta}}}} \end{bmatrix}, \end{equation} \tag{11} \]</div> <p>such that <span class=arithmatex>\(Q^\top Q = \Lambda\)</span> and <span class=arithmatex>\(\Lambda\)</span> is diagonal with entry <span class=arithmatex>\(d_i\)</span> and can be expressed as:</p> <div class=arithmatex>\[ \begin{align} d_i = q_i^\top q_i = \sum^{k=1}_{n}q_{{_i}k}q_{{_i}k}, \qquad 1\leq i \leq n_{\Theta}. \end{align} \]</div> <p>Because the space spanned by the orthogonal basis <span class=arithmatex>\(Q\)</span> (Equation 11) is the same as that spanned by the basis set <span class=arithmatex>\(\Psi\)</span> (Equation 8) (i.e, contains every linear combination of elements of such subspace), we can define the Equation 7 as</p> <div class=arithmatex>\[ \begin{equation} Y = \underbrace{(\Psi A^{-1})}_{Q}\underbrace{(A\Theta)}_{g}+ \Xi = Qg+\Xi, \end{equation} \tag{12} \]</div> <p>where <span class=arithmatex>\(g\in \mathbb{R}^{n_\Theta}\)</span> is an auxiliary parameter vector. The solution of the model described in Equation 12 is given by</p> <div class=arithmatex>\[ \begin{equation} g = \left(Q^\top Q\right)^{-1}Q^\top Y = \Lambda^{-1}Q^\top Y \end{equation} \tag{13} \]</div> <p>or</p> <div class=arithmatex>\[ \begin{equation} g_{{_i}} = \frac{q_{{_i}}^\top Y}{q_{{_i}}^\top q_{{_i}}}. \end{equation} \tag{14} \]</div> <p>Since the parameter <span class=arithmatex>\(\Theta\)</span> and <span class=arithmatex>\(g\)</span> satisfies the triangular system <span class=arithmatex>\(A\Theta = g\)</span>, any orthogonalization method like Householder, Gram-Schmidt, modified Gram-Schmidt or Givens transformations can be used to solve the equation and estimate the original parameters. Assuming that <span class=arithmatex>\(E[\Psi^\top \Xi] = 0\)</span>, the output variance can be derived by multiplying Equation 12 with itself and dividing by <span class=arithmatex>\(n\)</span>, resulting in</p> <div class=arithmatex>\[ \begin{equation} \frac{1}{n}Y^\top Y = \underbrace{\frac{1}{n}\sum^{i = 1}_{n_{\Theta}}g_{{_i}}^2q^\top_{{_i}}q_{{_i}}}_{\text{{output explained by the regressors}}} + \underbrace{\frac{1}{n}\Xi^\top \Xi}_{\text{{unexplained variance}}}. \end{equation} \tag{15} \]</div> <p>Thus, the ERR due to the inclusion of the regressor <span class=arithmatex>\(q_{{_i}}\)</span> is expressed as:</p> <div class=arithmatex>\[ [\text{ERR}]_i = \frac{g_{i}^2 \cdot q_{i}^\top q_{i}}{Y^\top Y}, \qquad \text{for } i=1,2,\dotsc, n_\Theta. \]</div> <p>There are many ways to terminate the algorithm. An approach often used is stop the algorithm if the model output variance drops below some predetermined limit <span class=arithmatex>\(\varepsilon\)</span>:</p> <div class=arithmatex>\[ \begin{equation} 1 - \sum_{i = 1}^{n_{\Theta}}\text{ERR}_i \leq \varepsilon, \end{equation} \tag{17} \]</div> <h3 id=keep-it-simple>Keep it simple<a class=headerlink href=#keep-it-simple title="Permanent link">&para;</a></h3> <p>For the sake of simplicity, let's present the FROLS along with simple examples to make the intuition clear. First, let define the ERR calculation and then explain the idea of the FROLS in simple terms.</p> <h4 id=orthogonal-case>Orthogonal case<a class=headerlink href=#orthogonal-case title="Permanent link">&para;</a></h4> <p>Consider the case where we have a set of inputs defined as <span class=arithmatex>\(x_1, x_2, \ldots, x_n\)</span> and an output called <span class=arithmatex>\(y\)</span>. These inputs are orthogonal vectors.</p> <p>Lets suppose that we want to create a model to approximate <span class=arithmatex>\(y\)</span> using <span class=arithmatex>\(x_1, x_2, \ldots, x_n\)</span>, as follows:</p> <div class=arithmatex>\[ y=\hat{\theta}_1 x_1+\hat{\theta}_2 x_2+\ldots+\hat{\theta}_n x_n+e \tag{18} \]</div> <p>where <span class=arithmatex>\(\hat{\theta}_1, \hat{\theta}_2, \ldots, \hat{\theta}_n\)</span> are parameters and <span class=arithmatex>\(e\)</span> is white noise and independent of <span class=arithmatex>\(x\)</span> and <span class=arithmatex>\(y\)</span> (remember the <span class=arithmatex>\(E[\Psi^\top \Xi] = 0\)</span>, in previous section). In this case, we can rewrite the equation above as</p> <div class=arithmatex>\[ y = \hat{\theta} x \tag{19} \]</div> <p>so</p> <div class=arithmatex>\[ \left\langle x, y\right\rangle = \left\langle \hat{\theta} x, x\right\rangle = \hat{\theta} \left\langle x, x\right\rangle \tag{20} \]</div> <p>Which implies that</p> <div class=arithmatex>\[ \hat{\theta} = \frac{\left\langle x, y\right\rangle}{\left\langle x, x\right\rangle} \tag{21} \]</div> <p>Therefore we can show that</p> <div class=arithmatex>\[ \begin{align} &amp; \left\langle x_1, y\right\rangle=\hat{\theta}_1\left\langle x_1, x_1\right\rangle \Rightarrow \hat{\theta}_1=\frac{\left\langle x_1, y\right\rangle}{\left\langle x_1, x_1\right\rangle}=\frac{x_1^T y}{x_1^T x_1} \\ &amp; \left\langle x_2, y\right\rangle=\hat{\theta}_2\left\langle x_2, x_2\right\rangle \Rightarrow \hat{\theta}_2=\frac{\left\langle x_2, y\right\rangle}{\left\langle x_2, x_2\right\rangle}=\frac{x_2^T y}{x_2^T x_2}, \ldots \\ &amp; \left\langle x_n, y\right\rangle=\hat{\theta}_n\left\langle x_n, x_n\right\rangle \Rightarrow \hat{\theta}_n=\frac{\left\langle x_n, y\right\rangle}{\left\langle x_n, x_n\right\rangle}=\frac{x_n^T y}{x_n^T x_n}, \end{align} \tag{22} \]</div> <p>Following the same idea, we can also show that</p> <div class=arithmatex>\[ \langle y, y\rangle=\hat{\theta}_1^2\left\langle x_1, x_1\right\rangle+\hat{\theta}_2^2\left\langle x_2, x_2\right\rangle+\ldots+\hat{\theta}_n^2\left\langle x_n, x_n\right\rangle+\langle e, e\rangle \tag{23} \]</div> <p>which can be described as</p> <div class=arithmatex>\[ y^T y=\hat{\theta}_1^2 x_1^T x_1+\hat{\theta}_2^2 x_2^T x_2+\ldots+\hat{\theta}_n^2 x_n^T x_n+e^T e \tag{24} \]</div> <p>or</p> <div class=arithmatex>\[ \|y\|^2=\hat{\theta}_1^2\left\|x_1\right\|^2+\hat{\theta}_2^2\left\|x_2\right\|^2+\ldots+\hat{\theta}_n^2\left\|x_n\right\|^2+\|e\|^2 \tag{25} \]</div> <p>So, dividing both sides of the equation by <span class=arithmatex>\(y\)</span> and rearranging the equation, we have</p> <div class=arithmatex>\[ \frac{\|e\|^2}{\|y\|^2}=1-\hat{\theta}_1^2 \frac{\left\|x_1\right\|^2}{\|y\|^2}-\hat{\theta}_2^2 \frac{\left\|x_2\right\|^2}{\|y\|^2}-\ldots-\hat{\theta}_n^2 \frac{\left\|x_n\right\|^2}{\|y\|^2} \tag{26} \]</div> <p>Because <span class=arithmatex>\(\hat{\theta}_k=\frac{x_k^T y}{x_k^T x_k}=\frac{x_k^T y}{\left\|x_k\right\|^2}, k=1,2, . ., n\)</span>, we have</p> <div class=arithmatex>\[ \begin{align} \frac{\|e\|^2}{\|y\|^2} &amp; =1-\left(\frac{x_1^T y}{\left\|x_1\right\|^2}\right)^2 \frac{\left\|x_1\right\|^2}{\|y\|^2}-\left(\frac{x_2^T y}{\left\|x_2\right\|^2}\right)^2 \frac{\left\|x_2\right\|^2}{\|y\|^2}-\ldots-\left(\frac{x_n^T y}{\left\|x_n\right\|^2}\right)^2 \frac{\left\|x_n\right\|^2}{\|y\|^2} \\ &amp; =1-\frac{\left(x_1^T y\right)^2}{\left\|x_1\right\|\left\|^2\right\| y \|^2}-\frac{\left(x_2^T y\right)^2}{\left\|x_2\right\|^2\|y\|^2}-\cdots-\frac{\left(x_n^T y\right)^2}{\left\|x_n\right\|^2\|y\|^2} \\ &amp; =1-ERR_1 \quad-ERR_2-\cdots-ERR_n \end{align} \tag{27} \]</div> <p>where <span class=arithmatex>\(\operatorname{ERR}_k(k=1,2 \ldots, n)\)</span> is the Error Reduction Ratio defined in previous section.</p> <p>Check the example bellow using the fundamental basis</p> <div class=highlight><pre><span></span><code><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a>
<a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=n>y</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>3</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>])</span>
<a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=c1># Orthogonal Basis</span>
<a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=n>x1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>])</span>
<a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a><span class=n>x2</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>])</span>
<a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a><span class=n>x3</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>])</span>
<a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>
<a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a><span class=n>theta1</span> <span class=o>=</span> <span class=p>(</span><span class=n>x1</span><span class=o>.</span><span class=n>T</span><span class=nd>@y</span><span class=p>)</span><span class=o>/</span><span class=p>(</span><span class=n>x1</span><span class=o>.</span><span class=n>T</span><span class=nd>@x1</span><span class=p>)</span>
<a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a><span class=n>theta2</span> <span class=o>=</span> <span class=p>(</span><span class=n>x2</span><span class=o>.</span><span class=n>T</span><span class=nd>@y</span><span class=p>)</span><span class=o>/</span><span class=p>(</span><span class=n>x2</span><span class=o>.</span><span class=n>T</span><span class=nd>@x2</span><span class=p>)</span>
<a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a><span class=n>theta3</span> <span class=o>=</span> <span class=p>(</span><span class=n>x3</span><span class=o>.</span><span class=n>T</span><span class=nd>@y</span><span class=p>)</span><span class=o>/</span><span class=p>(</span><span class=n>x3</span><span class=o>.</span><span class=n>T</span><span class=nd>@x3</span><span class=p>)</span>
<a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a>
<a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a><span class=n>squared_y</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>y</span>
<a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a><span class=n>err1</span> <span class=o>=</span> <span class=p>(</span><span class=n>x1</span><span class=o>.</span><span class=n>T</span><span class=nd>@y</span><span class=p>)</span><span class=o>**</span><span class=mi>2</span><span class=o>/</span><span class=p>((</span><span class=n>x1</span><span class=o>.</span><span class=n>T</span><span class=nd>@x1</span><span class=p>)</span> <span class=o>*</span> <span class=n>squared_y</span><span class=p>)</span>
<a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a><span class=n>err2</span> <span class=o>=</span> <span class=p>(</span><span class=n>x2</span><span class=o>.</span><span class=n>T</span><span class=nd>@y</span><span class=p>)</span><span class=o>**</span><span class=mi>2</span><span class=o>/</span><span class=p>((</span><span class=n>x2</span><span class=o>.</span><span class=n>T</span><span class=nd>@x2</span><span class=p>)</span> <span class=o>*</span> <span class=n>squared_y</span><span class=p>)</span>
<a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a><span class=n>err3</span> <span class=o>=</span> <span class=p>(</span><span class=n>x3</span><span class=o>.</span><span class=n>T</span><span class=nd>@y</span><span class=p>)</span><span class=o>**</span><span class=mi>2</span><span class=o>/</span><span class=p>((</span><span class=n>x3</span><span class=o>.</span><span class=n>T</span><span class=nd>@x3</span><span class=p>)</span> <span class=o>*</span> <span class=n>squared_y</span><span class=p>)</span>
<a id=__codelineno-0-17 name=__codelineno-0-17 href=#__codelineno-0-17></a>
<a id=__codelineno-0-18 name=__codelineno-0-18 href=#__codelineno-0-18></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;x1 represents </span><span class=si>{</span><span class=nb>round</span><span class=p>(</span><span class=n>err1</span><span class=o>*</span><span class=mi>100</span><span class=p>,</span><span class=w> </span><span class=mi>2</span><span class=p>)</span><span class=si>}</span><span class=s2>% of the variation in y, </span><span class=se>\n</span><span class=s2> x2 represents </span><span class=si>{</span><span class=nb>round</span><span class=p>(</span><span class=n>err2</span><span class=o>*</span><span class=mi>100</span><span class=p>,</span><span class=w> </span><span class=mi>2</span><span class=p>)</span><span class=si>}</span><span class=s2>% of the variation in y, </span><span class=se>\n</span><span class=s2> x3 represents </span><span class=si>{</span><span class=nb>round</span><span class=p>(</span><span class=n>err3</span><span class=o>*</span><span class=mi>100</span><span class=p>,</span><span class=w> </span><span class=mi>2</span><span class=p>)</span><span class=si>}</span><span class=s2>% of the variation in y&quot;</span><span class=p>)</span>
<a id=__codelineno-0-19 name=__codelineno-0-19 href=#__codelineno-0-19></a>
<a id=__codelineno-0-20 name=__codelineno-0-20 href=#__codelineno-0-20></a><span class=n>x1</span> <span class=n>represents</span> <span class=mf>7.38</span><span class=o>%</span> <span class=n>of</span> <span class=n>the</span> <span class=n>variation</span> <span class=ow>in</span> <span class=n>y</span><span class=p>,</span>
<a id=__codelineno-0-21 name=__codelineno-0-21 href=#__codelineno-0-21></a><span class=n>x2</span> <span class=n>represents</span> <span class=mf>40.16</span><span class=o>%</span> <span class=n>of</span> <span class=n>the</span> <span class=n>variation</span> <span class=ow>in</span> <span class=n>y</span><span class=p>,</span>
<a id=__codelineno-0-22 name=__codelineno-0-22 href=#__codelineno-0-22></a><span class=n>x3</span> <span class=n>represents</span> <span class=mf>52.46</span><span class=o>%</span> <span class=n>of</span> <span class=n>the</span> <span class=n>variation</span> <span class=ow>in</span> <span class=n>y</span>
</code></pre></div> <p>Lets see what happens in a non-orthogonal scenario.</p> <p><div class=highlight><pre><span></span><code><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=n>y</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>3</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>])</span>
<a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=n>x1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>])</span>
<a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a><span class=n>x2</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>])</span>
<a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a><span class=n>x3</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>])</span>
<a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a>
<a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a><span class=n>theta1</span> <span class=o>=</span> <span class=p>(</span><span class=n>x1</span><span class=o>.</span><span class=n>T</span><span class=nd>@y</span><span class=p>)</span><span class=o>/</span><span class=p>(</span><span class=n>x1</span><span class=o>.</span><span class=n>T</span><span class=nd>@x1</span><span class=p>)</span>
<a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a><span class=n>theta2</span> <span class=o>=</span> <span class=p>(</span><span class=n>x2</span><span class=o>.</span><span class=n>T</span><span class=nd>@y</span><span class=p>)</span><span class=o>/</span><span class=p>(</span><span class=n>x2</span><span class=o>.</span><span class=n>T</span><span class=nd>@x2</span><span class=p>)</span>
<a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a><span class=n>theta3</span> <span class=o>=</span> <span class=p>(</span><span class=n>x3</span><span class=o>.</span><span class=n>T</span><span class=nd>@y</span><span class=p>)</span><span class=o>/</span><span class=p>(</span><span class=n>x3</span><span class=o>.</span><span class=n>T</span><span class=nd>@x3</span><span class=p>)</span>
<a id=__codelineno-1-9 name=__codelineno-1-9 href=#__codelineno-1-9></a>
<a id=__codelineno-1-10 name=__codelineno-1-10 href=#__codelineno-1-10></a><span class=n>squared_y</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>y</span>
<a id=__codelineno-1-11 name=__codelineno-1-11 href=#__codelineno-1-11></a><span class=n>err1</span> <span class=o>=</span> <span class=p>(</span><span class=n>x1</span><span class=o>.</span><span class=n>T</span><span class=nd>@y</span><span class=p>)</span><span class=o>**</span><span class=mi>2</span><span class=o>/</span><span class=p>((</span><span class=n>x1</span><span class=o>.</span><span class=n>T</span><span class=nd>@x1</span><span class=p>)</span> <span class=o>*</span> <span class=n>squared_y</span><span class=p>)</span>
<a id=__codelineno-1-12 name=__codelineno-1-12 href=#__codelineno-1-12></a><span class=n>err2</span> <span class=o>=</span> <span class=p>(</span><span class=n>x2</span><span class=o>.</span><span class=n>T</span><span class=nd>@y</span><span class=p>)</span><span class=o>/</span><span class=p>((</span><span class=n>x2</span><span class=o>.</span><span class=n>T</span><span class=nd>@x2</span><span class=p>)</span> <span class=o>*</span> <span class=n>squared_y</span><span class=p>)</span>
<a id=__codelineno-1-13 name=__codelineno-1-13 href=#__codelineno-1-13></a><span class=n>err3</span> <span class=o>=</span> <span class=p>(</span><span class=n>x3</span><span class=o>.</span><span class=n>T</span><span class=nd>@y</span><span class=p>)</span><span class=o>**</span><span class=mi>2</span><span class=o>/</span><span class=p>((</span><span class=n>x3</span><span class=o>.</span><span class=n>T</span><span class=nd>@x3</span><span class=p>)</span> <span class=o>*</span> <span class=n>squared_y</span><span class=p>)</span>
<a id=__codelineno-1-14 name=__codelineno-1-14 href=#__codelineno-1-14></a>
<a id=__codelineno-1-15 name=__codelineno-1-15 href=#__codelineno-1-15></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;x1 represents </span><span class=si>{</span><span class=nb>round</span><span class=p>(</span><span class=n>err1</span><span class=o>*</span><span class=mi>100</span><span class=p>,</span><span class=w> </span><span class=mi>2</span><span class=p>)</span><span class=si>}</span><span class=s2>% of the variation in y, </span><span class=se>\n</span><span class=s2> x2 represents </span><span class=si>{</span><span class=nb>round</span><span class=p>(</span><span class=n>err2</span><span class=o>*</span><span class=mi>100</span><span class=p>,</span><span class=w> </span><span class=mi>2</span><span class=p>)</span><span class=si>}</span><span class=s2>% of the variation in y, </span><span class=se>\n</span><span class=s2> x3 represents </span><span class=si>{</span><span class=nb>round</span><span class=p>(</span><span class=n>err3</span><span class=o>*</span><span class=mi>100</span><span class=p>,</span><span class=w> </span><span class=mi>2</span><span class=p>)</span><span class=si>}</span><span class=s2>% of the variation in y&quot;</span><span class=p>)</span>
<a id=__codelineno-1-16 name=__codelineno-1-16 href=#__codelineno-1-16></a>
<a id=__codelineno-1-17 name=__codelineno-1-17 href=#__codelineno-1-17></a><span class=o>&gt;&gt;&gt;</span> <span class=n>x1</span> <span class=n>represents</span> <span class=mf>99.18</span><span class=o>%</span> <span class=n>of</span> <span class=n>the</span> <span class=n>variation</span> <span class=ow>in</span> <span class=n>y</span><span class=p>,</span>
<a id=__codelineno-1-18 name=__codelineno-1-18 href=#__codelineno-1-18></a><span class=o>&gt;&gt;&gt;</span> <span class=n>x2</span> <span class=n>represents</span> <span class=mf>2.13</span><span class=o>%</span> <span class=n>of</span> <span class=n>the</span> <span class=n>variation</span> <span class=ow>in</span> <span class=n>y</span><span class=p>,</span>
<a id=__codelineno-1-19 name=__codelineno-1-19 href=#__codelineno-1-19></a><span class=o>&gt;&gt;&gt;</span> <span class=n>x3</span> <span class=n>represents</span> <span class=mf>52.46</span><span class=o>%</span> <span class=n>of</span> <span class=n>the</span> <span class=n>variation</span> <span class=ow>in</span> <span class=n>y</span>
</code></pre></div> In this case, <span class=arithmatex>\(x1\)</span> have the highest <span class=arithmatex>\(err\)</span> value, so we have chosen it to be the first orthogonal vector.</p> <div class=highlight><pre><span></span><code><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=n>q1</span> <span class=o>=</span> <span class=n>x1</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
<a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a>
<a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a><span class=n>v1</span> <span class=o>=</span> <span class=n>x2</span> <span class=o>-</span> <span class=p>(</span><span class=n>q1</span><span class=o>.</span><span class=n>T</span><span class=nd>@x2</span><span class=p>)</span><span class=o>/</span><span class=p>(</span><span class=n>q1</span><span class=o>.</span><span class=n>T</span><span class=nd>@q1</span><span class=p>)</span><span class=o>*</span><span class=n>q1</span>
<a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a><span class=n>errv1</span> <span class=o>=</span> <span class=p>(</span><span class=n>v1</span><span class=o>.</span><span class=n>T</span><span class=nd>@y</span><span class=p>)</span><span class=o>**</span><span class=mi>2</span><span class=o>/</span><span class=p>((</span><span class=n>v1</span><span class=o>.</span><span class=n>T</span><span class=nd>@v1</span><span class=p>)</span> <span class=o>*</span> <span class=n>squared_y</span><span class=p>)</span>
<a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a>
<a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a><span class=n>v2</span> <span class=o>=</span> <span class=n>x3</span> <span class=o>-</span> <span class=p>(</span><span class=n>q1</span><span class=o>.</span><span class=n>T</span><span class=nd>@x3</span><span class=p>)</span><span class=o>/</span><span class=p>(</span><span class=n>q1</span><span class=o>.</span><span class=n>T</span><span class=nd>@q1</span><span class=p>)</span><span class=o>*</span><span class=n>q1</span>
<a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a><span class=n>errv2</span> <span class=o>=</span> <span class=p>(</span><span class=n>v2</span><span class=o>.</span><span class=n>T</span><span class=nd>@y</span><span class=p>)</span><span class=o>**</span><span class=mi>2</span><span class=o>/</span><span class=p>((</span><span class=n>v2</span><span class=o>.</span><span class=n>T</span><span class=nd>@v2</span><span class=p>)</span> <span class=o>*</span> <span class=n>squared_y</span><span class=p>)</span>
<a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a>
<a id=__codelineno-2-9 name=__codelineno-2-9 href=#__codelineno-2-9></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;v1 represents </span><span class=si>{</span><span class=nb>round</span><span class=p>(</span><span class=n>errv1</span><span class=o>*</span><span class=mi>100</span><span class=p>,</span><span class=w> </span><span class=mi>2</span><span class=p>)</span><span class=si>}</span><span class=s2>% of the variation in y, </span><span class=se>\n</span><span class=s2> v2 represents </span><span class=si>{</span><span class=nb>round</span><span class=p>(</span><span class=n>errv2</span><span class=o>*</span><span class=mi>100</span><span class=p>,</span><span class=w> </span><span class=mi>2</span><span class=p>)</span><span class=si>}</span><span class=s2>% of the variation in y&quot;</span><span class=p>)</span>
<a id=__codelineno-2-10 name=__codelineno-2-10 href=#__codelineno-2-10></a>
<a id=__codelineno-2-11 name=__codelineno-2-11 href=#__codelineno-2-11></a><span class=o>&gt;&gt;&gt;</span> <span class=n>v1</span> <span class=n>represents</span> <span class=mf>0.82</span><span class=o>%</span> <span class=n>of</span> <span class=n>the</span> <span class=n>variation</span> <span class=ow>in</span> <span class=n>y</span><span class=p>,</span>
<a id=__codelineno-2-12 name=__codelineno-2-12 href=#__codelineno-2-12></a><span class=o>&gt;&gt;&gt;</span> <span class=n>v2</span> <span class=n>represents</span> <span class=mf>0.66</span><span class=o>%</span> <span class=n>of</span> <span class=n>the</span> <span class=n>variation</span> <span class=ow>in</span> <span class=n>y</span>
</code></pre></div> <p>So, in this case, when we sum the err values of the first two orthogonal vectors, <span class=arithmatex>\(x1\)</span> and <span class=arithmatex>\(v1\)</span>, we get <span class=arithmatex>\(err_3 + errv1 = 100\%\)</span>. Then there is no need to keep the iterations looking for more terms. The model with this two terms already explain all the variance in the data.</p> <blockquote> <p>That's the idea of the FROLS algorithm. We calculate the ERR, choose the vector with the highest ERR to be the first orthogonal vector, orthogonalize every vector but the one we choose in the first step, calculate the ERR for each one of them, choose the vector with the highest ERR value and keep doing that until we reach some criteria.</p> </blockquote> <p>In SysIdentPy, we have 2 hyperparameters called <code>n_terms</code> and <code>err_tol</code>. Both of them can be used to stop the iterations. The first one will iterate until <code>n_terms</code> are chosen. The second one iterate until the <span class=arithmatex>\(\sum ERR_i &gt; err_{tol}\)</span> . If you set both, the algorithm stop when any of the conditions is true.</p> <div class=highlight><pre><span></span><code><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=n>model</span> <span class=o>=</span> <span class=n>FROLS</span><span class=p>(</span>
<a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>        <span class=n>n_terms</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span>
<a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a>        <span class=n>ylag</span><span class=o>=</span><span class=mi>7</span><span class=p>,</span>
<a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a>        <span class=n>xlag</span><span class=o>=</span><span class=mi>7</span><span class=p>,</span>
<a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a>        <span class=n>basis_function</span><span class=o>=</span><span class=n>basis_function</span><span class=p>,</span>
<a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a>        <span class=n>err_tol</span><span class=o>=</span><span class=mf>0.98</span>
<a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a>    <span class=p>)</span>
</code></pre></div> <p>SysIdentPy apply the Golub -Householder method for the orthogonal decomposition. A more detailed discussion about Householder and orthogonalization procedures in general can be found in <a href=https://www.tandfonline.com/doi/abs/10.1080/00207178908953472>Chen, S. and Billings, S. A. and Luo, W.</a></p> <h2 id=case-study>Case Study<a class=headerlink href=#case-study title="Permanent link">&para;</a></h2> <p>An example using real data will be described using SysIdentPy. In this example, we will build models linear and nonlinear models to describe the behavior of a DC motor operating as generator. Details of the experiment used to generate this data can be found in the paper (in Portuguese) <a href=https://www.researchgate.net/publication/320418710_Identificacao_de_um_motorgerador_CC_por_meio_de_modelos_polinomiais_autorregressivos_e_redes_neurais_artificiais>IDENTIFICAÇÃO DE UM MOTOR/GERADOR CC POR MEIO DE MODELOS POLINOMIAIS AUTORREGRESSIVOS E REDES NEURAIS ARTIFICIAIS</a></p> <div class=highlight><pre><span></span><code><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
<a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a><span class=kn>from</span><span class=w> </span><span class=nn>sysidentpy.model_structure_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>FROLS</span>
<a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a><span class=kn>from</span><span class=w> </span><span class=nn>sysidentpy.basis_function</span><span class=w> </span><span class=kn>import</span> <span class=n>Polynomial</span>
<a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a><span class=kn>from</span><span class=w> </span><span class=nn>sysidentpy.parameter_estimation</span><span class=w> </span><span class=kn>import</span> <span class=n>LeastSquares</span>
<a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a><span class=kn>from</span><span class=w> </span><span class=nn>sysidentpy.utils.display_results</span><span class=w> </span><span class=kn>import</span> <span class=n>results</span>
<a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a><span class=kn>from</span><span class=w> </span><span class=nn>sysidentpy.utils.plotting</span><span class=w> </span><span class=kn>import</span> <span class=n>plot_results</span>
<a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a>
<a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a><span class=n>df1</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>&quot;examples/datasets/x_cc.csv&quot;</span><span class=p>)</span>
<a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a><span class=n>df2</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>&quot;examples/datasets/y_cc.csv&quot;</span><span class=p>)</span>
<a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a>
<a id=__codelineno-4-12 name=__codelineno-4-12 href=#__codelineno-4-12></a><span class=c1># checking the ouput</span>
<a id=__codelineno-4-13 name=__codelineno-4-13 href=#__codelineno-4-13></a><span class=n>df2</span><span class=p>[</span><span class=mi>5000</span><span class=p>:</span><span class=mi>80000</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>
</code></pre></div> <p><a class=glightbox href="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/generator_example.png?raw=true" data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/generator_example.png?raw=true"></a></p> <blockquote> <p>Figure 2. Output of the electromechanical system.</p> </blockquote> <p>In this example, we will decimate the data using <span class=arithmatex>\(d = 500\)</span>. The rationale behind decimation here is that the data is oversampled due to the experimental setup. A future section will provide a detailed explanation of how to handle oversampled data in the context of system identification. For now, consider this approach as the most appropriate solution.</p> <div class=highlight><pre><span></span><code><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=n>x_train</span><span class=p>,</span> <span class=n>x_valid</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=n>df1</span><span class=o>.</span><span class=n>iloc</span><span class=p>[::</span><span class=mi>500</span><span class=p>]</span><span class=o>.</span><span class=n>values</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
<a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=n>y_train</span><span class=p>,</span> <span class=n>y_valid</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=n>df2</span><span class=o>.</span><span class=n>iloc</span><span class=p>[::</span><span class=mi>500</span><span class=p>]</span><span class=o>.</span><span class=n>values</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</code></pre></div> <p>In this case, we will build a NARX model. In SysIdentPy, this means setting <code>unbiased=False</code> in the <code>LeastSquares</code> definition. We'll use a <code>Polynomial</code> basis function and set the maximum lag for both input and output to 2. This configuration results in 15 terms in the information matrix, so we'll set <code>n_terms=15</code>. This specification is necessary because, in this example, <code>order_selection</code> is set to <code>False</code>. We will discuss <code>order_selection</code> in more detail in the Information Criteria section later on.</p> <blockquote> <p><code>order_selection</code> is <code>True</code> by default in SysIdentPy. When <code>order_selection=False</code> the user must pass a values to <code>n_terms</code> because it is an optional argument and its default value is <code>None</code>. If we set <code>n_terms=5</code>, for exemple, the FROLS will stop after choosing the first 5 regressors. We do not want that in this case because we want the FROLS stop only when <code>e_tol</code> is reached.</p> </blockquote> <div class=highlight><pre><span></span><code><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=n>basis_function</span> <span class=o>=</span> <span class=n>Polynomial</span><span class=p>(</span><span class=n>degree</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a>
<a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a><span class=n>model</span> <span class=o>=</span> <span class=n>FROLS</span><span class=p>(</span>
<a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a>    <span class=n>order_selection</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
<a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a>    <span class=n>ylag</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a>    <span class=n>xlag</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a>    <span class=n>estimator</span><span class=o>=</span><span class=n>LeastSquares</span><span class=p>(</span><span class=n>unbiased</span><span class=o>=</span><span class=kc>False</span><span class=p>),</span>
<a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a>    <span class=n>basis_function</span><span class=o>=</span><span class=n>basis_function</span><span class=p>,</span>
<a id=__codelineno-6-9 name=__codelineno-6-9 href=#__codelineno-6-9></a>    <span class=n>e_tol</span><span class=o>=</span><span class=mf>0.9999</span>
<a id=__codelineno-6-10 name=__codelineno-6-10 href=#__codelineno-6-10></a>    <span class=n>n_terms</span><span class=o>=</span><span class=mi>15</span>
<a id=__codelineno-6-11 name=__codelineno-6-11 href=#__codelineno-6-11></a><span class=p>)</span>
</code></pre></div> <p>SysIdentPy aims to simplify the use of algorithms like <code>FROLS</code> for the user. Building, training, or fitting a model is made straightforward through a simple interface called <code>fit</code>. By using this method, the entire process is handled internally, requiring no further interaction from the user.</p> <div class=highlight><pre><span></span><code><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y_train</span><span class=p>)</span>
</code></pre></div> <p>SysIdentPy also offers a method to retrieve detailed information about the fitted model. Users can check the terms included in the model, the estimated parameters, the Error Reduction Ratio (ERR) values, and more.</p> <blockquote> <p>We're using <code>pandas</code> here only to make the output more readable, but it's optional.</p> </blockquote> <div class=highlight><pre><span></span><code><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=n>r</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span>
<a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a>    <span class=n>results</span><span class=p>(</span>
<a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a>        <span class=n>model</span><span class=o>.</span><span class=n>final_model</span><span class=p>,</span>
<a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a>        <span class=n>model</span><span class=o>.</span><span class=n>theta</span><span class=p>,</span>
<a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a>        <span class=n>model</span><span class=o>.</span><span class=n>err</span><span class=p>,</span>
<a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a>        <span class=n>model</span><span class=o>.</span><span class=n>n_terms</span><span class=p>,</span>
<a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a>        <span class=n>err_precision</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
<a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a>        <span class=n>dtype</span><span class=o>=</span><span class=s2>&quot;sci&quot;</span><span class=p>,</span>
<a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a>    <span class=p>),</span>
<a id=__codelineno-8-10 name=__codelineno-8-10 href=#__codelineno-8-10></a>    <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;Regressors&quot;</span><span class=p>,</span> <span class=s2>&quot;Parameters&quot;</span><span class=p>,</span> <span class=s2>&quot;ERR&quot;</span><span class=p>],</span>
<a id=__codelineno-8-11 name=__codelineno-8-11 href=#__codelineno-8-11></a><span class=p>)</span>
<a id=__codelineno-8-12 name=__codelineno-8-12 href=#__codelineno-8-12></a>
<a id=__codelineno-8-13 name=__codelineno-8-13 href=#__codelineno-8-13></a><span class=nb>print</span><span class=p>(</span><span class=n>r</span><span class=p>)</span>
</code></pre></div> <table> <thead> <tr> <th>Regressors</th> <th>Parameters</th> <th>ERR</th> </tr> </thead> <tbody> <tr> <td>y(k-1)</td> <td>1.0998E+00</td> <td>9.86000384E-01</td> </tr> <tr> <td>x1(k-1)^2</td> <td>1.0165E+02</td> <td>7.94805130E-03</td> </tr> <tr> <td>y(k-2)^2</td> <td>-1.9786E-05</td> <td>2.50905908E-03</td> </tr> <tr> <td>x1(k-1)y(k-1)</td> <td>-1.2138E-01</td> <td>1.43301039E-03</td> </tr> <tr> <td>y(k-2)</td> <td>-3.2621E-01</td> <td>1.02781443E-03</td> </tr> <tr> <td>x1(k-1)y(k-2)</td> <td>5.3596E-02</td> <td>5.35200312E-04</td> </tr> <tr> <td>x1(k-2)</td> <td>3.4655E+02</td> <td>2.79648078E-04</td> </tr> <tr> <td>x1(k-2)y(k-1)</td> <td>-5.1647E-02</td> <td>1.12211942E-04</td> </tr> <tr> <td>x1(k-2)x1(k-1)</td> <td>-8.2162E+00</td> <td>4.54743448E-05</td> </tr> <tr> <td>y(k-2)y(k-1)</td> <td>4.0961E-05</td> <td>3.25346101E-05</td> </tr> <tr> <td>&gt;Table 1</td> <td></td> <td></td> </tr> </tbody> </table> <p>The table above shows that 10 regressors (out of the 15 available) were needed to reach the defined <code>e_tol</code>, with the sum of the ERR for the selected regressors being <span class=arithmatex>\(0.99992\)</span>.</p> <p>Next, let's evaluate the model's performance using the test data. Similar to the <code>fit</code> method, SysIdentPy provides a <code>predict</code> method. To obtain the predicted values and plot the results, simply follow these steps:</p> <div class=highlight><pre><span></span><code><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=n>yhat</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>x_valid</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y_valid</span><span class=p>)</span>
<a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a><span class=c1># plot only the first 100 samples (n=100)</span>
<a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a><span class=n>plot_results</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=n>y_valid</span><span class=p>,</span> <span class=n>yhat</span><span class=o>=</span><span class=n>yhat</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>100</span><span class=p>)</span>
</code></pre></div> <p><a class=glightbox href="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/generator_predict_c4.png?raw=true" data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/generator_predict_c4.png?raw=true"></a></p> <blockquote> <p>Figure 3. Free run simulation (or infinity-steps ahead prediction) of the fitted model.</p> </blockquote> <h2 id=information-criteria>Information Criteria<a class=headerlink href=#information-criteria title="Permanent link">&para;</a></h2> <p>We said that there are many ways to terminate the algorithm and select the model terms, but only ERR criteria was defined in previous section. Different ways to terminate the algorithm is by using some information criteria, e.g, Akaike Information Criteria (AIC). For Least Squares based regression analysis, the AIC indicates the number of regressors by minimizing the objective function (<a href=https://ieeexplore.ieee.org/document/1100705>Akaike, H. - A new look at the statistical model identification</a>):</p> <div class=arithmatex>\[ \begin{equation} J_{\text{AIC}} = \underbrace{n\log\left(Var[\xi_k]\right)}_{\text{first component}}+\underbrace{2n_{\Theta}}_{\text{{second component}}}. \end{equation} \tag{28} \]</div> <p>It is important to note that the equation above illustrates a trade-off between model fit and model complexity. Specifically, this trade-off involves balancing the model's ability to accurately fit the data (the first component) against its complexity, which is related to the number of parameters included (the second component). As additional terms are included in the model, the Akaike Information Criterion (AIC) value initially decreases, reaching a minimum that represents an optimal balance between model complexity and predictive accuracy. However, if the number of parameters becomes excessive, the penalty for complexity outweighs the benefit of a better fit, causing the AIC value to increase. The AIC and many others variants have been extensively used for linear and nonlinear system identification. Check <a href=https://www.sciencedirect.com/science/article/abs/pii/S0273117707002086>Wei, H. and Zhu, D. and Billings, S. A. and Balikhin, M. A. - Forecasting the geomagnetic activity of the Dst index using multiscale radial basis function networks</a>, <a href=https://link.springer.com/article/10.1007/s40313-013-0071-9>Martins, S. A. M. and Nepomuceno, E. G. and Barroso, M. F. S. - Improved Structure Detection For Polynomial NARX Models Using a Multiobjective Error Reduction Ratio</a>, <a href=https://ieeexplore.ieee.org/document/8477782>Hafiz, F. and Swain, A. and Mendes, E. M. A. M. and Patel, N. - Structure Selection of Polynomial NARX Models Using Two Dimensional (2D) Particle Swarms</a>, <a href=https://www.tandfonline.com/doi/full/10.1080/21642583.2018.1496042>Gu, Y. and Wei, H. and Balikhin, M. M. - Nonlinear predictive model selection and model averaging using information criteria</a> and references therein.</p> <p>Despite their effectiveness in many linear model selection scenarios, information criteria such as AIC can struggle to select an appropriate number of parameters when dealing with systems exhibiting significant nonlinear behavior. Additionally, these criteria may lead to suboptimal models if the search space does not encompass all the necessary terms required to accurately represent the <em>true</em> model. Consequently, in highly nonlinear systems or when critical model components are missing, information criteria might not provide reliable guidance, resulting in models that exhibit poor performance.</p> <p>Besides AIC, SysIdentPy provides other four different information criteria: <a href=https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wics.199>Bayesian Information Criteria</a> (BIC), <a href=https://www.researchgate.net/publication/303679484_Introducao_a_Identificacao_de_Sistemas>Final Prediction Error</a> (FPE), <a href=https://www.sciencedirect.com/science/article/abs/pii/S0169743902000515>Low of Iterated Logarithm Criteria</a> (LILC), and <a href=https://www.sciencedirect.com/science/article/abs/pii/S0167715296001289>Corrected Akaike Information Criteria</a> (AICc), which can be described respectively as</p> <div class=arithmatex>\[ \begin{align} \operatorname{FPE}\left(n_\theta\right) &amp; =N \ln \left[\sigma_{\text {erro }}^2\left(n_\theta\right)\right]+N \ln \left[\frac{N+n_\theta}{N-n_\theta}\right] \\ B I C\left(n_\theta\right) &amp; =N \ln \left[\sigma_{\text {erro }}^2\left(n_\theta\right)\right]+n_\theta \ln N \\ A I C c &amp;=A I C+2 n_p * \frac{n_p+1}{N-n_p-1} \\ LILC &amp;= 2n_{\theta}\ln(\ln(N)) + N \ln(\left[\sigma_{\text {erro }}^2\left(n_\theta\right)\right]) \end{align} \tag{29} \]</div> <p>To use any information criteria in SysIdentPy, set <code>order_selection=True</code> (as said before, the default value is already <code>True</code>). Besides <code>order_selection</code>, you can define how many regressors you want to evaluate before stopping the algorithm by using the <code>n_info_values</code> hyperparameter. The default value is <span class=arithmatex>\(15\)</span>, but the user should increase it based on how many regressors exists given the <code>ylag</code>, <code>xlag</code> and the degree of the basis function.</p> <blockquote> <p>Using information Criteria can take a long time depending on how many regressors you are evaluating and the number of samples. To calculate the criteria, the ERR algorithm is executed <code>n</code> times, where <code>n</code> is the number defined in <code>n_info_values</code>. Make sure to understand how it works to define whether you have to use it or not.</p> </blockquote> <p>Running the same example, but now using the BIC information criteria to select the order of the model, we have</p> <div class=highlight><pre><span></span><code><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=n>model</span> <span class=o>=</span> <span class=n>FROLS</span><span class=p>(</span>
<a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a>    <span class=n>order_selection</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
<a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a>    <span class=n>n_info_values</span><span class=o>=</span><span class=mi>15</span><span class=p>,</span>
<a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a>    <span class=n>ylag</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a>    <span class=n>xlag</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a>    <span class=n>info_criteria</span><span class=o>=</span><span class=s2>&quot;bic&quot;</span><span class=p>,</span>
<a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a>    <span class=n>estimator</span><span class=o>=</span><span class=n>LeastSquares</span><span class=p>(</span><span class=n>unbiased</span><span class=o>=</span><span class=kc>False</span><span class=p>),</span>
<a id=__codelineno-10-8 name=__codelineno-10-8 href=#__codelineno-10-8></a>    <span class=n>basis_function</span><span class=o>=</span><span class=n>basis_function</span>
<a id=__codelineno-10-9 name=__codelineno-10-9 href=#__codelineno-10-9></a><span class=p>)</span>
<a id=__codelineno-10-10 name=__codelineno-10-10 href=#__codelineno-10-10></a><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y_train</span><span class=p>)</span>
<a id=__codelineno-10-11 name=__codelineno-10-11 href=#__codelineno-10-11></a><span class=n>r</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span>
<a id=__codelineno-10-12 name=__codelineno-10-12 href=#__codelineno-10-12></a>    <span class=n>results</span><span class=p>(</span>
<a id=__codelineno-10-13 name=__codelineno-10-13 href=#__codelineno-10-13></a>        <span class=n>model</span><span class=o>.</span><span class=n>final_model</span><span class=p>,</span>
<a id=__codelineno-10-14 name=__codelineno-10-14 href=#__codelineno-10-14></a>        <span class=n>model</span><span class=o>.</span><span class=n>theta</span><span class=p>,</span>
<a id=__codelineno-10-15 name=__codelineno-10-15 href=#__codelineno-10-15></a>        <span class=n>model</span><span class=o>.</span><span class=n>err</span><span class=p>,</span>
<a id=__codelineno-10-16 name=__codelineno-10-16 href=#__codelineno-10-16></a>        <span class=n>model</span><span class=o>.</span><span class=n>n_terms</span><span class=p>,</span>
<a id=__codelineno-10-17 name=__codelineno-10-17 href=#__codelineno-10-17></a>        <span class=n>err_precision</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
<a id=__codelineno-10-18 name=__codelineno-10-18 href=#__codelineno-10-18></a>        <span class=n>dtype</span><span class=o>=</span><span class=s2>&quot;sci&quot;</span><span class=p>,</span>
<a id=__codelineno-10-19 name=__codelineno-10-19 href=#__codelineno-10-19></a>    <span class=p>),</span>
<a id=__codelineno-10-20 name=__codelineno-10-20 href=#__codelineno-10-20></a>    <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;Regressors&quot;</span><span class=p>,</span> <span class=s2>&quot;Parameters&quot;</span><span class=p>,</span> <span class=s2>&quot;ERR&quot;</span><span class=p>],</span>
<a id=__codelineno-10-21 name=__codelineno-10-21 href=#__codelineno-10-21></a><span class=p>)</span>
<a id=__codelineno-10-22 name=__codelineno-10-22 href=#__codelineno-10-22></a>
<a id=__codelineno-10-23 name=__codelineno-10-23 href=#__codelineno-10-23></a><span class=nb>print</span><span class=p>(</span><span class=n>r</span><span class=p>)</span>
</code></pre></div> <table> <thead> <tr> <th>Regressors</th> <th>Parameters</th> <th>ERR</th> </tr> </thead> <tbody> <tr> <td>y(k-1)</td> <td>1.3666E+00</td> <td>9.86000384E-01</td> </tr> <tr> <td>x1(k-1)^2</td> <td>1.0500E+02</td> <td>7.94805130E-03</td> </tr> <tr> <td>y(k-2)^2</td> <td>-5.8577E-05</td> <td>2.50905908E-03</td> </tr> <tr> <td>x1(k-1)y(k-1)</td> <td>-1.2427E-01</td> <td>1.43301039E-03</td> </tr> <tr> <td>y(k-2)</td> <td>-5.1414E-01</td> <td>1.02781443E-03</td> </tr> <tr> <td>x1(k-1)y(k-2)</td> <td>5.3001E-02</td> <td>5.35200312E-04</td> </tr> <tr> <td>x1(k-2)</td> <td>3.1144E+02</td> <td>2.79648078E-04</td> </tr> <tr> <td>x1(k-2)y(k-1)</td> <td>-4.8013E-02</td> <td>1.12211942E-04</td> </tr> <tr> <td>x1(k-2)x1(k-1)</td> <td>-8.0561E+00</td> <td>4.54743448E-05</td> </tr> <tr> <td>x1(k-2)y(k-2)</td> <td>4.1381E-03</td> <td>3.25346101E-05</td> </tr> <tr> <td>1</td> <td>-5.6653E+01</td> <td>7.54107553E-06</td> </tr> <tr> <td>y(k-2)y(k-1)</td> <td>1.5679E-04</td> <td>3.52002717E-06</td> </tr> <tr> <td>y(k-1)^2</td> <td>-9.0164E-05</td> <td>6.17373260E-06</td> </tr> <tr> <td>&gt;Table 2</td> <td></td> <td></td> </tr> </tbody> </table> <p>In this case, instead of 8 regressors, the final model have 13 terms.</p> <p>Currently, the number of regressors is determined by identifying the index of the last value where the difference between the current and previous value is less than 0. To inspect these values, you can use the following approach:</p> <div class=highlight><pre><span></span><code><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=n>xaxis</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>n_info_values</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>xaxis</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>info_values</span><span class=p>)</span>
<a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&quot;n_terms&quot;</span><span class=p>)</span>
<a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&quot;Information Criteria&quot;</span><span class=p>)</span>
</code></pre></div> <p><a class=glightbox href="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/dc_generator_aic_c4.png?raw=true" data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/dc_generator_aic_c4.png?raw=true"></a></p> <blockquote> <p>Figure 4. The plot shows the Information Criterion values (BIC) as a function of the number of terms included in the model. The model selection process, using the BIC criterion, iteratively adds regressors until the BIC reaches a minimum, indicating the optimal balance between model complexity and fit. The point where the BIC value stops decreasing marks the optimal number of terms, resulting in a final model with 13 terms.</p> </blockquote> <p>The model prediction in this case is shown in Figure 5</p> <div class=highlight><pre><span></span><code><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=n>yhat</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>x_valid</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y_valid</span><span class=p>)</span>
<a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a><span class=c1># plot only the first 100 samples (n=100)</span>
<a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a><span class=n>plot_results</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=n>y_valid</span><span class=p>,</span> <span class=n>yhat</span><span class=o>=</span><span class=n>yhat</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>100</span><span class=p>)</span>
</code></pre></div> <p><a class=glightbox href="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/dc_generator_bic_c4.png?raw=true" data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/dc_generator_bic_c4.png?raw=true"></a></p> <blockquote> <p>Figure 5. Free run simulation (or infinity-steps ahead prediction) of the fitted model using BIC.</p> </blockquote> <h3 id=overview-of-the-information-criteria-methods>Overview of the Information Criteria Methods<a class=headerlink href=#overview-of-the-information-criteria-methods title="Permanent link">&para;</a></h3> <p>In this section, simulated data are used to provide users with a clearer understanding of the information criteria available in SysIdentPy.</p> <blockquote> <p>Here, we're working with a known model structure, which allows us to focus on how different information criteria perform. When dealing with real data, the correct number of terms in the model is unknown, making these methods invaluable for guiding model selection.</p> <p>If you review the metrics below, you'll notice excellent performance across all models. However, it's crucial to remember that System Identification is about finding the optimal model structure. Model Structure Selection is at the heart of NARMAX methods!</p> </blockquote> <p>The data is generated by simulating the following model:</p> <div class=arithmatex>\[ y_k = 0.2y_{k-1} + 0.1y_{k-1}x_{k-1} + 0.9x_{k-1} + e_k \tag{30} \]</div> <p>If <code>colored_noise</code> is set to <code>True</code>, the noise term is defined as:</p> <div class=arithmatex>\[ e_k = 0.8\nu_{k-1} + \nu_k \tag{31} \]</div> <p>where <span class=arithmatex>\(x\)</span> is a uniformly distributed random variable and <span class=arithmatex>\(\nu\)</span> is a Gaussian-distributed variable with <span class=arithmatex>\(\mu = 0\)</span> and <span class=arithmatex>\(\sigma = 0.1\)</span>.</p> <p>In the next example, we will generate data with 100 samples, using white noise, and select 70% of the data to train the model.</p> <div class=highlight><pre><span></span><code><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a><span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
<a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a><span class=kn>from</span><span class=w> </span><span class=nn>sysidentpy.model_structure_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>FROLS</span>
<a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a><span class=kn>from</span><span class=w> </span><span class=nn>sysidentpy.basis_function</span><span class=w> </span><span class=kn>import</span> <span class=n>Polynomial</span>
<a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a><span class=kn>from</span><span class=w> </span><span class=nn>sysidentpy.utils.generate_data</span><span class=w> </span><span class=kn>import</span> <span class=n>get_siso_data</span>
<a id=__codelineno-13-6 name=__codelineno-13-6 href=#__codelineno-13-6></a><span class=kn>from</span><span class=w> </span><span class=nn>sysidentpy.utils.display_results</span><span class=w> </span><span class=kn>import</span> <span class=n>results</span>
<a id=__codelineno-13-7 name=__codelineno-13-7 href=#__codelineno-13-7></a>
<a id=__codelineno-13-8 name=__codelineno-13-8 href=#__codelineno-13-8></a>
<a id=__codelineno-13-9 name=__codelineno-13-9 href=#__codelineno-13-9></a><span class=n>x_train</span><span class=p>,</span> <span class=n>x_valid</span><span class=p>,</span> <span class=n>y_train</span><span class=p>,</span> <span class=n>y_valid</span> <span class=o>=</span> <span class=n>get_siso_data</span><span class=p>(</span>
<a id=__codelineno-13-10 name=__codelineno-13-10 href=#__codelineno-13-10></a>    <span class=n>n</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>colored_noise</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>sigma</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>train_percentage</span><span class=o>=</span><span class=mi>70</span>
<a id=__codelineno-13-11 name=__codelineno-13-11 href=#__codelineno-13-11></a><span class=p>)</span>
</code></pre></div> <p>The idea is to show the impact of the information criteria to select the number of terms to compose the final model. You will se why it is an auxiliary tool and let the algorithm select the number of terms based on the minimum value is not always a good idea when dealing with data highly corrupted by noise (even white noise).</p> <h4 id=aic>AIC<a class=headerlink href=#aic title="Permanent link">&para;</a></h4> <div class=highlight><pre><span></span><code><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=n>basis_function</span> <span class=o>=</span> <span class=n>Polynomial</span><span class=p>(</span><span class=n>degree</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a><span class=n>model</span> <span class=o>=</span> <span class=n>FROLS</span><span class=p>(</span>
<a id=__codelineno-14-3 name=__codelineno-14-3 href=#__codelineno-14-3></a>    <span class=n>order_selection</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
<a id=__codelineno-14-4 name=__codelineno-14-4 href=#__codelineno-14-4></a>    <span class=n>ylag</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-14-5 name=__codelineno-14-5 href=#__codelineno-14-5></a>    <span class=n>xlag</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-14-6 name=__codelineno-14-6 href=#__codelineno-14-6></a>    <span class=n>info_criteria</span><span class=o>=</span><span class=s2>&quot;aic&quot;</span><span class=p>,</span>
<a id=__codelineno-14-7 name=__codelineno-14-7 href=#__codelineno-14-7></a>    <span class=n>basis_function</span><span class=o>=</span><span class=n>basis_function</span><span class=p>,</span>
<a id=__codelineno-14-8 name=__codelineno-14-8 href=#__codelineno-14-8></a><span class=p>)</span>
<a id=__codelineno-14-9 name=__codelineno-14-9 href=#__codelineno-14-9></a>
<a id=__codelineno-14-10 name=__codelineno-14-10 href=#__codelineno-14-10></a><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y_train</span><span class=p>)</span>
<a id=__codelineno-14-11 name=__codelineno-14-11 href=#__codelineno-14-11></a><span class=n>yhat</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>x_valid</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y_valid</span><span class=p>)</span>
<a id=__codelineno-14-12 name=__codelineno-14-12 href=#__codelineno-14-12></a>
<a id=__codelineno-14-13 name=__codelineno-14-13 href=#__codelineno-14-13></a><span class=n>r</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span>
<a id=__codelineno-14-14 name=__codelineno-14-14 href=#__codelineno-14-14></a>    <span class=n>results</span><span class=p>(</span>
<a id=__codelineno-14-15 name=__codelineno-14-15 href=#__codelineno-14-15></a>        <span class=n>model</span><span class=o>.</span><span class=n>final_model</span><span class=p>,</span>
<a id=__codelineno-14-16 name=__codelineno-14-16 href=#__codelineno-14-16></a>        <span class=n>model</span><span class=o>.</span><span class=n>theta</span><span class=p>,</span>
<a id=__codelineno-14-17 name=__codelineno-14-17 href=#__codelineno-14-17></a>        <span class=n>model</span><span class=o>.</span><span class=n>err</span><span class=p>,</span>
<a id=__codelineno-14-18 name=__codelineno-14-18 href=#__codelineno-14-18></a>        <span class=n>model</span><span class=o>.</span><span class=n>n_terms</span><span class=p>,</span>
<a id=__codelineno-14-19 name=__codelineno-14-19 href=#__codelineno-14-19></a>        <span class=n>err_precision</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
<a id=__codelineno-14-20 name=__codelineno-14-20 href=#__codelineno-14-20></a>        <span class=n>dtype</span><span class=o>=</span><span class=s2>&quot;sci&quot;</span><span class=p>,</span>
<a id=__codelineno-14-21 name=__codelineno-14-21 href=#__codelineno-14-21></a>    <span class=p>),</span>
<a id=__codelineno-14-22 name=__codelineno-14-22 href=#__codelineno-14-22></a>    <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;Regressors&quot;</span><span class=p>,</span> <span class=s2>&quot;Parameters&quot;</span><span class=p>,</span> <span class=s2>&quot;ERR&quot;</span><span class=p>],</span>
<a id=__codelineno-14-23 name=__codelineno-14-23 href=#__codelineno-14-23></a><span class=p>)</span>
<a id=__codelineno-14-24 name=__codelineno-14-24 href=#__codelineno-14-24></a>
<a id=__codelineno-14-25 name=__codelineno-14-25 href=#__codelineno-14-25></a><span class=nb>print</span><span class=p>(</span><span class=n>r</span><span class=p>)</span>
<a id=__codelineno-14-26 name=__codelineno-14-26 href=#__codelineno-14-26></a>
<a id=__codelineno-14-27 name=__codelineno-14-27 href=#__codelineno-14-27></a><span class=n>xaxis</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>n_info_values</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-14-28 name=__codelineno-14-28 href=#__codelineno-14-28></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>xaxis</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>info_values</span><span class=p>)</span>
<a id=__codelineno-14-29 name=__codelineno-14-29 href=#__codelineno-14-29></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&quot;n_terms&quot;</span><span class=p>)</span>
<a id=__codelineno-14-30 name=__codelineno-14-30 href=#__codelineno-14-30></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&quot;Information Criteria&quot;</span><span class=p>)</span>
</code></pre></div> <p>The regressors, the free run simulation and the AIC values are detailed bellow.</p> <table> <thead> <tr> <th>Regressors</th> <th>Parameters</th> <th>ERR</th> </tr> </thead> <tbody> <tr> <td>x1(k-2)</td> <td>9.4236E-01</td> <td>9.26094341E-01</td> </tr> <tr> <td>y(k-1)</td> <td>2.4933E-01</td> <td>3.35898283E-02</td> </tr> <tr> <td>x1(k-1)y(k-1)</td> <td>1.3001E-01</td> <td>2.35736200E-03</td> </tr> <tr> <td>x1(k-1)</td> <td>8.4024E-02</td> <td>4.11741791E-03</td> </tr> <tr> <td>x1(k-1)^2</td> <td>7.0807E-02</td> <td>2.54231877E-03</td> </tr> <tr> <td>x1(k-2)^2</td> <td>-9.1138E-02</td> <td>1.39658893E-03</td> </tr> <tr> <td>y(k-1)^2</td> <td>1.1698E-01</td> <td>1.70257419E-03</td> </tr> <tr> <td>x1(k-2)y(k-2)</td> <td>8.3745E-02</td> <td>1.11056684E-03</td> </tr> <tr> <td>y(k-2)^2</td> <td>-4.1946E-02</td> <td>1.01686239E-03</td> </tr> <tr> <td>x1(k-2)x1(k-1)</td> <td>5.9034E-02</td> <td>7.47435512E-04</td> </tr> <tr> <td>&gt;Table 3</td> <td></td> <td></td> </tr> </tbody> </table> <p><a class=glightbox href="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/predict_aic_c4.png?raw=true" data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/predict_aic_c4.png?raw=true"></a></p> <blockquote> <p>Figure 5. Free run simulation (or infinity-steps ahead prediction) of the fitted model using AIC.</p> </blockquote> <p><a class=glightbox href="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/aic_c4.png?raw=true" data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/aic_c4.png?raw=true"></a></p> <blockquote> <p>Figure 6. The plot shows the Information Criterion values (AIC) as a function of the number of terms included in the model. The model selection process, using the AIC criterion, iteratively adds regressors until the AIC reaches a minimum, indicating the optimal balance between model complexity and fit. The point where the AICc value stops decreasing marks the optimal number of terms, resulting in a final model with 10 terms.</p> </blockquote> <p>For this case, we have a model with 10 terms. We know that the correct number is 3 because of the simulated system we are using as example.</p> <h4 id=aicc>AICc<a class=headerlink href=#aicc title="Permanent link">&para;</a></h4> <p>The only change we have to do to use AICc instead of AIC is changing the information criteria hyperparameter: <code>information_criteria="aicc"</code></p> <div class=highlight><pre><span></span><code><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a><span class=n>basis_function</span> <span class=o>=</span> <span class=n>Polynomial</span><span class=p>(</span><span class=n>degree</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a><span class=n>model</span> <span class=o>=</span> <span class=n>FROLS</span><span class=p>(</span>
<a id=__codelineno-15-3 name=__codelineno-15-3 href=#__codelineno-15-3></a>    <span class=n>order_selection</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
<a id=__codelineno-15-4 name=__codelineno-15-4 href=#__codelineno-15-4></a>    <span class=n>n_info_values</span><span class=o>=</span><span class=mi>15</span><span class=p>,</span>
<a id=__codelineno-15-5 name=__codelineno-15-5 href=#__codelineno-15-5></a>    <span class=n>ylag</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-15-6 name=__codelineno-15-6 href=#__codelineno-15-6></a>    <span class=n>xlag</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-15-7 name=__codelineno-15-7 href=#__codelineno-15-7></a>    <span class=n>info_criteria</span><span class=o>=</span><span class=s2>&quot;aicc&quot;</span><span class=p>,</span>
<a id=__codelineno-15-8 name=__codelineno-15-8 href=#__codelineno-15-8></a>    <span class=n>basis_function</span><span class=o>=</span><span class=n>basis_function</span><span class=p>,</span>
<a id=__codelineno-15-9 name=__codelineno-15-9 href=#__codelineno-15-9></a><span class=p>)</span>
<a id=__codelineno-15-10 name=__codelineno-15-10 href=#__codelineno-15-10></a><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y_train</span><span class=p>)</span>
<a id=__codelineno-15-11 name=__codelineno-15-11 href=#__codelineno-15-11></a><span class=n>yhat</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>x_valid</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y_valid</span><span class=p>)</span>
<a id=__codelineno-15-12 name=__codelineno-15-12 href=#__codelineno-15-12></a><span class=n>r</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span>
<a id=__codelineno-15-13 name=__codelineno-15-13 href=#__codelineno-15-13></a>    <span class=n>results</span><span class=p>(</span>
<a id=__codelineno-15-14 name=__codelineno-15-14 href=#__codelineno-15-14></a>        <span class=n>model</span><span class=o>.</span><span class=n>final_model</span><span class=p>,</span>
<a id=__codelineno-15-15 name=__codelineno-15-15 href=#__codelineno-15-15></a>        <span class=n>model</span><span class=o>.</span><span class=n>theta</span><span class=p>,</span>
<a id=__codelineno-15-16 name=__codelineno-15-16 href=#__codelineno-15-16></a>        <span class=n>model</span><span class=o>.</span><span class=n>err</span><span class=p>,</span>
<a id=__codelineno-15-17 name=__codelineno-15-17 href=#__codelineno-15-17></a>        <span class=n>model</span><span class=o>.</span><span class=n>n_terms</span><span class=p>,</span>
<a id=__codelineno-15-18 name=__codelineno-15-18 href=#__codelineno-15-18></a>        <span class=n>err_precision</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
<a id=__codelineno-15-19 name=__codelineno-15-19 href=#__codelineno-15-19></a>        <span class=n>dtype</span><span class=o>=</span><span class=s2>&quot;sci&quot;</span><span class=p>,</span>
<a id=__codelineno-15-20 name=__codelineno-15-20 href=#__codelineno-15-20></a>    <span class=p>),</span>
<a id=__codelineno-15-21 name=__codelineno-15-21 href=#__codelineno-15-21></a>    <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;Regressors&quot;</span><span class=p>,</span> <span class=s2>&quot;Parameters&quot;</span><span class=p>,</span> <span class=s2>&quot;ERR&quot;</span><span class=p>],</span>
<a id=__codelineno-15-22 name=__codelineno-15-22 href=#__codelineno-15-22></a><span class=p>)</span>
<a id=__codelineno-15-23 name=__codelineno-15-23 href=#__codelineno-15-23></a><span class=nb>print</span><span class=p>(</span><span class=n>r</span><span class=p>)</span>
<a id=__codelineno-15-24 name=__codelineno-15-24 href=#__codelineno-15-24></a><span class=n>plot_results</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=n>y_valid</span><span class=p>,</span> <span class=n>yhat</span><span class=o>=</span><span class=n>yhat</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>1000</span><span class=p>)</span>
<a id=__codelineno-15-25 name=__codelineno-15-25 href=#__codelineno-15-25></a>
<a id=__codelineno-15-26 name=__codelineno-15-26 href=#__codelineno-15-26></a><span class=n>xaxis</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>n_info_values</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-15-27 name=__codelineno-15-27 href=#__codelineno-15-27></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>xaxis</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>info_values</span><span class=p>)</span>
<a id=__codelineno-15-28 name=__codelineno-15-28 href=#__codelineno-15-28></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&quot;n_terms&quot;</span><span class=p>)</span>
<a id=__codelineno-15-29 name=__codelineno-15-29 href=#__codelineno-15-29></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&quot;Information Criteria&quot;</span><span class=p>)</span>
</code></pre></div> <table> <thead> <tr> <th>Regressors</th> <th>Parameters</th> <th>ERR</th> </tr> </thead> <tbody> <tr> <td>x1(k-2)</td> <td>9.2282E-01</td> <td>9.26094341E-01</td> </tr> <tr> <td>y(k-1)</td> <td>2.4294E-01</td> <td>3.35898283E-02</td> </tr> <tr> <td>x1(k-1)y(k-1)</td> <td>1.2753E-01</td> <td>2.35736200E-03</td> </tr> <tr> <td>x1(k-1)</td> <td>6.9597E-02</td> <td>4.11741791E-03</td> </tr> <tr> <td>x1(k-1)^2</td> <td>7.0578E-02</td> <td>2.54231877E-03</td> </tr> <tr> <td>x1(k-2)^2</td> <td>-1.0523E-01</td> <td>1.39658893E-03</td> </tr> <tr> <td>y(k-1)^2</td> <td>1.0949E-01</td> <td>1.70257419E-03</td> </tr> <tr> <td>x1(k-2)y(k-2)</td> <td>7.1821E-02</td> <td>1.11056684E-03</td> </tr> <tr> <td>y(k-2)^2</td> <td>-3.9756E-02</td> <td>1.01686239E-03</td> </tr> <tr> <td>&gt;Table 4</td> <td></td> <td></td> </tr> </tbody> </table> <p><a class=glightbox href="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/predicted_aicc_c4.png?raw=true" data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/predicted_aicc_c4.png?raw=true"></a></p> <blockquote> <p>Figure 7. Free run simulation (or infinity-steps ahead prediction) of the fitted model using AICc.</p> </blockquote> <p><a class=glightbox href="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/aicc_c4.png?raw=true" data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/aicc_c4.png?raw=true"></a></p> <blockquote> <p>Figure 8. The plot shows the Information Criterion values (AICc) as a function of the number of terms included in the model. The model selection process, using the AIC criterion, iteratively adds regressors until the AICc reaches a minimum, indicating the optimal balance between model complexity and fit. The point where the AICc value stops decreasing marks the optimal number of terms, resulting in a final model with 9 terms.</p> </blockquote> <p>This time we have a model with 9 regressors.</p> <h4 id=bic>BIC<a class=headerlink href=#bic title="Permanent link">&para;</a></h4> <div class=highlight><pre><span></span><code><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a><span class=n>basis_function</span> <span class=o>=</span> <span class=n>Polynomial</span><span class=p>(</span><span class=n>degree</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<a id=__codelineno-16-2 name=__codelineno-16-2 href=#__codelineno-16-2></a><span class=n>model</span> <span class=o>=</span> <span class=n>FROLS</span><span class=p>(</span>
<a id=__codelineno-16-3 name=__codelineno-16-3 href=#__codelineno-16-3></a>    <span class=n>order_selection</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
<a id=__codelineno-16-4 name=__codelineno-16-4 href=#__codelineno-16-4></a>    <span class=n>n_info_values</span><span class=o>=</span><span class=mi>15</span><span class=p>,</span>
<a id=__codelineno-16-5 name=__codelineno-16-5 href=#__codelineno-16-5></a>    <span class=n>ylag</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-16-6 name=__codelineno-16-6 href=#__codelineno-16-6></a>    <span class=n>xlag</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-16-7 name=__codelineno-16-7 href=#__codelineno-16-7></a>    <span class=n>info_criteria</span><span class=o>=</span><span class=s2>&quot;bic&quot;</span><span class=p>,</span>
<a id=__codelineno-16-8 name=__codelineno-16-8 href=#__codelineno-16-8></a>    <span class=n>basis_function</span><span class=o>=</span><span class=n>basis_function</span><span class=p>,</span>
<a id=__codelineno-16-9 name=__codelineno-16-9 href=#__codelineno-16-9></a><span class=p>)</span>
<a id=__codelineno-16-10 name=__codelineno-16-10 href=#__codelineno-16-10></a><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y_train</span><span class=p>)</span>
<a id=__codelineno-16-11 name=__codelineno-16-11 href=#__codelineno-16-11></a><span class=n>yhat</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>x_valid</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y_valid</span><span class=p>)</span>
<a id=__codelineno-16-12 name=__codelineno-16-12 href=#__codelineno-16-12></a><span class=n>r</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span>
<a id=__codelineno-16-13 name=__codelineno-16-13 href=#__codelineno-16-13></a>    <span class=n>results</span><span class=p>(</span>
<a id=__codelineno-16-14 name=__codelineno-16-14 href=#__codelineno-16-14></a>        <span class=n>model</span><span class=o>.</span><span class=n>final_model</span><span class=p>,</span>
<a id=__codelineno-16-15 name=__codelineno-16-15 href=#__codelineno-16-15></a>        <span class=n>model</span><span class=o>.</span><span class=n>theta</span><span class=p>,</span>
<a id=__codelineno-16-16 name=__codelineno-16-16 href=#__codelineno-16-16></a>        <span class=n>model</span><span class=o>.</span><span class=n>err</span><span class=p>,</span>
<a id=__codelineno-16-17 name=__codelineno-16-17 href=#__codelineno-16-17></a>        <span class=n>model</span><span class=o>.</span><span class=n>n_terms</span><span class=p>,</span>
<a id=__codelineno-16-18 name=__codelineno-16-18 href=#__codelineno-16-18></a>        <span class=n>err_precision</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
<a id=__codelineno-16-19 name=__codelineno-16-19 href=#__codelineno-16-19></a>        <span class=n>dtype</span><span class=o>=</span><span class=s2>&quot;sci&quot;</span><span class=p>,</span>
<a id=__codelineno-16-20 name=__codelineno-16-20 href=#__codelineno-16-20></a>    <span class=p>),</span>
<a id=__codelineno-16-21 name=__codelineno-16-21 href=#__codelineno-16-21></a>    <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;Regressors&quot;</span><span class=p>,</span> <span class=s2>&quot;Parameters&quot;</span><span class=p>,</span> <span class=s2>&quot;ERR&quot;</span><span class=p>],</span>
<a id=__codelineno-16-22 name=__codelineno-16-22 href=#__codelineno-16-22></a><span class=p>)</span>
<a id=__codelineno-16-23 name=__codelineno-16-23 href=#__codelineno-16-23></a><span class=nb>print</span><span class=p>(</span><span class=n>r</span><span class=p>)</span>
<a id=__codelineno-16-24 name=__codelineno-16-24 href=#__codelineno-16-24></a><span class=n>plot_results</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=n>y_valid</span><span class=p>,</span> <span class=n>yhat</span><span class=o>=</span><span class=n>yhat</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>1000</span><span class=p>)</span>
<a id=__codelineno-16-25 name=__codelineno-16-25 href=#__codelineno-16-25></a>
<a id=__codelineno-16-26 name=__codelineno-16-26 href=#__codelineno-16-26></a><span class=n>xaxis</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>n_info_values</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-16-27 name=__codelineno-16-27 href=#__codelineno-16-27></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>xaxis</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>info_values</span><span class=p>)</span>
<a id=__codelineno-16-28 name=__codelineno-16-28 href=#__codelineno-16-28></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&quot;n_terms&quot;</span><span class=p>)</span>
<a id=__codelineno-16-29 name=__codelineno-16-29 href=#__codelineno-16-29></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&quot;Information Criteria&quot;</span><span class=p>)</span>
</code></pre></div> <table> <thead> <tr> <th>Regressors</th> <th>Parameters</th> <th>ERR</th> </tr> </thead> <tbody> <tr> <td>x1(k-2)</td> <td>9.1726E-01</td> <td>9.26094341E-01</td> </tr> <tr> <td>y(k-1)</td> <td>1.8670E-01</td> <td>3.35898283E-02</td> </tr> <tr> <td>&gt;Table 5</td> <td></td> <td></td> </tr> </tbody> </table> <p><a class=glightbox href="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/predicted_bic_c4.png?raw=true" data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/predicted_bic_c4.png?raw=true"></a></p> <blockquote> <p>Figure 9. Free run simulation (or infinity-steps ahead prediction) of the fitted model using BIC.</p> </blockquote> <p><a class=glightbox href="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/bic_c4.png?raw=true" data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/bic_c4.png?raw=true"></a></p> <blockquote> <p>Figure 10. The plot shows the Information Criterion values (BIC) as a function of the number of terms included in the model. The model selection process, using the BIC criterion, iteratively adds regressors until the BIC reaches a minimum, indicating the optimal balance between model complexity and fit. The point where the BIC value stops decreasing marks the optimal number of terms, resulting in a final model with 2 terms.</p> </blockquote> <p>BIC returned a model with only 2 regressors!</p> <h4 id=lilc>LILC<a class=headerlink href=#lilc title="Permanent link">&para;</a></h4> <div class=highlight><pre><span></span><code><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a><span class=n>basis_function</span> <span class=o>=</span> <span class=n>Polynomial</span><span class=p>(</span><span class=n>degree</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<a id=__codelineno-17-2 name=__codelineno-17-2 href=#__codelineno-17-2></a><span class=n>model</span> <span class=o>=</span> <span class=n>FROLS</span><span class=p>(</span>
<a id=__codelineno-17-3 name=__codelineno-17-3 href=#__codelineno-17-3></a>    <span class=n>order_selection</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
<a id=__codelineno-17-4 name=__codelineno-17-4 href=#__codelineno-17-4></a>    <span class=n>n_info_values</span><span class=o>=</span><span class=mi>15</span><span class=p>,</span>
<a id=__codelineno-17-5 name=__codelineno-17-5 href=#__codelineno-17-5></a>    <span class=n>ylag</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-17-6 name=__codelineno-17-6 href=#__codelineno-17-6></a>    <span class=n>xlag</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-17-7 name=__codelineno-17-7 href=#__codelineno-17-7></a>    <span class=n>info_criteria</span><span class=o>=</span><span class=s2>&quot;lilc&quot;</span><span class=p>,</span>
<a id=__codelineno-17-8 name=__codelineno-17-8 href=#__codelineno-17-8></a>    <span class=n>basis_function</span><span class=o>=</span><span class=n>basis_function</span><span class=p>,</span>
<a id=__codelineno-17-9 name=__codelineno-17-9 href=#__codelineno-17-9></a><span class=p>)</span>
<a id=__codelineno-17-10 name=__codelineno-17-10 href=#__codelineno-17-10></a><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y_train</span><span class=p>)</span>
<a id=__codelineno-17-11 name=__codelineno-17-11 href=#__codelineno-17-11></a><span class=n>yhat</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>x_valid</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y_valid</span><span class=p>)</span>
<a id=__codelineno-17-12 name=__codelineno-17-12 href=#__codelineno-17-12></a><span class=n>r</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span>
<a id=__codelineno-17-13 name=__codelineno-17-13 href=#__codelineno-17-13></a>    <span class=n>results</span><span class=p>(</span>
<a id=__codelineno-17-14 name=__codelineno-17-14 href=#__codelineno-17-14></a>        <span class=n>model</span><span class=o>.</span><span class=n>final_model</span><span class=p>,</span>
<a id=__codelineno-17-15 name=__codelineno-17-15 href=#__codelineno-17-15></a>        <span class=n>model</span><span class=o>.</span><span class=n>theta</span><span class=p>,</span>
<a id=__codelineno-17-16 name=__codelineno-17-16 href=#__codelineno-17-16></a>        <span class=n>model</span><span class=o>.</span><span class=n>err</span><span class=p>,</span>
<a id=__codelineno-17-17 name=__codelineno-17-17 href=#__codelineno-17-17></a>        <span class=n>model</span><span class=o>.</span><span class=n>n_terms</span><span class=p>,</span>
<a id=__codelineno-17-18 name=__codelineno-17-18 href=#__codelineno-17-18></a>        <span class=n>err_precision</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
<a id=__codelineno-17-19 name=__codelineno-17-19 href=#__codelineno-17-19></a>        <span class=n>dtype</span><span class=o>=</span><span class=s2>&quot;sci&quot;</span><span class=p>,</span>
<a id=__codelineno-17-20 name=__codelineno-17-20 href=#__codelineno-17-20></a>    <span class=p>),</span>
<a id=__codelineno-17-21 name=__codelineno-17-21 href=#__codelineno-17-21></a>    <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;Regressors&quot;</span><span class=p>,</span> <span class=s2>&quot;Parameters&quot;</span><span class=p>,</span> <span class=s2>&quot;ERR&quot;</span><span class=p>],</span>
<a id=__codelineno-17-22 name=__codelineno-17-22 href=#__codelineno-17-22></a><span class=p>)</span>
<a id=__codelineno-17-23 name=__codelineno-17-23 href=#__codelineno-17-23></a><span class=nb>print</span><span class=p>(</span><span class=n>r</span><span class=p>)</span>
<a id=__codelineno-17-24 name=__codelineno-17-24 href=#__codelineno-17-24></a><span class=n>plot_results</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=n>y_valid</span><span class=p>,</span> <span class=n>yhat</span><span class=o>=</span><span class=n>yhat</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>1000</span><span class=p>)</span>
<a id=__codelineno-17-25 name=__codelineno-17-25 href=#__codelineno-17-25></a>
<a id=__codelineno-17-26 name=__codelineno-17-26 href=#__codelineno-17-26></a><span class=n>xaxis</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>n_info_values</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-17-27 name=__codelineno-17-27 href=#__codelineno-17-27></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>xaxis</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>info_values</span><span class=p>)</span>
<a id=__codelineno-17-28 name=__codelineno-17-28 href=#__codelineno-17-28></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&quot;n_terms&quot;</span><span class=p>)</span>
<a id=__codelineno-17-29 name=__codelineno-17-29 href=#__codelineno-17-29></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&quot;Information Criteria&quot;</span><span class=p>)</span>
</code></pre></div> <table> <thead> <tr> <th>Regressors</th> <th>Parameters</th> <th>ERR</th> </tr> </thead> <tbody> <tr> <td>x1(k-2)</td> <td>9.1160E-01</td> <td>9.26094341E-01</td> </tr> <tr> <td>y(k-1)</td> <td>2.3178E-01</td> <td>3.35898283E-02</td> </tr> <tr> <td>x1(k-1)y(k-1)</td> <td>1.2080E-01</td> <td>2.35736200E-03</td> </tr> <tr> <td>x1(k-1)</td> <td>6.3113E-02</td> <td>4.11741791E-03</td> </tr> <tr> <td>x1(k-1)^2</td> <td>5.4088E-02</td> <td>2.54231877E-03</td> </tr> <tr> <td>x1(k-2)^2</td> <td>-9.0683E-02</td> <td>1.39658893E-03</td> </tr> <tr> <td>y(k-1)^2</td> <td>8.2157E-02</td> <td>1.70257419E-03</td> </tr> <tr> <td>&gt;Table 6</td> <td></td> <td></td> </tr> </tbody> </table> <p><a class=glightbox href="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/predicted_lilc_c4.png?raw=true" data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/predicted_lilc_c4.png?raw=true"></a></p> <blockquote> <p>Figure 11. Free run simulation (or infinity-steps ahead prediction) of the fitted model using LILC.</p> </blockquote> <p><a class=glightbox href="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/lilc_c4.png?raw=true" data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/lilc_c4.png?raw=true"></a></p> <blockquote> <p>Figure 12. The plot shows the Information Criterion values (LILC) as a function of the number of terms included in the model. The model selection process, using the LILC criterion, iteratively adds regressors until the LILC reaches a minimum, indicating the optimal balance between model complexity and fit. The point where the LILC value stops decreasing marks the optimal number of terms, resulting in a final model with 7 terms.</p> </blockquote> <p>LILC returned a model with 7 regressors.</p> <h4 id=fpe>FPE<a class=headerlink href=#fpe title="Permanent link">&para;</a></h4> <div class=highlight><pre><span></span><code><a id=__codelineno-18-1 name=__codelineno-18-1 href=#__codelineno-18-1></a><span class=n>basis_function</span> <span class=o>=</span> <span class=n>Polynomial</span><span class=p>(</span><span class=n>degree</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<a id=__codelineno-18-2 name=__codelineno-18-2 href=#__codelineno-18-2></a><span class=n>model</span> <span class=o>=</span> <span class=n>FROLS</span><span class=p>(</span>
<a id=__codelineno-18-3 name=__codelineno-18-3 href=#__codelineno-18-3></a>    <span class=n>order_selection</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
<a id=__codelineno-18-4 name=__codelineno-18-4 href=#__codelineno-18-4></a>    <span class=n>n_info_values</span><span class=o>=</span><span class=mi>15</span><span class=p>,</span>
<a id=__codelineno-18-5 name=__codelineno-18-5 href=#__codelineno-18-5></a>    <span class=n>ylag</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-18-6 name=__codelineno-18-6 href=#__codelineno-18-6></a>    <span class=n>xlag</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-18-7 name=__codelineno-18-7 href=#__codelineno-18-7></a>    <span class=n>info_criteria</span><span class=o>=</span><span class=s2>&quot;fpe&quot;</span><span class=p>,</span>
<a id=__codelineno-18-8 name=__codelineno-18-8 href=#__codelineno-18-8></a>    <span class=n>basis_function</span><span class=o>=</span><span class=n>basis_function</span><span class=p>,</span>
<a id=__codelineno-18-9 name=__codelineno-18-9 href=#__codelineno-18-9></a><span class=p>)</span>
<a id=__codelineno-18-10 name=__codelineno-18-10 href=#__codelineno-18-10></a><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y_train</span><span class=p>)</span>
<a id=__codelineno-18-11 name=__codelineno-18-11 href=#__codelineno-18-11></a><span class=n>yhat</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>x_valid</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y_valid</span><span class=p>)</span>
<a id=__codelineno-18-12 name=__codelineno-18-12 href=#__codelineno-18-12></a><span class=n>r</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span>
<a id=__codelineno-18-13 name=__codelineno-18-13 href=#__codelineno-18-13></a>    <span class=n>results</span><span class=p>(</span>
<a id=__codelineno-18-14 name=__codelineno-18-14 href=#__codelineno-18-14></a>        <span class=n>model</span><span class=o>.</span><span class=n>final_model</span><span class=p>,</span>
<a id=__codelineno-18-15 name=__codelineno-18-15 href=#__codelineno-18-15></a>        <span class=n>model</span><span class=o>.</span><span class=n>theta</span><span class=p>,</span>
<a id=__codelineno-18-16 name=__codelineno-18-16 href=#__codelineno-18-16></a>        <span class=n>model</span><span class=o>.</span><span class=n>err</span><span class=p>,</span>
<a id=__codelineno-18-17 name=__codelineno-18-17 href=#__codelineno-18-17></a>        <span class=n>model</span><span class=o>.</span><span class=n>n_terms</span><span class=p>,</span>
<a id=__codelineno-18-18 name=__codelineno-18-18 href=#__codelineno-18-18></a>        <span class=n>err_precision</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
<a id=__codelineno-18-19 name=__codelineno-18-19 href=#__codelineno-18-19></a>        <span class=n>dtype</span><span class=o>=</span><span class=s2>&quot;sci&quot;</span><span class=p>,</span>
<a id=__codelineno-18-20 name=__codelineno-18-20 href=#__codelineno-18-20></a>    <span class=p>),</span>
<a id=__codelineno-18-21 name=__codelineno-18-21 href=#__codelineno-18-21></a>    <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;Regressors&quot;</span><span class=p>,</span> <span class=s2>&quot;Parameters&quot;</span><span class=p>,</span> <span class=s2>&quot;ERR&quot;</span><span class=p>],</span>
<a id=__codelineno-18-22 name=__codelineno-18-22 href=#__codelineno-18-22></a><span class=p>)</span>
<a id=__codelineno-18-23 name=__codelineno-18-23 href=#__codelineno-18-23></a><span class=nb>print</span><span class=p>(</span><span class=n>r</span><span class=p>)</span>
<a id=__codelineno-18-24 name=__codelineno-18-24 href=#__codelineno-18-24></a><span class=n>plot_results</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=n>y_valid</span><span class=p>,</span> <span class=n>yhat</span><span class=o>=</span><span class=n>yhat</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>1000</span><span class=p>)</span>
<a id=__codelineno-18-25 name=__codelineno-18-25 href=#__codelineno-18-25></a>
<a id=__codelineno-18-26 name=__codelineno-18-26 href=#__codelineno-18-26></a><span class=n>xaxis</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>n_info_values</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-18-27 name=__codelineno-18-27 href=#__codelineno-18-27></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>xaxis</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>info_values</span><span class=p>)</span>
<a id=__codelineno-18-28 name=__codelineno-18-28 href=#__codelineno-18-28></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&quot;n_terms&quot;</span><span class=p>)</span>
<a id=__codelineno-18-29 name=__codelineno-18-29 href=#__codelineno-18-29></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&quot;Information Criteria&quot;</span><span class=p>)</span>
</code></pre></div> <table> <thead> <tr> <th>Regressors</th> <th>Parameters</th> <th>ERR</th> </tr> </thead> <tbody> <tr> <td>x1(k-2)</td> <td>9.4236E-01</td> <td>9.26094341E-01</td> </tr> <tr> <td>y(k-1)</td> <td>2.4933E-01</td> <td>3.35898283E-02</td> </tr> <tr> <td>x1(k-1)y(k-1)</td> <td>1.3001E-01</td> <td>2.35736200E-03</td> </tr> <tr> <td>x1(k-1)</td> <td>8.4024E-02</td> <td>4.11741791E-03</td> </tr> <tr> <td>x1(k-1)^2</td> <td>7.0807E-02</td> <td>2.54231877E-03</td> </tr> <tr> <td>x1(k-2)^2</td> <td>-9.1138E-02</td> <td>1.39658893E-03</td> </tr> <tr> <td>y(k-1)^2</td> <td>1.1698E-01</td> <td>1.70257419E-03</td> </tr> <tr> <td>x1(k-2)y(k-2)</td> <td>8.3745E-02</td> <td>1.11056684E-03</td> </tr> <tr> <td>y(k-2)^2</td> <td>-4.1946E-02</td> <td>1.01686239E-03</td> </tr> <tr> <td>x1(k-2)x1(k-1)</td> <td>5.9034E-02</td> <td>7.47435512E-04</td> </tr> <tr> <td>&gt;Table 7</td> <td></td> <td></td> </tr> </tbody> </table> <p><a class=glightbox href="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/predicted_fpe_c4.png?raw=true" data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/predicted_fpe_c4.png?raw=true"></a></p> <blockquote> <p>Figure 13. Free run simulation (or infinity-steps ahead prediction) of the fitted model using FPE.</p> </blockquote> <p><a class=glightbox href="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/fpe_c4.png?raw=true" data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/fpe_c4.png?raw=true"></a></p> <blockquote> <p>Figure 14. The plot shows the Information Criterion values (FPE) as a function of the number of terms included in the model. The model selection process, using the FPE criterion, iteratively adds regressors until the FPE reaches a minimum, indicating the optimal balance between model complexity and fit. The point where the FPE value stops decreasing marks the optimal number of terms, resulting in a final model with 10 terms.</p> </blockquote> <p>FPE returned a model with 10 regressors.</p> <h2 id=meta-model-structure-selection-metamss>Meta Model Structure Selection (MetaMSS)<a class=headerlink href=#meta-model-structure-selection-metamss title="Permanent link">&para;</a></h2> <blockquote> <p>This section largely reflects content from a paper I published on <a href=https://arxiv.org/abs/2109.09917>ArXiv</a> titled <em>"Meta-Model Structure Selection: Building Polynomial NARX Models for Regression and Classification."</em> This paper was initially written for journal publication based on the results of my <a href=https://ufsj.edu.br/portal2-repositorio/File/ppgel/225-2020-02-17-DissertacaoWilsonLacerda.pdf>master's thesis</a>. However, as I transitioned into a Data Scientist role and considering the lengthy journal submission process and academic delays, I decided not to pursue journal publication at this time. Thus, the paper remains available only on ArXiv.</p> <p>The work extends a previous paper I presented at a <a href="https://proceedings.science/sbai-2019/trabalhos/identificacao-de-sistemas-nao-lineares-utilizando-o-algoritmo-hibrido-e-binario?lang=pt-br">Brazilian conference</a> (in Portuguese), where part of the results were initially shared.</p> </blockquote> <p>This section introduces a meta-heuristic approach for selecting the structure of polynomial NARX models in regression tasks. The proposed method considers both the complexity of the model and the contribution of each term to construct parsimonious models through a novel cost function formulation. The robustness of this new algorithm is evaluated using various simulated and experimental systems with different nonlinear characteristics. The results demonstrate that the algorithm effectively identifies the correct model when the true structure is known and produces parsimonious models for experimental data, even in cases where traditional and contemporary methods often fail. The new approach is compared against classical methods such as FROLS and recent randomized techniques.</p> <p>We mentioned that selecting the appropriate model terms is crucial for accurately capturing the dynamics of the original system. Challenges such as over-parameterization and numerical ill-conditioning often arise due to the limitations of existing identification algorithms in selecting the right terms for the final model. Check <a href=https://www.sciencedirect.com/science/article/abs/pii/0167278995900535>Aguirre, L. A. and Billings, S. A. - Dynamical effects of overparametrization in nonlinear models</a>, <a href=https://www.tandfonline.com/doi/abs/10.1080/00207170310001635419>Piroddi, L. and Spinelli, W. - An identification algorithm for polynomial NARX models based on simulation error minimization</a>. We also mentioned that one of the most traditionally algorithms for structure selection of polynomial NARMAX is the ERR algorithm. Numerous variants of FROLS algorithm has been developed to improve the model selection performance such as <a href=https://www.tandfonline.com/doi/abs/10.1080/00207178908559767>Billings, S. A., Chen, S., and Korenberg, M. J. - Identification of MIMO non-linear systems using a forward-regression orthogonal estimator</a>, <a href=https://www.sciencedirect.com/science/article/pii/S1474667016388462>Farina, M. and Piroddi, L. - Simulation Error Minimization–Based Identification of Polynomial Input–Output Recursive Models</a>, <a href=https://eprints.whiterose.ac.uk/107315/3/A%20New%20Iterative%20Orthogonal%20Forward%20Regression%20Algorithm%20-%20R2.pdf>Guo, Y., Guo, L. Z., Billings, S. A., and Wei, H. - A New Iterative Orthogonal Forward Regression Algorithm</a>, <a href=https://www.sciencedirect.com/science/article/abs/pii/S0888327098901807>Mao, K. Z. and Billings, S. A. - VARIABLE SELECTION IN NON-LINEAR SYSTEMS MODELLING</a>. The drawbacks of the FROLS have been extensively reviewed in the literature, e.g., in <a href=https://core.ac.uk/download/pdf/29031334.pdf>Billings, S. A. and Aguirre, L. A.</a>, <a href=https://ui.adsabs.harvard.edu/abs/2001JSV...239..405P/abstract>Palumbo, P. and Piroddi, L.</a>, <a href=https://www.sciencedirect.com/science/article/abs/pii/S0005109815003088>Falsone, A., Piroddi, L., and Prandini, M.</a>. Most of these weak points are related to (i) the Prediction Error Minimization (PEM) framework; (ii) the inadequacy of the ERR index in measuring the absolute importance of regressors; (iii) the use of information criteria such as AIC, FPE and the BIC, to select the model order. Regarding the information criteria, although these techniques work well for linear models, in a nonlinear context no simple relation between model size and accuracy can be established <a href=https://www.sciencedirect.com/science/article/abs/pii/S0005109815003088>Falsone, A., Piroddi, L., and Prandini, M. - A randomized algorithm for nonlinear model structure selection</a>, <a href=https://ieeexplore.ieee.org/document/1205199>Chen, S., Hong, X., and Harris, C. J. - Sparse kernel regression modeling using combined locally regularized orthogonal least squares and D-optimality experimental design</a>.</p> <p>Due to the limitations of Ordinary Least Squares (OLS)-based algorithms, recent research has presented solutions that diverged from the classical FROLS approach. New methods have reformulated the Model Structure Selection (MSS) process within a probabilistic framework and employed random sampling techniques <a href=https://www.sciencedirect.com/science/article/abs/pii/S0005109815003088>Falsone, A., Piroddi, L., and Prandini, M. - A randomized algorithm for nonlinear model structure selection</a>, <a href=https://link.springer.com/book/10.1007/978-1-4471-4610-0>Tempo, R., Calafiore, G., and Dabbene, F. - Randomized Algorithms for Analysis and Control of Uncertain Systems: With Applications</a>, <a href=https://www.sciencedirect.com/science/article/abs/pii/S0005109813003063>Baldacchino, T., Anderson, S. R., and Kadirkamanathan, V. - Computational system identification for Bayesian NARMAX modelling</a>, <a href=https://ieeexplore.ieee.org/document/1306531>Rodriguez-Vazquez, K., Fonseca, C. M., and Fleming, P. J. - Identifying the structure of nonlinear dynamic systems using multiobjective genetic programming</a>, <a href=https://repositorio.ufrn.br/bitstream/123456789/24900/1/AlcemyGabrielVitorSeverino_DISSERT.pdf>Severino, A. G. V. and Araujo, F. M. U. de</a>. Despite their advancements, these meta-heuristic and probabilistic approaches exhibit certain shortcomings. In particular, these methods often rely on information criteria such as AIC, FPE, and BIC to define the cost function for optimization, which frequently leads to over-parameterized models.</p> <p>Consider <span class=arithmatex>\(\mathcal{F}\)</span> as a class of bounded functions <span class=arithmatex>\(\phi: \mathbf{R} \mapsto \mathbf{R}\)</span>. If the properties of <span class=arithmatex>\(\phi(x)\)</span> satisfy</p> <div class=arithmatex>\[ \begin{align} &amp;\lim\limits_{x \to \infty} \phi(x) = \alpha \nonumber \\ &amp;\lim\limits_{x \to -\infty} \phi(x) = \beta \quad \text{with } \alpha &gt; \beta, \nonumber \end{align} \tag{32} \]</div> <p>the function is called sigmoidal.</p> <p>In this particular case and following definition Equation 32 with <span class=arithmatex>\(alpha = 0\)</span> and <span class=arithmatex>\(\beta = 1\)</span>, we write a "S" shaped curve as</p> <div class=arithmatex>\[ \begin{equation} \varsigma(x) = \frac{1}{1+e^{-a(x-c)}}. \end{equation} \tag{33} \]</div> <p>In that case, we can specify <span class=arithmatex>\(a\)</span>, the rate of change. If <span class=arithmatex>\(a\)</span> is close to zero, the sigmoid function will be gradual. If <span class=arithmatex>\(a\)</span> is large, the sigmoid function will have an abrupt or sharp transition. If <span class=arithmatex>\(a\)</span> is negative, the sigmoid will go from <span class=arithmatex>\(1\)</span> to zero. The parameter <span class=arithmatex>\(c\)</span> corresponds to the x value where <span class=arithmatex>\(y = 0.5\)</span>.</p> <p>The Sigmoid Linear Unit Function (SiLU) is defined by the sigmoid function multiplied by its input</p> <div class=arithmatex>\[ \begin{equation} \text{silu}(x) = x \varsigma(x), \end{equation} \tag{34} \]</div> <p>which can be viewed as a steeper sigmoid function with overshoot.</p> <h3 id=meta-heuristics>Meta-heuristics<a class=headerlink href=#meta-heuristics title="Permanent link">&para;</a></h3> <p>Over the past two decades, nature-inspired optimization algorithms have gained prominence due to their flexibility, simplicity, versatility, and ability to avoid local optima in real-world applications.</p> <p>Meta-heuristic algorithms are characterized by two fundamental features: exploitation and exploration <a href=https://dl.acm.org/doi/10.1145/937503.937505>Blum, C. and Roli, A. - Metaheuristics in combinatorial optimization: Overview and conceptual comparison</a>. <strong>Exploitation</strong> focuses on utilizing local information to refine the search around the current best solution, improving the quality of nearby solutions. Conversely, <strong>exploration</strong> aims to search a broader area of the solution space to discover potentially superior solutions and prevent the algorithm from getting trapped in local optima.</p> <p>Despite the lack of a universal consensus on the definitions of exploration and exploitation in evolutionary computing, as highlighted by <a href=https://www.researchgate.net/publication/220443407_On_Evolutionary_Exploration_and_Exploitation>Eiben, Agoston E and Schippers, Cornelis A</a>, it is generally agreed that these concepts function as opposing forces that are challenging to balance. To address this challenge, hybrid metaheuristics combine multiple algorithms to leverage both exploitation and exploration, resulting in more robust optimization methods.</p> <h4 id=the-binary-hybrid-particle-swarm-optimization-and-gravitational-search-algorithm-bpsogsa-algorithm>The Binary hybrid Particle Swarm Optimization and Gravitational Search Algorithm (BPSOGSA) algorithm<a class=headerlink href=#the-binary-hybrid-particle-swarm-optimization-and-gravitational-search-algorithm-bpsogsa-algorithm title="Permanent link">&para;</a></h4> <p>Achieving a balance between exploration and exploitation is a significant challenge in most meta-heuristic algorithms. For this method, we enhance performance and flexibility in the search process by employing a hybrid approach that combines Binary Particle Swarm Optimization (BPSO) with Gravitational Search Algorithm (GSA), as proposed by <a href=https://ieeexplore.ieee.org/abstract/document/6141614>Mirjalili, S. and Hashim, S. Z. M.</a>. This hybrid method incorporates a low-level co-evolutionary heterogeneous technique originally introduced by <a href=https://link.springer.com/article/10.1023/A:1016540724870>Talbi, E. G.</a>.</p> <p>The BPSOGSA approach leverages the strengths of both algorithms: the Particle Swarm Optimization (PSO) component is known to be good at exploring the entire search space to identify the global optimum, while the Gravitational Search Algorithm (GSA) component effectively refines the search by focusing on local solutions within a binary space. This combination aims to provide a more comprehensive and effective optimization strategy, ensuring a better balance between exploration and exploitation.</p> <h4 id=standard-particle-swarm-optimization-pso>Standard Particle Swarm Optimization (PSO)<a class=headerlink href=#standard-particle-swarm-optimization-pso title="Permanent link">&para;</a></h4> <p>In Particle Swarm Optimization (PSO) <a href=https://ieeexplore.ieee.org/document/488968>Kennedy, J. and Eberhart, R. C.</a>, <a href=https://ieeexplore.ieee.org/document/488968>Kennedy, J.</a>, each particle represents a candidate solution and is characterized by two components: its position in the search space, denoted as <span class=arithmatex>\(\vec{x}_{\,np,d} \in \mathbb{R}^{np \times d}\)</span>, and its velocity, <span class=arithmatex>\(\vec{v}_{\,np,d} \in \mathbb{R}^{np \times d}\)</span>. Here, <span class=arithmatex>\(np = 1, 2, \ldots, n_a\)</span> where <span class=arithmatex>\(n_a\)</span> is the size of the swarm, and <span class=arithmatex>\(d\)</span> is the dimensionality of the problem. The initial population is represented as follows:</p> <div class=arithmatex>\[ \vec{x}_{\,np,d} = \begin{bmatrix} x_{1,1} &amp; x_{1,2} &amp; \cdots &amp; x_{1,d} \\ x_{2,1} &amp; x_{2,2} &amp; \cdots &amp; x_{2,d} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ x_{n_a,1} &amp; x_{n_a,2} &amp; \cdots &amp; x_{n_a,d} \end{bmatrix} \tag{35} \]</div> <p>At each iteration <span class=arithmatex>\(t\)</span>, the position and velocity of a particle are updated using the following equations:</p> <div class=arithmatex>\[ v_{np,d}^{t+1} = \zeta v_{np,d}^{t} + c_1 \kappa_1 (pbest_{np}^{t} - x_{np,d}^{t}) + c_2 \kappa_2 (gbest_{np}^{t} - x_{np,d}^{t}), \tag{36} \]</div> <p>where <span class=arithmatex>\(\kappa_j \in \mathbb{R}\)</span> for <span class=arithmatex>\(j = [1,2]\)</span> are continuous random variables in the interval <span class=arithmatex>\([0,1]\)</span>, <span class=arithmatex>\(\zeta \in \mathbb{R}\)</span> is the inertia factor that controls the influence of the previous velocity on the current one and represents a trade-off between exploration and exploitation, <span class=arithmatex>\(c_1\)</span> is the cognitive factor associated with the personal best position <span class=arithmatex>\(pbest\)</span>, and <span class=arithmatex>\(c_2\)</span> is the social factor associated with the global best position <span class=arithmatex>\(gbest\)</span>. The velocity <span class=arithmatex>\(\vec{v}_{\,np,d}\)</span> is typically constrained within the range <span class=arithmatex>\([v_{min}, v_{max}]\)</span> to prevent particles from moving outside the search space. The updated position is then computed as:</p> <div class=arithmatex>\[ x_{np,d}^{t+1} = x_{np,d}^{t} + v_{np,d}^{t+1}. \tag{37} \]</div> <h4 id=standard-gravitational-search-algorithm-gsa>Standard Gravitational Search Algorithm (GSA)<a class=headerlink href=#standard-gravitational-search-algorithm-gsa title="Permanent link">&para;</a></h4> <p>In the Gravitational Search Algorithm (GSA) <a href=https://www.sciencedirect.com/science/article/abs/pii/S0020025509001200>Rashedi, Esmat, Nezamabadi-Pour, Hossein, and Saryazdi, Saeid - GSA: A Gravitational Search Algorithm</a>, agents are represented by masses, where the magnitude of each mass is proportional to the fitness value of the agent. These masses interact through gravitational forces, attracting each other towards locations closer to the global optimum. Heavier masses (agents with better fitness) move more slowly, while lighter masses (agents with poorer fitness) move more rapidly. Each mass in GSA has four properties: position, inertial mass, active gravitational mass, and passive gravitational mass. The position of a mass represents a candidate solution to the problem, and its gravitational and inertial masses are derived from the fitness function.</p> <p>Consider a population of agents as described by the following equations. At a specific time <span class=arithmatex>\(t\)</span>, the velocity and position of each agent are updated as follows:</p> <div class=arithmatex>\[ \begin{align} v_{i,d}^{t+1} &amp;= \kappa_i \times v_{i,d}^t + a_{i,d}^t, \\ x_{i,d}^{t+1} &amp;= x_{i,d}^t + v_{i,d}^{t+1}. \end{align} \tag{38} \]</div> <p>Here, <span class=arithmatex>\(\kappa_i\)</span> introduces stochastic characteristics to the search process. The acceleration <span class=arithmatex>\(a_{i,d}^t\)</span> is computed according to the law of motion <a href=https://www.sciencedirect.com/science/article/abs/pii/S0020025509001200>Rashedi, Esmat and Nezamabadi-Pour, Hossein and Saryazdi, Saeid</a>:</p> <div class=arithmatex>\[ \begin{equation} a_{i,d}^t = \frac{F_{i,d}^t}{M_{ii}^{t}}, \end{equation} \tag{39} \]</div> <p>where <span class=arithmatex>\(M_{ii}^{t}\)</span> is the inertial mass of agent <span class=arithmatex>\(i\)</span> and <span class=arithmatex>\(F_{i,d}^t\)</span> represents the gravitational force acting on agent <span class=arithmatex>\(i\)</span> in the <span class=arithmatex>\(d\)</span>-dimensional space. The detailed process for calculating and updating <span class=arithmatex>\(F_{i,d}\)</span> and <span class=arithmatex>\(M_{ii}\)</span> can be found in <a href=https://www.sciencedirect.com/science/article/abs/pii/S0020025509001200>Rashedi, Esmat and Nezamabadi-Pour, Hossein and Saryazdi, Saeid</a>.</p> <h4 id=the-binary-hybrid-optimization-algorithm>The Binary Hybrid Optimization Algorithm<a class=headerlink href=#the-binary-hybrid-optimization-algorithm title="Permanent link">&para;</a></h4> <p>The combination of algorithms follows the approach described in <a href=https://ieeexplore.ieee.org/abstract/document/6141614>Mirjalili, S. and Hashim, S. Z. M. - A new hybrid PSOGSA algorithm for function optimization</a>:</p> <div class=arithmatex>\[ \begin{align} v_{i}^{t+1} = \zeta \times v_i^t + \mathrm{c}'_{1} \times \kappa \times a_i^t + \mathrm{c}'_2 \times \kappa \times (gbest - x_i^t), \end{align} \tag{40} \]</div> <p>where <span class=arithmatex>\(\mathrm{c}'_j \in \mathbb{R}\)</span> are acceleration coefficients. This formulation accelerates the exploitation phase by incorporating the best mass location found so far. However, this method may negatively impact the exploration phase. To address this issue, <a href=https://www.sciencedirect.com/science/article/abs/pii/S0965997813001853>Mirjalili, S., Mirjalili, S. M., and Lewis, A. - Grey Wolf Optimizer</a> proposed adaptive values for <span class=arithmatex>\(\mathrm{c}'_j\)</span>, as described in <a href=https://dl.acm.org/doi/10.1007/s00521-014-1629-6>Mirjalili, S., Wang, Gai-Ge, and Coelho, L. dos S. - Binary optimization using hybrid particle swarm optimization and gravitational search algorithm</a>:</p> <div class=arithmatex>\[ \begin{align} \mathrm{c}_1' &amp;= -2 \times \frac{t^3}{\max(t)^3} + 2, \\ \mathrm{c}_2' &amp;= 2 \times \frac{t^3}{\max(t)^3} + 2. \end{align} \tag{41} \]</div> <p>In each iteration, the positions of particles are updated according to the following rules, with continuous space mapped to discrete solutions using a transfer function <a href=https://www.sciencedirect.com/science/article/abs/pii/S2210650212000648>Mirjalili, S. and Lewis, A. - S-shaped versus V-shaped transfer functions for binary Particle Swarm Optimization</a>:</p> <div class=arithmatex>\[ \begin{equation} S(v_{ik}) = \left|\frac{2}{\pi}\arctan\left(\frac{\pi}{2}v_{ik}\right)\right|. \end{equation} \tag{42} \]</div> <p>With a uniformly distributed random number <span class=arithmatex>\(\kappa \in (0,1)\)</span>, the positions of the agents in the binary space are updated as follows:</p> <div class=arithmatex>\[ \begin{equation} x_{np,d}^{t+1} = \begin{cases} (x_{np,d}^{t})^{-1}, &amp; \text{if } \kappa &lt; S(v_{ik}^{t+1}), \\ x_{np,d}^{t}, &amp; \text{if } \kappa \geq S(v_{ik}^{t+1}). \end{cases} \end{equation} \tag{43} \]</div> <h3 id=meta-model-structure-selection-metamss-building-narx-for-regression>Meta-Model Structure Selection (MetaMSS): Building NARX for Regression<a class=headerlink href=#meta-model-structure-selection-metamss-building-narx-for-regression title="Permanent link">&para;</a></h3> <p>In this section, we explore the meta-heuristic approach for selecting the structure of NARX models using BPSOGSA proposed in my <a href=https://ufsj.edu.br/portal2-repositorio/File/ppgel/225-2020-02-17-DissertacaoWilsonLacerda.pdf>master's thesis</a>. This method searches for the optimal model structure within a decision space defined by a predefined dictionary of regressors. The objective function for this optimization problem is based on the root mean squared error (RMSE) of the free-run simulation output, augmented by a penalty factor that accounts for the model's complexity and the contribution of each regressor to the final model.</p> <h4 id=encoding-scheme>Encoding Scheme<a class=headerlink href=#encoding-scheme title="Permanent link">&para;</a></h4> <p>The process of using BPSOGSA for model structure selection involves defining the dimensions of the test function. Specifically, <span class=arithmatex>\(n_y\)</span>, <span class=arithmatex>\(n_x\)</span>, and <span class=arithmatex>\(\ell\)</span> are set to cover all possible regressors, and a general matrix of regressors, <span class=arithmatex>\(\Psi\)</span>, is constructed. The number of columns in <span class=arithmatex>\(\Psi\)</span> is denoted as <span class=arithmatex>\(noV\)</span>, and the number of agents, <span class=arithmatex>\(N\)</span>, is specified. A binary <span class=arithmatex>\(noV \times N\)</span> matrix, referred to as <span class=arithmatex>\(\mathcal{X}\)</span>, is then randomly generated to represent the position of each agent in the search space. Each column of <span class=arithmatex>\(\mathcal{X}\)</span> represents a potential solution, which is essentially a candidate model structure to be evaluated in each iteration. In this matrix, a value of 1 indicates that the corresponding column of <span class=arithmatex>\(\Psi\)</span> is included in the reduced matrix of regressors, while a value of 0 indicates exclusion.</p> <p>For example, consider a case where all possible regressors are defined with <span class=arithmatex>\(\ell = 1\)</span> and <span class=arithmatex>\(n_y = n_u = 2\)</span>. The matrix <span class=arithmatex>\(\Psi\)</span> is:</p> <div class=arithmatex>\[ \begin{align} [ \text{constant} \quad y(k-1) \quad y(k-2) \quad u(k-1) \quad u(k-2) ] \end{align} \tag{44} \]</div> <p>With 5 possible regressors, <span class=arithmatex>\(noV = 5\)</span>. Assuming <span class=arithmatex>\(N = 5\)</span>, <span class=arithmatex>\(\mathcal{X}\)</span> might be represented as:</p> <div class=arithmatex>\[ \begin{equation} \mathcal{X} = \begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\ 1 &amp; 1 &amp; 1 &amp; 0 &amp; 1 \\ 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 \\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 \\ 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 \end{bmatrix} \end{equation} \tag{45} \]</div> <p>Each column of <span class=arithmatex>\(\mathcal{X}\)</span> is transposed to generate a candidate solution. For example, the first column of <span class=arithmatex>\(\mathcal{X}\)</span> yields:</p> <div class=arithmatex>\[ \begin{equation*} \mathcal{X} = \begin{bmatrix} \text{constant} &amp; y(k-1) &amp; y(k-2) &amp; u(k-1) &amp; u(k-2) \\ 1 &amp; 1 &amp; 1 &amp; 0 &amp; 1 \end{bmatrix} \end{equation*} \tag{46} \]</div> <p>In this scenario, the first model to be evaluated is <span class=arithmatex>\(\alpha y(k-1) + \beta u(k-2)\)</span>, where <span class=arithmatex>\(\alpha\)</span> and <span class=arithmatex>\(\beta\)</span> are parameters estimated using some parameter estimation method. The process is repeated for each subsequent column of <span class=arithmatex>\(\mathcal{X}\)</span>.</p> <h4 id=formulation-of-the-objective-function>Formulation of the objective function<a class=headerlink href=#formulation-of-the-objective-function title="Permanent link">&para;</a></h4> <p>For each candidate model structure randomly defined, the linear-in-the-parameters system can be solved directly using the Least Squares algorithm or any other method available in SysIdentPy. The variance of the estimated parameters can be calculated as:</p> <div class=arithmatex>\[ \hat{\sigma}^2 = \hat{\sigma}_e^2 V_{jj}, \tag{47} \]</div> <p>where <span class=arithmatex>\(\hat{\sigma}_e^2\)</span> is the estimated noise variance, given by:</p> <div class=arithmatex>\[ \hat{\sigma}_e^2 = \frac{1}{N-m} \sum_{k=1}^{N} (y_k - \psi_{k-1}^\top \hat{\Theta}), \tag{48} \]</div> <p>and <span class=arithmatex>\(V_{jj}\)</span> is the <span class=arithmatex>\(j\)</span>th diagonal element of <span class=arithmatex>\((\Psi^\top \Psi)^{-1}\)</span>.</p> <p>The estimated standard error of the <span class=arithmatex>\(j\)</span>th regression coefficient <span class=arithmatex>\(\hat{\Theta}_j\)</span> is the positive square root of the diagonal elements of <span class=arithmatex>\(\hat{\sigma}^2\)</span>:</p> <div class=arithmatex>\[ \mathrm{se}(\hat{\Theta}_j) = \sqrt{\hat{\sigma}^2_{jj}}. \tag{49} \]</div> <p>To assess the statistical relevance of each regressor, a penalty test considers the standard error of the regression coefficients. In this case, the <span class=arithmatex>\(t\)</span>-test is used to perform a hypothesis test on the coefficients, evaluating the significance of individual regressors in the multiple linear regression model. The hypothesis statements are:</p> <div class=arithmatex>\[ \begin{align*} H_0 &amp;: \Theta_j = 0, \\ H_a &amp;: \Theta_j \neq 0. \end{align*} \tag{50} \]</div> <p>The <span class=arithmatex>\(t\)</span>-statistic is computed as:</p> <div class=arithmatex>\[ T_0 = \frac{\hat{\Theta}_j}{\mathrm{se}(\hat{\Theta}_j)}, \tag{51} \]</div> <p>which measures how many standard deviations <span class=arithmatex>\(\hat{\Theta}_j\)</span> is from zero. More precisely, if:</p> <div class=arithmatex>\[ -t_{\alpha/2, N-m} &lt; T_0 &lt; t_{\alpha/2, N-m}, \tag{52} \]</div> <p>where <span class=arithmatex>\(t_{\alpha/2, N-m}\)</span> is the <span class=arithmatex>\(t\)</span> value obtained considering <span class=arithmatex>\(\alpha\)</span> as the significance level and <span class=arithmatex>\(N-m\)</span> as the degrees of freedom, then if <span class=arithmatex>\(T_0\)</span> falls outside this acceptance region, the null hypothesis <span class=arithmatex>\(H_0: \Theta_j = 0\)</span> is rejected. This implies that <span class=arithmatex>\(\Theta_j\)</span> is significant at the <span class=arithmatex>\(\alpha\)</span> level. Otherwise, if <span class=arithmatex>\(T_0\)</span> lies within the acceptance region, <span class=arithmatex>\(\Theta_j\)</span> is not significantly different from zero, and the null hypothesis cannot be rejected.</p> <h4 id=penalty-value-based-on-the-derivative-of-the-sigmoid-linear-unit-function>Penalty value based on the Derivative of the Sigmoid Linear Unit function<a class=headerlink href=#penalty-value-based-on-the-derivative-of-the-sigmoid-linear-unit-function title="Permanent link">&para;</a></h4> <p>We propose a penalty value based on the derivative of the sigmoid function, defined as:</p> <div class=arithmatex>\[ \dot{\varsigma}(x(\varrho)) = \varsigma(x) [1 + (a(x - c))(1 - \varsigma(x))]. \tag{53} \]</div> <p>In this formulation, the parameters are defined as follows: <span class=arithmatex>\(x\)</span> has the dimension of <span class=arithmatex>\(noV\)</span>; <span class=arithmatex>\(c = noV / 2\)</span>; and <span class=arithmatex>\(a\)</span> is set as the ratio of the number of regressors in the current test model to <span class=arithmatex>\(c\)</span>. This approach results in a distinct curve for each model, with the slope of the sigmoid curve becoming steeper as the number of regressors increases. The penalty value, <span class=arithmatex>\(\varrho\)</span>, corresponds to the <span class=arithmatex>\(y\)</span> value of the sigmoid curve for the given number of regressors in <span class=arithmatex>\(x\)</span>. Since the derivative of the sigmoid function can return negative values, we normalize <span class=arithmatex>\(\varsigma\)</span> as:</p> <div class=arithmatex>\[ \varrho = \varsigma - \mathrm{min}(\varsigma), \tag{54} \]</div> <p>ensuring that <span class=arithmatex>\(\varrho \in \mathbb{R}^{+}\)</span>.</p> <p>However, two different models with the same number of regressors can yield significantly different results due to the varying importance of each regressor. To address this, we use the <span class=arithmatex>\(t\)</span>-student test to assess the statistical relevance of each regressor and incorporate this information into the penalty function. Specifically, we calculate <span class=arithmatex>\(n_{\Theta, H_{0}}\)</span>, the number of regressors that are not significant for the model. The penalty value is then adjusted based on the model size:</p> <div class=arithmatex>\[ \mathrm{model\_size} = n_{\Theta} + n_{\Theta, H_{0}}. \tag{55} \]</div> <p>The objective function, which integrates the relative root mean squared error of the model with <span class=arithmatex>\(\varrho\)</span>, is defined as:</p> <div class=arithmatex>\[ \mathcal{F} = \frac{\sqrt{\sum_{k=1}^{n} (y_k - \hat{y}_k)^2}}{\sqrt{\sum_{k=1}^{n} (y_k - \bar{y})^2}} \times \varrho. \tag{56} \]</div> <p>This approach ensures that even if models have the same number of regressors, those with redundant regressors are penalized more heavily.</p> <h4 id=case-studies-simulation-results>Case Studies: Simulation Results<a class=headerlink href=#case-studies-simulation-results title="Permanent link">&para;</a></h4> <p>In this section, six simulation examples are presented to illustrate the effectiveness of the MetaMSS algorithm. An analysis of the algorithm's performance has been conducted, considering various tuning parameters. The selected systems are generally used as benchmarks for model structure algorithms and were taken from the following sources: <a href=https://www.inderscienceonline.com/doi/abs/10.1504/IJMIC.2008.020543>Wei, H. and Billings, S. A., "Model structure selection using an integrated forward orthogonal search algorithm assisted by squared correlation and mutual information"</a>, <a href=https://www.sciencedirect.com/science/article/abs/pii/S0005109815003088>Falsone, A. and Piroddi, L. and Prandini, M., "A randomized algorithm for nonlinear model structure selection"</a>, <a href=https://www.sciencedirect.com/science/article/abs/pii/S0005109813003063>Baldacchino, T. and Anderson, S. R. and Kadirkamanathan, V., "Computational system identification for Bayesian NARMAX modelling"</a>, <a href=https://www.tandfonline.com/doi/abs/10.1080/00207170310001635419>Piroddi, L. and Spinelli, W., "An identification algorithm for polynomial NARX models based on simulation error minimization"</a>, <a href=https://eprints.whiterose.ac.uk/107315/3/A%20New%20Iterative%20Orthogonal%20Forward%20Regression%20Algorithm%20-%20R2.pdf>Guo, Y. and Guo, L. Z. and Billings, S. A. and Wei, H., "A New Iterative Orthogonal Forward Regression Algorithm"</a>, <a href=https://www.researchgate.net/publication/224153379_NARX_model_selection_based_on_simulation_error_minimisation_and_LASSO>Bonin, M. and Seghezza, V. and Piroddi, L., "NARX model selection based on simulation error minimization and LASSO"</a>, and <a href=https://www.sciencedirect.com/science/article/abs/pii/S0888327010001469>Aguirre, L. A. and Barbosa, B. H. G. and Braga, A. P., "Prediction and simulation errors in parameter estimation for nonlinear systems"</a>. Finally, a comparative analysis has been performed with respect to the <a href=https://www.sciencedirect.com/science/article/abs/pii/S0005109815003088>Randomized Model Structure Selection (RaMSS), "A randomized algorithm for nonlinear model structure selection"</a>, the FROLS, and the <a href=https://www.sciencedirect.com/science/article/abs/pii/S0005109813003063>Reversible-jump Markov chain Monte Carlo (RJMCMC), "Computational system identification for Bayesian NARMAX modelling"</a> algorithms to evaluate the effectiveness of the proposed method.</p> <p>The simulation models are described as:</p> <div class=arithmatex>\[ \begin{align} &amp; S_1: \quad y_k = -1.7y_{k-1} - 0.8y_{k-2} + x_{k-1} + 0.81x_{k-2} + e_k, \\ &amp; \qquad \quad \text{with } x_k \sim \mathcal{U}(-2, 2) \text{ and } e_k \sim \mathcal{N}(0, 0.01^2); \nonumber \\ &amp; S_2: \quad y_k = 0.8y_{k-1} + 0.4x_{k-1} + 0.4x_{k-1}^2 + 0.4x_{k-1}^3 + e_k, \\ &amp; \qquad \quad \text{with } x_k \sim \mathcal{N}(0, 0.3^2) \text{ and } e_k \sim \mathcal{N}(0, 0.01^2). \nonumber \\ &amp; S_3: \quad y_k = 0.2y_{k-1}^3 + 0.7y_{k-1}x_{k-1} + 0.6x_{k-2}^2 \nonumber \\ &amp;- 0.7y_{k-2}x_{k-2}^2 -0.5y_{k-2}+ e_k, \\ &amp; \qquad \quad \text{with } x_k \sim \mathcal{U}(-1, 1) \text{ and } e_k \sim \mathcal{N}(0, 0.01^2). \nonumber \\ &amp; S_4: \quad y_k = 0.7y_{k-1}x_{k-1} - 0.5y_{k-2} + 0.6x_{k-2}^2 \nonumber \\ &amp;- 0.7y_{k-2}x_{k-2}^2 + e_k, \\ &amp; \qquad \quad \text{with } x_k \sim \mathcal{U}(-1, 1) \text{ and } e_k \sim \mathcal{N}(0, 0.04^2). \nonumber \\ &amp; S_5: \quad y_k = 0.7y_{k-1}x_{k-1} - 0.5y_{k-2} + 0.6x_{k-2}^2 \nonumber \\ &amp;- 0.7y_{k-2}x_{k-2}^2 + 0.2e_{k-1} \nonumber \\ &amp; \qquad \quad - 0.3x_{k-1}e_{k-2} + e_k,\\ &amp; \qquad \quad \text{with } x_k \sim \mathcal{U}(-1, 1) \text{ and } e_k \sim \mathcal{N}(0, 0.02^2); \nonumber \\ &amp; S_6: \quad y_k = 0.75y_{k-2} + 0.25x_{k-2} - 0.2y_{k-2}x_{k-2} + e_k \nonumber \\ &amp; \qquad \quad \text{with } x_k \sim \mathcal{N}(0, 0.25^2) \text{ and } e_k \sim \mathcal{N}(0, 0.02^2); \nonumber \end{align} \tag{57} \]</div> <p>where <span class=arithmatex>\(\mathcal{U}(a, b)\)</span> are samples evenly distributed over~<span class=arithmatex>\([a, b]\)</span>, and <span class=arithmatex>\(\mathcal{N}(\eta, \sigma^2)\)</span> are samples with a Gaussian distribution with mean <span class=arithmatex>\(\eta\)</span> and standard deviation <span class=arithmatex>\(\sigma\)</span>. All realizations of the systems are composed of a total of <span class=arithmatex>\(500\)</span> input-output data samples. Also, the same random seed is used to reproducibility purpose.</p> <p>All tests shown in this section are based on the original implementation and are took from the results of my master thesis. At the time, the algorithm was performed in Matlab <span class=arithmatex>\(2018\)</span>a environment, on a Dell Inspiron <span class=arithmatex>\(5448\)</span> Core i<span class=arithmatex>\(5-5200\)</span>U CPU <span class=arithmatex>\(2.20\)</span>GHz with <span class=arithmatex>\(12\)</span>GB of RAM. However, it is not a hard task to adapt them to SysIdentPy.</p> <p>Following the aforementioned studies, the maximum lags for the input and output are chosen to be, respectively, <span class=arithmatex>\(n_u=n_y=4\)</span> and the nonlinear degree is <span class=arithmatex>\(\ell = 3\)</span>. The parameters related to the BPSOGSA are detailed on Table 8.</p> <table> <thead> <tr> <th>Parameters</th> <th><span class=arithmatex>\(n_u\)</span></th> <th><span class=arithmatex>\(n_y\)</span></th> <th><span class=arithmatex>\(\ell\)</span></th> <th>p-value</th> <th>max_iter</th> <th>n_agents</th> <th><span class=arithmatex>\(\alpha\)</span></th> <th><span class=arithmatex>\(G_0\)</span></th> </tr> </thead> <tbody> <tr> <td>Values</td> <td><span class=arithmatex>\(4\)</span></td> <td><span class=arithmatex>\(4\)</span></td> <td><span class=arithmatex>\(3\)</span></td> <td><span class=arithmatex>\(0.05\)</span></td> <td><span class=arithmatex>\(30\)</span></td> <td><span class=arithmatex>\(10\)</span></td> <td><span class=arithmatex>\(23\)</span></td> <td><span class=arithmatex>\(100\)</span></td> </tr> <tr> <td>&gt;Table 8. Parameters used in MetaMSS</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> </tr> </tbody> </table> <p><span class=arithmatex>\(300\)</span> runs of the Meta-MSS algorithm have been executed for each model, aiming to compare some statistics about the algorithm performance. The elapsed time, the time required to obtain the final model, and correctness, the percentage of exact model selections, are analyzed.</p> <p>The results in Table 9 are obtained with the parameters configured accordingly to Table 8.</p> <table> <thead> <tr> <th></th> <th><span class=arithmatex>\(S_1\)</span></th> <th><span class=arithmatex>\(S_2\)</span></th> <th><span class=arithmatex>\(S_3\)</span></th> <th><span class=arithmatex>\(S_4\)</span></th> <th><span class=arithmatex>\(S_5\)</span></th> <th><span class=arithmatex>\(S_6\)</span></th> </tr> </thead> <tbody> <tr> <td>Correct model</td> <td>100\%</td> <td>100\%</td> <td>100\%</td> <td>100\%</td> <td>100\%</td> <td>100\%</td> </tr> <tr> <td>Elapsed time (mean)</td> <td>5.16s</td> <td>3.90s</td> <td>3.40s</td> <td>2.37s</td> <td>1.40s</td> <td>3.80s</td> </tr> <tr> <td>&gt;Table 9. Overall performance of the MetaMSS</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> </tr> </tbody> </table> <p>Table 9 shows that all the model terms are correctly selected using the Meta-MSS. It is worth to notice that even the model <span class=arithmatex>\(S_5\)</span>, which have an autoregressive noise, was correctly selected using the proposed algorithm. This result resides in the evaluation of all regressors individually, and the ones considered redundant are removed from the model.</p> <p>Figure 15 presents the convergence of each execution of Meta-MSS. It is noticeable that the majority of executions converges to the correct model structures with <span class=arithmatex>\(10\)</span> or fewer iterations. The reason for this relies on the maximum number of iterations and the number of search agents. The first one is related to the acceleration coefficient, which boosts the exploration phase of the algorithm, while the latter increases the number of candidate models to be evaluated. Intuitively, one can see that both parameters influence the elapsed time and, more importantly, the model structure selected to compose the final model. Consequently, an inappropriate choice of one of them may results in sub/over-parameterized models, since the algorithm can converge to a local optimum. The next subsection presents an analysis of the max_iter and n_agents influence in the algorithm performance.</p> <p><a class=glightbox href="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/metamss_convergence.png?raw=true" data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/metamss_convergence.png?raw=true"></a></p> <blockquote> <p>Figure 15. Convergence of Meta-MSS for different model structures. The figure illustrates the convergence behavior of the Meta-MSS algorithm across multiple executions. Each curve represents the convergence trajectory for a specific model structure from <span class=arithmatex>\(S_1\)</span> to <span class=arithmatex>\(S_6\)</span> over a maximum of 30 iterations.</p> </blockquote> <h4 id=influence-of-the-max_iter-and-n_agents-parameters>Influence of the <span class=arithmatex>\(max\_iter\)</span> and <span class=arithmatex>\(n\_agents\)</span> parameters<a class=headerlink href=#influence-of-the-max_iter-and-n_agents-parameters title="Permanent link">&para;</a></h4> <p>The simulation models are used to show the performance of the Meta-MSS considering different tuning for <code>max_iter</code> and <code>n_agents</code> parameters. First, we set and uphold the <code>max_iter=30</code> while the <code>n_agents</code> are changed. Then, we set and uphold the <code>n_agents</code> while the <code>max_iter</code> is modified. The results detailed in this section have been obtained by setting the remaining parameters according to Table 8.</p> <table> <thead> <tr> <th></th> <th></th> <th><span class=arithmatex>\(S_1\)</span></th> <th><span class=arithmatex>\(S_2\)</span></th> <th><span class=arithmatex>\(S_3\)</span></th> <th><span class=arithmatex>\(S_4\)</span></th> <th><span class=arithmatex>\(S_5\)</span></th> <th><span class=arithmatex>\(S_6\)</span></th> </tr> </thead> <tbody> <tr> <td><strong>max_iter = 30, n_agents = 1</strong></td> <td><strong>Correct model</strong></td> <td><span class=arithmatex>\(65\%\)</span></td> <td><span class=arithmatex>\(55.66\%\)</span></td> <td><span class=arithmatex>\(14\%\)</span></td> <td><span class=arithmatex>\(14\%\)</span></td> <td><span class=arithmatex>\(7.3\%\)</span></td> <td><span class=arithmatex>\(20.66\%\)</span></td> </tr> <tr> <td></td> <td><strong>Elapsed time (mean)</strong></td> <td><span class=arithmatex>\(0.26\)</span>s</td> <td><span class=arithmatex>\(0.19\)</span>s</td> <td><span class=arithmatex>\(0.15\)</span>s</td> <td><span class=arithmatex>\(0.11\)</span>s</td> <td><span class=arithmatex>\(0.13\)</span>s</td> <td><span class=arithmatex>\(0.13\)</span>s</td> </tr> <tr> <td><strong>max_iter = 30, n_agents = 5</strong></td> <td><strong>Correct model</strong></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(99\%\)</span></td> <td><span class=arithmatex>\(98\%\)</span></td> <td><span class=arithmatex>\(91.66\%\)</span></td> <td><span class=arithmatex>\(98.33\%\)</span></td> </tr> <tr> <td></td> <td><strong>Elapsed time (mean)</strong></td> <td><span class=arithmatex>\(2.08\)</span>s</td> <td><span class=arithmatex>\(1.51\)</span>s</td> <td><span class=arithmatex>\(1.41\)</span>s</td> <td><span class=arithmatex>\(0.99\)</span>s</td> <td><span class=arithmatex>\(0.59\)</span>s</td> <td><span class=arithmatex>\(1.13\)</span>s</td> </tr> <tr> <td><strong>max_iter = 30, n_agents = 20</strong></td> <td><strong>Correct model</strong></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> </tr> <tr> <td></td> <td><strong>Elapsed time (mean)</strong></td> <td><span class=arithmatex>\(12.88\)</span>s</td> <td><span class=arithmatex>\(9.10\)</span>s</td> <td><span class=arithmatex>\(8.77\)</span>s</td> <td><span class=arithmatex>\(5.70\)</span>s</td> <td><span class=arithmatex>\(3.37\)</span>s</td> <td><span class=arithmatex>\(9.50\)</span>s</td> </tr> <tr> <td><strong>max_iter = 5, n_agents = 10</strong></td> <td><strong>Correct model</strong></td> <td><span class=arithmatex>\(96.33\%\)</span></td> <td><span class=arithmatex>\(99\%\)</span></td> <td><span class=arithmatex>\(86\%\)</span></td> <td><span class=arithmatex>\(93.66\%\)</span></td> <td><span class=arithmatex>\(93\%\)</span></td> <td><span class=arithmatex>\(97.33\%\)</span></td> </tr> <tr> <td></td> <td><strong>Elapsed time (mean)</strong></td> <td><span class=arithmatex>\(0.92\)</span>s</td> <td><span class=arithmatex>\(0.73\)</span>s</td> <td><span class=arithmatex>\(0.72\)</span>s</td> <td><span class=arithmatex>\(0.52\)</span>s</td> <td><span class=arithmatex>\(0.29\)</span>s</td> <td><span class=arithmatex>\(0.64\)</span>s</td> </tr> <tr> <td><strong>max_iter = 15, n_agents = 10</strong></td> <td><strong>Correct model</strong></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(99\%\)</span></td> <td><span class=arithmatex>\(99\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> </tr> <tr> <td></td> <td><strong>Elapsed time (mean)</strong></td> <td><span class=arithmatex>\(2.80\)</span>s</td> <td><span class=arithmatex>\(2.33\)</span>s</td> <td><span class=arithmatex>\(2.25\)</span>s</td> <td><span class=arithmatex>\(1.60\)</span>s</td> <td><span class=arithmatex>\(0.90\)</span>s</td> <td><span class=arithmatex>\(2.30\)</span>s</td> </tr> <tr> <td><strong>max_iter = 50, n_agents = 10</strong></td> <td><strong>Correct model</strong></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> </tr> <tr> <td></td> <td><strong>Elapsed time (mean)</strong></td> <td><span class=arithmatex>\(7.38\)</span>s</td> <td><span class=arithmatex>\(5.44\)</span>s</td> <td><span class=arithmatex>\(4.56\)</span>s</td> <td><span class=arithmatex>\(3.01\)</span>s</td> <td><span class=arithmatex>\(2.10\)</span>s</td> <td><span class=arithmatex>\(4.52\)</span>s</td> </tr> <tr> <td>&gt;Table 10.</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> </tr> </tbody> </table> <p>The aggregated results in Table 10 confirms the expected performance regarding the elapsed time and percentage of correct models. Indeed, both metrics increases significantly as the number of agents and the maximum number of iteration increases. The number of agents is very relevant because it yields a broader exploration of the search space. All system are affected by the increase in the number of agents and the maximum number of iterations.</p> <p>Regarding all tested systems, it is straightforward to notice that the more extensive exploration dramatically impacts on the exactitude of the selection procedure. If only a few agents are assigned, the performance of Meta-MSS algorithm deteriorates significantly, especially for systems <span class=arithmatex>\(S_3, S_4\)</span> and <span class=arithmatex>\(S_5\)</span>. The maximum number of iteration empowers agents to explore, globally and locally, the space around the candidate models tested so far. In this sense, as the number of iterations increases, more the agents can explore the search space and examine different regressors.</p> <p>If these parameters are improperly chosen, the algorithm might fail to select the best model structure. In this respect, the results presented here concerns only the selected systems. The larger the search space, the larger the number of agents and iterations should be. Although the computational effort increases with larger values for n_agents and max_iteration, the algorithm remains very efficient regarding the elapsed time for all tuning configurations that ensured the selection of the exact model structures.</p> <h4 id=selection-of-over-and-sub-parameterized-models>Selection of over and sub-parameterized models<a class=headerlink href=#selection-of-over-and-sub-parameterized-models title="Permanent link">&para;</a></h4> <p>Regardless of the successful selection of all models structures by the Meta-Structure Selection Algorithm, one can ask how the models differs from the true ones in the cases presented in Table 10 where the algorithm failed to ensure <span class=arithmatex>\(100\%\)</span> of correctness. Figure 16 depicts the distribution of terms number selected in each case. It is evident that the number of over-parameterized models selected is higher than the sub-parameterized in overall. Regarding the cases where the number of search agents are low, due to low exploration and exploitation capacity, the algorithm converged early and resulted in models with a high number of spurious regressors. In respect to <span class=arithmatex>\(S_2\)</span> and <span class=arithmatex>\(S_5\)</span>, for example, with n_agents<span class=arithmatex>\(=1\)</span>, the algorithm ends up selecting models with more than <span class=arithmatex>\(20\)</span> terms. One can say this was a extreme scenario for comparison purpose. However, a suitable choice for the parameters is intrinsically related to the dimension of the search space. Referring to cases where n_agents<span class=arithmatex>\(\geq 5\)</span>, the number of spurious terms decreased significantly where the algorithm failed to select the true models.</p> <p>Furthermore, it is interesting to point out the importance of tuning the parameters properly because since the exploration and exploitation phase of the algorithm are strongly dependent on them. A premature convergence of the algorithm may result in models with the factual number of terms, but with wrong ones. This happened with all cases with <code>n_agents=1</code>. For example, the algorithm generates models with correct number of terms in <span class=arithmatex>\(33.33\%\)</span> of the cases analyzed regarding <span class=arithmatex>\(S_3\)</span>. However, Table 10 shows that only <span class=arithmatex>\(14\%\)</span> are, in fact, equivalent to the true model.</p> <p><a class=glightbox href="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/metamss_terms_distribution.png?raw=true" data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/metamss_terms_distribution.png?raw=true"></a></p> <blockquote> <p>Figure 16. The distribution of terms number selected for each simulated models concerning the variation of the <code>max_iter</code> and <code>n_agents</code>.</p> </blockquote> <h4 id=selection-of-over-and-sub-parameterized-models_1>Selection of over and sub-parameterized models<a class=headerlink href=#selection-of-over-and-sub-parameterized-models_1 title="Permanent link">&para;</a></h4> <p>Regardless of the successful selection of all models structures by the MetaMSS, one can ask how the models differ from the true ones in the cases presented in Table 10 where the algorithm failed to ensure <span class=arithmatex>\(100\%\)</span> of correctness. Figure 16 depicts the distribution of terms number selected in each case. It is evident that the number of over-parameterized models selected is higher than the sub-parameterized in overall. Regarding the cases where the number of search agents is low, due to low exploration and exploitation capacity, the algorithm converged early and resulted in models with a high number of spurious regressors. In respect to <span class=arithmatex>\(S_2\)</span> and <span class=arithmatex>\(S_5\)</span>, for example, with <code>n_agents=1</code>, the algorithm ends up selecting models with more than <span class=arithmatex>\(20\)</span> terms. One can say this was an extreme scenario for comparison purpose. However, a suitable choice for the parameters is intrinsically related to the dimension of the search space. By referring to cases where <code>n_agents</code><span class=arithmatex>\(\geq 5\)</span>, the number of spurious terms decreased significantly where the algorithm failed to select the true models.</p> <p>Furthermore, it is interesting to point out the importance of tuning the parameters properly because since the exploration and exploitation phase of the algorithm is strongly dependent on them. A premature convergence of the algorithm may result in models with the actual number of terms, but with wrong ones. This issue happened with all cases with <code>n_agents=1</code>. For example, the algorithm generates models with the correct number of terms in <span class=arithmatex>\(33.33\%\)</span> of the cases analyzed regarding <span class=arithmatex>\(S_3\)</span>. However, Table 10 shows that only <span class=arithmatex>\(14\%\)</span> are, in fact, equivalent to the true model.</p> <p>The systems <span class=arithmatex>\(S_1\)</span>, <span class=arithmatex>\(S_2\)</span>, <span class=arithmatex>\(S_3\)</span>, <span class=arithmatex>\(S_4\)</span> and <span class=arithmatex>\(S_6\)</span> has been used as benchmark by <a href=https://www.tandfonline.com/doi/abs/10.1080/00207721.2016.1244309>Bianchi, F., Falsone, A., Prandini, M. and Piroddi, L.</a>, so we can compare directly our results with those reported by the author in his thesis. All techniques used <span class=arithmatex>\(n_y=n_u=4\)</span> and <span class=arithmatex>\(\ell = 3\)</span>. The RaMSS and the RaMSS with Conditional Linear Family (C-RaMSS) used the following configuration for the tuning parameters: <span class=arithmatex>\(K=1\)</span>, <span class=arithmatex>\(\alpha = 0.997\)</span>, <span class=arithmatex>\(NP = 200\)</span> and <span class=arithmatex>\(v=0.1\)</span>. The Meta-Structure Selection Algorithm was tuned according to Table 8.</p> <table> <thead> <tr> <th></th> <th></th> <th><span class=arithmatex>\(S_1\)</span></th> <th><span class=arithmatex>\(S_2\)</span></th> <th><span class=arithmatex>\(S_3\)</span></th> <th><span class=arithmatex>\(S_4\)</span></th> <th><span class=arithmatex>\(S_6\)</span></th> </tr> </thead> <tbody> <tr> <td><strong>Meta-MSS</strong></td> <td><strong>Correct model</strong></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> </tr> <tr> <td></td> <td><strong>Elapsed time (mean)</strong></td> <td><span class=arithmatex>\(5.16\)</span>s</td> <td><span class=arithmatex>\(3.90\)</span>s</td> <td><span class=arithmatex>\(3.40\)</span>s</td> <td><span class=arithmatex>\(2.37\)</span>s</td> <td><span class=arithmatex>\(3.80\)</span>s</td> </tr> <tr> <td><strong>RaMSS- <span class=arithmatex>\(NP=100\)</span></strong></td> <td><strong>Correct model</strong></td> <td><span class=arithmatex>\(90.33\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(66\%\)</span></td> </tr> <tr> <td></td> <td><strong>Elapsed time (mean)</strong></td> <td><span class=arithmatex>\(3.27\)</span>s</td> <td><span class=arithmatex>\(1.24\)</span>s</td> <td><span class=arithmatex>\(2.59\)</span>s</td> <td><span class=arithmatex>\(1.67\)</span>s</td> <td><span class=arithmatex>\(6.66\)</span>s</td> </tr> <tr> <td><strong>RaMSS- <span class=arithmatex>\(NP=200\)</span></strong></td> <td><strong>Correct model</strong></td> <td><span class=arithmatex>\(78.33\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(82\%\)</span></td> </tr> <tr> <td></td> <td><strong>Elapsed time (mean)</strong></td> <td><span class=arithmatex>\(6.25\)</span>s</td> <td><span class=arithmatex>\(2.07\)</span>s</td> <td><span class=arithmatex>\(4.42\)</span>s</td> <td><span class=arithmatex>\(2.77\)</span>s</td> <td><span class=arithmatex>\(9.16\)</span>s</td> </tr> <tr> <td><strong>C-RaMSS</strong></td> <td><strong>Correct model</strong></td> <td><span class=arithmatex>\(93.33\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> <td><span class=arithmatex>\(100\%\)</span></td> </tr> <tr> <td></td> <td><strong>Elapsed time (mean)</strong></td> <td><span class=arithmatex>\(18\)</span>s</td> <td><span class=arithmatex>\(10.50\)</span>s</td> <td><span class=arithmatex>\(16.96\)</span>s</td> <td><span class=arithmatex>\(10.56\)</span>s</td> <td><span class=arithmatex>\(48.52\)</span>s</td> </tr> <tr> <td>&gt; Table 11. Comparative analysis between MetaMSS, RaMSS, and C-RaMSS</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> </tr> </tbody> </table> <p>In terms of correctness, the MetaMSS outperforms (or at least equals) the RaMSS and C-RaMSS for all analyzed systems as shown in Table 11. Regarding <span class=arithmatex>\(S_6\)</span>, the correctness rate increased by <span class=arithmatex>\(18\%\)</span> when compared with RaMSS and the elapsed time required for C-RaMSS obtain <span class=arithmatex>\(100\%\)</span> of correctness is <span class=arithmatex>\(1276.84\%\)</span> higher than the MetaMSS. Furthermore, the MetaMSS is notably more computationally efficient than C-RaMSS and similar to RaMSS.</p> <h4 id=metamss-vs-frols>MetaMSS vs FROLS<a class=headerlink href=#metamss-vs-frols title="Permanent link">&para;</a></h4> <p>The FROLS algorithm was applied to all tested systems, with the results summarized in Table 12. The algorithm successfully selected the correct model terms for <span class=arithmatex>\(S_2\)</span> and <span class=arithmatex>\(S_6\)</span>. However, it failed to identify two out of four regressors for <span class=arithmatex>\(S_1\)</span>. For <span class=arithmatex>\(S_3\)</span>, FROLS included <span class=arithmatex>\(y_{k-1}\)</span> instead of the correct term <span class=arithmatex>\(y_{k-1}^3\)</span>. Similarly, <span class=arithmatex>\(S_4\)</span> incorrectly included <span class=arithmatex>\(y_{k-4}\)</span> rather than the required term <span class=arithmatex>\(y_{k-2}\)</span>. Additionally, for <span class=arithmatex>\(S_5\)</span>, the algorithm produced an incorrect model structure by including the spurious term <span class=arithmatex>\(y_{k-4}\)</span>.</p> <table> <thead> <tr> <th></th> <th>Meta-MSS Regressor</th> <th>Correct</th> <th>FROLS Regressor</th> <th>Correct</th> </tr> </thead> <tbody> <tr> <td><strong><span class=arithmatex>\(S_1\)</span></strong></td> <td><span class=arithmatex>\(y_{k-1}\)</span></td> <td>yes</td> <td><span class=arithmatex>\(y_{k-1}\)</span></td> <td>yes</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(y_{k-2}\)</span></td> <td>yes</td> <td><span class=arithmatex>\(y_{k-4}\)</span></td> <td>no</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(x_{k-1}\)</span></td> <td>yes</td> <td><span class=arithmatex>\(x_{k-1}\)</span></td> <td>yes</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(x_{k-2}\)</span></td> <td>yes</td> <td><span class=arithmatex>\(x_{k-4}\)</span></td> <td>no</td> </tr> <tr> <td><strong><span class=arithmatex>\(S_2\)</span></strong></td> <td><span class=arithmatex>\(y_{k-1}\)</span></td> <td>yes</td> <td><span class=arithmatex>\(y_{k-1}\)</span></td> <td>yes</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(x_{k-1}\)</span></td> <td>yes</td> <td><span class=arithmatex>\(x_{k-1}\)</span></td> <td>yes</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(x_{k-1}^2\)</span></td> <td>yes</td> <td><span class=arithmatex>\(x_{k-1}^2\)</span></td> <td>yes</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(x_{k-1}^3\)</span></td> <td>yes</td> <td><span class=arithmatex>\(x_{k-1}^3\)</span></td> <td>yes</td> </tr> <tr> <td><strong><span class=arithmatex>\(S_3\)</span></strong></td> <td><span class=arithmatex>\(y_{k-1}^3\)</span></td> <td>yes</td> <td><span class=arithmatex>\(y_{k-1}\)</span></td> <td>no</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(y_{k-1}x_{k-1}\)</span></td> <td>yes</td> <td><span class=arithmatex>\(y_{k-1}x_{k-1}\)</span></td> <td>yes</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(x_{k-2}^2\)</span></td> <td>yes</td> <td><span class=arithmatex>\(x_{k-2}^2\)</span></td> <td>yes</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(y_{k-2}x_{k-2}^2\)</span></td> <td>yes</td> <td><span class=arithmatex>\(y_{k-2}x_{k-2}^2\)</span></td> <td>yes</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(y_{k-2}\)</span></td> <td>yes</td> <td><span class=arithmatex>\(y_{k-2}\)</span></td> <td>yes</td> </tr> <tr> <td><strong><span class=arithmatex>\(S_4\)</span></strong></td> <td><span class=arithmatex>\(y_{k-1}x_{k-1}\)</span></td> <td>yes</td> <td><span class=arithmatex>\(y_{k-1}x_{k-1}\)</span></td> <td>yes</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(y_{k-2}\)</span></td> <td>yes</td> <td><span class=arithmatex>\(y_{k-4}\)</span></td> <td>no</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(x_{k-2}^2\)</span></td> <td>yes</td> <td><span class=arithmatex>\(x_{k-2}^2\)</span></td> <td>yes</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(y_{k-2}x_{k-2}^2\)</span></td> <td>yes</td> <td><span class=arithmatex>\(y_{k-2}x_{k-2}^2\)</span></td> <td>yes</td> </tr> <tr> <td><strong><span class=arithmatex>\(S_5\)</span></strong></td> <td><span class=arithmatex>\(y_{k-1}x_{k-1}\)</span></td> <td>yes</td> <td><span class=arithmatex>\(y_{k-1}x_{k-1}\)</span></td> <td>yes</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(y_{k-2}\)</span></td> <td>yes</td> <td><span class=arithmatex>\(y_{k-4}\)</span></td> <td>no</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(x_{k-2}^2\)</span></td> <td>yes</td> <td><span class=arithmatex>\(x_{k-2}^2\)</span></td> <td>yes</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(y_{k-2}x_{k-2}^2\)</span></td> <td>yes</td> <td><span class=arithmatex>\(y_{k-2}x_{k-2}^2\)</span></td> <td>yes</td> </tr> <tr> <td><strong><span class=arithmatex>\(S_6\)</span></strong></td> <td><span class=arithmatex>\(y_{k-2}\)</span></td> <td>yes</td> <td><span class=arithmatex>\(y_{k-2}\)</span></td> <td>yes</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(x_{k-1}\)</span></td> <td>yes</td> <td><span class=arithmatex>\(x_{k-1}\)</span></td> <td>yes</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(y_{k-2}x_{k-2}\)</span></td> <td>yes</td> <td><span class=arithmatex>\(y_{k-2}x_{k-1}\)</span></td> <td>yes</td> </tr> <tr> <td>&gt; Table 12. Comparative analysis between MetaMSS and FROLS</td> <td></td> <td></td> <td></td> <td></td> </tr> </tbody> </table> <h4 id=meta-mss-vs-rjmcmc>Meta-MSS vs RJMCMC<a class=headerlink href=#meta-mss-vs-rjmcmc title="Permanent link">&para;</a></h4> <p>The <span class=arithmatex>\(S_4\)</span> model is taken from Baldacchino, Anderson, and Kadirkamanathan's work (<a href=https://www.sciencedirect.com/science/article/abs/pii/S0005109813003063>Computational System Identification for Bayesian NARMAX Modelling</a>). In their study, the maximum lags for the input and output are <span class=arithmatex>\(n_y = n_u = 4\)</span>, and the nonlinear degree is <span class=arithmatex>\(\ell = 3\)</span>. The authors ran the RJMCMC algorithm 10 times on the same input-output data. The RJMCMC method successfully identified the true model structure 7 out of 10 times. In contrast, the MetaMSS algorithm consistently identified the true model structure in all runs. These results are summarized in Table 13.</p> <p>Additionally, the RJMCMC method has notable drawbacks that are addressed by the MetaMSS algorithm. Specifically, RJMCMC is computationally intensive, requiring <span class=arithmatex>\(30,000\)</span> iterations to achieve results. Furthermore, it relies on various probability distributions to simplify the parameter estimation process, which can complicate the computations. In contrast, MetaMSS offers a more efficient and straightforward approach, avoiding these issues.</p> <table> <thead> <tr> <th></th> <th>Meta-MSS Model</th> <th>Correct</th> <th>RJMCMC Model 1 (<span class=arithmatex>\(7\times\)</span>)</th> <th>RJMCMC Model 2</th> <th>RJMCMC Model 3</th> <th>RJMCMC Model 4</th> <th>Correct</th> </tr> </thead> <tbody> <tr> <td><strong><span class=arithmatex>\(S_4\)</span></strong></td> <td><span class=arithmatex>\(y_{k-1}x_{k-1}\)</span></td> <td>yes</td> <td><span class=arithmatex>\(y_{k-1}x_{k-1}\)</span></td> <td><span class=arithmatex>\(y_{k-1}x_{k-1}\)</span></td> <td><span class=arithmatex>\(y_{k-1}x_{k-1}\)</span></td> <td><span class=arithmatex>\(y_{k-1}x_{k-1}\)</span></td> <td>yes</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(y_{k-2}\)</span></td> <td>yes</td> <td><span class=arithmatex>\(y_{k-2}\)</span></td> <td><span class=arithmatex>\(y_{k-2}\)</span></td> <td><span class=arithmatex>\(y_{k-2}\)</span></td> <td><span class=arithmatex>\(y_{k-2}\)</span></td> <td>yes</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(x_{k-2}^2\)</span></td> <td>yes</td> <td><span class=arithmatex>\(x_{k-2}^2\)</span></td> <td><span class=arithmatex>\(x_{k-2}^2\)</span></td> <td><span class=arithmatex>\(x_{k-2}^2\)</span></td> <td><span class=arithmatex>\(x_{k-2}^2\)</span></td> <td>yes</td> </tr> <tr> <td></td> <td><span class=arithmatex>\(y_{k-2}x_{k-2}^2\)</span></td> <td>yes</td> <td><span class=arithmatex>\(y_{k-2}x_{k-2}^2\)</span></td> <td><span class=arithmatex>\(y_{k-2}x_{k-2}^2\)</span></td> <td><span class=arithmatex>\(y_{k-2}x_{k-2}^2\)</span></td> <td><span class=arithmatex>\(y_{k-2}x_{k-2}^2\)</span></td> <td>yes</td> </tr> <tr> <td></td> <td>-</td> <td>-</td> <td>-</td> <td><span class=arithmatex>\(y_{k-3}x_{k-3}\)</span></td> <td><span class=arithmatex>\(x_{k-4}^2\)</span></td> <td><span class=arithmatex>\(x_{k-1}x_{k-3}^2\)</span></td> <td>no</td> </tr> <tr> <td>&gt; Table 13. Comparative analysis between MetaMSS and RJMCMC.</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> </tr> </tbody> </table> <h3 id=metamss-algorithm-using-sysidentpy>MetaMSS algorithm using SysIdentPy<a class=headerlink href=#metamss-algorithm-using-sysidentpy title="Permanent link">&para;</a></h3> <p>Consider the same data used in the Overview of the Information Criteria Methods.</p> <div class=highlight><pre><span></span><code><a id=__codelineno-19-1 name=__codelineno-19-1 href=#__codelineno-19-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sysidentpy.model_structure_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>MetaMSS</span>
<a id=__codelineno-19-2 name=__codelineno-19-2 href=#__codelineno-19-2></a>
<a id=__codelineno-19-3 name=__codelineno-19-3 href=#__codelineno-19-3></a>
<a id=__codelineno-19-4 name=__codelineno-19-4 href=#__codelineno-19-4></a><span class=n>basis_function</span> <span class=o>=</span> <span class=n>Polynomial</span><span class=p>(</span><span class=n>degree</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<a id=__codelineno-19-5 name=__codelineno-19-5 href=#__codelineno-19-5></a><span class=n>model</span> <span class=o>=</span> <span class=n>MetaMSS</span><span class=p>(</span>
<a id=__codelineno-19-6 name=__codelineno-19-6 href=#__codelineno-19-6></a>    <span class=n>ylag</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-19-7 name=__codelineno-19-7 href=#__codelineno-19-7></a>    <span class=n>xlag</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-19-8 name=__codelineno-19-8 href=#__codelineno-19-8></a>    <span class=n>random_state</span><span class=o>=</span><span class=mi>42</span><span class=p>,</span>
<a id=__codelineno-19-9 name=__codelineno-19-9 href=#__codelineno-19-9></a>    <span class=n>basis_function</span><span class=o>=</span><span class=n>basis_function</span><span class=p>,</span>
<a id=__codelineno-19-10 name=__codelineno-19-10 href=#__codelineno-19-10></a><span class=p>)</span>
<a id=__codelineno-19-11 name=__codelineno-19-11 href=#__codelineno-19-11></a>
<a id=__codelineno-19-12 name=__codelineno-19-12 href=#__codelineno-19-12></a><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y_train</span><span class=p>)</span>
<a id=__codelineno-19-13 name=__codelineno-19-13 href=#__codelineno-19-13></a><span class=n>yhat</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>x_valid</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y_valid</span><span class=p>)</span>
<a id=__codelineno-19-14 name=__codelineno-19-14 href=#__codelineno-19-14></a>
<a id=__codelineno-19-15 name=__codelineno-19-15 href=#__codelineno-19-15></a><span class=n>r</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span>
<a id=__codelineno-19-16 name=__codelineno-19-16 href=#__codelineno-19-16></a>    <span class=n>results</span><span class=p>(</span>
<a id=__codelineno-19-17 name=__codelineno-19-17 href=#__codelineno-19-17></a>        <span class=n>model</span><span class=o>.</span><span class=n>final_model</span><span class=p>,</span>
<a id=__codelineno-19-18 name=__codelineno-19-18 href=#__codelineno-19-18></a>        <span class=n>model</span><span class=o>.</span><span class=n>theta</span><span class=p>,</span>
<a id=__codelineno-19-19 name=__codelineno-19-19 href=#__codelineno-19-19></a>        <span class=n>model</span><span class=o>.</span><span class=n>err</span><span class=p>,</span>
<a id=__codelineno-19-20 name=__codelineno-19-20 href=#__codelineno-19-20></a>        <span class=n>model</span><span class=o>.</span><span class=n>n_terms</span><span class=p>,</span>
<a id=__codelineno-19-21 name=__codelineno-19-21 href=#__codelineno-19-21></a>        <span class=n>err_precision</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
<a id=__codelineno-19-22 name=__codelineno-19-22 href=#__codelineno-19-22></a>        <span class=n>dtype</span><span class=o>=</span><span class=s2>&quot;sci&quot;</span><span class=p>,</span>
<a id=__codelineno-19-23 name=__codelineno-19-23 href=#__codelineno-19-23></a>    <span class=p>),</span>
<a id=__codelineno-19-24 name=__codelineno-19-24 href=#__codelineno-19-24></a>    <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;Regressors&quot;</span><span class=p>,</span> <span class=s2>&quot;Parameters&quot;</span><span class=p>,</span> <span class=s2>&quot;ERR&quot;</span><span class=p>],</span>
<a id=__codelineno-19-25 name=__codelineno-19-25 href=#__codelineno-19-25></a><span class=p>)</span>
<a id=__codelineno-19-26 name=__codelineno-19-26 href=#__codelineno-19-26></a><span class=nb>print</span><span class=p>(</span><span class=n>r</span><span class=p>)</span>
<a id=__codelineno-19-27 name=__codelineno-19-27 href=#__codelineno-19-27></a><span class=n>plot_results</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=n>y_valid</span><span class=p>,</span> <span class=n>yhat</span><span class=o>=</span><span class=n>yhat</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>1000</span><span class=p>)</span>
</code></pre></div> <p>The MetaMSS algorithm does not rely on information criteria methods such as ERR for model structure selection, which is why it does not involve those hyperparameters. This is also true for the AOLS and ER algorithms. For more details on how to use these methods and their associated hyperparameters, please refer to the documentation.</p> <p>When it comes to parameter estimation, SysIdentPy allows the use of any available method, regardless of the model structure selection algorithm. Users can select from a range of parameter estimation methods to apply to their chosen model structure. This flexibility enables users to explore various modeling approaches and customize their system identification process. While the examples provided use the default parameter estimation method, users are encouraged to experiment with different options to find the best fit for their needs.</p> <p>The results of the MetaMSS are</p> <table> <thead> <tr> <th>Regressors</th> <th>Parameters</th> <th>ERR</th> </tr> </thead> <tbody> <tr> <td>y(k-1)</td> <td>1.8004E-01</td> <td>0.00000000E+00</td> </tr> <tr> <td>x1(k-2)</td> <td>8.9747E-01</td> <td>0.00000000E+00</td> </tr> </tbody> </table> <p><a class=glightbox href="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/metamss_result_c4_example.png?raw=true" data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/metamss_result_c4_example.png?raw=true"></a></p> <blockquote> <p>Figure 17. Free Run Simulation for the model fitted using MetaMSS.</p> </blockquote> <p>The <code>results</code> method brings ERR as 0 for every regressor because, as mentioned, ERR algorithm is not executed in this case.</p> <h2 id=accelerated-orthogonal-least-squares-aols-and-entropic-regression-er>Accelerated Orthogonal Least Squares (AOLS) and Entropic Regression (ER)<a class=headerlink href=#accelerated-orthogonal-least-squares-aols-and-entropic-regression-er title="Permanent link">&para;</a></h2> <p>In addition to FROLS and MetaMSS, SysIdentPy includes two other methods for model structure selection: Accelerated Orthogonal Least Squares (AOLS) and Entropic Regression (ER). While I won't delve into the details of these methods in this section as I have with FROLS and MetaMSS, I will provide an overview and references for further reading:</p> <ul> <li><strong>Accelerated Orthogonal Least Squares (AOLS):</strong> For an in-depth exploration of AOLS, refer to the original paper <a href=https://www.sciencedirect.com/science/article/abs/pii/S1051200418305311>here</a>.</li> <li><strong>Entropic Regression (ER):</strong> Detailed information about ER can be found in the original paper <a href=https://arxiv.org/pdf/1905.08061>here</a>.</li> </ul> <p>For now, I will demonstrate how to use these methods within SysIdentPy.</p> <h3 id=accelerated-orthogonal-least-squares>Accelerated Orthogonal Least Squares<a class=headerlink href=#accelerated-orthogonal-least-squares title="Permanent link">&para;</a></h3> <div class=highlight><pre><span></span><code><a id=__codelineno-20-1 name=__codelineno-20-1 href=#__codelineno-20-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sysidentpy.model_structure_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>AOLS</span>
<a id=__codelineno-20-2 name=__codelineno-20-2 href=#__codelineno-20-2></a>
<a id=__codelineno-20-3 name=__codelineno-20-3 href=#__codelineno-20-3></a><span class=n>basis_function</span> <span class=o>=</span> <span class=n>Polynomial</span><span class=p>(</span><span class=n>degree</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<a id=__codelineno-20-4 name=__codelineno-20-4 href=#__codelineno-20-4></a><span class=n>model</span> <span class=o>=</span> <span class=n>AOLS</span><span class=p>(</span>
<a id=__codelineno-20-5 name=__codelineno-20-5 href=#__codelineno-20-5></a>    <span class=n>ylag</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-20-6 name=__codelineno-20-6 href=#__codelineno-20-6></a>    <span class=n>xlag</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-20-7 name=__codelineno-20-7 href=#__codelineno-20-7></a>    <span class=n>basis_function</span><span class=o>=</span><span class=n>basis_function</span><span class=p>,</span>
<a id=__codelineno-20-8 name=__codelineno-20-8 href=#__codelineno-20-8></a><span class=p>)</span>
<a id=__codelineno-20-9 name=__codelineno-20-9 href=#__codelineno-20-9></a>
<a id=__codelineno-20-10 name=__codelineno-20-10 href=#__codelineno-20-10></a><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y_train</span><span class=p>)</span>
<a id=__codelineno-20-11 name=__codelineno-20-11 href=#__codelineno-20-11></a><span class=n>yhat</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>x_valid</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y_valid</span><span class=p>)</span>
<a id=__codelineno-20-12 name=__codelineno-20-12 href=#__codelineno-20-12></a>
<a id=__codelineno-20-13 name=__codelineno-20-13 href=#__codelineno-20-13></a><span class=n>r</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span>
<a id=__codelineno-20-14 name=__codelineno-20-14 href=#__codelineno-20-14></a>    <span class=n>results</span><span class=p>(</span>
<a id=__codelineno-20-15 name=__codelineno-20-15 href=#__codelineno-20-15></a>        <span class=n>model</span><span class=o>.</span><span class=n>final_model</span><span class=p>,</span>
<a id=__codelineno-20-16 name=__codelineno-20-16 href=#__codelineno-20-16></a>        <span class=n>model</span><span class=o>.</span><span class=n>theta</span><span class=p>,</span>
<a id=__codelineno-20-17 name=__codelineno-20-17 href=#__codelineno-20-17></a>        <span class=n>model</span><span class=o>.</span><span class=n>err</span><span class=p>,</span>
<a id=__codelineno-20-18 name=__codelineno-20-18 href=#__codelineno-20-18></a>        <span class=n>model</span><span class=o>.</span><span class=n>n_terms</span><span class=p>,</span>
<a id=__codelineno-20-19 name=__codelineno-20-19 href=#__codelineno-20-19></a>        <span class=n>err_precision</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
<a id=__codelineno-20-20 name=__codelineno-20-20 href=#__codelineno-20-20></a>        <span class=n>dtype</span><span class=o>=</span><span class=s2>&quot;sci&quot;</span><span class=p>,</span>
<a id=__codelineno-20-21 name=__codelineno-20-21 href=#__codelineno-20-21></a>    <span class=p>),</span>
<a id=__codelineno-20-22 name=__codelineno-20-22 href=#__codelineno-20-22></a>    <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;Regressors&quot;</span><span class=p>,</span> <span class=s2>&quot;Parameters&quot;</span><span class=p>,</span> <span class=s2>&quot;ERR&quot;</span><span class=p>],</span>
<a id=__codelineno-20-23 name=__codelineno-20-23 href=#__codelineno-20-23></a><span class=p>)</span>
<a id=__codelineno-20-24 name=__codelineno-20-24 href=#__codelineno-20-24></a><span class=nb>print</span><span class=p>(</span><span class=n>r</span><span class=p>)</span>
<a id=__codelineno-20-25 name=__codelineno-20-25 href=#__codelineno-20-25></a><span class=n>plot_results</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=n>y_valid</span><span class=p>,</span> <span class=n>yhat</span><span class=o>=</span><span class=n>yhat</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>1000</span><span class=p>)</span>
</code></pre></div> <table> <thead> <tr> <th>Regressors</th> <th>Parameters</th> <th>ERR</th> </tr> </thead> <tbody> <tr> <td>x1(k-2)</td> <td>9.1542E-01</td> <td>0.00000000E+00</td> </tr> </tbody> </table> <p><a class=glightbox href="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/aols_example_c4.png?raw=true" data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/aols_example_c4.png?raw=true"></a></p> <blockquote> <p>Figure 18. Free Run Simulation for the model fitted using AOLS algorithm.</p> </blockquote> <h3 id=entropic-regression>Entropic Regression<a class=headerlink href=#entropic-regression title="Permanent link">&para;</a></h3> <div class=highlight><pre><span></span><code><a id=__codelineno-21-1 name=__codelineno-21-1 href=#__codelineno-21-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sysidentpy.model_structure_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>ER</span>
<a id=__codelineno-21-2 name=__codelineno-21-2 href=#__codelineno-21-2></a>
<a id=__codelineno-21-3 name=__codelineno-21-3 href=#__codelineno-21-3></a><span class=n>basis_function</span> <span class=o>=</span> <span class=n>Polynomial</span><span class=p>(</span><span class=n>degree</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
<a id=__codelineno-21-4 name=__codelineno-21-4 href=#__codelineno-21-4></a><span class=n>model</span> <span class=o>=</span> <span class=n>ER</span><span class=p>(</span>
<a id=__codelineno-21-5 name=__codelineno-21-5 href=#__codelineno-21-5></a>    <span class=n>ylag</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-21-6 name=__codelineno-21-6 href=#__codelineno-21-6></a>    <span class=n>xlag</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-21-7 name=__codelineno-21-7 href=#__codelineno-21-7></a>    <span class=n>basis_function</span><span class=o>=</span><span class=n>basis_function</span><span class=p>,</span>
<a id=__codelineno-21-8 name=__codelineno-21-8 href=#__codelineno-21-8></a><span class=p>)</span>
<a id=__codelineno-21-9 name=__codelineno-21-9 href=#__codelineno-21-9></a><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y_train</span><span class=p>)</span>
<a id=__codelineno-21-10 name=__codelineno-21-10 href=#__codelineno-21-10></a><span class=n>yhat</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>x_valid</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y_valid</span><span class=p>)</span>
<a id=__codelineno-21-11 name=__codelineno-21-11 href=#__codelineno-21-11></a>
<a id=__codelineno-21-12 name=__codelineno-21-12 href=#__codelineno-21-12></a><span class=n>r</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span>
<a id=__codelineno-21-13 name=__codelineno-21-13 href=#__codelineno-21-13></a>    <span class=n>results</span><span class=p>(</span>
<a id=__codelineno-21-14 name=__codelineno-21-14 href=#__codelineno-21-14></a>        <span class=n>model</span><span class=o>.</span><span class=n>final_model</span><span class=p>,</span>
<a id=__codelineno-21-15 name=__codelineno-21-15 href=#__codelineno-21-15></a>        <span class=n>model</span><span class=o>.</span><span class=n>theta</span><span class=p>,</span>
<a id=__codelineno-21-16 name=__codelineno-21-16 href=#__codelineno-21-16></a>        <span class=n>model</span><span class=o>.</span><span class=n>err</span><span class=p>,</span>
<a id=__codelineno-21-17 name=__codelineno-21-17 href=#__codelineno-21-17></a>        <span class=n>model</span><span class=o>.</span><span class=n>n_terms</span><span class=p>,</span>
<a id=__codelineno-21-18 name=__codelineno-21-18 href=#__codelineno-21-18></a>        <span class=n>err_precision</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
<a id=__codelineno-21-19 name=__codelineno-21-19 href=#__codelineno-21-19></a>        <span class=n>dtype</span><span class=o>=</span><span class=s2>&quot;sci&quot;</span><span class=p>,</span>
<a id=__codelineno-21-20 name=__codelineno-21-20 href=#__codelineno-21-20></a>    <span class=p>),</span>
<a id=__codelineno-21-21 name=__codelineno-21-21 href=#__codelineno-21-21></a>    <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;Regressors&quot;</span><span class=p>,</span> <span class=s2>&quot;Parameters&quot;</span><span class=p>,</span> <span class=s2>&quot;ERR&quot;</span><span class=p>],</span>
<a id=__codelineno-21-22 name=__codelineno-21-22 href=#__codelineno-21-22></a><span class=p>)</span>
<a id=__codelineno-21-23 name=__codelineno-21-23 href=#__codelineno-21-23></a>
<a id=__codelineno-21-24 name=__codelineno-21-24 href=#__codelineno-21-24></a><span class=nb>print</span><span class=p>(</span><span class=n>r</span><span class=p>)</span>
<a id=__codelineno-21-25 name=__codelineno-21-25 href=#__codelineno-21-25></a><span class=n>plot_results</span><span class=p>(</span><span class=n>y</span><span class=o>=</span><span class=n>y_valid</span><span class=p>,</span> <span class=n>yhat</span><span class=o>=</span><span class=n>yhat</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>1000</span><span class=p>)</span>
</code></pre></div> <table> <thead> <tr> <th>Regressors</th> <th>Parameters</th> <th>ERR</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>-2.4554E-02</td> <td>0.00000000E+00</td> </tr> <tr> <td>x1(k-2)</td> <td>9.0273E-01</td> <td>0.00000000E+00</td> </tr> </tbody> </table> <p><a class=glightbox href="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/er_example_c4.png?raw=true" data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src="https://github.com/wilsonrljr/sysidentpy-data/blob/4085901293ba5ed5674bb2911ef4d1fa20f3438d/book/assets/er_example_c4.png?raw=true"></a></p> <blockquote> <p>Figure 19. Free Run Simulation for the model fitted using Entropic Regression algorithm.</p> </blockquote> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../3-Parameter-Estimation/ class="md-footer__link md-footer__link--prev" aria-label="Previous: 3. Parameter Estimation"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> 3. Parameter Estimation </div> </div> </a> <a href=../5-Multiobjective-Parameter-Estimation/ class="md-footer__link md-footer__link--next" aria-label="Next: 5. Multiobjective Parameter Estimation"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> 5. Multiobjective Parameter Estimation </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2016 - 2025 Wilson Rocha </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/wilsonrljr target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://pypi.org/project/sysidentpy/ target=_blank rel=noopener title=pypi.org class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3"/></svg> </a> <a href=https://twitter.com/wilsonrljr target=_blank rel=noopener title=twitter.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["content.code.copy", "content.action.edit", "content.action.view", "navigation.footer", "content.code.annotate", "content.tabs.link", "content.tooltips", "navigation.indexes", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../assets/javascripts/bundle.c8b220af.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=../../overrides/assets/js/katex.js></script> <script src=https://unpkg.com/katex@0/dist/katex.min.js></script> <script src=https://unpkg.com/katex@0/dist/contrib/auto-render.min.js></script> <script src=https://cdn.jsdelivr.net/npm/swiper@11/swiper-bundle.min.js></script> <script src=../../overrides/assets/vendor/js/prism.js></script> <script src=https://cdn.jsdelivr.net/npm/apexcharts></script> <script src=../../overrides/assets/js/chart-example.js></script> <script src=../../overrides/assets/js/scripts.js></script> <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body> </html>