
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>sysidentpy.polynomial_basis.narmax &#8212; NARMAX models</title>
    
  <link rel="stylesheet" href="../../../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.37f24b989f4638ff9c27c22dc7559d4f.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <link rel="canonical" href="http://sysidentpy.org/_modules/sysidentpy/polynomial_basis/narmax.html" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="http://sysidentpy.org/_modules/sysidentpy/polynomial_basis/narmax.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="NARMAX models" />
<meta property="og:description" content="" />
<meta property="og:image"       content="http://sysidentpy.org/_static/sysidentpy-logo.png" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
  
  <img src="../../../_static/sysidentpy-logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">NARMAX models</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../installation.html">
   Install Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../introduction_to_narmax.html">
   A brief introduction to NARMAX models.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../user_guide.html">
   User Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../dev_guide.html">
   Contributing
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../../notebooks.html">
   Jupyter notebooks
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/basic_steps.html">
     Presenting main functionality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/multiple_inputs_example.html">
     Multiple Inputs usage
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/information_criteria_examples.html">
     Information Criteria - Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/extended_least_squares.html">
     Important notes and examples of how to use Extended Least Squares
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/defining_lags.html">
     Setting specific lags
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/parameter_estimation.html">
     Parameter Estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/f_16_benchmark.html">
     Example: F-16 Ground Vibration Test benchmark
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/narx_neural_network.html">
     Building NARX Neural Network using Sysidentpy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/general_estimators.html">
     Building NARX models using general estimators
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../changelog/v0.1.4.html">
   Changes in SysIdentPy
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../../../code.html">
   Codes
  </a>
  <ul class="simple collapse-ul">
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#module-sysidentpy.base">
   sysidentpy base
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#sysidentpy-narmax">
   sysidentpy narmax
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#sysidentpy-narx-neural-network">
   sysidentpy narx_neural_network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#sysidentpy-general-estimators">
   sysidentpy general_estimators
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#module-sysidentpy.residues.residues_correlation">
   sysidentpy residues
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#module-sysidentpy.metrics._regression">
   sysidentpy metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#module-sysidentpy.parameter_estimation.estimators">
   sysidentpy estimators
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#module-sysidentpy.utils._check_arrays">
   sysidentpy utils
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#module-sysidentpy.utils.generate_data">
   sysidentpy generate data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../code.html#indices-and-tables">
   Indices and tables
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/wilsonrljr/sysidentpy/tree/master/"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/wilsonrljr/sysidentpy/tree/master//issues/new?title=Issue%20on%20page%20%2F_modules/sysidentpy/polynomial_basis/narmax.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <h1>Source code for sysidentpy.polynomial_basis.narmax</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot; Build Polynomial NARMAX Models &quot;&quot;&quot;</span>

<span class="c1"># Authors:</span>
<span class="c1">#           Wilson Rocha Lacerda Junior &lt;wilsonrljr@outlook.com&gt;</span>
<span class="c1">#           Luan Pascoal da Costa Andrade &lt;luan_pascoal13@hotmail.com&gt;</span>
<span class="c1">#           Samuel Carlos Pessoa Oliveira &lt;samuelcpoliveira@gmail.com&gt;</span>
<span class="c1">#           Samir Angelo Milani Martins &lt;martins@ufsj.edu.br&gt;</span>
<span class="c1"># License: BSD 3 clause</span>


<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">..base</span> <span class="kn">import</span> <span class="n">GenerateRegressors</span>
<span class="kn">from</span> <span class="nn">..base</span> <span class="kn">import</span> <span class="n">HouseHolder</span>
<span class="kn">from</span> <span class="nn">..base</span> <span class="kn">import</span> <span class="n">InformationMatrix</span>
<span class="kn">from</span> <span class="nn">..parameter_estimation.estimators</span> <span class="kn">import</span> <span class="n">Estimators</span>
<span class="kn">from</span> <span class="nn">..residues.residues_correlation</span> <span class="kn">import</span> <span class="n">ResiduesAnalysis</span>
<span class="kn">from</span> <span class="nn">..utils._check_arrays</span> <span class="kn">import</span> <span class="n">check_X_y</span>


<div class="viewcode-block" id="PolynomialNarmax"><a class="viewcode-back" href="../../../code.html#sysidentpy.polynomial_basis.narmax.PolynomialNarmax">[docs]</a><span class="k">class</span> <span class="nc">PolynomialNarmax</span><span class="p">(</span>
    <span class="n">GenerateRegressors</span><span class="p">,</span> <span class="n">HouseHolder</span><span class="p">,</span> <span class="n">InformationMatrix</span><span class="p">,</span> <span class="n">ResiduesAnalysis</span><span class="p">,</span> <span class="n">Estimators</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Polynomial NARXMAX model</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    non_degree : int, default=2</span>
<span class="sd">        The nonlinearity degree of the polynomial function.</span>
<span class="sd">    ylag : int, default=2</span>
<span class="sd">        The maximum lag of the output.</span>
<span class="sd">    xlag : int, default=2</span>
<span class="sd">        The maximum lag of the input.</span>
<span class="sd">    order_selection: bool, default=False</span>
<span class="sd">        Whether to use information criteria for order selection.</span>
<span class="sd">    info_criteria : str, default=&quot;aic&quot;</span>
<span class="sd">        The information criteria method to be used.</span>
<span class="sd">    n_terms : int, default=None</span>
<span class="sd">        The number of the model terms to be selected.</span>
<span class="sd">        Note that n_terms overwrite the information criteria</span>
<span class="sd">        values.</span>
<span class="sd">    n_inputs : int, default=1</span>
<span class="sd">        The number of inputs of the system.</span>
<span class="sd">    n_info_values : int, default=10</span>
<span class="sd">        The number of iterations of the information</span>
<span class="sd">        criteria method.</span>
<span class="sd">    estimator : str, default=&quot;least_squares&quot;</span>
<span class="sd">        The parameter estimation method.</span>
<span class="sd">    extended_least_squres : bool, default=False</span>
<span class="sd">        Whether to use extended least squres method</span>
<span class="sd">        for parameter estimation.</span>
<span class="sd">        Note that we define a specific set of noise regressors.</span>
<span class="sd">    aux_lag : int, default=1</span>
<span class="sd">        Temporary lag value used only for parameter estimation.</span>
<span class="sd">        This value is overwriten by the max_lag value and will</span>
<span class="sd">        be removed in v0.1.4.</span>
<span class="sd">    lam : float, default=0.98</span>
<span class="sd">        Forgetting factor of the Recursive Least Squares method.</span>
<span class="sd">    delta : float, default=0.01</span>
<span class="sd">        Normalization factor of the P matrix.</span>
<span class="sd">    offset_covariance : float, default=0.2</span>
<span class="sd">        The offset covariance factor of the affine least mean squares</span>
<span class="sd">        filter.</span>
<span class="sd">    mu : float, defaul=0.01</span>
<span class="sd">        The convergence coefficient (learning rate) of the filter.</span>
<span class="sd">    eps : float</span>
<span class="sd">        Normalization factor of the normalized filters.</span>
<span class="sd">    gama : float, default=0.2</span>
<span class="sd">        The leakage factor of the Leaky LMS method.</span>
<span class="sd">    weight : float, default=0.02</span>
<span class="sd">        Weight factor to control the proportions of the error norms</span>
<span class="sd">        and offers an extra degree of freedom within the adaptation</span>
<span class="sd">        of the LMS mixed norm method.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">    &gt;&gt;&gt; from sysidentpy.polynomial_basis import PolynomialNarmax</span>
<span class="sd">    &gt;&gt;&gt; from sysidentpy.metrics import root_relative_squared_error</span>
<span class="sd">    &gt;&gt;&gt; from sysidentpy.utils.generate_data import get_miso_data, get_siso_data</span>
<span class="sd">    &gt;&gt;&gt; x_train, x_valid, y_train, y_valid = get_siso_data(n=1000,</span>
<span class="sd">    ...                                                    colored_noise=True,</span>
<span class="sd">    ...                                                    sigma=0.2,</span>
<span class="sd">    ...                                                    train_percentage=90)</span>
<span class="sd">    &gt;&gt;&gt; model = PolynomialNarmax(non_degree=2,</span>
<span class="sd">    ...                          order_selection=True,</span>
<span class="sd">    ...                          n_info_values=10,</span>
<span class="sd">    ...                          extended_least_squares=False,</span>
<span class="sd">    ...                          ylag=2, xlag=2,</span>
<span class="sd">    ...                          info_criteria=&#39;aic&#39;,</span>
<span class="sd">    ...                          estimator=&#39;least_squares&#39;,</span>
<span class="sd">    ...                          )</span>
<span class="sd">    &gt;&gt;&gt; model.fit(x_train, y_train)</span>
<span class="sd">    &gt;&gt;&gt; yhat = model.predict(x_valid, y_valid)</span>
<span class="sd">    &gt;&gt;&gt; rrse = root_relative_squared_error(y_valid, yhat)</span>
<span class="sd">    &gt;&gt;&gt; print(rrse)</span>
<span class="sd">    0.001993603325328823</span>
<span class="sd">    &gt;&gt;&gt; results = pd.DataFrame(model.results(err_precision=8,</span>
<span class="sd">    ...                                      dtype=&#39;dec&#39;),</span>
<span class="sd">    ...                        columns=[&#39;Regressors&#39;, &#39;Parameters&#39;, &#39;ERR&#39;])</span>
<span class="sd">    &gt;&gt;&gt; print(results)</span>
<span class="sd">        Regressors Parameters         ERR</span>
<span class="sd">    0        x1(k-2)     0.9000  0.95556574</span>
<span class="sd">    1         y(k-1)     0.1999  0.04107943</span>
<span class="sd">    2  x1(k-1)y(k-1)     0.1000  0.00335113</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    [1] Manuscript: Orthogonal least squares methods and their application</span>
<span class="sd">        to non-linear system identification</span>
<span class="sd">        https://eprints.soton.ac.uk/251147/1/778742007_content.pdf</span>
<span class="sd">    [2] Manuscript (portuguese): Identificação de Sistemas não Lineares</span>
<span class="sd">        Utilizando Modelos NARMAX Polinomiais–Uma Revisão</span>
<span class="sd">        e Novos Resultados</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">non_degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">ylag</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">xlag</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">order_selection</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">info_criteria</span><span class="o">=</span><span class="s2">&quot;aic&quot;</span><span class="p">,</span>
        <span class="n">n_terms</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">n_inputs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">n_info_values</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">estimator</span><span class="o">=</span><span class="s2">&quot;least_squares&quot;</span><span class="p">,</span>
        <span class="n">extended_least_squares</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">aux_lag</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">lam</span><span class="o">=</span><span class="mf">0.98</span><span class="p">,</span>
        <span class="n">delta</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">offset_covariance</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="n">mu</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">eps</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span>
        <span class="n">gama</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="n">weight</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span>
    <span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">non_degree</span> <span class="o">=</span> <span class="n">non_degree</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_order_selection</span> <span class="o">=</span> <span class="n">order_selection</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_inputs</span> <span class="o">=</span> <span class="n">n_inputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ylag</span> <span class="o">=</span> <span class="n">ylag</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xlag</span> <span class="o">=</span> <span class="n">xlag</span>
        <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor_code</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">]</span> <span class="o">=</span> <span class="n">GenerateRegressors</span><span class="p">()</span><span class="o">.</span><span class="n">regressor_space</span><span class="p">(</span>
            <span class="n">non_degree</span><span class="p">,</span> <span class="n">xlag</span><span class="p">,</span> <span class="n">ylag</span><span class="p">,</span> <span class="n">n_inputs</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">info_criteria</span> <span class="o">=</span> <span class="n">info_criteria</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_info_values</span> <span class="o">=</span> <span class="n">n_info_values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span> <span class="o">=</span> <span class="n">n_terms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">estimator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_extended_least_squares</span> <span class="o">=</span> <span class="n">extended_least_squares</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_mu</span> <span class="o">=</span> <span class="n">mu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_offset_covariance</span> <span class="o">=</span> <span class="n">offset_covariance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_aux_lag</span> <span class="o">=</span> <span class="n">aux_lag</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_lam</span> <span class="o">=</span> <span class="n">lam</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_delta</span> <span class="o">=</span> <span class="n">delta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_gama</span> <span class="o">=</span> <span class="n">gama</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weight</span> <span class="o">=</span> <span class="n">weight</span>  <span class="c1"># &lt;0  e &lt;1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_params</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_validate_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Validate input params.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_info_values</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_info_values</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;n_info_values must be integer and &gt; zero. Got </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_info_values</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_inputs</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_inputs</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;n_inputs must be integer and &gt; zero. Got </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_inputs</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_order_selection</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;order_selection must be False or True. Got </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_order_selection</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_extended_least_squares</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;extended_least_squares must be False or True. Got </span><span class="si">%f</span><span class="s2">&quot;</span>
                <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extended_least_squares</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">info_criteria</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;aic&quot;</span><span class="p">,</span> <span class="s2">&quot;bic&quot;</span><span class="p">,</span> <span class="s2">&quot;fpe&quot;</span><span class="p">,</span> <span class="s2">&quot;lilc&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;info_criteria must be aic, bic, fpe or lilc. Got </span><span class="si">%s</span><span class="s2">&quot;</span>
                <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">info_criteria</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span> <span class="o">&lt;</span> <span class="mi">1</span>
        <span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;n_terms must be integer and &gt; zero. Got </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor_code</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor_code</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="s2">&quot;n_terms is greater than the maximum number of &quot;</span>
                    <span class="s2">&quot;all regressors space considering the chosen y_lag,&quot;</span>
                    <span class="s2">&quot;u_lag, and non_degree. We set as &quot;</span>
                    <span class="s2">&quot;</span><span class="si">%d</span><span class="s2"> &quot;</span>
                <span class="p">)</span>
                <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor_code</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>

<div class="viewcode-block" id="PolynomialNarmax.error_reduction_ratio"><a class="viewcode-back" href="../../../code.html#sysidentpy.polynomial_basis.narmax.PolynomialNarmax.error_reduction_ratio">[docs]</a>    <span class="k">def</span> <span class="nf">error_reduction_ratio</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">process_term_number</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Perform the Error Reduction Ration algorithm.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y : array-like of shape = n_samples</span>
<span class="sd">            The target data used in the identification process.</span>
<span class="sd">        psi : ndarray of floats</span>
<span class="sd">            The information matrix of the model.</span>
<span class="sd">        process_term_number : int</span>
<span class="sd">            Number of Process Terms defined by the user.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        err : array-like of shape = number_of_model_elements</span>
<span class="sd">            The respective ERR calculated for each regressor.</span>
<span class="sd">        piv : array-like of shape = number_of_model_elements</span>
<span class="sd">            Contains the index to put the regressors in the correct order</span>
<span class="sd">            based on err values.</span>
<span class="sd">        psi_orthogonal : ndarray of floats</span>
<span class="sd">            The updated and orthogonal information matrix.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Manuscript: Orthogonal least squares methods and their application</span>
<span class="sd">            to non-linear system identification</span>
<span class="sd">            https://eprints.soton.ac.uk/251147/1/778742007_content.pdf</span>

<span class="sd">        [2] Manuscript (portuguese): Identificação de Sistemas não Lineares</span>
<span class="sd">            Utilizando Modelos NARMAX Polinomiais–Uma Revisão</span>
<span class="sd">            e Novos Resultados</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">squared_y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">:]</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">:]</span>
        <span class="n">tmp_psi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">:,</span> <span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">T</span>
        <span class="n">tmp_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">dimension</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp_psi</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">piv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">dimension</span><span class="p">)</span>
        <span class="n">tmp_err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">dimension</span><span class="p">)</span>
        <span class="n">err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">dimension</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dimension</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">dimension</span><span class="p">):</span>
                <span class="n">num</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tmp_psi</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">n</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">tmp_y</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">n</span><span class="p">])</span>
                <span class="n">num</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">den</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">tmp_psi</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">n</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">tmp_psi</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">n</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span> <span class="o">*</span> <span class="n">squared_y</span><span class="p">)</span>
                <span class="n">tmp_err</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">num</span> <span class="o">/</span> <span class="n">den</span>

            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">process_term_number</span><span class="p">:</span>
                <span class="k">break</span>

            <span class="n">tmp_err</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tmp_err</span><span class="p">)</span>
            <span class="n">piv_index</span> <span class="o">=</span> <span class="n">tmp_err</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">tmp_err</span><span class="p">[</span><span class="n">i</span><span class="p">:]))</span>
            <span class="n">err</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp_err</span><span class="p">[</span><span class="n">piv_index</span><span class="p">]</span>
            <span class="n">tmp_psi</span><span class="p">[:,</span> <span class="p">[</span><span class="n">piv_index</span><span class="p">,</span> <span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">tmp_psi</span><span class="p">[:,</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">piv_index</span><span class="p">]]</span>
            <span class="n">piv</span><span class="p">[[</span><span class="n">piv_index</span><span class="p">,</span> <span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">piv</span><span class="p">[[</span><span class="n">i</span><span class="p">,</span> <span class="n">piv_index</span><span class="p">]]</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">tmp_psi</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">n</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>

            <span class="n">v</span> <span class="o">=</span> <span class="n">HouseHolder</span><span class="p">()</span><span class="o">.</span><span class="n">_house</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

            <span class="n">aux_1</span> <span class="o">=</span> <span class="n">tmp_psi</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">n</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span><span class="n">dimension</span><span class="p">]</span>

            <span class="n">row_result</span> <span class="o">=</span> <span class="n">HouseHolder</span><span class="p">()</span><span class="o">.</span><span class="n">_rowhouse</span><span class="p">(</span><span class="n">aux_1</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

            <span class="n">tmp_y</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">HouseHolder</span><span class="p">()</span><span class="o">.</span><span class="n">_rowhouse</span><span class="p">(</span><span class="n">tmp_y</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">n</span><span class="p">],</span> <span class="n">v</span><span class="p">)</span>

            <span class="n">tmp_psi</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">n</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span><span class="n">dimension</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">row_result</span><span class="p">)</span>

        <span class="n">tmp_piv</span> <span class="o">=</span> <span class="n">piv</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">process_term_number</span><span class="p">]</span>
        <span class="n">tmp_psi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span>
        <span class="n">psi_orthogonal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">tmp_psi</span><span class="p">[:,</span> <span class="n">tmp_piv</span><span class="p">])</span>
        <span class="n">tmp_psi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">psi</span><span class="p">)</span>
        <span class="n">regressor_code_buffer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor_code</span>
        <span class="n">model_code</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">regressor_code_buffer</span><span class="p">[</span><span class="n">tmp_piv</span><span class="p">,</span> <span class="p">:])</span>
        <span class="k">return</span> <span class="n">model_code</span><span class="p">,</span> <span class="n">err</span><span class="p">,</span> <span class="n">piv</span><span class="p">,</span> <span class="n">psi_orthogonal</span></div>

<div class="viewcode-block" id="PolynomialNarmax.fit"><a class="viewcode-back" href="../../../code.html#sysidentpy.polynomial_basis.narmax.PolynomialNarmax.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fit polynomial NARMAX model.</span>

<span class="sd">        This is an &#39;alpha&#39; version of the &#39;fit&#39; function which allows</span>
<span class="sd">        a friendly usage by the user. Given two arguments, X and y, fit</span>
<span class="sd">        training data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : ndarray of floats</span>
<span class="sd">            The input data to be used in the training process.</span>
<span class="sd">        y : ndarray of floats</span>
<span class="sd">            The output data to be used in the training process.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        model : ndarray of ints</span>
<span class="sd">            The model code represetation.</span>
<span class="sd">        piv : array-like of shape = number_of_model_elements</span>
<span class="sd">            Contains the index to put the regressors in the correct order</span>
<span class="sd">            based on err values.</span>
<span class="sd">        theta : array-like of shape = number_of_model_elements</span>
<span class="sd">            The estimated parameters of the model.</span>
<span class="sd">        err : array-like of shape = number_of_model_elements</span>
<span class="sd">            The respective ERR calculated for each regressor.</span>
<span class="sd">        info_values : array-like of shape = n_regressor</span>
<span class="sd">            Vector with values of akaike&#39;s information criterion</span>
<span class="sd">            for models with N terms (where N is the</span>
<span class="sd">            vector position + 1).</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;y cannot be None&quot;</span><span class="p">)</span>

        <span class="n">check_X_y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="n">reg_Matrix</span> <span class="o">=</span> <span class="n">InformationMatrix</span><span class="p">()</span><span class="o">.</span><span class="n">build_information_matrix</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xlag</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ylag</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">non_degree</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_order_selection</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">info_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">information_criterion</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_order_selection</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">model_length</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">info_values</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">info_values</span><span class="p">))</span>
            <span class="n">model_length</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">model_length</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span> <span class="o">=</span> <span class="n">model_length</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_order_selection</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">True</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;If order_selection is False, you must define n_terms value.&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">model_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span>

        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">final_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">err</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pivv</span><span class="p">,</span> <span class="n">psi</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_reduction_ratio</span><span class="p">(</span>
            <span class="n">reg_Matrix</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">model_length</span>
        <span class="p">)</span>

        <span class="c1"># I know... the &#39;method&#39; below needs attention</span>
        <span class="n">parameter_estimation</span> <span class="o">=</span> <span class="n">Estimators</span><span class="p">(</span>
            <span class="n">aux_lag</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">,</span>
            <span class="n">lam</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_lam</span><span class="p">,</span>
            <span class="n">delta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_delta</span><span class="p">,</span>
            <span class="n">offset_covariance</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_offset_covariance</span><span class="p">,</span>
            <span class="n">mu</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_mu</span><span class="p">,</span>
            <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_eps</span><span class="p">,</span>
            <span class="n">gama</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_gama</span><span class="p">,</span>
            <span class="n">weight</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_weight</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">parameter_estimation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="p">)(</span><span class="n">psi</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extended_least_squares</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unbiased_estimator</span><span class="p">(</span>
                <span class="n">psi</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">,</span> <span class="n">parameter_estimation</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

    <span class="k">def</span> <span class="nf">_unbiased_estimator</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">psi</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">biased_theta</span><span class="p">,</span> <span class="n">aux_lag</span><span class="p">,</span> <span class="n">parameter_estimation</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Estimate the model parameters using Extended Least Squares method.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        psi : ndarray of floats</span>
<span class="sd">            The information matrix of the model.</span>
<span class="sd">        X : ndarray of floats</span>
<span class="sd">            The input data to be used in the training process.</span>
<span class="sd">        y_train : array-like of shape = y_training</span>
<span class="sd">            The data used to training the model.</span>
<span class="sd">        biased_theta : array-like of shape = number_of_model_elements</span>
<span class="sd">            The estimated biased parameters of the model.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array-like of shape = number_of_model_elements</span>
<span class="sd">            The estimated unbiased parameters of the model.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        [1] Manuscript: Sorenson, H. W. (1970). Least-squares estimation:</span>
<span class="sd">            from Gauss to Kalman. IEEE spectrum, 7(7), 63-68.</span>
<span class="sd">            http://pzs.dstu.dp.ua/DataMining/mls/bibl/Gauss2Kalman.pdf</span>
<span class="sd">        [2] Book (Portuguese): Aguirre, L. A. (2007). Introduçaoa identificaçao</span>
<span class="sd">            de sistemas: técnicas lineares enao-lineares aplicadas a sistemas</span>
<span class="sd">            reais. Editora da UFMG. 3a ediçao.</span>
<span class="sd">        [3] Manuscript: Markovsky, I., &amp; Van Huffel, S. (2007).</span>
<span class="sd">            Overview of total least-squares methods.</span>
<span class="sd">            Signal processing, 87(10), 2283-2302.</span>
<span class="sd">            https://eprints.soton.ac.uk/263855/1/tls_overview.pdf</span>
<span class="sd">        [4] Wikipedia entry on Least Squares</span>
<span class="sd">            https://en.wikipedia.org/wiki/Least_squares</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">e</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">aux_lag</span><span class="p">:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">psi</span> <span class="o">@</span> <span class="n">biased_theta</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">30</span><span class="p">):</span>
            <span class="n">e</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">aux_lag</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">e</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">ee</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">e</span><span class="p">,</span> <span class="n">X</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">elag</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="n">aux_lag</span><span class="p">]]</span> <span class="o">*</span> <span class="n">ee</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">psi_extended</span> <span class="o">=</span> <span class="n">InformationMatrix</span><span class="p">()</span><span class="o">.</span><span class="n">build_information_matrix</span><span class="p">(</span>
                <span class="n">ee</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">elag</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>
            <span class="p">)</span>

            <span class="n">psi_extended</span> <span class="o">=</span> <span class="n">psi_extended</span><span class="p">[:,</span> <span class="p">[</span>
                <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">]]</span>

            <span class="n">psi_e</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">psi</span><span class="p">,</span> <span class="n">psi_extended</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">unbiased_theta</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
                <span class="n">parameter_estimation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="p">)(</span><span class="n">psi_e</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">e</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">aux_lag</span><span class="p">:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> \
                <span class="n">psi_e</span> <span class="o">@</span> <span class="n">unbiased_theta</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">unbiased_theta</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">final_model</span><span class="p">),</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<div class="viewcode-block" id="PolynomialNarmax.predict"><a class="viewcode-back" href="../../../code.html#sysidentpy.polynomial_basis.narmax.PolynomialNarmax.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">steps_ahead</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the predicted values given an input.</span>

<span class="sd">        The predict function allows a friendly usage by the user.</span>
<span class="sd">        Given a previously trained model, predict values given</span>
<span class="sd">        a new set of data.</span>

<span class="sd">        This method accept y values mainly for prediction n-steps ahead</span>
<span class="sd">        (to be implemented in the future)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : ndarray of floats</span>
<span class="sd">            The input data to be used in the prediction process.</span>
<span class="sd">        y : ndarray of floats</span>
<span class="sd">            The output data to be used in the prediction process.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        yhat : ndarray of floats</span>
<span class="sd">            The predicted values of the model.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">steps_ahead</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_prediction</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">steps_ahead</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_one_step_ahead_prediction</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_positive_int</span><span class="p">(</span><span class="n">steps_ahead</span><span class="p">,</span> <span class="s1">&#39;steps_ahead&#39;</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_step_ahead_prediction</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">steps_ahead</span><span class="o">=</span><span class="n">steps_ahead</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_code2exponents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">code</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert regressor code to exponents array.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        code : 1D-array of ints</span>
<span class="sd">            Codification of one regressor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">regressors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">code</span><span class="p">)))</span>
        <span class="n">regressors_count</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">code</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">regressors</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_inputs</span><span class="p">))</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">exponents</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
            <span class="n">elements</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">regressors</span><span class="p">,</span> <span class="mi">1000</span><span class="p">),</span> <span class="mi">0</span><span class="p">)[</span>
                <span class="p">(</span><span class="n">regressors</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
            <span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_inputs</span> <span class="o">+</span> <span class="mi">2</span><span class="p">):</span>
                <span class="n">base_exponents</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">elements</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
                        <span class="n">regressor_code</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">j</span> <span class="o">*</span> <span class="mi">1000</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span>
                        <span class="n">base_exponents</span><span class="p">[</span><span class="o">-</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">regressors_count</span><span class="p">[</span><span class="n">regressor_code</span><span class="p">]</span>
                    <span class="n">exponents</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">exponents</span><span class="p">,</span> <span class="n">base_exponents</span><span class="p">)</span>

                <span class="k">else</span><span class="p">:</span>
                    <span class="n">exponents</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">exponents</span><span class="p">,</span> <span class="n">base_exponents</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">exponents</span>

    <span class="k">def</span> <span class="nf">_check_positive_int</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">value</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> must be integer and &gt; zero. Got </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_one_step_ahead_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Perform the 1-step-ahead prediction of a model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y : array-like of shape = max_lag</span>
<span class="sd">            Initial conditions values of the model</span>
<span class="sd">            to start recursive process.</span>
<span class="sd">        X : ndarray of floats of shape = n_samples</span>
<span class="sd">            Vector with entrace values to be used in model simulation.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        yhat : ndarray of floats</span>
<span class="sd">               The 1-step-ahead predicted values of the model.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X_base</span> <span class="o">=</span> <span class="n">InformationMatrix</span><span class="p">()</span><span class="o">.</span><span class="n">build_information_matrix</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xlag</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ylag</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">non_degree</span>
        <span class="p">)</span>
        <span class="n">piv_final_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pivv</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">final_model</span><span class="p">)]</span>
        <span class="n">X_base</span> <span class="o">=</span> <span class="n">X_base</span><span class="p">[:,</span> <span class="n">piv_final_model</span><span class="p">]</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_base</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">y</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">yhat</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">yhat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_n_step_ahead_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">steps_ahead</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Perform the n-steps-ahead prediction of a model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y : array-like of shape = max_lag</span>
<span class="sd">            Initial conditions values of the model</span>
<span class="sd">            to start recursive process.</span>
<span class="sd">        X : ndarray of floats of shape = n_samples</span>
<span class="sd">            Vector with entrace values to be used in model simulation.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        yhat : ndarray of floats</span>
<span class="sd">               The n-steps-ahead predicted values of the model.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Insufficient initial conditions elements!&quot;</span><span class="p">)</span>

        <span class="n">yhat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">yhat</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="n">yhat</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_inputs</span><span class="p">)</span>
        <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
            <span class="n">k</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">+</span> <span class="n">steps_ahead</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
                <span class="n">steps_ahead</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="n">i</span>  <span class="c1"># predicts the remaining values</span>

            <span class="n">yhat</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">steps_ahead</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_prediction</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">final_model</span><span class="p">,</span>
                <span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">steps_ahead</span><span class="p">],</span>
                <span class="n">y</span><span class="p">[</span><span class="n">k</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">steps_ahead</span><span class="p">],</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">)[</span><span class="o">-</span><span class="n">steps_ahead</span><span class="p">:]</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

            <span class="n">i</span> <span class="o">+=</span> <span class="n">steps_ahead</span>

        <span class="n">yhat</span> <span class="o">=</span> <span class="n">yhat</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">yhat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_model_prediction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y_initial</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Perform the infinity steps-ahead simulation of a model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y_initial : array-like of shape = max_lag</span>
<span class="sd">            Number of initial conditions values of output mensured</span>
<span class="sd">            to start recursive process.</span>
<span class="sd">        X : ndarray of floats of shape = n_samples</span>
<span class="sd">            Vector with entrace values to be used in model simulation.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        yhat : ndarray of floats</span>
<span class="sd">               The predicted values of the model.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_initial</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Insufficient initial conditions elements!&quot;</span><span class="p">)</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_inputs</span><span class="p">)</span>
        <span class="n">y_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">y_output</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="n">y_output</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_initial</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="n">model_exponents</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_code2exponents</span><span class="p">(</span>
            <span class="n">model</span><span class="p">)</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_model</span><span class="p">]</span>
        <span class="n">raw_regressor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model_exponents</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">init</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">final</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span>
            <span class="n">k</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">)</span>
            <span class="n">raw_regressor</span><span class="p">[:</span><span class="n">final</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_output</span><span class="p">[</span><span class="n">k</span><span class="p">:</span><span class="n">i</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_inputs</span><span class="p">):</span>
                <span class="n">init</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span>
                <span class="n">final</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span>
                <span class="n">raw_regressor</span><span class="p">[</span><span class="n">init</span><span class="p">:</span><span class="n">final</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">:</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>

            <span class="n">regressor_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model_exponents</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model_exponents</span><span class="p">)):</span>
                <span class="n">regressor_value</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">raw_regressor</span><span class="p">,</span> <span class="n">model_exponents</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
                <span class="p">)</span>

            <span class="n">y_output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">regressor_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">y_output</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<div class="viewcode-block" id="PolynomialNarmax.information_criterion"><a class="viewcode-back" href="../../../code.html#sysidentpy.polynomial_basis.narmax.PolynomialNarmax.information_criterion">[docs]</a>    <span class="k">def</span> <span class="nf">information_criterion</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Determine the model order.</span>

<span class="sd">        This function uses a information criterion to determine the model size.</span>
<span class="sd">        &#39;Akaike&#39;-  Akaike&#39;s Information Criterion with</span>
<span class="sd">                   critical value 2 (AIC) (default).</span>
<span class="sd">        &#39;Bayes&#39; -  Bayes Information Criterion (BIC).</span>
<span class="sd">        &#39;FPE&#39;   -  Final Prediction Error (FPE).</span>
<span class="sd">        &#39;LILC&#39;  -  Khundrin’s law ofiterated logarithm criterion (LILC).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y : array-like of shape = n_samples</span>
<span class="sd">            Target values of the system.</span>
<span class="sd">        X : array-like of shape = n_samples</span>
<span class="sd">            Input system values measured by the user.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        output_vector : array-like of shape = n_regressor</span>
<span class="sd">            Vector with values of akaike&#39;s information criterion</span>
<span class="sd">            for models with N terms (where N is the</span>
<span class="sd">            vector position + 1).</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_info_values</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_info_values</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor_code</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_info_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor_code</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="s2">&quot;n_info_values is greater than the maximum number &quot;</span>
                    <span class="s2">&quot;of all regressors space considering the chosen &quot;</span>
                    <span class="s2">&quot;y_lag, u_lag, and non_degree. We set as &quot;</span>
                    <span class="s2">&quot;</span><span class="si">%d</span><span class="s2"> &quot;</span>
                <span class="p">)</span>
                <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor_code</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">output_vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_info_values</span><span class="p">)</span>
        <span class="n">output_vector</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="n">X_base</span> <span class="o">=</span> <span class="n">InformationMatrix</span><span class="p">()</span><span class="o">.</span><span class="n">build_information_matrix</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xlag</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ylag</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">non_degree</span>
        <span class="p">)</span>

        <span class="n">n_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span>

        <span class="n">parameter_estimation</span> <span class="o">=</span> <span class="n">Estimators</span><span class="p">(</span>
            <span class="n">aux_lag</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">,</span>
            <span class="n">lam</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_lam</span><span class="p">,</span>
            <span class="n">delta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_delta</span><span class="p">,</span>
            <span class="n">offset_covariance</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_offset_covariance</span><span class="p">,</span>
            <span class="n">mu</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_mu</span><span class="p">,</span>
            <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_eps</span><span class="p">,</span>
            <span class="n">gama</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_gama</span><span class="p">,</span>
            <span class="n">weight</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_weight</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_info_values</span><span class="p">):</span>
            <span class="n">n_theta</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">regressor_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_reduction_ratio</span><span class="p">(</span><span class="n">X_base</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">n_theta</span><span class="p">)[</span>
                <span class="mi">3</span><span class="p">]</span>

            <span class="n">tmp_theta</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">parameter_estimation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="p">)(</span>
                <span class="n">regressor_matrix</span><span class="p">,</span> <span class="n">y</span>
            <span class="p">)</span>

            <span class="n">tmp_yhat</span> <span class="o">=</span> <span class="n">regressor_matrix</span> <span class="o">@</span> <span class="n">tmp_theta</span>
            <span class="n">tmp_residual</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">:]</span> <span class="o">-</span> <span class="n">tmp_yhat</span>
            <span class="n">e_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">tmp_residual</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">output_vector</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_info_value</span><span class="p">(</span>
                <span class="n">n_theta</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">e_var</span><span class="p">)</span>

            <span class="c1"># output_vector[i] = e_factor + model_factor</span>

        <span class="k">return</span> <span class="n">output_vector</span></div>

<div class="viewcode-block" id="PolynomialNarmax.results"><a class="viewcode-back" href="../../../code.html#sysidentpy.polynomial_basis.narmax.PolynomialNarmax.results">[docs]</a>    <span class="k">def</span> <span class="nf">results</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta_precision</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">err_precision</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;dec&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Write the model regressors, parameters and ERR values.</span>

<span class="sd">        This function returns the model regressors, its respectives parameter</span>
<span class="sd">        and ERR value on a string matrix.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta_precision : int (default: 4)</span>
<span class="sd">            Precision of shown parameters values.</span>
<span class="sd">        err_precision : int (default: 8)</span>
<span class="sd">            Precision of shown ERR values.</span>
<span class="sd">        dtype : string (default: &#39;dec&#39;)</span>
<span class="sd">            Type of representation:</span>
<span class="sd">            sci - Scientific notation;</span>
<span class="sd">            dec - Decimal notation.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        output_matrix : string</span>
<span class="sd">            Where:</span>
<span class="sd">                First column represents each regressor element;</span>
<span class="sd">                Second column represents associated parameter;</span>
<span class="sd">                Third column represents the error reduction ratio associated</span>
<span class="sd">                to each regressor.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">theta_precision</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">theta_precision</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;theta_precision must be integer and &gt; zero. Got </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">theta_precision</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">err_precision</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">err_precision</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;err_precision must be integer and &gt; zero. Got </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">err_precision</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;dec&quot;</span><span class="p">,</span> <span class="s2">&quot;sci&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;dtype must be dec or sci. Got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">dtype</span><span class="p">)</span>

        <span class="n">output_matrix</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">theta_output_format</span> <span class="o">=</span> <span class="s2">&quot;{:.&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">theta_precision</span><span class="p">)</span>
        <span class="n">err_output_format</span> <span class="o">=</span> <span class="s2">&quot;{:.&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">err_precision</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">dtype</span> <span class="o">==</span> <span class="s2">&quot;dec&quot;</span><span class="p">:</span>
            <span class="n">theta_output_format</span> <span class="o">=</span> <span class="n">theta_output_format</span> <span class="o">+</span> <span class="s2">&quot;f}&quot;</span>
            <span class="n">err_output_format</span> <span class="o">=</span> <span class="n">err_output_format</span> <span class="o">+</span> <span class="s2">&quot;f}&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">theta_output_format</span> <span class="o">=</span> <span class="n">theta_output_format</span> <span class="o">+</span> <span class="s2">&quot;E}&quot;</span>
            <span class="n">err_output_format</span> <span class="o">=</span> <span class="n">err_output_format</span> <span class="o">+</span> <span class="s2">&quot;E}&quot;</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">final_model</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">tmp_regressor</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">regressor_dic</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">final_model</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="n">regressor_string</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">regressor_dic</span><span class="o">.</span><span class="n">keys</span><span class="p">()))):</span>
                    <span class="n">regressor_key</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">regressor_dic</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="n">j</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">regressor_key</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="n">translated_key</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
                        <span class="n">translated_exponent</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">delay_string</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span>
                            <span class="nb">int</span><span class="p">(</span><span class="n">regressor_key</span> <span class="o">-</span>
                                <span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">regressor_key</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>
                        <span class="p">)</span>
                        <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">regressor_key</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
                            <span class="n">translated_key</span> <span class="o">=</span> <span class="s2">&quot;y(k-&quot;</span> <span class="o">+</span> <span class="n">delay_string</span> <span class="o">+</span> <span class="s2">&quot;)&quot;</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">translated_key</span> <span class="o">=</span> <span class="p">(</span>
                                <span class="s2">&quot;x&quot;</span>
                                <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">regressor_key</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                                <span class="o">+</span> <span class="s2">&quot;(k-&quot;</span>
                                <span class="o">+</span> <span class="n">delay_string</span>
                                <span class="o">+</span> <span class="s2">&quot;)&quot;</span>
                            <span class="p">)</span>
                        <span class="k">if</span> <span class="n">regressor_dic</span><span class="p">[</span><span class="n">regressor_key</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
                            <span class="n">translated_exponent</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">translated_exponent</span> <span class="o">=</span> <span class="s2">&quot;^&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span>
                                <span class="n">regressor_dic</span><span class="p">[</span><span class="n">regressor_key</span><span class="p">]</span>
                            <span class="p">)</span>
                    <span class="n">regressor_string</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="n">translated_key</span> <span class="o">+</span> <span class="n">translated_exponent</span><span class="p">)</span>
                <span class="n">tmp_regressor</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">regressor_string</span><span class="p">)</span>

            <span class="n">current_parameter</span> <span class="o">=</span> <span class="n">theta_output_format</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
            <span class="n">current_err</span> <span class="o">=</span> <span class="n">err_output_format</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">err</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">current_output</span> <span class="o">=</span> <span class="p">[</span><span class="n">tmp_regressor</span><span class="p">,</span> <span class="n">current_parameter</span><span class="p">,</span> <span class="n">current_err</span><span class="p">]</span>
            <span class="n">output_matrix</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_output</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output_matrix</span></div>

<div class="viewcode-block" id="PolynomialNarmax.compute_info_value"><a class="viewcode-back" href="../../../code.html#sysidentpy.polynomial_basis.narmax.PolynomialNarmax.compute_info_value">[docs]</a>    <span class="k">def</span> <span class="nf">compute_info_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_theta</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">e_var</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute the information criteria value.</span>

<span class="sd">        This function returns the information criteria concerning each</span>
<span class="sd">        number of regressor. The informotion criteria can be AIC, BIC,</span>
<span class="sd">        LILC and FPE.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_theta : int</span>
<span class="sd">            Number of parameters of the model.</span>
<span class="sd">        n_samples : int</span>
<span class="sd">            Number of samples given the maximum lag.</span>
<span class="sd">        e_var : float</span>
<span class="sd">            Variance of the residues</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        info_criteria_value : float</span>
<span class="sd">            The computed value given the information criteria selected by the</span>
<span class="sd">            user.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">info_criteria</span> <span class="o">==</span> <span class="s2">&quot;bic&quot;</span><span class="p">:</span>
            <span class="n">model_factor</span> <span class="o">=</span> <span class="n">n_theta</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">info_criteria</span> <span class="o">==</span> <span class="s2">&quot;fpe&quot;</span><span class="p">:</span>
            <span class="n">model_factor</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
                <span class="p">(</span><span class="n">n_samples</span> <span class="o">+</span> <span class="n">n_theta</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_samples</span> <span class="o">-</span> <span class="n">n_theta</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">info_criteria</span> <span class="o">==</span> <span class="s2">&quot;lilc&quot;</span><span class="p">:</span>
            <span class="n">model_factor</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">n_theta</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n_samples</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># AIC</span>
            <span class="n">model_factor</span> <span class="o">=</span> <span class="o">+</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n_theta</span>

        <span class="n">e_factor</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">e_var</span><span class="p">)</span>
        <span class="n">info_criteria_value</span> <span class="o">=</span> <span class="n">e_factor</span> <span class="o">+</span> <span class="n">model_factor</span>

        <span class="k">return</span> <span class="n">info_criteria_value</span></div></div>
</pre></div>

              </div>
              
        
        <div class='prev-next-bottom'>
            

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Wilson Rocha, Luan Pascoal, Samuel Oliveira, Samir Martins<br/>
        
            &copy; Copyright 2020, Wilson Rocha, Luan Pascoal, Samuel Oliveira, Samir Martins.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>