{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Estimation - Overview\n",
    "\n",
    "Example created by Wilson Rocha Lacerda Junior\n",
    "\n",
    "> **Looking for more details on NARMAX models?**\n",
    "> For comprehensive information on models, methods, and a wide range of examples and benchmarks implemented in SysIdentPy, check out our book:\n",
    "> [*Nonlinear System Identification and Forecasting: Theory and Practice With SysIdentPy*](https://sysidentpy.org/book/0%20-%20Preface/)\n",
    ">\n",
    "> This book provides in-depth guidance to support your work with SysIdentPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import the NARMAX model, the metric for model evaluation and the methods to generate sample data for tests. Also, we import pandas for specific usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sysidentpy.model_structure_selection import FROLS\n",
    "from sysidentpy.basis_function import Polynomial\n",
    "from sysidentpy.parameter_estimation import (\n",
    "    TotalLeastSquares,\n",
    "    RecursiveLeastSquares,\n",
    "    NonNegativeLeastSquares,\n",
    "    LeastMeanSquares,\n",
    "    AffineLeastMeanSquares,\n",
    ")\n",
    "from sysidentpy.metrics import root_relative_squared_error\n",
    "from sysidentpy.utils.generate_data import get_siso_data\n",
    "from sysidentpy.utils.display_results import results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating 1 input 1 output sample data  \n",
    "\n",
    "The data is generated by simulating the following model:\n",
    "\n",
    "$y_k = 0.2y_{k-1} + 0.1y_{k-1}x_{k-1} + 0.9x_{k-1} + e_{k}$\n",
    "\n",
    "If *colored_noise* is set to True:\n",
    "\n",
    "$e_{k} = 0.8\\nu_{k-1} + \\nu_{k}$\n",
    "\n",
    "where $x$ is a uniformly distributed random variable and $\\nu$ is a gaussian distributed variable with $\\mu=0$ and $\\sigma=0.1$\n",
    "\n",
    "In the next example we will generate a data with 1000 samples with white noise and selecting 90% of the data to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = get_siso_data(\n",
    "    n=1000, colored_noise=False, sigma=0.001, train_percentage=90\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are several method to be used for parameter estimation.\n",
    "\n",
    "- Least Squares;\n",
    "- Total Least Squares;\n",
    "- Recursive Least Squares\n",
    "- Ridge Regression\n",
    "- NonNegative Least Squares\n",
    "- Least Squares Minimal Residues\n",
    "- Bounded Variable Least Squares\n",
    "- Least Mean Squares\n",
    "- Affine Least Mean Squares\n",
    "- Least Mean Squares Sign Error\n",
    "- Normalized Least Mean Squares\n",
    "- Least Mean Squares Normalized Sign Error\n",
    "- Least Mean Squares Sign Regressor\n",
    "- Least Mean Squares Normalized Sign Regressor\n",
    "- Least Mean Squares Sign Sign\n",
    "- Least Mean Squares Normalized Sign Sign\n",
    "- Least Mean Squares Normalized Leaky\n",
    "- Least Mean Squares Leaky\n",
    "- Least Mean Squares Fourth\n",
    "- Least Mean Squares Mixed Norm\n",
    "\n",
    "\n",
    "Polynomial NARMAX models are linear-in-the-parameter, so Least Squares based methods works well for most cases (using with extended least squares algorithm when dealing with colered noise).\n",
    "\n",
    "However, the user can choose some recursive and stochastic gradient descent methods (in this case, the least mean squares algorithm and its variants) to that task too.\n",
    "\n",
    "Choosing the method is straightforward: pass any of the methods mentioned above on estimator parameters.\n",
    "\n",
    "- **Note: Each algorithm have specifc parameter that need to be tunned. In the following examples we will use the default ones. More examples regarding tunned parameter will be available soon. For now, the user can read the method documentation for more information.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0021167167052431584\n",
      "      Regressors  Parameters             ERR\n",
      "0        x1(k-2)  9.0000E-01  9.56200123E-01\n",
      "1         y(k-1)  1.9995E-01  4.05078042E-02\n",
      "2  x1(k-1)y(k-1)  1.0004E-01  3.28866604E-03\n"
     ]
    }
   ],
   "source": [
    "basis_function = Polynomial(degree=2)\n",
    "estimator = TotalLeastSquares()\n",
    "\n",
    "model = FROLS(\n",
    "    order_selection=False,\n",
    "    n_terms=3,\n",
    "    ylag=2,\n",
    "    xlag=2,\n",
    "    estimator=estimator,\n",
    "    basis_function=basis_function,\n",
    ")\n",
    "model.fit(X=x_train, y=y_train)\n",
    "yhat = model.predict(X=x_valid, y=y_valid)\n",
    "rrse = root_relative_squared_error(y_valid, yhat)\n",
    "print(rrse)\n",
    "\n",
    "r = pd.DataFrame(\n",
    "    results(\n",
    "        model.final_model,\n",
    "        model.theta,\n",
    "        model.err,\n",
    "        model.n_terms,\n",
    "        err_precision=8,\n",
    "        dtype=\"sci\",\n",
    "    ),\n",
    "    columns=[\"Regressors\", \"Parameters\", \"ERR\"],\n",
    ")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0020703083403116164\n",
      "      Regressors  Parameters             ERR\n",
      "0        x1(k-2)  9.0012E-01  9.56200123E-01\n",
      "1         y(k-1)  2.0021E-01  4.05078042E-02\n",
      "2  x1(k-1)y(k-1)  9.9550E-02  3.28866604E-03\n"
     ]
    }
   ],
   "source": [
    "# recursive least squares\n",
    "basis_function = Polynomial(degree=2)\n",
    "estimator = RecursiveLeastSquares()\n",
    "\n",
    "model = FROLS(\n",
    "    order_selection=False,\n",
    "    n_terms=3,\n",
    "    ylag=2,\n",
    "    xlag=2,\n",
    "    estimator=estimator,\n",
    "    basis_function=basis_function,\n",
    ")\n",
    "model.fit(X=x_train, y=y_train)\n",
    "yhat = model.predict(X=x_valid, y=y_valid)\n",
    "rrse = root_relative_squared_error(y_valid, yhat)\n",
    "print(rrse)\n",
    "\n",
    "r = pd.DataFrame(\n",
    "    results(\n",
    "        model.final_model,\n",
    "        model.theta,\n",
    "        model.err,\n",
    "        model.n_terms,\n",
    "        err_precision=8,\n",
    "        dtype=\"sci\",\n",
    "    ),\n",
    "    columns=[\"Regressors\", \"Parameters\", \"ERR\"],\n",
    ")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Mean Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015488793944313425\n",
      "      Regressors  Parameters             ERR\n",
      "0        x1(k-2)  8.9775E-01  9.56200123E-01\n",
      "1         y(k-1)  2.0085E-01  4.05078042E-02\n",
      "2  x1(k-1)y(k-1)  7.5708E-02  3.28866604E-03\n"
     ]
    }
   ],
   "source": [
    "basis_function = Polynomial(degree=2)\n",
    "estimator = LeastMeanSquares()\n",
    "\n",
    "model = FROLS(\n",
    "    order_selection=False,\n",
    "    n_terms=3,\n",
    "    ylag=2,\n",
    "    xlag=2,\n",
    "    estimator=estimator,\n",
    "    basis_function=basis_function,\n",
    ")\n",
    "model.fit(X=x_train, y=y_train)\n",
    "yhat = model.predict(X=x_valid, y=y_valid)\n",
    "rrse = root_relative_squared_error(y_valid, yhat)\n",
    "print(rrse)\n",
    "\n",
    "r = pd.DataFrame(\n",
    "    results(\n",
    "        model.final_model,\n",
    "        model.theta,\n",
    "        model.err,\n",
    "        model.n_terms,\n",
    "        err_precision=8,\n",
    "        dtype=\"sci\",\n",
    "    ),\n",
    "    columns=[\"Regressors\", \"Parameters\", \"ERR\"],\n",
    ")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine Least Mean Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0021441596280611167\n",
      "      Regressors  Parameters             ERR\n",
      "0        x1(k-2)  8.9989E-01  9.56200123E-01\n",
      "1         y(k-1)  1.9992E-01  4.05078042E-02\n",
      "2  x1(k-1)y(k-1)  1.0003E-01  3.28866604E-03\n"
     ]
    }
   ],
   "source": [
    "basis_function = Polynomial(degree=2)\n",
    "estimator = AffineLeastMeanSquares()\n",
    "\n",
    "model = FROLS(\n",
    "    order_selection=False,\n",
    "    n_terms=3,\n",
    "    ylag=2,\n",
    "    xlag=2,\n",
    "    estimator=estimator,\n",
    "    basis_function=basis_function,\n",
    ")\n",
    "model.fit(X=x_train, y=y_train)\n",
    "yhat = model.predict(X=x_valid, y=y_valid)\n",
    "rrse = root_relative_squared_error(y_valid, yhat)\n",
    "print(rrse)\n",
    "\n",
    "r = pd.DataFrame(\n",
    "    results(\n",
    "        model.final_model,\n",
    "        model.theta,\n",
    "        model.err,\n",
    "        model.n_terms,\n",
    "        err_precision=8,\n",
    "        dtype=\"sci\",\n",
    "    ),\n",
    "    columns=[\"Regressors\", \"Parameters\", \"ERR\"],\n",
    ")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NonNegative Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0021170157359329173\n",
      "      Regressors  Parameters             ERR\n",
      "0        x1(k-2)  9.0000E-01  9.56200123E-01\n",
      "1         y(k-1)  1.9995E-01  4.05078042E-02\n",
      "2  x1(k-1)y(k-1)  1.0004E-01  3.28866604E-03\n"
     ]
    }
   ],
   "source": [
    "basis_function = Polynomial(degree=2)\n",
    "estimator = NonNegativeLeastSquares()\n",
    "\n",
    "model = FROLS(\n",
    "    order_selection=False,\n",
    "    n_terms=3,\n",
    "    ylag=2,\n",
    "    xlag=2,\n",
    "    estimator=estimator,\n",
    "    basis_function=basis_function,\n",
    ")\n",
    "model.fit(X=x_train, y=y_train)\n",
    "yhat = model.predict(X=x_valid, y=y_valid)\n",
    "rrse = root_relative_squared_error(y_valid, yhat)\n",
    "print(rrse)\n",
    "\n",
    "r = pd.DataFrame(\n",
    "    results(\n",
    "        model.final_model,\n",
    "        model.theta,\n",
    "        model.err,\n",
    "        model.n_terms,\n",
    "        err_precision=8,\n",
    "        dtype=\"sci\",\n",
    "    ),\n",
    "    columns=[\"Regressors\", \"Parameters\", \"ERR\"],\n",
    ")\n",
    "print(r)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e65fe37feb8ff9f7778552a28949e943d61f86c936833305e2c18cda5b438ac"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('rd': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
