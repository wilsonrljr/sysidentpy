---
template: overrides/main.html
title: Uso B√°sico
---

## 1. Pr√©-requisitos

Voc√™ precisa conhecer um pouco de Python.

Para executar os exemplos, al√©m do NumPy voc√™ precisar√° do `pandas` instalado.

```bash
pip install sysidentpy pandas
# Opcional: Para redes neurais e recursos avan√ßados
pip install sysidentpy["all"]
```

## 2. Principais Recursos

SysIdentPy oferece uma estrutura flex√≠vel para construir, validar e visualizar modelos n√£o lineares de s√©ries temporais e sistemas din√¢micos. O processo de modelagem envolve algumas etapas: definir a representa√ß√£o matem√°tica, escolher o algoritmo de estima√ß√£o de par√¢metros, selecionar a estrutura do modelo e determinar o horizonte de previs√£o.

Os seguintes recursos est√£o dispon√≠veis no SysIdentPy:

### Classes de Modelo
- NARMAX, NARX, NARMA, NAR, NFIR, ARMAX, ARX, AR e suas variantes.

### Representa√ß√µes Matem√°ticas
- Polynomial (Polinomial)
- Neural
- Fourier
- Laguerre
- Bernstein
- Bilinear
- Legendre
- Hermite
- HermiteNormalized

Voc√™ tamb√©m pode definir modelos NARX como Bayesian e Gradient Boosting usando a classe GeneralNARX, que oferece integra√ß√£o direta com v√°rios algoritmos de aprendizado de m√°quina.

### Algoritmos de Sele√ß√£o de Estrutura
- Forward Regression Orthogonal Least Squares (FROLS)
- Meta-model Structure Selection (MeMoSS / MetaMSS)
- Accelerated Orthogonal Least Squares (AOLS)
- Entropic Regression (ER)
- Ultra Orthogonal Least Squares (UOLS)

### M√©todos de Estima√ß√£o de Par√¢metros
- M√≠nimos Quadrados (MQ)
- Total Least Squares (TLS)
- M√≠nimos Quadrados Recursivos (MQR)
- Ridge Regression
- Non-Negative Least Squares (NNLS)
- Least Squares Minimal Residues (LSMR)
- Bounded Variable Least Squares (BVLS)
- Least Mean Squares (LMS) e suas variantes:
  - Affine LMS
  - LMS with Sign Error
  - Normalized LMS
  - LMS with Normalized Sign Error
  - LMS with Sign Regressor
  - Normalized LMS with Sign Sign
  - Leaky LMS
  - Fourth-Order LMS
  - Mixed Norm LMS

### Crit√©rios de Sele√ß√£o de Ordem
- Crit√©rio de Informa√ß√£o de Akaike (AIC)
- Crit√©rio de Informa√ß√£o de Akaike Corrigido (AICc)
- Crit√©rio de Informa√ß√£o Bayesiano (BIC)
- Final Prediction Error (FPE)
- Khundrin's Law of Iterated Logarithm Criterion (LILC)

### M√©todos de Previs√£o
- Um passo √† frente (one-step ahead)
- n passos √† frente (n-steps ahead)
- Infinito passos √† frente / simula√ß√£o livre (infinity-steps / free run simulation)

### Ferramentas de Visualiza√ß√£o
- Gr√°ficos de previs√£o
- An√°lise de res√≠duos
- Visualiza√ß√£o da estrutura do modelo
- Visualiza√ß√£o de par√¢metros

---

Como voc√™ pode ver, o SysIdentPy suporta diversas combina√ß√µes de modelos. N√£o se preocupe em escolher todas as configura√ß√µes logo no come√ßo. Vamos come√ßar com as configura√ß√µes padr√£o.

<div class="custom-collapsible-card">
    <input type="checkbox" id="toggle-info">
    <label for="toggle-info">
        üìö <strong>Em busca de mais detalhes sobre modelos NARMAX?</strong>
        <span class="arrow">‚ñº</span>
    </label>
    <div class="collapsible-content">
        <p>
            Para informa√ß√µes completas sobre modelos, m√©todos e um conjunto de exemplos e benchmarks implementados no <strong>SysIdentPy</strong>, confira nosso livro:
        </p>
        <a href="https://sysidentpy.org/book/0-Preface/" target="_blank">
            <em><strong>Nonlinear System Identification and Forecasting: Theory and Practice With SysIdentPy</strong></em>
        </a>
        <p>
            Esse livro oferece uma orienta√ß√£o detalhada para auxiliar no seu trabalho com o <strong>SysIdentPy</strong>.
        </p>
        <p>
            üõ†Ô∏è Voc√™ tamb√©m pode explorar os <a href="https://sysidentpy.org/user-guide/overview/" target="_blank"><strong>tutoriais na documenta√ß√£o</strong></a> para exemplos pr√°ticos.
        </p>
    </div>
</div>

## 3. Guia R√°pido

Para manter as coisas simples, vamos carregar alguns dados simulados para os exemplos.

```python
from sysidentpy.utils.generate_data import get_siso_data

# Gera um conjunto de dados de um sistema din√¢mico simulado.
x_train, x_valid, y_train, y_valid = get_siso_data(
        n=300,
        colored_noise=False,
        sigma=0.0001,
        train_percentage=80
)
```

### Construa seu primeiro modelo NARX

Com os dados carregados, vamos construir um modelo NARX Polinomial. Usando as configura√ß√µes padr√£o, voc√™ precisa definir pelo menos o m√©todo de sele√ß√£o de estrutura e a representa√ß√£o matem√°tica (fun√ß√£o base).

```python
import pandas as pd

from sysidentpy.model_structure_selection import FROLS
from sysidentpy.basis_function import Polynomial

basis_function = Polynomial(degree=2)
model = FROLS(
        ylag=2,
        xlag=2,
        basis_function=basis_function,
)
```

O m√©todo de sele√ß√£o de estrutura (MSS) habilita as opera√ß√µes de "treinamento" e previs√£o do modelo.

Embora diferentes algoritmos tenham diferentes hiperpar√¢metros, esse n√£o √© o foco aqui. Mostraremos como modific√°-los, mas n√£o discutiremos as melhores configura√ß√µes nesse guia.

```python
model.fit(X=x_train, y=y_train)
yhat = model.predict(X=x_valid, y=y_valid)
```

Para avaliar o desempenho, voc√™ pode usar qualquer m√©trica dispon√≠vel na biblioteca. Exemplo com Root Relative Squared Error (RRSE):

```python
from sysidentpy.metrics import root_relative_squared_error

rrse = root_relative_squared_error(y_valid, yhat)
print(rrse)
```

```console
0.00014
```

Para visualizar a equa√ß√£o final do modelo polinomial, use a fun√ß√£o `results`. Ela requer a seguinte configura√ß√£o:

- `final_model`: Regressoras selecionadas ap√≥s o ajuste
- `theta`: Par√¢metros estimados
- `err`: Error Reduction Ratio (ERR)

```python
from sysidentpy.utils.display_results import results

r = pd.DataFrame(
        results(
                model.final_model, model.theta, model.err,
                model.n_terms, err_precision=8, dtype='sci'
        ),
        columns=['Regressores', 'Par√¢metros', 'ERR'])
print(r)
```

Resultado (exemplo):

```console
Regressores     Par√¢metros        ERR
0        x1(k-2)     0.9000  0.95556574
1         y(k-1)     0.1999  0.04107943
2  x1(k-1)y(k-1)     0.1000  0.00335113
```

Para visualizar o desempenho do modelo:

```python
from sysidentpy.utils.plotting import plot_results

plot_results(y=y_valid, yhat=yhat, n=1000)
```
![](https://github.com/wilsonrljr/sysidentpy-data/blob/main/docs/images/quickstart-polynomial-narx.png?raw=true)

Analisar res√≠duos de um modelo √© essencial. Podemos calcular a autocorrela√ß√£o dos res√≠duos e correla√ß√£o cruzada entre res√≠duos e entradas conforme exemplo abaixo:

```python
from sysidentpy.utils.plotting import plot_residues_correlation
from sysidentpy.residues.residues_correlation import (
        compute_residues_autocorrelation,
        compute_cross_correlation,
)

# Autocorrela√ß√£o
ee = compute_residues_autocorrelation(y_valid, yhat)
plot_residues_correlation(data=ee, title="Res√≠duos", ylabel="$e^2$")

# Correla√ß√£o cruzada com uma entrada
x1e = compute_cross_correlation(y_valid, yhat, x_valid)
plot_residues_correlation(data=x1e, title="Res√≠duos", ylabel="$x_1e$")
```

<div style="display: flex; justify-content: space-between;">
    <img src="https://github.com/wilsonrljr/sysidentpy-data/blob/main/docs/images/quickstart-ee.png?raw=true" width="400" alt="Quickstart EE" />
    <img src="https://github.com/wilsonrljr/sysidentpy-data/blob/main/docs/images/quickstart-xe.png?raw=true" width="400" alt="Quickstart XE" />
</div>

C√≥digo completo para refer√™ncia:

```python
import pandas as pd

from sysidentpy.utils.generate_data import get_siso_data
from sysidentpy.model_structure_selection import FROLS
from sysidentpy.basis_function import Polynomial
from sysidentpy.metrics import root_relative_squared_error
from sysidentpy.utils.display_results import results
from sysidentpy.utils.plotting import plot_results
from sysidentpy.utils.plotting import plot_residues_correlation
from sysidentpy.residues.residues_correlation import (
        compute_residues_autocorrelation,
        compute_cross_correlation,
)

x_train, x_valid, y_train, y_valid = get_siso_data(
        n=300,
        colored_noise=False,
        sigma=0.0001,
        train_percentage=80
)

basis_function = Polynomial(degree=2)
model = FROLS(
        ylag=2,
        xlag=2,
        basis_function=basis_function,
)
model.fit(X=x_train, y=y_train)
yhat = model.predict(X=x_valid, y=y_valid)

rrse = root_relative_squared_error(y_valid, yhat)
print(rrse)

r = pd.DataFrame(
        results(
                model.final_model, model.theta, model.err,
                model.n_terms, err_precision=8, dtype='sci'
                ),
        columns=['Regressores', 'Par√¢metros', 'ERR'])
print(r)

plot_results(y=y_valid, yhat=yhat, n=1000, figsize=(15, 4))
ee = compute_residues_autocorrelation(y_valid, yhat)
plot_residues_correlation(data=ee, title="Res√≠duos", ylabel="$e^2$")
x1e = compute_cross_correlation(y_valid, yhat, x_valid)
plot_residues_correlation(data=x1e, title="Res√≠duos", ylabel="$x_1e$")
```

### Personalizando a configura√ß√£o do modelo

#### Sele√ß√£o de Estrutura

Para usar o algoritmo **AOLS** em vez de `FROLS`:

```python
from sysidentpy.model_structure_selection import AOLS
from sysidentpy.basis_function import Polynomial

basis_function = Polynomial(degree=2)
model = AOLS(
        ylag=2,
        xlag=2,
        basis_function=basis_function,
)
model.fit(X=x_train, y=y_train)
yhat = model.predict(X=x_valid, y=y_valid)
```

Usando **MetaMSS**:

```python
from sysidentpy.model_structure_selection import MetaMSS
from sysidentpy.basis_function import Polynomial

basis_function = Polynomial(degree=2)
model = MetaMSS(
        ylag=2,
        xlag=2,
        basis_function=basis_function,
)
model.fit(X=x_train, y=y_train)
yhat = model.predict(X=x_valid, y=y_valid)
```

Usando **Entropic Regression (ER)**:

```python
from sysidentpy.model_structure_selection import ER
from sysidentpy.basis_function import Polynomial

basis_function = Polynomial(degree=2)
model = ER(
        ylag=2,
        xlag=2,
        basis_function=basis_function,
)
model.fit(X=x_train, y=y_train)
yhat = model.predict(X=x_valid, y=y_valid)
```

#### Estima√ß√£o de Par√¢metros

Listar algoritmos dispon√≠veis:

```python
from sysidentpy import parameter_estimation
print("Algoritmos dispon√≠veis:", parameter_estimation.__all__)
```

Definir estimador espec√≠fico (ex: LSMR):

```python
from sysidentpy.model_structure_selection import ER
from sysidentpy.basis_function import Polynomial
from sysidentpy.parameter_estimation import LeastSquaresMinimalResidual

basis_function = Polynomial(degree=2)
model = ER(
        ylag=2,
        xlag=2,
        basis_function=basis_function,
        estimator=LeastSquaresMinimalResidual(),
)
model.fit(X=x_train, y=y_train)
yhat = model.predict(X=x_valid, y=y_valid)
```

#### Fun√ß√£o Base (Representa√ß√£o Matem√°tica)

Listar fun√ß√µes base:

```python
from sysidentpy import basis_function
print("Fun√ß√µes base dispon√≠veis:", basis_function.__all__)
```

Exemplo com Fourier:

```python
from sysidentpy.model_structure_selection import AOLS
from sysidentpy.basis_function import Fourier
from sysidentpy.parameter_estimation import LeastSquaresMinimalResidual

basis_function = Fourier(degree=2)
model = AOLS(
        ylag=2,
        xlag=2,
        basis_function=basis_function,
        estimator=LeastSquaresMinimalResidual(),
)
model.fit(X=x_train, y=y_train)
yhat = model.predict(X=x_valid, y=y_valid)
```

!!! note
        O m√©todo `results` suporta apenas a base **Polynomial** no momento. Suporte a todas as fun√ß√µes de base est√° planejado para a vers√£o 1.0.

#### Customizando o Tipo de Modelo

Diferen√ßa entre **NARX** e **ARX**: presen√ßa de termos n√£o lineares. `degree=2` (Polynomial) permite um modelo potencialmente NARX; `degree=1` resulta em ARX. Por√©m, a linearidade final depende da equa√ß√£o obtida pelo m√©todo de sele√ß√£o de estrutura.

```python
from sysidentpy.model_structure_selection import FROLS
from sysidentpy.basis_function import Polynomial

basis_function = Polynomial(degree=1)  # ARX
model = FROLS(
        ylag=2,
        xlag=2,
        basis_function=basis_function,
)
model.fit(X=x_train, y=y_train)
yhat = model.predict(X=x_valid, y=y_valid)
```

Para criar um **NAR**:

```python
from sysidentpy.model_structure_selection import FROLS
from sysidentpy.basis_function import Polynomial

basis_function = Polynomial(degree=1)
model = FROLS(
        ylag=2,
        basis_function=basis_function,
        model_type="NAR",
)
model.fit(y=y_train)
yhat = model.predict(y=y_valid, forecast_horizon=23)
```

Para **NFIR** (apenas entradas):

```python
from sysidentpy.model_structure_selection import FROLS
from sysidentpy.basis_function import Polynomial

basis_function = Polynomial(degree=1)
model = FROLS(
        xlag=2,
        basis_function=basis_function,
        model_type="NFIR",
)
model.fit(X=x_train, y=y_train)
yhat = model.predict(X=x_valid, y=y_valid)
```

<div class="custom-collapsible-card">
    <input type="checkbox" id="initial-info">
    <label for="initial-info">
        üìö <strong>Quer saber mais detalhes sobre condi√ß√µes iniciais?</strong>
        <span class="arrow">‚ñº</span>
    </label>
    <div class="collapsible-content">
        <p>
            Veja o cap√≠tulo 9 do nosso livro para entender por que modelos autorregressivos precisam de condi√ß√µes iniciais:
        </p>
        <a href="https://sysidentpy.org/book/9-Validation/" target="_blank">
            <em><strong>Nonlinear System Identification and Forecasting: Theory and Practice With SysIdentPy</strong></em>
        </a>
    </div>
</div>

#### Horizonte de Previs√£o

Por padr√£o, `predict` realiza previs√£o de infinitos passos a frente (ou simula√ß√£o livre). Para um n√∫mero espec√≠fico de passos √† frente, use `steps_ahead`:

```python
from sysidentpy.model_structure_selection import FROLS
from sysidentpy.basis_function import Polynomial

basis_function = Polynomial(degree=2)
model = FROLS(
        ylag=2,
        xlag=2,
        basis_function=basis_function,
)
model.fit(X=x_train, y=y_train)

yhat_1 = model.predict(X=x_valid, y=y_valid, steps_ahead=1)
yhat_4 = model.predict(X=x_valid, y=y_valid, steps_ahead=4)
```

<div class="custom-collapsible-card">
    <input type="checkbox" id="steps-info">
    <label for="steps-info">
        üìö <strong>Mais detalhes sobre previs√£o com diferentes passos a frente?</strong>
        <span class="arrow">‚ñº</span>
    </label>
    <div class="collapsible-content">
        <p>
            Veja o cap√≠tulo 9 do nosso livro para saber como funcionam previs√µes um passo, n-passos e infinitos passos a frente:
        </p>
        <a href="https://sysidentpy.org/book/9-Validation/" target="_blank">
            <em><strong>Nonlinear System Identification and Forecasting: Theory and Practice With SysIdentPy</strong></em>
        </a>
    </div>
</div>

#### Sele√ß√£o de Ordem

A sele√ß√£o de ordem √© uma abordagem cl√°ssica para determinar automaticamente a ordem √≥tima do modelo ao utilizar o algoritmo **FROLS**. Esse processo auxilia na identifica√ß√£o da melhor combina√ß√£o dos atrasos e regressores por meio da avalia√ß√£o de diferentes modelos com base em um crit√©rio de informa√ß√£o.

!!! Important
        Crit√©rios de informa√ß√£o *s√≥ se aplicam* ao algoritmo **FROLS**.

Habilite com:
1. `order_selection=True`
2. `info_criteria="bic"` (ou `"aic"`, `"aicc"`, `"fpe"`, `"lilc"`).

```python
from sysidentpy.model_structure_selection import FROLS
from sysidentpy.basis_function import Polynomial

basis_function = Polynomial(degree=2)
model = FROLS(
        ylag=2,
        xlag=2,
        basis_function=basis_function,
        order_selection=True,
        info_criteria="bic"
)
model.fit(X=x_train, y=y_train)
yhat = model.predict(X=x_valid, y=y_valid)
```

Controlar n√∫mero de regressores testados: `n_info_values`.

```python
model = FROLS(
        ylag=2,
        xlag=2,
        basis_function=basis_function,
        order_selection=True,
        info_criteria="bic",
        n_info_values=50
)
```

!!! Important
        Aumentar `n_info_values` pode melhorar a precis√£o, mas aumenta o tempo computacional.

#### Rede Neural NARX

Exemplo com PyTorch:

```python
from torch import nn
from sysidentpy.neural_network import NARXNN
from sysidentpy.basis_function import Polynomial
from sysidentpy.utils.plotting import plot_results

basis_function = Polynomial(degree=1)

class NARX(nn.Module):
        def __init__(self):
                super().__init__()
                self.lin = nn.Linear(4, 10)
                self.lin2 = nn.Linear(10, 10)
                self.lin3 = nn.Linear(10, 1)
                self.tanh = nn.Tanh()

        def forward(self, xb):
                z = self.lin(xb)
                z = self.tanh(z)
                z = self.lin2(z)
                z = self.tanh(z)
                z = self.lin3(z)
                return z

narx_net = NARXNN(
        net=NARX(),
        ylag=2,
        xlag=2,
        basis_function=basis_function,
        model_type="NARMAX",
        loss_func='mse_loss',
        optimizer='Adam',
        epochs=200,
        verbose=False,
        optim_params={'betas': (0.9, 0.999), 'eps': 1e-05}
)

narx_net.fit(X=x_train, y=y_train)
yhat = narx_net.predict(X=x_valid, y=y_valid)
plot_results(y=y_valid, yhat=yhat, n=1000, figsize=(15, 4))
```

![](https://github.com/wilsonrljr/sysidentpy-data/blob/main/docs/images/quickstart-neural-narx.png?raw=true)

#### Estimadores Gerais

Voc√™ pode integrar qualquer estimador (scikit-learn, xgboost, catboost etc.) desde que eles sigam o padr√£o `fit` e `predict`.

Exemplo CatBoost NARX:

```python
from sysidentpy.general_estimators import NARX
from catboost import CatBoostRegressor
from sysidentpy.basis_function import Polynomial
from sysidentpy.utils.plotting import plot_results

basis_function = Polynomial(degree=1)
catboost_narx = NARX(
        base_estimator=CatBoostRegressor(
                iterations=300,
                learning_rate=0.1,
                depth=6),
        xlag=2,
        ylag=2,
        basis_function=basis_function,
        model_type="NARMAX",
        fit_params={'verbose': False}
)

catboost_narx.fit(X=x_train, y=y_train)
yhat = catboost_narx.predict(X=x_valid, y=y_valid)
plot_results(y=y_valid, yhat=yhat, n=200)
```

![](https://github.com/wilsonrljr/sysidentpy-data/blob/main/docs/images/quickstart-catboost-narx.png?raw=true)

Sem NARX (para compara√ß√£o):

```python
from catboost import CatBoostRegressor
from sysidentpy.utils.plotting import plot_results

catboost = CatBoostRegressor(
        iterations=300,
        learning_rate=0.1,
        depth=6
)
catboost.fit(x_train, y_train, verbose=False)
plot_results(y=y_valid, yhat=catboost.predict(x_valid), figsize=(15, 4))
```

![](https://github.com/wilsonrljr/sysidentpy-data/blob/main/docs/images/quickstart-catboost-without-narx.png?raw=true)

Voc√™ ainda pode explorar combina√ß√µes: usar fun√ß√£o base Fourier, previs√£o multi-passos, diferentes estimadores etc.

Este √© apenas um guia r√°pido. Para tutoriais completos, guias passo a passo, explica√ß√µes detalhadas e casos avan√ßados, veja a [documenta√ß√£o](https://sysidentpy.org/) e o [livro](https://sysidentpy.org/book/0-Preface/).
