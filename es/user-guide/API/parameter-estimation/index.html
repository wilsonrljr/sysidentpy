<!doctype html><html lang=es class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="De Métodos Clásicos a Redes Neuronales"><meta name=author content="Wilson Rocha"><link href=https://sysidentpy.org/es/user-guide/API/parameter-estimation/ rel=canonical><link href=../general-estimators/ rel=prev><link href=../multiobjective-parameter-estimation/ rel=next><link rel=icon href=../../../../en/assets/img/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.6"><title>Parameter Estimation - SysIdentPy</title><link rel=stylesheet href=../../../../assets/stylesheets/main.8608ea7d.min.css><link rel=stylesheet href=../../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Nunito+Sans:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Nunito Sans";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../../assets/_mkdocstrings.css><link rel=stylesheet href=../../../../assets/_mkdocstrings.css><link rel=stylesheet href=../../../../assets/_mkdocstrings.css><link rel=stylesheet href=../../../../overrides/assets/css/extra.css><link rel=stylesheet href=../../../../overrides/assets/css/feature-grid.css><link rel=stylesheet href=../../../../overrides/assets/css/fontsize.css><link rel=stylesheet href=../../../../overrides/assets/css/card-container.css><link rel=stylesheet href=https://unpkg.com/katex@0/dist/katex.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/swiper@11/swiper-bundle.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css><link rel=stylesheet href=../../../../overrides/assets/vendor/css/prism.css><link rel=stylesheet href=../../../../overrides/assets/css/style.css><script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-16K3SQT164"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-16K3SQT164",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-16K3SQT164",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script> <link href="../../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../../../assets/javascripts/glightbox.min.js"></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=orange> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#documentation-for-parameters-estimation class=md-skip> Saltar a contenido </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <a href=https://github.com/sponsors/wilsonrljr> Sponsor <strong>SysIdentPy</strong> on <span class="twemoji github"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </span> <strong>Github</strong> </a> </div> </aside> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Cabecera> <a href=../../../ title=SysIdentPy class="md-header__button md-logo" aria-label=SysIdentPy data-md-component=logo> <img src=../../../../overrides/assets/img/logotype-sysidentpy.svg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> SysIdentPy </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Parameter Estimation </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=orange aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=orange aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <div class=md-header__option> <div class=md-select> <button class="md-header__button md-icon" aria-label="Seleccionar idioma"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"/></svg> </button> <div class=md-select__inner> <ul class=md-select__list> <li class=md-select__item> <a href=../../../../user-guide/API/parameter-estimation/ hreflang=en class=md-select__link> English </a> </li> <li class=md-select__item> <a href=../../../../pt/user-guide/API/parameter-estimation/ hreflang=pt class=md-select__link> Português (Brasil) </a> </li> <li class=md-select__item> <a href=./ hreflang=es class=md-select__link> Español </a> </li> </ul> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Búsqueda placeholder=Búsqueda autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Buscar> <a href=javascript:void(0) class="md-search__icon md-icon" title=Compartir aria-label=Compartir data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Limpiar aria-label=Limpiar tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Inicializando búsqueda </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/wilsonrljr/sysidentpy title="Ir al repositorio" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> wilsonrljr/sysidentpy </div> </a> </div> </nav> <nav class=md-tabs aria-label=Pestañas data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../../ class=md-tabs__link> Inicio </a> </li> <li class=md-tabs__item> <a href=../../../getting-started/getting-started/ class=md-tabs__link> Primeros pasos </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../overview/ class=md-tabs__link> Guía de usuario </a> </li> <li class=md-tabs__item> <a href=../../../book/0-Preface/ class=md-tabs__link> Libro </a> </li> <li class=md-tabs__item> <a href=../../../developer-guide/contribute/ class=md-tabs__link> Guía de desarrollo </a> </li> <li class=md-tabs__item> <a href=../../../community-support/community-overview/ class=md-tabs__link> Comunidad y soporte </a> </li> <li class=md-tabs__item> <a href=../../../landing-page/about-us/ class=md-tabs__link> Acerca de </a> </li> <li class=md-tabs__item> <a href=../../../changelog/changelog/ class=md-tabs__link> Registro de cambios </a> </li> <li class=md-tabs__item> <a href=../../../landing-page/sponsor/ class=md-tabs__link> Patrocinadores </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navegación data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../../ title=SysIdentPy class="md-nav__button md-logo" aria-label=SysIdentPy data-md-component=logo> <img src=../../../../overrides/assets/img/logotype-sysidentpy.svg alt=logo> </a> SysIdentPy </label> <div class=md-nav__source> <a href=https://github.com/wilsonrljr/sysidentpy title="Ir al repositorio" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> wilsonrljr/sysidentpy </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../ class=md-nav__link> <span class=md-ellipsis> Inicio </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Primeros pasos </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Primeros pasos </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../getting-started/getting-started/ class=md-nav__link> <span class=md-ellipsis> Resumen </span> </a> </li> <li class=md-nav__item> <a href=../../../getting-started/quickstart-guide/ class=md-nav__link> <span class=md-ellipsis> Guía rápida </span> </a> </li> <li class=md-nav__item> <a href=../../../getting-started/narmax-intro/ class=md-nav__link> <span class=md-ellipsis> Introducción a NARMAX </span> </a> </li> <li class=md-nav__item> <a href=../../../getting-started/license/ class=md-nav__link> <span class=md-ellipsis> Licencia </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3 checked> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex> <span class=md-ellipsis> Guía de usuario </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Guía de usuario </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../overview/ class=md-nav__link> <span class=md-ellipsis> Resumen </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex=0> <span class=md-ellipsis> Tutorials </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> Tutorials </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2_1> <label class=md-nav__link for=__nav_3_2_1 id=__nav_3_2_1_label tabindex=0> <span class=md-ellipsis> Features </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_3_2_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2_1> <span class="md-nav__icon md-icon"></span> Features </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../tutorials/your-first-model/ class=md-nav__link> <span class=md-ellipsis> Your First Model </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/model-with-multiple-inputs/ class=md-nav__link> <span class=md-ellipsis> Model with Multiple Inputs </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/parameter-estimation-overview/ class=md-nav__link> <span class=md-ellipsis> Parameter Estimation - Overview </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/basis-function-overview/ class=md-nav__link> <span class=md-ellipsis> Basis Function - Overview </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/information-criteria-overview/ class=md-nav__link> <span class=md-ellipsis> Information Criteria - Overview </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/general-NARX-models/ class=md-nav__link> <span class=md-ellipsis> General NARX Models - Overview </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/fourier-NARX-overview/ class=md-nav__link> <span class=md-ellipsis> Fourier NARX - Overview </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/aols-overview/ class=md-nav__link> <span class=md-ellipsis> AOLS - Overview </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/NFIR-model-overview/ class=md-nav__link> <span class=md-ellipsis> NFIR - Overview </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/importance-of-extended-least-squares/ class=md-nav__link> <span class=md-ellipsis> Importance of Extended Least Squares </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2_2> <label class=md-nav__link for=__nav_3_2_2 id=__nav_3_2_2_label tabindex=0> <span class=md-ellipsis> Electrical and Mechanical Systems </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_3_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2_2> <span class="md-nav__icon md-icon"></span> Electrical and Mechanical Systems </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../tutorials/modeling-a-magneto-rheological-damper-device/ class=md-nav__link> <span class=md-ellipsis> Modeling a Magneto-Rheological Damper Device </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/silver-box-system/ class=md-nav__link> <span class=md-ellipsis> Silver Box System </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/coupled-eletric-device/ class=md-nav__link> <span class=md-ellipsis> Coupled Electric Device </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/wiener-hammerstein-system/ class=md-nav__link> <span class=md-ellipsis> Wiener-Hammerstein System </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/f-16-aircraft/ class=md-nav__link> <span class=md-ellipsis> F-16 Aircraft </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/f-16-aircraft-n-steps-ahead-prediction/ class=md-nav__link> <span class=md-ellipsis> F-16 Aircraft - N-Steps Ahead Prediction </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/electromechanical-system-identification-overview/ class=md-nav__link> <span class=md-ellipsis> Electromechanical System Identification - Overview </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/electromechanical-system-identification-metamss/ class=md-nav__link> <span class=md-ellipsis> Electromechanical System Identification - MetaMSS </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/electromechanical-system-identification-entropic-regression/ class=md-nav__link> <span class=md-ellipsis> Electromechanical System Identification - Entropic Regression </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/multiobjective-parameter-estimation-overview/ class=md-nav__link> <span class=md-ellipsis> Multiobjective Parameter Estimation - Overview </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2_3> <label class=md-nav__link for=__nav_3_2_3 id=__nav_3_2_3_label tabindex=0> <span class=md-ellipsis> Industrial and Corporate </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_3_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2_3> <span class="md-nav__icon md-icon"></span> Industrial and Corporate </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../tutorials/m4-benchmark/ class=md-nav__link> <span class=md-ellipsis> M4 Benchmark </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/air-passenger-benchmark/ class=md-nav__link> <span class=md-ellipsis> Air Passenger Benchmark </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/load-forecasting-benchmark/ class=md-nav__link> <span class=md-ellipsis> Load Forecasting Benchmark </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/PV-forecasting-benchmark/ class=md-nav__link> <span class=md-ellipsis> PV Forecasting Benchmark </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2_4> <label class=md-nav__link for=__nav_3_2_4 id=__nav_3_2_4_label tabindex=0> <span class=md-ellipsis> Chaotic Systems </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_3_2_4_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2_4> <span class="md-nav__icon md-icon"></span> Chaotic Systems </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../tutorials/chaotic-systems/lorenz-system/ class=md-nav__link> <span class=md-ellipsis> Lorenz System </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/chaotic-systems/logistic-map/ class=md-nav__link> <span class=md-ellipsis> Logistic Map </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_3> <label class=md-nav__link for=__nav_3_3 id=__nav_3_3_label tabindex=0> <span class=md-ellipsis> How to </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3_3> <span class="md-nav__icon md-icon"></span> How to </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../how-to/create-custom-basis-function/ class=md-nav__link> <span class=md-ellipsis> Create a Custom Basis Function </span> </a> </li> <li class=md-nav__item> <a href=../../how-to/create-a-narx-neural-network/ class=md-nav__link> <span class=md-ellipsis> Create a Neural NARX Network </span> </a> </li> <li class=md-nav__item> <a href=../../how-to/save-and-load-models/ class=md-nav__link> <span class=md-ellipsis> Save and Load Models </span> </a> </li> <li class=md-nav__item> <a href=../../how-to/set-specific-lags/ class=md-nav__link> <span class=md-ellipsis> Set Specific Lags </span> </a> </li> <li class=md-nav__item> <a href=../../how-to/simulating-existing-models/ class=md-nav__link> <span class=md-ellipsis> Simulating Existing Models </span> </a> </li> <li class=md-nav__item> <a href=../../how-to/use-extended-least-squares/ class=md-nav__link> <span class=md-ellipsis> Use Extended Least Squares </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_4 checked> <label class=md-nav__link for=__nav_3_4 id=__nav_3_4_label tabindex=0> <span class=md-ellipsis> API </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_4_label aria-expanded=true> <label class=md-nav__title for=__nav_3_4> <span class="md-nav__icon md-icon"></span> API </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../narmax-base/ class=md-nav__link> <span class=md-ellipsis> NARMAX Base </span> </a> </li> <li class=md-nav__item> <a href=../ofr-base/ class=md-nav__link> <span class=md-ellipsis> OFR Base </span> </a> </li> <li class=md-nav__item> <a href=../basis-function/ class=md-nav__link> <span class=md-ellipsis> Basis Functions </span> </a> </li> <li class=md-nav__item> <a href=../frols/ class=md-nav__link> <span class=md-ellipsis> FROLS </span> </a> </li> <li class=md-nav__item> <a href=../metamss/ class=md-nav__link> <span class=md-ellipsis> MetaMSS </span> </a> </li> <li class=md-nav__item> <a href=../aols/ class=md-nav__link> <span class=md-ellipsis> AOLS </span> </a> </li> <li class=md-nav__item> <a href=../uofr/ class=md-nav__link> <span class=md-ellipsis> UOFR </span> </a> </li> <li class=md-nav__item> <a href=../entropic-regression/ class=md-nav__link> <span class=md-ellipsis> Entropic Regression </span> </a> </li> <li class=md-nav__item> <a href=../neural-narx/ class=md-nav__link> <span class=md-ellipsis> Neural NARX </span> </a> </li> <li class=md-nav__item> <a href=../general-estimators/ class=md-nav__link> <span class=md-ellipsis> General Estimators </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Parameter Estimation </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Parameter Estimation </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Tabla de contenidos"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Tabla de contenidos </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators class=md-nav__link> <span class=md-ellipsis> estimators </span> </a> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.AffineLeastMeanSquares class=md-nav__link> <span class=md-ellipsis> AffineLeastMeanSquares </span> </a> <nav class=md-nav aria-label=AffineLeastMeanSquares> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.AffineLeastMeanSquares.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.BoundedVariableLeastSquares class=md-nav__link> <span class=md-ellipsis> BoundedVariableLeastSquares </span> </a> <nav class=md-nav aria-label=BoundedVariableLeastSquares> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.BoundedVariableLeastSquares.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.EstimatorError class=md-nav__link> <span class=md-ellipsis> EstimatorError </span> </a> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquareMixedNorm class=md-nav__link> <span class=md-ellipsis> LeastMeanSquareMixedNorm </span> </a> <nav class=md-nav aria-label=LeastMeanSquareMixedNorm> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquareMixedNorm.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquares class=md-nav__link> <span class=md-ellipsis> LeastMeanSquares </span> </a> <nav class=md-nav aria-label=LeastMeanSquares> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquares.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresFourth class=md-nav__link> <span class=md-ellipsis> LeastMeanSquaresFourth </span> </a> <nav class=md-nav aria-label=LeastMeanSquaresFourth> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresFourth.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresLeaky class=md-nav__link> <span class=md-ellipsis> LeastMeanSquaresLeaky </span> </a> <nav class=md-nav aria-label=LeastMeanSquaresLeaky> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresLeaky.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedLeaky class=md-nav__link> <span class=md-ellipsis> LeastMeanSquaresNormalizedLeaky </span> </a> <nav class=md-nav aria-label=LeastMeanSquaresNormalizedLeaky> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedLeaky.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignRegressor class=md-nav__link> <span class=md-ellipsis> LeastMeanSquaresNormalizedSignRegressor </span> </a> <nav class=md-nav aria-label=LeastMeanSquaresNormalizedSignRegressor> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignRegressor.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignSign class=md-nav__link> <span class=md-ellipsis> LeastMeanSquaresNormalizedSignSign </span> </a> <nav class=md-nav aria-label=LeastMeanSquaresNormalizedSignSign> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignSign.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignError class=md-nav__link> <span class=md-ellipsis> LeastMeanSquaresSignError </span> </a> <nav class=md-nav aria-label=LeastMeanSquaresSignError> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignError.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignRegressor class=md-nav__link> <span class=md-ellipsis> LeastMeanSquaresSignRegressor </span> </a> <nav class=md-nav aria-label=LeastMeanSquaresSignRegressor> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignRegressor.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignSign class=md-nav__link> <span class=md-ellipsis> LeastMeanSquaresSignSign </span> </a> <nav class=md-nav aria-label=LeastMeanSquaresSignSign> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignSign.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastSquares class=md-nav__link> <span class=md-ellipsis> LeastSquares </span> </a> <nav class=md-nav aria-label=LeastSquares> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastSquares.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastSquaresMinimalResidual class=md-nav__link> <span class=md-ellipsis> LeastSquaresMinimalResidual </span> </a> <nav class=md-nav aria-label=LeastSquaresMinimalResidual> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastSquaresMinimalResidual.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.NonNegativeLeastSquares class=md-nav__link> <span class=md-ellipsis> NonNegativeLeastSquares </span> </a> <nav class=md-nav aria-label=NonNegativeLeastSquares> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.NonNegativeLeastSquares.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquares class=md-nav__link> <span class=md-ellipsis> NormalizedLeastMeanSquares </span> </a> <nav class=md-nav aria-label=NormalizedLeastMeanSquares> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquares.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquaresSignError class=md-nav__link> <span class=md-ellipsis> NormalizedLeastMeanSquaresSignError </span> </a> <nav class=md-nav aria-label=NormalizedLeastMeanSquaresSignError> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquaresSignError.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.RecursiveLeastSquares class=md-nav__link> <span class=md-ellipsis> RecursiveLeastSquares </span> </a> <nav class=md-nav aria-label=RecursiveLeastSquares> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.RecursiveLeastSquares.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.RidgeRegression class=md-nav__link> <span class=md-ellipsis> RidgeRegression </span> </a> <nav class=md-nav aria-label=RidgeRegression> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.RidgeRegression.ridge_regression class=md-nav__link> <span class=md-ellipsis> ridge_regression </span> </a> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.RidgeRegression.ridge_regression_classic class=md-nav__link> <span class=md-ellipsis> ridge_regression_classic </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.TotalLeastSquares class=md-nav__link> <span class=md-ellipsis> TotalLeastSquares </span> </a> <nav class=md-nav aria-label=TotalLeastSquares> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.TotalLeastSquares.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../multiobjective-parameter-estimation/ class=md-nav__link> <span class=md-ellipsis> Multiobjective Parameter Estimation </span> </a> </li> <li class=md-nav__item> <a href=../simulation/ class=md-nav__link> <span class=md-ellipsis> Simulation </span> </a> </li> <li class=md-nav__item> <a href=../residues/ class=md-nav__link> <span class=md-ellipsis> Residual Analysis </span> </a> </li> <li class=md-nav__item> <a href=../metaheuristics/ class=md-nav__link> <span class=md-ellipsis> Metaheuristics </span> </a> </li> <li class=md-nav__item> <a href=../metrics/ class=md-nav__link> <span class=md-ellipsis> Metrics </span> </a> </li> <li class=md-nav__item> <a href=../utils/ class=md-nav__link> <span class=md-ellipsis> Utils </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> Libro </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Libro </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../book/0-Preface/ class=md-nav__link> <span class=md-ellipsis> Preface </span> </a> </li> <li class=md-nav__item> <a href=../../../book/0.1-Contents/ class=md-nav__link> <span class=md-ellipsis> Contents </span> </a> </li> <li class=md-nav__item> <a href=../../../book/1-Introduction/ class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=../../../book/2-NARMAX-Model-Representation/ class=md-nav__link> <span class=md-ellipsis> 2. NARMAX Model Representation </span> </a> </li> <li class=md-nav__item> <a href=../../../book/3-Parameter-Estimation/ class=md-nav__link> <span class=md-ellipsis> 3. Parameter Estimation </span> </a> </li> <li class=md-nav__item> <a href=../../../book/4-Model-Structure-Selection/ class=md-nav__link> <span class=md-ellipsis> 4. Model Structure Selection </span> </a> </li> <li class=md-nav__item> <a href=../../../book/5-Multiobjective-Parameter-Estimation/ class=md-nav__link> <span class=md-ellipsis> 5. Multiobjective Parameter Estimation </span> </a> </li> <li class=md-nav__item> <a href=../../../book/6-Multiobjective-Model-Structure-Selection/ class=md-nav__link> <span class=md-ellipsis> 6. Multiobjective Model Structure Selection </span> </a> </li> <li class=md-nav__item> <a href=../../../book/7-NARX-Neural-Network/ class=md-nav__link> <span class=md-ellipsis> 7. NARX Neural Network </span> </a> </li> <li class=md-nav__item> <a href=../../../book/8-Severely-Nonlinear-System-Identification/ class=md-nav__link> <span class=md-ellipsis> 8. Severely Nonlinear System Identification </span> </a> </li> <li class=md-nav__item> <a href=../../../book/9-Validation/ class=md-nav__link> <span class=md-ellipsis> 9. Validation </span> </a> </li> <li class=md-nav__item> <a href=../../../book/10-Case-Studies/ class=md-nav__link> <span class=md-ellipsis> 10. Case Studies </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> Guía de desarrollo </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Guía de desarrollo </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../developer-guide/contribute/ class=md-nav__link> <span class=md-ellipsis> How to contribute </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5_2> <label class=md-nav__link for=__nav_5_2 id=__nav_5_2_label tabindex=0> <span class=md-ellipsis> Documentation </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_5_2_label aria-expanded=false> <label class=md-nav__title for=__nav_5_2> <span class="md-nav__icon md-icon"></span> Documentation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../developer-guide/documentation-overview/ class=md-nav__link> <span class=md-ellipsis> Documentation Overview </span> </a> </li> <li class=md-nav__item> <a href=../../../developer-guide/how-to-write-a-tutorial/ class=md-nav__link> <span class=md-ellipsis> How To Write a Tutorial </span> </a> </li> <li class=md-nav__item> <a href=../../../developer-guide/how-to-write-a-how-to-guide/ class=md-nav__link> <span class=md-ellipsis> How To Write a How-to Guide </span> </a> </li> <li class=md-nav__item> <a href=../../../developer-guide/how-to-add-a-translation/ class=md-nav__link> <span class=md-ellipsis> How to Add a Translation </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> Comunidad y soporte </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Comunidad y soporte </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../community-support/community-overview/ class=md-nav__link> <span class=md-ellipsis> community-overview </span> </a> </li> <li class=md-nav__item> <a href=../../../community-support/get-help/ class=md-nav__link> <span class=md-ellipsis> Get Help </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_6_3> <label class=md-nav__link for=__nav_6_3 id=__nav_6_3_label tabindex=0> <span class=md-ellipsis> Meetups </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_6_3_label aria-expanded=false> <label class=md-nav__title for=__nav_6_3> <span class="md-nav__icon md-icon"></span> Meetups </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../community-support/meetups/ai-networks-meetup/ class=md-nav__link> <span class=md-ellipsis> AI Networks Meetup </span> </a> </li> <li class=md-nav__item> <a href=../../../community-support/meetups/nubank-meetup/ class=md-nav__link> <span class=md-ellipsis> Nubank Timeseries Meetup </span> </a> </li> <li class=md-nav__item> <a href=../../../community-support/meetups/nubank-meetup-open-source/ class=md-nav__link> <span class=md-ellipsis> Nubank Open Source Talk </span> </a> </li> <li class=md-nav__item> <a href=../../../community-support/meetups/gcom-meetup/ class=md-nav__link> <span class=md-ellipsis> GCoM Meetup </span> </a> </li> <li class=md-nav__item> <a href=../../../community-support/meetups/estatidados/ class=md-nav__link> <span class=md-ellipsis> Estatidados Meetup </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../landing-page/about-us/ class=md-nav__link> <span class=md-ellipsis> Acerca de </span> </a> </li> <li class=md-nav__item> <a href=../../../changelog/changelog/ class=md-nav__link> <span class=md-ellipsis> Registro de cambios </span> </a> </li> <li class=md-nav__item> <a href=../../../landing-page/sponsor/ class=md-nav__link> <span class=md-ellipsis> Patrocinadores </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Tabla de contenidos"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Tabla de contenidos </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators class=md-nav__link> <span class=md-ellipsis> estimators </span> </a> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.AffineLeastMeanSquares class=md-nav__link> <span class=md-ellipsis> AffineLeastMeanSquares </span> </a> <nav class=md-nav aria-label=AffineLeastMeanSquares> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.AffineLeastMeanSquares.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.BoundedVariableLeastSquares class=md-nav__link> <span class=md-ellipsis> BoundedVariableLeastSquares </span> </a> <nav class=md-nav aria-label=BoundedVariableLeastSquares> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.BoundedVariableLeastSquares.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.EstimatorError class=md-nav__link> <span class=md-ellipsis> EstimatorError </span> </a> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquareMixedNorm class=md-nav__link> <span class=md-ellipsis> LeastMeanSquareMixedNorm </span> </a> <nav class=md-nav aria-label=LeastMeanSquareMixedNorm> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquareMixedNorm.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquares class=md-nav__link> <span class=md-ellipsis> LeastMeanSquares </span> </a> <nav class=md-nav aria-label=LeastMeanSquares> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquares.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresFourth class=md-nav__link> <span class=md-ellipsis> LeastMeanSquaresFourth </span> </a> <nav class=md-nav aria-label=LeastMeanSquaresFourth> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresFourth.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresLeaky class=md-nav__link> <span class=md-ellipsis> LeastMeanSquaresLeaky </span> </a> <nav class=md-nav aria-label=LeastMeanSquaresLeaky> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresLeaky.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedLeaky class=md-nav__link> <span class=md-ellipsis> LeastMeanSquaresNormalizedLeaky </span> </a> <nav class=md-nav aria-label=LeastMeanSquaresNormalizedLeaky> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedLeaky.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignRegressor class=md-nav__link> <span class=md-ellipsis> LeastMeanSquaresNormalizedSignRegressor </span> </a> <nav class=md-nav aria-label=LeastMeanSquaresNormalizedSignRegressor> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignRegressor.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignSign class=md-nav__link> <span class=md-ellipsis> LeastMeanSquaresNormalizedSignSign </span> </a> <nav class=md-nav aria-label=LeastMeanSquaresNormalizedSignSign> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignSign.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignError class=md-nav__link> <span class=md-ellipsis> LeastMeanSquaresSignError </span> </a> <nav class=md-nav aria-label=LeastMeanSquaresSignError> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignError.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignRegressor class=md-nav__link> <span class=md-ellipsis> LeastMeanSquaresSignRegressor </span> </a> <nav class=md-nav aria-label=LeastMeanSquaresSignRegressor> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignRegressor.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignSign class=md-nav__link> <span class=md-ellipsis> LeastMeanSquaresSignSign </span> </a> <nav class=md-nav aria-label=LeastMeanSquaresSignSign> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignSign.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastSquares class=md-nav__link> <span class=md-ellipsis> LeastSquares </span> </a> <nav class=md-nav aria-label=LeastSquares> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastSquares.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastSquaresMinimalResidual class=md-nav__link> <span class=md-ellipsis> LeastSquaresMinimalResidual </span> </a> <nav class=md-nav aria-label=LeastSquaresMinimalResidual> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.LeastSquaresMinimalResidual.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.NonNegativeLeastSquares class=md-nav__link> <span class=md-ellipsis> NonNegativeLeastSquares </span> </a> <nav class=md-nav aria-label=NonNegativeLeastSquares> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.NonNegativeLeastSquares.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquares class=md-nav__link> <span class=md-ellipsis> NormalizedLeastMeanSquares </span> </a> <nav class=md-nav aria-label=NormalizedLeastMeanSquares> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquares.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquaresSignError class=md-nav__link> <span class=md-ellipsis> NormalizedLeastMeanSquaresSignError </span> </a> <nav class=md-nav aria-label=NormalizedLeastMeanSquaresSignError> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquaresSignError.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.RecursiveLeastSquares class=md-nav__link> <span class=md-ellipsis> RecursiveLeastSquares </span> </a> <nav class=md-nav aria-label=RecursiveLeastSquares> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.RecursiveLeastSquares.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.RidgeRegression class=md-nav__link> <span class=md-ellipsis> RidgeRegression </span> </a> <nav class=md-nav aria-label=RidgeRegression> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.RidgeRegression.ridge_regression class=md-nav__link> <span class=md-ellipsis> ridge_regression </span> </a> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.RidgeRegression.ridge_regression_classic class=md-nav__link> <span class=md-ellipsis> ridge_regression_classic </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.TotalLeastSquares class=md-nav__link> <span class=md-ellipsis> TotalLeastSquares </span> </a> <nav class=md-nav aria-label=TotalLeastSquares> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sysidentpy.parameter_estimation.estimators.TotalLeastSquares.optimize class=md-nav__link> <span class=md-ellipsis> optimize </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/wilsonrljr/sysidentpy/edit/main/docs/en/user-guide/API/parameter-estimation.md title=edit.link.title class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://raw.githubusercontent.com/wilsonrljr/sysidentpy/main/docs/en/user-guide/API/parameter-estimation.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <h1 id=documentation-for-parameters-estimation>Documentation for <code>Parameters Estimation</code><a class=headerlink href=#documentation-for-parameters-estimation title="Permanent link">&para;</a></h1> <div class="doc doc-object doc-module"> <a id=sysidentpy.parameter_estimation.estimators></a> <div class="doc doc-contents first"> <p>Methods for parameter estimation.</p> <div class="doc doc-children"> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.AffineLeastMeanSquares class="doc doc-heading"> <code>AffineLeastMeanSquares</code> <a href=#sysidentpy.parameter_estimation.estimators.AffineLeastMeanSquares class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=sysidentpy.parameter_estimation.estimators_base.BaseEstimator>BaseEstimator</span></code></p> <p>Affine Least Mean Squares (ALMS) filter for parameter estimation.</p> <p>The ALMS filter is an adaptive filter used to estimate the parameters of a model. It incorporates an offset covariance factor to improve the stability and convergence of the parameter estimation process.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>mu</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> <td> <code>0.01</code> </td> </tr> <tr class=doc-section-item> <td> <code>offset_covariance</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The offset covariance factor of the affine least mean squares filter.</p> </div> </td> <td> <code>0.2</code> </td> </tr> <tr class=doc-section-item> <td> <code>unbiased</code> </td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>If True, applies an unbiased estimator. Default is False.</p> </div> </td> <td> <code>False</code> </td> </tr> <tr class=doc-section-item> <td> <code>uiter</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of iterations for the unbiased estimator. Default is 30.</p> </div> </td> <td> <code>30</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Attributes:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.AffineLeastMeanSquares.mu>mu</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.AffineLeastMeanSquares.offset_covariance>offset_covariance</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The offset covariance factor of the affine least mean squares filter.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.AffineLeastMeanSquares.xi>xi</span></code></td> <td> <code><span title=numpy.ndarray>ndarray</span> or None</code> </td> <td> <div class=doc-md-description> <p>The estimation error at each iteration. Initialized as None and updated during optimization.</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Methods:</span></p> <table> <thead> <tr> <th>Name</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><a class="autorefs autorefs-internal" title="<code>sysidentpy.parameter_estimation.estimators.AffineLeastMeanSquares.optimize</code>" href=../../../../user-guide/API/parameter-estimation/#sysidentpy.parameter_estimation.estimators.AffineLeastMeanSquares.optimize>optimize</a></code></td> <td> <div class=doc-md-description> <p>Estimate the model parameters using the ALMS filter.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Poularikas, A. D. (2017). Adaptive filtering: Fundamentals of least mean squares with MATLAB®. CRC Press.</li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-448>448</a></span>
<span class=normal><a href=#__codelineno-0-449>449</a></span>
<span class=normal><a href=#__codelineno-0-450>450</a></span>
<span class=normal><a href=#__codelineno-0-451>451</a></span>
<span class=normal><a href=#__codelineno-0-452>452</a></span>
<span class=normal><a href=#__codelineno-0-453>453</a></span>
<span class=normal><a href=#__codelineno-0-454>454</a></span>
<span class=normal><a href=#__codelineno-0-455>455</a></span>
<span class=normal><a href=#__codelineno-0-456>456</a></span>
<span class=normal><a href=#__codelineno-0-457>457</a></span>
<span class=normal><a href=#__codelineno-0-458>458</a></span>
<span class=normal><a href=#__codelineno-0-459>459</a></span>
<span class=normal><a href=#__codelineno-0-460>460</a></span>
<span class=normal><a href=#__codelineno-0-461>461</a></span>
<span class=normal><a href=#__codelineno-0-462>462</a></span>
<span class=normal><a href=#__codelineno-0-463>463</a></span>
<span class=normal><a href=#__codelineno-0-464>464</a></span>
<span class=normal><a href=#__codelineno-0-465>465</a></span>
<span class=normal><a href=#__codelineno-0-466>466</a></span>
<span class=normal><a href=#__codelineno-0-467>467</a></span>
<span class=normal><a href=#__codelineno-0-468>468</a></span>
<span class=normal><a href=#__codelineno-0-469>469</a></span>
<span class=normal><a href=#__codelineno-0-470>470</a></span>
<span class=normal><a href=#__codelineno-0-471>471</a></span>
<span class=normal><a href=#__codelineno-0-472>472</a></span>
<span class=normal><a href=#__codelineno-0-473>473</a></span>
<span class=normal><a href=#__codelineno-0-474>474</a></span>
<span class=normal><a href=#__codelineno-0-475>475</a></span>
<span class=normal><a href=#__codelineno-0-476>476</a></span>
<span class=normal><a href=#__codelineno-0-477>477</a></span>
<span class=normal><a href=#__codelineno-0-478>478</a></span>
<span class=normal><a href=#__codelineno-0-479>479</a></span>
<span class=normal><a href=#__codelineno-0-480>480</a></span>
<span class=normal><a href=#__codelineno-0-481>481</a></span>
<span class=normal><a href=#__codelineno-0-482>482</a></span>
<span class=normal><a href=#__codelineno-0-483>483</a></span>
<span class=normal><a href=#__codelineno-0-484>484</a></span>
<span class=normal><a href=#__codelineno-0-485>485</a></span>
<span class=normal><a href=#__codelineno-0-486>486</a></span>
<span class=normal><a href=#__codelineno-0-487>487</a></span>
<span class=normal><a href=#__codelineno-0-488>488</a></span>
<span class=normal><a href=#__codelineno-0-489>489</a></span>
<span class=normal><a href=#__codelineno-0-490>490</a></span>
<span class=normal><a href=#__codelineno-0-491>491</a></span>
<span class=normal><a href=#__codelineno-0-492>492</a></span>
<span class=normal><a href=#__codelineno-0-493>493</a></span>
<span class=normal><a href=#__codelineno-0-494>494</a></span>
<span class=normal><a href=#__codelineno-0-495>495</a></span>
<span class=normal><a href=#__codelineno-0-496>496</a></span>
<span class=normal><a href=#__codelineno-0-497>497</a></span>
<span class=normal><a href=#__codelineno-0-498>498</a></span>
<span class=normal><a href=#__codelineno-0-499>499</a></span>
<span class=normal><a href=#__codelineno-0-500>500</a></span>
<span class=normal><a href=#__codelineno-0-501>501</a></span>
<span class=normal><a href=#__codelineno-0-502>502</a></span>
<span class=normal><a href=#__codelineno-0-503>503</a></span>
<span class=normal><a href=#__codelineno-0-504>504</a></span>
<span class=normal><a href=#__codelineno-0-505>505</a></span>
<span class=normal><a href=#__codelineno-0-506>506</a></span>
<span class=normal><a href=#__codelineno-0-507>507</a></span>
<span class=normal><a href=#__codelineno-0-508>508</a></span>
<span class=normal><a href=#__codelineno-0-509>509</a></span>
<span class=normal><a href=#__codelineno-0-510>510</a></span>
<span class=normal><a href=#__codelineno-0-511>511</a></span>
<span class=normal><a href=#__codelineno-0-512>512</a></span>
<span class=normal><a href=#__codelineno-0-513>513</a></span>
<span class=normal><a href=#__codelineno-0-514>514</a></span>
<span class=normal><a href=#__codelineno-0-515>515</a></span>
<span class=normal><a href=#__codelineno-0-516>516</a></span>
<span class=normal><a href=#__codelineno-0-517>517</a></span>
<span class=normal><a href=#__codelineno-0-518>518</a></span>
<span class=normal><a href=#__codelineno-0-519>519</a></span>
<span class=normal><a href=#__codelineno-0-520>520</a></span>
<span class=normal><a href=#__codelineno-0-521>521</a></span>
<span class=normal><a href=#__codelineno-0-522>522</a></span>
<span class=normal><a href=#__codelineno-0-523>523</a></span>
<span class=normal><a href=#__codelineno-0-524>524</a></span>
<span class=normal><a href=#__codelineno-0-525>525</a></span>
<span class=normal><a href=#__codelineno-0-526>526</a></span>
<span class=normal><a href=#__codelineno-0-527>527</a></span>
<span class=normal><a href=#__codelineno-0-528>528</a></span>
<span class=normal><a href=#__codelineno-0-529>529</a></span>
<span class=normal><a href=#__codelineno-0-530>530</a></span>
<span class=normal><a href=#__codelineno-0-531>531</a></span>
<span class=normal><a href=#__codelineno-0-532>532</a></span>
<span class=normal><a href=#__codelineno-0-533>533</a></span>
<span class=normal><a href=#__codelineno-0-534>534</a></span>
<span class=normal><a href=#__codelineno-0-535>535</a></span>
<span class=normal><a href=#__codelineno-0-536>536</a></span>
<span class=normal><a href=#__codelineno-0-537>537</a></span>
<span class=normal><a href=#__codelineno-0-538>538</a></span>
<span class=normal><a href=#__codelineno-0-539>539</a></span>
<span class=normal><a href=#__codelineno-0-540>540</a></span>
<span class=normal><a href=#__codelineno-0-541>541</a></span>
<span class=normal><a href=#__codelineno-0-542>542</a></span>
<span class=normal><a href=#__codelineno-0-543>543</a></span>
<span class=normal><a href=#__codelineno-0-544>544</a></span>
<span class=normal><a href=#__codelineno-0-545>545</a></span>
<span class=normal><a href=#__codelineno-0-546>546</a></span>
<span class=normal><a href=#__codelineno-0-547>547</a></span>
<span class=normal><a href=#__codelineno-0-548>548</a></span>
<span class=normal><a href=#__codelineno-0-549>549</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-448 name=__codelineno-0-448></a><span class=k>class</span><span class=w> </span><span class=nc>AffineLeastMeanSquares</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>):</span>
<a id=__codelineno-0-449 name=__codelineno-0-449></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Affine Least Mean Squares (ALMS) filter for parameter estimation.</span>
<a id=__codelineno-0-450 name=__codelineno-0-450></a>
<a id=__codelineno-0-451 name=__codelineno-0-451></a><span class=sd>    The ALMS filter is an adaptive filter used to estimate the parameters of a model.</span>
<a id=__codelineno-0-452 name=__codelineno-0-452></a><span class=sd>    It incorporates an offset covariance factor to improve the stability and convergence</span>
<a id=__codelineno-0-453 name=__codelineno-0-453></a><span class=sd>    of the parameter estimation process.</span>
<a id=__codelineno-0-454 name=__codelineno-0-454></a>
<a id=__codelineno-0-455 name=__codelineno-0-455></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-456 name=__codelineno-0-456></a><span class=sd>    ----------</span>
<a id=__codelineno-0-457 name=__codelineno-0-457></a><span class=sd>    mu : float, default=0.01</span>
<a id=__codelineno-0-458 name=__codelineno-0-458></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-459 name=__codelineno-0-459></a><span class=sd>    offset_covariance : float, default=0.2</span>
<a id=__codelineno-0-460 name=__codelineno-0-460></a><span class=sd>        The offset covariance factor of the affine least mean squares filter.</span>
<a id=__codelineno-0-461 name=__codelineno-0-461></a><span class=sd>    unbiased : bool, optional</span>
<a id=__codelineno-0-462 name=__codelineno-0-462></a><span class=sd>        If True, applies an unbiased estimator. Default is False.</span>
<a id=__codelineno-0-463 name=__codelineno-0-463></a><span class=sd>    uiter : int, optional</span>
<a id=__codelineno-0-464 name=__codelineno-0-464></a><span class=sd>        Number of iterations for the unbiased estimator. Default is 30.</span>
<a id=__codelineno-0-465 name=__codelineno-0-465></a>
<a id=__codelineno-0-466 name=__codelineno-0-466></a><span class=sd>    Attributes</span>
<a id=__codelineno-0-467 name=__codelineno-0-467></a><span class=sd>    ----------</span>
<a id=__codelineno-0-468 name=__codelineno-0-468></a><span class=sd>    mu : float</span>
<a id=__codelineno-0-469 name=__codelineno-0-469></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-470 name=__codelineno-0-470></a><span class=sd>    offset_covariance : float</span>
<a id=__codelineno-0-471 name=__codelineno-0-471></a><span class=sd>        The offset covariance factor of the affine least mean squares filter.</span>
<a id=__codelineno-0-472 name=__codelineno-0-472></a><span class=sd>    xi : np.ndarray or None</span>
<a id=__codelineno-0-473 name=__codelineno-0-473></a><span class=sd>        The estimation error at each iteration. Initialized as None and updated during</span>
<a id=__codelineno-0-474 name=__codelineno-0-474></a><span class=sd>        optimization.</span>
<a id=__codelineno-0-475 name=__codelineno-0-475></a>
<a id=__codelineno-0-476 name=__codelineno-0-476></a><span class=sd>    Methods</span>
<a id=__codelineno-0-477 name=__codelineno-0-477></a><span class=sd>    -------</span>
<a id=__codelineno-0-478 name=__codelineno-0-478></a><span class=sd>    optimize(psi: np.ndarray, y: np.ndarray) -&gt; np.ndarray</span>
<a id=__codelineno-0-479 name=__codelineno-0-479></a><span class=sd>        Estimate the model parameters using the ALMS filter.</span>
<a id=__codelineno-0-480 name=__codelineno-0-480></a>
<a id=__codelineno-0-481 name=__codelineno-0-481></a><span class=sd>    References</span>
<a id=__codelineno-0-482 name=__codelineno-0-482></a><span class=sd>    ----------</span>
<a id=__codelineno-0-483 name=__codelineno-0-483></a><span class=sd>    - Poularikas, A. D. (2017). Adaptive filtering: Fundamentals of least mean squares</span>
<a id=__codelineno-0-484 name=__codelineno-0-484></a><span class=sd>    with MATLAB®. CRC Press.</span>
<a id=__codelineno-0-485 name=__codelineno-0-485></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-486 name=__codelineno-0-486></a>
<a id=__codelineno-0-487 name=__codelineno-0-487></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span>
<a id=__codelineno-0-488 name=__codelineno-0-488></a>        <span class=bp>self</span><span class=p>,</span>
<a id=__codelineno-0-489 name=__codelineno-0-489></a>        <span class=o>*</span><span class=p>,</span>
<a id=__codelineno-0-490 name=__codelineno-0-490></a>        <span class=n>mu</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.01</span><span class=p>,</span>
<a id=__codelineno-0-491 name=__codelineno-0-491></a>        <span class=n>offset_covariance</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.2</span><span class=p>,</span>
<a id=__codelineno-0-492 name=__codelineno-0-492></a>        <span class=n>unbiased</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>
<a id=__codelineno-0-493 name=__codelineno-0-493></a>        <span class=n>uiter</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>30</span><span class=p>,</span>
<a id=__codelineno-0-494 name=__codelineno-0-494></a>    <span class=p>):</span>
<a id=__codelineno-0-495 name=__codelineno-0-495></a>        <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>=</span> <span class=n>mu</span>
<a id=__codelineno-0-496 name=__codelineno-0-496></a>        <span class=bp>self</span><span class=o>.</span><span class=n>offset_covariance</span> <span class=o>=</span> <span class=n>offset_covariance</span>
<a id=__codelineno-0-497 name=__codelineno-0-497></a>        <span class=bp>self</span><span class=o>.</span><span class=n>uiter</span> <span class=o>=</span> <span class=n>uiter</span>
<a id=__codelineno-0-498 name=__codelineno-0-498></a>        <span class=bp>self</span><span class=o>.</span><span class=n>unbiased</span> <span class=o>=</span> <span class=n>unbiased</span>
<a id=__codelineno-0-499 name=__codelineno-0-499></a>        <span class=n>_validate_params</span><span class=p>(</span><span class=nb>vars</span><span class=p>(</span><span class=bp>self</span><span class=p>))</span>
<a id=__codelineno-0-500 name=__codelineno-0-500></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
<a id=__codelineno-0-501 name=__codelineno-0-501></a>
<a id=__codelineno-0-502 name=__codelineno-0-502></a>    <span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-503 name=__codelineno-0-503></a><span class=w>        </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Estimate the model parameters using the Affine Least Mean Squares.</span>
<a id=__codelineno-0-504 name=__codelineno-0-504></a>
<a id=__codelineno-0-505 name=__codelineno-0-505></a><span class=sd>        The ALMS method updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-506 name=__codelineno-0-506></a>
<a id=__codelineno-0-507 name=__codelineno-0-507></a><span class=sd>        1. Compute the estimation error:</span>
<a id=__codelineno-0-508 name=__codelineno-0-508></a>
<a id=__codelineno-0-509 name=__codelineno-0-509></a><span class=sd>           $$</span>
<a id=__codelineno-0-510 name=__codelineno-0-510></a><span class=sd>           \xi = y - \psi \theta_{i-1}</span>
<a id=__codelineno-0-511 name=__codelineno-0-511></a><span class=sd>           $$</span>
<a id=__codelineno-0-512 name=__codelineno-0-512></a>
<a id=__codelineno-0-513 name=__codelineno-0-513></a><span class=sd>        2. Update the parameter vector:</span>
<a id=__codelineno-0-514 name=__codelineno-0-514></a>
<a id=__codelineno-0-515 name=__codelineno-0-515></a><span class=sd>           $$</span>
<a id=__codelineno-0-516 name=__codelineno-0-516></a><span class=sd>           \theta_i = \theta_{i-1} + \mu \psi (\psi^T \psi + \text{offset_covariance}</span>
<a id=__codelineno-0-517 name=__codelineno-0-517></a><span class=sd>           \cdot I)^{-1} \xi</span>
<a id=__codelineno-0-518 name=__codelineno-0-518></a><span class=sd>           $$</span>
<a id=__codelineno-0-519 name=__codelineno-0-519></a>
<a id=__codelineno-0-520 name=__codelineno-0-520></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-521 name=__codelineno-0-521></a><span class=sd>        ----------</span>
<a id=__codelineno-0-522 name=__codelineno-0-522></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-523 name=__codelineno-0-523></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-524 name=__codelineno-0-524></a><span class=sd>        y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-525 name=__codelineno-0-525></a><span class=sd>            The data used to train the model.</span>
<a id=__codelineno-0-526 name=__codelineno-0-526></a>
<a id=__codelineno-0-527 name=__codelineno-0-527></a><span class=sd>        Returns</span>
<a id=__codelineno-0-528 name=__codelineno-0-528></a><span class=sd>        -------</span>
<a id=__codelineno-0-529 name=__codelineno-0-529></a><span class=sd>        theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-530 name=__codelineno-0-530></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-531 name=__codelineno-0-531></a>
<a id=__codelineno-0-532 name=__codelineno-0-532></a><span class=sd>        Notes</span>
<a id=__codelineno-0-533 name=__codelineno-0-533></a><span class=sd>        -----</span>
<a id=__codelineno-0-534 name=__codelineno-0-534></a><span class=sd>        A more in-depth documentation of all methods for parameters estimation</span>
<a id=__codelineno-0-535 name=__codelineno-0-535></a><span class=sd>        will be available soon. For now, please refer to the mentioned references.</span>
<a id=__codelineno-0-536 name=__codelineno-0-536></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-537 name=__codelineno-0-537></a>        <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-538 name=__codelineno-0-538></a>
<a id=__codelineno-0-539 name=__codelineno-0-539></a>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-540 name=__codelineno-0-540></a>            <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>y</span> <span class=o>-</span> <span class=n>psi</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
<a id=__codelineno-0-541 name=__codelineno-0-541></a>            <span class=n>aux</span> <span class=o>=</span> <span class=p>(</span>
<a id=__codelineno-0-542 name=__codelineno-0-542></a>                <span class=bp>self</span><span class=o>.</span><span class=n>mu</span>
<a id=__codelineno-0-543 name=__codelineno-0-543></a>                <span class=o>*</span> <span class=n>psi</span>
<a id=__codelineno-0-544 name=__codelineno-0-544></a>                <span class=o>@</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>pinv</span><span class=p>(</span><span class=n>psi</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>psi</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>offset_covariance</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>eye</span><span class=p>(</span><span class=n>n_theta</span><span class=p>))</span>
<a id=__codelineno-0-545 name=__codelineno-0-545></a>            <span class=p>)</span>
<a id=__codelineno-0-546 name=__codelineno-0-546></a>            <span class=n>tmp_list</span> <span class=o>=</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=n>aux</span><span class=o>.</span><span class=n>T</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>)</span>
<a id=__codelineno-0-547 name=__codelineno-0-547></a>            <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-548 name=__codelineno-0-548></a>
<a id=__codelineno-0-549 name=__codelineno-0-549></a>        <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.AffineLeastMeanSquares.optimize class="doc doc-heading"> <code class="highlight language-python"><span class=n>optimize</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.AffineLeastMeanSquares.optimize class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Estimate the model parameters using the Affine Least Mean Squares.</p> <p>The ALMS method updates the parameter estimates recursively as follows:</p> <ol> <li>Compute the estimation error:</li> </ol> <p>$$ \xi = y - \psi \theta_{i-1} $$</p> <ol> <li>Update the parameter vector:</li> </ol> <p>$$ \theta_i = \theta_{i-1} + \mu \psi (\psi^T \psi + \text{offset_covariance} \cdot I)^{-1} \xi $$</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>array-like of shape (n_samples, 1)</code> </td> <td> <div class=doc-md-description> <p>The data used to train the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>array-like of shape (n_features, 1)</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=note open> <summary>Notes</summary> <p>A more in-depth documentation of all methods for parameters estimation will be available soon. For now, please refer to the mentioned references.</p> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-502>502</a></span>
<span class=normal><a href=#__codelineno-0-503>503</a></span>
<span class=normal><a href=#__codelineno-0-504>504</a></span>
<span class=normal><a href=#__codelineno-0-505>505</a></span>
<span class=normal><a href=#__codelineno-0-506>506</a></span>
<span class=normal><a href=#__codelineno-0-507>507</a></span>
<span class=normal><a href=#__codelineno-0-508>508</a></span>
<span class=normal><a href=#__codelineno-0-509>509</a></span>
<span class=normal><a href=#__codelineno-0-510>510</a></span>
<span class=normal><a href=#__codelineno-0-511>511</a></span>
<span class=normal><a href=#__codelineno-0-512>512</a></span>
<span class=normal><a href=#__codelineno-0-513>513</a></span>
<span class=normal><a href=#__codelineno-0-514>514</a></span>
<span class=normal><a href=#__codelineno-0-515>515</a></span>
<span class=normal><a href=#__codelineno-0-516>516</a></span>
<span class=normal><a href=#__codelineno-0-517>517</a></span>
<span class=normal><a href=#__codelineno-0-518>518</a></span>
<span class=normal><a href=#__codelineno-0-519>519</a></span>
<span class=normal><a href=#__codelineno-0-520>520</a></span>
<span class=normal><a href=#__codelineno-0-521>521</a></span>
<span class=normal><a href=#__codelineno-0-522>522</a></span>
<span class=normal><a href=#__codelineno-0-523>523</a></span>
<span class=normal><a href=#__codelineno-0-524>524</a></span>
<span class=normal><a href=#__codelineno-0-525>525</a></span>
<span class=normal><a href=#__codelineno-0-526>526</a></span>
<span class=normal><a href=#__codelineno-0-527>527</a></span>
<span class=normal><a href=#__codelineno-0-528>528</a></span>
<span class=normal><a href=#__codelineno-0-529>529</a></span>
<span class=normal><a href=#__codelineno-0-530>530</a></span>
<span class=normal><a href=#__codelineno-0-531>531</a></span>
<span class=normal><a href=#__codelineno-0-532>532</a></span>
<span class=normal><a href=#__codelineno-0-533>533</a></span>
<span class=normal><a href=#__codelineno-0-534>534</a></span>
<span class=normal><a href=#__codelineno-0-535>535</a></span>
<span class=normal><a href=#__codelineno-0-536>536</a></span>
<span class=normal><a href=#__codelineno-0-537>537</a></span>
<span class=normal><a href=#__codelineno-0-538>538</a></span>
<span class=normal><a href=#__codelineno-0-539>539</a></span>
<span class=normal><a href=#__codelineno-0-540>540</a></span>
<span class=normal><a href=#__codelineno-0-541>541</a></span>
<span class=normal><a href=#__codelineno-0-542>542</a></span>
<span class=normal><a href=#__codelineno-0-543>543</a></span>
<span class=normal><a href=#__codelineno-0-544>544</a></span>
<span class=normal><a href=#__codelineno-0-545>545</a></span>
<span class=normal><a href=#__codelineno-0-546>546</a></span>
<span class=normal><a href=#__codelineno-0-547>547</a></span>
<span class=normal><a href=#__codelineno-0-548>548</a></span>
<span class=normal><a href=#__codelineno-0-549>549</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-502 name=__codelineno-0-502></a><span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-503 name=__codelineno-0-503></a><span class=w>    </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Estimate the model parameters using the Affine Least Mean Squares.</span>
<a id=__codelineno-0-504 name=__codelineno-0-504></a>
<a id=__codelineno-0-505 name=__codelineno-0-505></a><span class=sd>    The ALMS method updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-506 name=__codelineno-0-506></a>
<a id=__codelineno-0-507 name=__codelineno-0-507></a><span class=sd>    1. Compute the estimation error:</span>
<a id=__codelineno-0-508 name=__codelineno-0-508></a>
<a id=__codelineno-0-509 name=__codelineno-0-509></a><span class=sd>       $$</span>
<a id=__codelineno-0-510 name=__codelineno-0-510></a><span class=sd>       \xi = y - \psi \theta_{i-1}</span>
<a id=__codelineno-0-511 name=__codelineno-0-511></a><span class=sd>       $$</span>
<a id=__codelineno-0-512 name=__codelineno-0-512></a>
<a id=__codelineno-0-513 name=__codelineno-0-513></a><span class=sd>    2. Update the parameter vector:</span>
<a id=__codelineno-0-514 name=__codelineno-0-514></a>
<a id=__codelineno-0-515 name=__codelineno-0-515></a><span class=sd>       $$</span>
<a id=__codelineno-0-516 name=__codelineno-0-516></a><span class=sd>       \theta_i = \theta_{i-1} + \mu \psi (\psi^T \psi + \text{offset_covariance}</span>
<a id=__codelineno-0-517 name=__codelineno-0-517></a><span class=sd>       \cdot I)^{-1} \xi</span>
<a id=__codelineno-0-518 name=__codelineno-0-518></a><span class=sd>       $$</span>
<a id=__codelineno-0-519 name=__codelineno-0-519></a>
<a id=__codelineno-0-520 name=__codelineno-0-520></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-521 name=__codelineno-0-521></a><span class=sd>    ----------</span>
<a id=__codelineno-0-522 name=__codelineno-0-522></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-523 name=__codelineno-0-523></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-524 name=__codelineno-0-524></a><span class=sd>    y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-525 name=__codelineno-0-525></a><span class=sd>        The data used to train the model.</span>
<a id=__codelineno-0-526 name=__codelineno-0-526></a>
<a id=__codelineno-0-527 name=__codelineno-0-527></a><span class=sd>    Returns</span>
<a id=__codelineno-0-528 name=__codelineno-0-528></a><span class=sd>    -------</span>
<a id=__codelineno-0-529 name=__codelineno-0-529></a><span class=sd>    theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-530 name=__codelineno-0-530></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-531 name=__codelineno-0-531></a>
<a id=__codelineno-0-532 name=__codelineno-0-532></a><span class=sd>    Notes</span>
<a id=__codelineno-0-533 name=__codelineno-0-533></a><span class=sd>    -----</span>
<a id=__codelineno-0-534 name=__codelineno-0-534></a><span class=sd>    A more in-depth documentation of all methods for parameters estimation</span>
<a id=__codelineno-0-535 name=__codelineno-0-535></a><span class=sd>    will be available soon. For now, please refer to the mentioned references.</span>
<a id=__codelineno-0-536 name=__codelineno-0-536></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-537 name=__codelineno-0-537></a>    <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-538 name=__codelineno-0-538></a>
<a id=__codelineno-0-539 name=__codelineno-0-539></a>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-540 name=__codelineno-0-540></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>y</span> <span class=o>-</span> <span class=n>psi</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
<a id=__codelineno-0-541 name=__codelineno-0-541></a>        <span class=n>aux</span> <span class=o>=</span> <span class=p>(</span>
<a id=__codelineno-0-542 name=__codelineno-0-542></a>            <span class=bp>self</span><span class=o>.</span><span class=n>mu</span>
<a id=__codelineno-0-543 name=__codelineno-0-543></a>            <span class=o>*</span> <span class=n>psi</span>
<a id=__codelineno-0-544 name=__codelineno-0-544></a>            <span class=o>@</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>pinv</span><span class=p>(</span><span class=n>psi</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>psi</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>offset_covariance</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>eye</span><span class=p>(</span><span class=n>n_theta</span><span class=p>))</span>
<a id=__codelineno-0-545 name=__codelineno-0-545></a>        <span class=p>)</span>
<a id=__codelineno-0-546 name=__codelineno-0-546></a>        <span class=n>tmp_list</span> <span class=o>=</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=n>aux</span><span class=o>.</span><span class=n>T</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>)</span>
<a id=__codelineno-0-547 name=__codelineno-0-547></a>        <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-548 name=__codelineno-0-548></a>
<a id=__codelineno-0-549 name=__codelineno-0-549></a>    <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.BoundedVariableLeastSquares class="doc doc-heading"> <code>BoundedVariableLeastSquares</code> <a href=#sysidentpy.parameter_estimation.estimators.BoundedVariableLeastSquares class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=sysidentpy.parameter_estimation.estimators_base.BaseEstimator>BaseEstimator</span></code></p> <p>Solve a linear least-squares problem with bounds on the variables.</p> <p>This is a wrapper class for the <code>scipy.optimize.lsq_linear</code> method.</p> <p>Given a m-by-n design matrix A and a target vector b with m elements, <code>lsq_linear</code> solves the following optimization problem::</p> <div class=highlight><pre><span></span><code>minimize 0.5 * ||A x - b||**2
subject to lb &lt;= x &lt;= ub
</code></pre></div> <p>This optimization problem is convex, hence a found minimum (if iterations have converged) is guaranteed to be global.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>unbiased</code> </td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>Indicates whether an unbiased estimator is applied.</p> </div> </td> <td> <code>False</code> </td> </tr> <tr class=doc-section-item> <td> <code>uiter</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of iterations for the unbiased estimator.</p> </div> </td> <td> <code>30</code> </td> </tr> <tr class=doc-section-item> <td> <code>method</code> </td> <td> <code><span title=trf>trf</span> or <span title=bvls>bvls</span></code> </td> <td> <div class=doc-md-description> <p>Method to perform minimization.</p> <div class=highlight><pre><span></span><code>* &#39;trf&#39; : Trust Region Reflective algorithm adapted for a linear
  least-squares problem. This is an interior-point-like method
  and the required number of iterations is weakly correlated with
  the number of variables.
* &#39;bvls&#39; : Bounded-variable least-squares algorithm. This is
  an active set method, which requires the number of iterations
  comparable to the number of variables. Can&#39;t be used when `A` is
  sparse or LinearOperator.
</code></pre></div> <p>Default is 'trf'.</p> </div> </td> <td> <code>&#39;trf&#39;</code> </td> </tr> <tr class=doc-section-item> <td> <code>tol</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>Tolerance parameter. The algorithm terminates if a relative change of the cost function is less than <code>tol</code> on the last iteration. Additionally, the first-order optimality measure is considered:</p> <div class=highlight><pre><span></span><code>* ``method=&#39;trf&#39;`` terminates if the uniform norm of the gradient,
  scaled to account for the presence of the bounds, is less than
  `tol`.
* ``method=&#39;bvls&#39;`` terminates if Karush-Kuhn-Tucker conditions
  are satisfied within `tol` tolerance.
</code></pre></div> </div> </td> <td> <code>1e-10</code> </td> </tr> <tr class=doc-section-item> <td> <code>lsq_solver</code> </td> <td> <code>(None, <span title=exact>exact</span>, <span title=scipy.sparse.linalg.lsmr>lsmr</span>)</code> </td> <td> <div class=doc-md-description> <p>Method of solving unbounded least-squares problems throughout iterations:</p> <div class=highlight><pre><span></span><code>* &#39;exact&#39; : Use dense QR or SVD decomposition approach. Can&#39;t be
  used when `A` is sparse or LinearOperator.
* &#39;lsmr&#39; : Use `scipy.sparse.linalg.lsmr` iterative procedure
  which requires only matrix-vector product evaluations. Can&#39;t
  be used with ``method=&#39;bvls&#39;``.
</code></pre></div> <p>If None (default), the solver is chosen based on type of <code>A</code>.</p> </div> </td> <td> <code>None</code> </td> </tr> <tr class=doc-section-item> <td> <code>lsmr_tol</code> </td> <td> <code>(None, <span title=float>float</span> or <span title=auto>auto</span>)</code> </td> <td> <div class=doc-md-description> <p>Tolerance parameters 'atol' and 'btol' for <code>scipy.sparse.linalg.lsmr</code> If None (default), it is set to <code>1e-2 * tol</code>. If 'auto', the tolerance will be adjusted based on the optimality of the current iterate, which can speed up the optimization process, but is not always reliable.</p> </div> </td> <td> <code>None</code> </td> </tr> <tr class=doc-section-item> <td> <code>max_iter</code> </td> <td> <code>None or <span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Maximum number of iterations before termination. If None (default), it is set to 100 for <code>method='trf'</code> or to the number of variables for <code>method='bvls'</code> (not counting iterations for 'bvls' initialization).</p> </div> </td> <td> <code>None</code> </td> </tr> <tr class=doc-section-item> <td> <code>verbose</code> </td> <td> <code>(0, 1, 2)</code> </td> <td> <div class=doc-md-description> <p>Level of algorithm's verbosity:</p> <div class=highlight><pre><span></span><code>* 0 : work silently (default).
* 1 : display a termination report.
* 2 : display progress during iterations.
</code></pre></div> </div> </td> <td> <code>0</code> </td> </tr> <tr class=doc-section-item> <td> <code>lsmr_maxiter</code> </td> <td> <code>None or <span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Maximum number of iterations for the lsmr least squares solver, if it is used (by setting <code>lsq_solver='lsmr'</code>). If None (default), it uses lsmr's default of <code>min(m, n)</code> where <code>m</code> and <code>n</code> are the number of rows and columns of <code>A</code>, respectively. Has no effect if <code>lsq_solver='exact'</code>.</p> </div> </td> <td> <code>None</code> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <p>M. A. Branch, T. F. Coleman, and Y. Li, "A Subspace, Interior, and Conjugate Gradient Method for Large-Scale Bound-Constrained Minimization Problems," SIAM Journal on Scientific Computing, Vol. 21, Number 1, pp 1-23, 1999. P. B. Start and R. L. Parker, "Bounded-Variable Least-Squares: an Algorithm and Applications", Computational Statistics, 10, 129-141, 1995.</p> </details> <details class=note open> <summary>Notes</summary> <p>This docstring is adapted from the <code>scipy.optimize.lsq_linear</code> method.</p> </details> <p><span class=doc-section-title>Examples:</span></p> <p>In this example, a problem with a large sparse matrix and bounds on the variables is solved.</p> <div class=highlight><pre><span></span><code><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=gp>&gt;&gt;&gt; </span><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=gp>&gt;&gt;&gt; </span><span class=kn>from</span><span class=w> </span><span class=nn>scipy.sparse</span><span class=w> </span><span class=kn>import</span> <span class=n>rand</span>
<a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=gp>&gt;&gt;&gt; </span><span class=kn>from</span><span class=w> </span><span class=nn>sysidentpy.parameter_estimation</span><span class=w> </span><span class=kn>import</span> <span class=n>BoundedVariableLeastSquares</span>
<a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=gp>&gt;&gt;&gt; </span><span class=n>rng</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>default_rng</span><span class=p>()</span>
<a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=gp>...</span>
<a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a><span class=gp>&gt;&gt;&gt; </span><span class=n>m</span> <span class=o>=</span> <span class=mi>20000</span>
<a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a><span class=gp>&gt;&gt;&gt; </span><span class=n>n</span> <span class=o>=</span> <span class=mi>10000</span>
<a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a><span class=gp>...</span>
<a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a><span class=gp>&gt;&gt;&gt; </span><span class=n>A</span> <span class=o>=</span> <span class=n>rand</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>density</span><span class=o>=</span><span class=mf>1e-4</span><span class=p>,</span> <span class=n>random_state</span><span class=o>=</span><span class=n>rng</span><span class=p>)</span>
<a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a><span class=gp>&gt;&gt;&gt; </span><span class=n>b</span> <span class=o>=</span> <span class=n>rng</span><span class=o>.</span><span class=n>standard_normal</span><span class=p>(</span><span class=n>m</span><span class=p>)</span>
<a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a><span class=gp>...</span>
<a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a><span class=gp>&gt;&gt;&gt; </span><span class=n>lb</span> <span class=o>=</span> <span class=n>rng</span><span class=o>.</span><span class=n>standard_normal</span><span class=p>(</span><span class=n>n</span><span class=p>)</span>
<a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a><span class=gp>&gt;&gt;&gt; </span><span class=n>ub</span> <span class=o>=</span> <span class=n>lb</span> <span class=o>+</span> <span class=mi>1</span>
<a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a><span class=gp>...</span>
<a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a><span class=gp>&gt;&gt;&gt; </span><span class=n>res</span> <span class=o>=</span> <span class=n>BoundedVariableLeastSquares</span><span class=p>(</span><span class=n>A</span><span class=p>,</span> <span class=n>b</span><span class=p>,</span> <span class=n>bounds</span><span class=o>=</span><span class=p>(</span><span class=n>lb</span><span class=p>,</span> <span class=n>ub</span><span class=p>),</span> <span class=n>lsmr_tol</span><span class=o>=</span><span class=s1>&#39;auto&#39;</span><span class=p>,</span>
<a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a><span class=go>verbose=1)</span>
<a id=__codelineno-0-17 name=__codelineno-0-17 href=#__codelineno-0-17></a><span class=go>The relative change of the cost function is less than `tol`.</span>
<a id=__codelineno-0-18 name=__codelineno-0-18 href=#__codelineno-0-18></a><span class=go>Number of iterations 16, initial cost 1.5039e+04, final cost 1.1112e+04,</span>
<a id=__codelineno-0-19 name=__codelineno-0-19 href=#__codelineno-0-19></a><span class=go>first-order optimality 4.66e-08.</span>
</code></pre></div> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-1856>1856</a></span>
<span class=normal><a href=#__codelineno-0-1857>1857</a></span>
<span class=normal><a href=#__codelineno-0-1858>1858</a></span>
<span class=normal><a href=#__codelineno-0-1859>1859</a></span>
<span class=normal><a href=#__codelineno-0-1860>1860</a></span>
<span class=normal><a href=#__codelineno-0-1861>1861</a></span>
<span class=normal><a href=#__codelineno-0-1862>1862</a></span>
<span class=normal><a href=#__codelineno-0-1863>1863</a></span>
<span class=normal><a href=#__codelineno-0-1864>1864</a></span>
<span class=normal><a href=#__codelineno-0-1865>1865</a></span>
<span class=normal><a href=#__codelineno-0-1866>1866</a></span>
<span class=normal><a href=#__codelineno-0-1867>1867</a></span>
<span class=normal><a href=#__codelineno-0-1868>1868</a></span>
<span class=normal><a href=#__codelineno-0-1869>1869</a></span>
<span class=normal><a href=#__codelineno-0-1870>1870</a></span>
<span class=normal><a href=#__codelineno-0-1871>1871</a></span>
<span class=normal><a href=#__codelineno-0-1872>1872</a></span>
<span class=normal><a href=#__codelineno-0-1873>1873</a></span>
<span class=normal><a href=#__codelineno-0-1874>1874</a></span>
<span class=normal><a href=#__codelineno-0-1875>1875</a></span>
<span class=normal><a href=#__codelineno-0-1876>1876</a></span>
<span class=normal><a href=#__codelineno-0-1877>1877</a></span>
<span class=normal><a href=#__codelineno-0-1878>1878</a></span>
<span class=normal><a href=#__codelineno-0-1879>1879</a></span>
<span class=normal><a href=#__codelineno-0-1880>1880</a></span>
<span class=normal><a href=#__codelineno-0-1881>1881</a></span>
<span class=normal><a href=#__codelineno-0-1882>1882</a></span>
<span class=normal><a href=#__codelineno-0-1883>1883</a></span>
<span class=normal><a href=#__codelineno-0-1884>1884</a></span>
<span class=normal><a href=#__codelineno-0-1885>1885</a></span>
<span class=normal><a href=#__codelineno-0-1886>1886</a></span>
<span class=normal><a href=#__codelineno-0-1887>1887</a></span>
<span class=normal><a href=#__codelineno-0-1888>1888</a></span>
<span class=normal><a href=#__codelineno-0-1889>1889</a></span>
<span class=normal><a href=#__codelineno-0-1890>1890</a></span>
<span class=normal><a href=#__codelineno-0-1891>1891</a></span>
<span class=normal><a href=#__codelineno-0-1892>1892</a></span>
<span class=normal><a href=#__codelineno-0-1893>1893</a></span>
<span class=normal><a href=#__codelineno-0-1894>1894</a></span>
<span class=normal><a href=#__codelineno-0-1895>1895</a></span>
<span class=normal><a href=#__codelineno-0-1896>1896</a></span>
<span class=normal><a href=#__codelineno-0-1897>1897</a></span>
<span class=normal><a href=#__codelineno-0-1898>1898</a></span>
<span class=normal><a href=#__codelineno-0-1899>1899</a></span>
<span class=normal><a href=#__codelineno-0-1900>1900</a></span>
<span class=normal><a href=#__codelineno-0-1901>1901</a></span>
<span class=normal><a href=#__codelineno-0-1902>1902</a></span>
<span class=normal><a href=#__codelineno-0-1903>1903</a></span>
<span class=normal><a href=#__codelineno-0-1904>1904</a></span>
<span class=normal><a href=#__codelineno-0-1905>1905</a></span>
<span class=normal><a href=#__codelineno-0-1906>1906</a></span>
<span class=normal><a href=#__codelineno-0-1907>1907</a></span>
<span class=normal><a href=#__codelineno-0-1908>1908</a></span>
<span class=normal><a href=#__codelineno-0-1909>1909</a></span>
<span class=normal><a href=#__codelineno-0-1910>1910</a></span>
<span class=normal><a href=#__codelineno-0-1911>1911</a></span>
<span class=normal><a href=#__codelineno-0-1912>1912</a></span>
<span class=normal><a href=#__codelineno-0-1913>1913</a></span>
<span class=normal><a href=#__codelineno-0-1914>1914</a></span>
<span class=normal><a href=#__codelineno-0-1915>1915</a></span>
<span class=normal><a href=#__codelineno-0-1916>1916</a></span>
<span class=normal><a href=#__codelineno-0-1917>1917</a></span>
<span class=normal><a href=#__codelineno-0-1918>1918</a></span>
<span class=normal><a href=#__codelineno-0-1919>1919</a></span>
<span class=normal><a href=#__codelineno-0-1920>1920</a></span>
<span class=normal><a href=#__codelineno-0-1921>1921</a></span>
<span class=normal><a href=#__codelineno-0-1922>1922</a></span>
<span class=normal><a href=#__codelineno-0-1923>1923</a></span>
<span class=normal><a href=#__codelineno-0-1924>1924</a></span>
<span class=normal><a href=#__codelineno-0-1925>1925</a></span>
<span class=normal><a href=#__codelineno-0-1926>1926</a></span>
<span class=normal><a href=#__codelineno-0-1927>1927</a></span>
<span class=normal><a href=#__codelineno-0-1928>1928</a></span>
<span class=normal><a href=#__codelineno-0-1929>1929</a></span>
<span class=normal><a href=#__codelineno-0-1930>1930</a></span>
<span class=normal><a href=#__codelineno-0-1931>1931</a></span>
<span class=normal><a href=#__codelineno-0-1932>1932</a></span>
<span class=normal><a href=#__codelineno-0-1933>1933</a></span>
<span class=normal><a href=#__codelineno-0-1934>1934</a></span>
<span class=normal><a href=#__codelineno-0-1935>1935</a></span>
<span class=normal><a href=#__codelineno-0-1936>1936</a></span>
<span class=normal><a href=#__codelineno-0-1937>1937</a></span>
<span class=normal><a href=#__codelineno-0-1938>1938</a></span>
<span class=normal><a href=#__codelineno-0-1939>1939</a></span>
<span class=normal><a href=#__codelineno-0-1940>1940</a></span>
<span class=normal><a href=#__codelineno-0-1941>1941</a></span>
<span class=normal><a href=#__codelineno-0-1942>1942</a></span>
<span class=normal><a href=#__codelineno-0-1943>1943</a></span>
<span class=normal><a href=#__codelineno-0-1944>1944</a></span>
<span class=normal><a href=#__codelineno-0-1945>1945</a></span>
<span class=normal><a href=#__codelineno-0-1946>1946</a></span>
<span class=normal><a href=#__codelineno-0-1947>1947</a></span>
<span class=normal><a href=#__codelineno-0-1948>1948</a></span>
<span class=normal><a href=#__codelineno-0-1949>1949</a></span>
<span class=normal><a href=#__codelineno-0-1950>1950</a></span>
<span class=normal><a href=#__codelineno-0-1951>1951</a></span>
<span class=normal><a href=#__codelineno-0-1952>1952</a></span>
<span class=normal><a href=#__codelineno-0-1953>1953</a></span>
<span class=normal><a href=#__codelineno-0-1954>1954</a></span>
<span class=normal><a href=#__codelineno-0-1955>1955</a></span>
<span class=normal><a href=#__codelineno-0-1956>1956</a></span>
<span class=normal><a href=#__codelineno-0-1957>1957</a></span>
<span class=normal><a href=#__codelineno-0-1958>1958</a></span>
<span class=normal><a href=#__codelineno-0-1959>1959</a></span>
<span class=normal><a href=#__codelineno-0-1960>1960</a></span>
<span class=normal><a href=#__codelineno-0-1961>1961</a></span>
<span class=normal><a href=#__codelineno-0-1962>1962</a></span>
<span class=normal><a href=#__codelineno-0-1963>1963</a></span>
<span class=normal><a href=#__codelineno-0-1964>1964</a></span>
<span class=normal><a href=#__codelineno-0-1965>1965</a></span>
<span class=normal><a href=#__codelineno-0-1966>1966</a></span>
<span class=normal><a href=#__codelineno-0-1967>1967</a></span>
<span class=normal><a href=#__codelineno-0-1968>1968</a></span>
<span class=normal><a href=#__codelineno-0-1969>1969</a></span>
<span class=normal><a href=#__codelineno-0-1970>1970</a></span>
<span class=normal><a href=#__codelineno-0-1971>1971</a></span>
<span class=normal><a href=#__codelineno-0-1972>1972</a></span>
<span class=normal><a href=#__codelineno-0-1973>1973</a></span>
<span class=normal><a href=#__codelineno-0-1974>1974</a></span>
<span class=normal><a href=#__codelineno-0-1975>1975</a></span>
<span class=normal><a href=#__codelineno-0-1976>1976</a></span>
<span class=normal><a href=#__codelineno-0-1977>1977</a></span>
<span class=normal><a href=#__codelineno-0-1978>1978</a></span>
<span class=normal><a href=#__codelineno-0-1979>1979</a></span>
<span class=normal><a href=#__codelineno-0-1980>1980</a></span>
<span class=normal><a href=#__codelineno-0-1981>1981</a></span>
<span class=normal><a href=#__codelineno-0-1982>1982</a></span>
<span class=normal><a href=#__codelineno-0-1983>1983</a></span>
<span class=normal><a href=#__codelineno-0-1984>1984</a></span>
<span class=normal><a href=#__codelineno-0-1985>1985</a></span>
<span class=normal><a href=#__codelineno-0-1986>1986</a></span>
<span class=normal><a href=#__codelineno-0-1987>1987</a></span>
<span class=normal><a href=#__codelineno-0-1988>1988</a></span>
<span class=normal><a href=#__codelineno-0-1989>1989</a></span>
<span class=normal><a href=#__codelineno-0-1990>1990</a></span>
<span class=normal><a href=#__codelineno-0-1991>1991</a></span>
<span class=normal><a href=#__codelineno-0-1992>1992</a></span>
<span class=normal><a href=#__codelineno-0-1993>1993</a></span>
<span class=normal><a href=#__codelineno-0-1994>1994</a></span>
<span class=normal><a href=#__codelineno-0-1995>1995</a></span>
<span class=normal><a href=#__codelineno-0-1996>1996</a></span>
<span class=normal><a href=#__codelineno-0-1997>1997</a></span>
<span class=normal><a href=#__codelineno-0-1998>1998</a></span>
<span class=normal><a href=#__codelineno-0-1999>1999</a></span>
<span class=normal><a href=#__codelineno-0-2000>2000</a></span>
<span class=normal><a href=#__codelineno-0-2001>2001</a></span>
<span class=normal><a href=#__codelineno-0-2002>2002</a></span>
<span class=normal><a href=#__codelineno-0-2003>2003</a></span>
<span class=normal><a href=#__codelineno-0-2004>2004</a></span>
<span class=normal><a href=#__codelineno-0-2005>2005</a></span>
<span class=normal><a href=#__codelineno-0-2006>2006</a></span>
<span class=normal><a href=#__codelineno-0-2007>2007</a></span>
<span class=normal><a href=#__codelineno-0-2008>2008</a></span>
<span class=normal><a href=#__codelineno-0-2009>2009</a></span>
<span class=normal><a href=#__codelineno-0-2010>2010</a></span>
<span class=normal><a href=#__codelineno-0-2011>2011</a></span>
<span class=normal><a href=#__codelineno-0-2012>2012</a></span>
<span class=normal><a href=#__codelineno-0-2013>2013</a></span>
<span class=normal><a href=#__codelineno-0-2014>2014</a></span>
<span class=normal><a href=#__codelineno-0-2015>2015</a></span>
<span class=normal><a href=#__codelineno-0-2016>2016</a></span>
<span class=normal><a href=#__codelineno-0-2017>2017</a></span>
<span class=normal><a href=#__codelineno-0-2018>2018</a></span>
<span class=normal><a href=#__codelineno-0-2019>2019</a></span>
<span class=normal><a href=#__codelineno-0-2020>2020</a></span>
<span class=normal><a href=#__codelineno-0-2021>2021</a></span>
<span class=normal><a href=#__codelineno-0-2022>2022</a></span>
<span class=normal><a href=#__codelineno-0-2023>2023</a></span>
<span class=normal><a href=#__codelineno-0-2024>2024</a></span>
<span class=normal><a href=#__codelineno-0-2025>2025</a></span>
<span class=normal><a href=#__codelineno-0-2026>2026</a></span>
<span class=normal><a href=#__codelineno-0-2027>2027</a></span>
<span class=normal><a href=#__codelineno-0-2028>2028</a></span>
<span class=normal><a href=#__codelineno-0-2029>2029</a></span>
<span class=normal><a href=#__codelineno-0-2030>2030</a></span>
<span class=normal><a href=#__codelineno-0-2031>2031</a></span>
<span class=normal><a href=#__codelineno-0-2032>2032</a></span>
<span class=normal><a href=#__codelineno-0-2033>2033</a></span>
<span class=normal><a href=#__codelineno-0-2034>2034</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-1856 name=__codelineno-0-1856></a><span class=k>class</span><span class=w> </span><span class=nc>BoundedVariableLeastSquares</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>):</span>
<a id=__codelineno-0-1857 name=__codelineno-0-1857></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Solve a linear least-squares problem with bounds on the variables.</span>
<a id=__codelineno-0-1858 name=__codelineno-0-1858></a>
<a id=__codelineno-0-1859 name=__codelineno-0-1859></a><span class=sd>    This is a wrapper class for the `scipy.optimize.lsq_linear` method.</span>
<a id=__codelineno-0-1860 name=__codelineno-0-1860></a>
<a id=__codelineno-0-1861 name=__codelineno-0-1861></a><span class=sd>    Given a m-by-n design matrix A and a target vector b with m elements,</span>
<a id=__codelineno-0-1862 name=__codelineno-0-1862></a><span class=sd>    `lsq_linear` solves the following optimization problem::</span>
<a id=__codelineno-0-1863 name=__codelineno-0-1863></a>
<a id=__codelineno-0-1864 name=__codelineno-0-1864></a><span class=sd>        minimize 0.5 * ||A x - b||**2</span>
<a id=__codelineno-0-1865 name=__codelineno-0-1865></a><span class=sd>        subject to lb &lt;= x &lt;= ub</span>
<a id=__codelineno-0-1866 name=__codelineno-0-1866></a>
<a id=__codelineno-0-1867 name=__codelineno-0-1867></a><span class=sd>    This optimization problem is convex, hence a found minimum (if iterations</span>
<a id=__codelineno-0-1868 name=__codelineno-0-1868></a><span class=sd>    have converged) is guaranteed to be global.</span>
<a id=__codelineno-0-1869 name=__codelineno-0-1869></a>
<a id=__codelineno-0-1870 name=__codelineno-0-1870></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-1871 name=__codelineno-0-1871></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1872 name=__codelineno-0-1872></a><span class=sd>    unbiased : bool</span>
<a id=__codelineno-0-1873 name=__codelineno-0-1873></a><span class=sd>        Indicates whether an unbiased estimator is applied.</span>
<a id=__codelineno-0-1874 name=__codelineno-0-1874></a><span class=sd>    uiter : int</span>
<a id=__codelineno-0-1875 name=__codelineno-0-1875></a><span class=sd>        Number of iterations for the unbiased estimator.</span>
<a id=__codelineno-0-1876 name=__codelineno-0-1876></a><span class=sd>    method : &#39;trf&#39; or &#39;bvls&#39;, optional</span>
<a id=__codelineno-0-1877 name=__codelineno-0-1877></a><span class=sd>        Method to perform minimization.</span>
<a id=__codelineno-0-1878 name=__codelineno-0-1878></a>
<a id=__codelineno-0-1879 name=__codelineno-0-1879></a><span class=sd>            * &#39;trf&#39; : Trust Region Reflective algorithm adapted for a linear</span>
<a id=__codelineno-0-1880 name=__codelineno-0-1880></a><span class=sd>              least-squares problem. This is an interior-point-like method</span>
<a id=__codelineno-0-1881 name=__codelineno-0-1881></a><span class=sd>              and the required number of iterations is weakly correlated with</span>
<a id=__codelineno-0-1882 name=__codelineno-0-1882></a><span class=sd>              the number of variables.</span>
<a id=__codelineno-0-1883 name=__codelineno-0-1883></a><span class=sd>            * &#39;bvls&#39; : Bounded-variable least-squares algorithm. This is</span>
<a id=__codelineno-0-1884 name=__codelineno-0-1884></a><span class=sd>              an active set method, which requires the number of iterations</span>
<a id=__codelineno-0-1885 name=__codelineno-0-1885></a><span class=sd>              comparable to the number of variables. Can&#39;t be used when `A` is</span>
<a id=__codelineno-0-1886 name=__codelineno-0-1886></a><span class=sd>              sparse or LinearOperator.</span>
<a id=__codelineno-0-1887 name=__codelineno-0-1887></a>
<a id=__codelineno-0-1888 name=__codelineno-0-1888></a><span class=sd>        Default is &#39;trf&#39;.</span>
<a id=__codelineno-0-1889 name=__codelineno-0-1889></a><span class=sd>    tol : float, optional</span>
<a id=__codelineno-0-1890 name=__codelineno-0-1890></a><span class=sd>        Tolerance parameter. The algorithm terminates if a relative change</span>
<a id=__codelineno-0-1891 name=__codelineno-0-1891></a><span class=sd>        of the cost function is less than `tol` on the last iteration.</span>
<a id=__codelineno-0-1892 name=__codelineno-0-1892></a><span class=sd>        Additionally, the first-order optimality measure is considered:</span>
<a id=__codelineno-0-1893 name=__codelineno-0-1893></a>
<a id=__codelineno-0-1894 name=__codelineno-0-1894></a><span class=sd>            * ``method=&#39;trf&#39;`` terminates if the uniform norm of the gradient,</span>
<a id=__codelineno-0-1895 name=__codelineno-0-1895></a><span class=sd>              scaled to account for the presence of the bounds, is less than</span>
<a id=__codelineno-0-1896 name=__codelineno-0-1896></a><span class=sd>              `tol`.</span>
<a id=__codelineno-0-1897 name=__codelineno-0-1897></a><span class=sd>            * ``method=&#39;bvls&#39;`` terminates if Karush-Kuhn-Tucker conditions</span>
<a id=__codelineno-0-1898 name=__codelineno-0-1898></a><span class=sd>              are satisfied within `tol` tolerance.</span>
<a id=__codelineno-0-1899 name=__codelineno-0-1899></a>
<a id=__codelineno-0-1900 name=__codelineno-0-1900></a><span class=sd>    lsq_solver : {None, &#39;exact&#39;, &#39;lsmr&#39;}, optional</span>
<a id=__codelineno-0-1901 name=__codelineno-0-1901></a><span class=sd>        Method of solving unbounded least-squares problems throughout</span>
<a id=__codelineno-0-1902 name=__codelineno-0-1902></a><span class=sd>        iterations:</span>
<a id=__codelineno-0-1903 name=__codelineno-0-1903></a>
<a id=__codelineno-0-1904 name=__codelineno-0-1904></a><span class=sd>            * &#39;exact&#39; : Use dense QR or SVD decomposition approach. Can&#39;t be</span>
<a id=__codelineno-0-1905 name=__codelineno-0-1905></a><span class=sd>              used when `A` is sparse or LinearOperator.</span>
<a id=__codelineno-0-1906 name=__codelineno-0-1906></a><span class=sd>            * &#39;lsmr&#39; : Use `scipy.sparse.linalg.lsmr` iterative procedure</span>
<a id=__codelineno-0-1907 name=__codelineno-0-1907></a><span class=sd>              which requires only matrix-vector product evaluations. Can&#39;t</span>
<a id=__codelineno-0-1908 name=__codelineno-0-1908></a><span class=sd>              be used with ``method=&#39;bvls&#39;``.</span>
<a id=__codelineno-0-1909 name=__codelineno-0-1909></a>
<a id=__codelineno-0-1910 name=__codelineno-0-1910></a><span class=sd>        If None (default), the solver is chosen based on type of `A`.</span>
<a id=__codelineno-0-1911 name=__codelineno-0-1911></a><span class=sd>    lsmr_tol : None, float or &#39;auto&#39;, optional</span>
<a id=__codelineno-0-1912 name=__codelineno-0-1912></a><span class=sd>        Tolerance parameters &#39;atol&#39; and &#39;btol&#39; for `scipy.sparse.linalg.lsmr`</span>
<a id=__codelineno-0-1913 name=__codelineno-0-1913></a><span class=sd>        If None (default), it is set to ``1e-2 * tol``. If &#39;auto&#39;, the</span>
<a id=__codelineno-0-1914 name=__codelineno-0-1914></a><span class=sd>        tolerance will be adjusted based on the optimality of the current</span>
<a id=__codelineno-0-1915 name=__codelineno-0-1915></a><span class=sd>        iterate, which can speed up the optimization process, but is not always</span>
<a id=__codelineno-0-1916 name=__codelineno-0-1916></a><span class=sd>        reliable.</span>
<a id=__codelineno-0-1917 name=__codelineno-0-1917></a><span class=sd>    max_iter : None or int, optional</span>
<a id=__codelineno-0-1918 name=__codelineno-0-1918></a><span class=sd>        Maximum number of iterations before termination. If None (default), it</span>
<a id=__codelineno-0-1919 name=__codelineno-0-1919></a><span class=sd>        is set to 100 for ``method=&#39;trf&#39;`` or to the number of variables for</span>
<a id=__codelineno-0-1920 name=__codelineno-0-1920></a><span class=sd>        ``method=&#39;bvls&#39;`` (not counting iterations for &#39;bvls&#39; initialization).</span>
<a id=__codelineno-0-1921 name=__codelineno-0-1921></a><span class=sd>    verbose : {0, 1, 2}, optional</span>
<a id=__codelineno-0-1922 name=__codelineno-0-1922></a><span class=sd>        Level of algorithm&#39;s verbosity:</span>
<a id=__codelineno-0-1923 name=__codelineno-0-1923></a>
<a id=__codelineno-0-1924 name=__codelineno-0-1924></a><span class=sd>            * 0 : work silently (default).</span>
<a id=__codelineno-0-1925 name=__codelineno-0-1925></a><span class=sd>            * 1 : display a termination report.</span>
<a id=__codelineno-0-1926 name=__codelineno-0-1926></a><span class=sd>            * 2 : display progress during iterations.</span>
<a id=__codelineno-0-1927 name=__codelineno-0-1927></a><span class=sd>    lsmr_maxiter : None or int, optional</span>
<a id=__codelineno-0-1928 name=__codelineno-0-1928></a><span class=sd>        Maximum number of iterations for the lsmr least squares solver,</span>
<a id=__codelineno-0-1929 name=__codelineno-0-1929></a><span class=sd>        if it is used (by setting ``lsq_solver=&#39;lsmr&#39;``). If None (default), it</span>
<a id=__codelineno-0-1930 name=__codelineno-0-1930></a><span class=sd>        uses lsmr&#39;s default of ``min(m, n)`` where ``m`` and ``n`` are the</span>
<a id=__codelineno-0-1931 name=__codelineno-0-1931></a><span class=sd>        number of rows and columns of `A`, respectively. Has no effect if</span>
<a id=__codelineno-0-1932 name=__codelineno-0-1932></a><span class=sd>        ``lsq_solver=&#39;exact&#39;``.</span>
<a id=__codelineno-0-1933 name=__codelineno-0-1933></a>
<a id=__codelineno-0-1934 name=__codelineno-0-1934></a><span class=sd>    References</span>
<a id=__codelineno-0-1935 name=__codelineno-0-1935></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1936 name=__codelineno-0-1936></a><span class=sd>    M. A. Branch, T. F. Coleman, and Y. Li, &quot;A Subspace, Interior,</span>
<a id=__codelineno-0-1937 name=__codelineno-0-1937></a><span class=sd>        and Conjugate Gradient Method for Large-Scale Bound-Constrained</span>
<a id=__codelineno-0-1938 name=__codelineno-0-1938></a><span class=sd>        Minimization Problems,&quot; SIAM Journal on Scientific Computing,</span>
<a id=__codelineno-0-1939 name=__codelineno-0-1939></a><span class=sd>        Vol. 21, Number 1, pp 1-23, 1999.</span>
<a id=__codelineno-0-1940 name=__codelineno-0-1940></a><span class=sd>    P. B. Start and R. L. Parker, &quot;Bounded-Variable Least-Squares:</span>
<a id=__codelineno-0-1941 name=__codelineno-0-1941></a><span class=sd>        an Algorithm and Applications&quot;, Computational Statistics, 10,</span>
<a id=__codelineno-0-1942 name=__codelineno-0-1942></a><span class=sd>        129-141, 1995.</span>
<a id=__codelineno-0-1943 name=__codelineno-0-1943></a>
<a id=__codelineno-0-1944 name=__codelineno-0-1944></a><span class=sd>    Notes</span>
<a id=__codelineno-0-1945 name=__codelineno-0-1945></a><span class=sd>    -----</span>
<a id=__codelineno-0-1946 name=__codelineno-0-1946></a><span class=sd>    This docstring is adapted from the `scipy.optimize.lsq_linear` method.</span>
<a id=__codelineno-0-1947 name=__codelineno-0-1947></a>
<a id=__codelineno-0-1948 name=__codelineno-0-1948></a><span class=sd>    Examples</span>
<a id=__codelineno-0-1949 name=__codelineno-0-1949></a><span class=sd>    --------</span>
<a id=__codelineno-0-1950 name=__codelineno-0-1950></a><span class=sd>    In this example, a problem with a large sparse matrix and bounds on the</span>
<a id=__codelineno-0-1951 name=__codelineno-0-1951></a><span class=sd>    variables is solved.</span>
<a id=__codelineno-0-1952 name=__codelineno-0-1952></a>
<a id=__codelineno-0-1953 name=__codelineno-0-1953></a><span class=sd>    &gt;&gt;&gt; import numpy as np</span>
<a id=__codelineno-0-1954 name=__codelineno-0-1954></a><span class=sd>    &gt;&gt;&gt; from scipy.sparse import rand</span>
<a id=__codelineno-0-1955 name=__codelineno-0-1955></a><span class=sd>    &gt;&gt;&gt; from sysidentpy.parameter_estimation import BoundedVariableLeastSquares</span>
<a id=__codelineno-0-1956 name=__codelineno-0-1956></a><span class=sd>    &gt;&gt;&gt; rng = np.random.default_rng()</span>
<a id=__codelineno-0-1957 name=__codelineno-0-1957></a><span class=sd>    ...</span>
<a id=__codelineno-0-1958 name=__codelineno-0-1958></a><span class=sd>    &gt;&gt;&gt; m = 20000</span>
<a id=__codelineno-0-1959 name=__codelineno-0-1959></a><span class=sd>    &gt;&gt;&gt; n = 10000</span>
<a id=__codelineno-0-1960 name=__codelineno-0-1960></a><span class=sd>    ...</span>
<a id=__codelineno-0-1961 name=__codelineno-0-1961></a><span class=sd>    &gt;&gt;&gt; A = rand(m, n, density=1e-4, random_state=rng)</span>
<a id=__codelineno-0-1962 name=__codelineno-0-1962></a><span class=sd>    &gt;&gt;&gt; b = rng.standard_normal(m)</span>
<a id=__codelineno-0-1963 name=__codelineno-0-1963></a><span class=sd>    ...</span>
<a id=__codelineno-0-1964 name=__codelineno-0-1964></a><span class=sd>    &gt;&gt;&gt; lb = rng.standard_normal(n)</span>
<a id=__codelineno-0-1965 name=__codelineno-0-1965></a><span class=sd>    &gt;&gt;&gt; ub = lb + 1</span>
<a id=__codelineno-0-1966 name=__codelineno-0-1966></a><span class=sd>    ...</span>
<a id=__codelineno-0-1967 name=__codelineno-0-1967></a><span class=sd>    &gt;&gt;&gt; res = BoundedVariableLeastSquares(A, b, bounds=(lb, ub), lsmr_tol=&#39;auto&#39;,</span>
<a id=__codelineno-0-1968 name=__codelineno-0-1968></a><span class=sd>    verbose=1)</span>
<a id=__codelineno-0-1969 name=__codelineno-0-1969></a><span class=sd>    The relative change of the cost function is less than `tol`.</span>
<a id=__codelineno-0-1970 name=__codelineno-0-1970></a><span class=sd>    Number of iterations 16, initial cost 1.5039e+04, final cost 1.1112e+04,</span>
<a id=__codelineno-0-1971 name=__codelineno-0-1971></a><span class=sd>    first-order optimality 4.66e-08.</span>
<a id=__codelineno-0-1972 name=__codelineno-0-1972></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-1973 name=__codelineno-0-1973></a>
<a id=__codelineno-0-1974 name=__codelineno-0-1974></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span>
<a id=__codelineno-0-1975 name=__codelineno-0-1975></a>        <span class=bp>self</span><span class=p>,</span>
<a id=__codelineno-0-1976 name=__codelineno-0-1976></a>        <span class=o>*</span><span class=p>,</span>
<a id=__codelineno-0-1977 name=__codelineno-0-1977></a>        <span class=n>unbiased</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>
<a id=__codelineno-0-1978 name=__codelineno-0-1978></a>        <span class=n>uiter</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>30</span><span class=p>,</span>
<a id=__codelineno-0-1979 name=__codelineno-0-1979></a>        <span class=n>bounds</span><span class=o>=</span><span class=p>(</span><span class=o>-</span><span class=n>np</span><span class=o>.</span><span class=n>inf</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>inf</span><span class=p>),</span>
<a id=__codelineno-0-1980 name=__codelineno-0-1980></a>        <span class=n>method</span><span class=o>=</span><span class=s2>&quot;trf&quot;</span><span class=p>,</span>
<a id=__codelineno-0-1981 name=__codelineno-0-1981></a>        <span class=n>tol</span><span class=o>=</span><span class=mf>1e-10</span><span class=p>,</span>
<a id=__codelineno-0-1982 name=__codelineno-0-1982></a>        <span class=n>lsq_solver</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
<a id=__codelineno-0-1983 name=__codelineno-0-1983></a>        <span class=n>lsmr_tol</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
<a id=__codelineno-0-1984 name=__codelineno-0-1984></a>        <span class=n>max_iter</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
<a id=__codelineno-0-1985 name=__codelineno-0-1985></a>        <span class=n>verbose</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>
<a id=__codelineno-0-1986 name=__codelineno-0-1986></a>        <span class=n>lsmr_maxiter</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
<a id=__codelineno-0-1987 name=__codelineno-0-1987></a>    <span class=p>):</span>
<a id=__codelineno-0-1988 name=__codelineno-0-1988></a>        <span class=bp>self</span><span class=o>.</span><span class=n>unbiased</span> <span class=o>=</span> <span class=n>unbiased</span>
<a id=__codelineno-0-1989 name=__codelineno-0-1989></a>        <span class=bp>self</span><span class=o>.</span><span class=n>uiter</span> <span class=o>=</span> <span class=n>uiter</span>
<a id=__codelineno-0-1990 name=__codelineno-0-1990></a>        <span class=bp>self</span><span class=o>.</span><span class=n>max_iter</span> <span class=o>=</span> <span class=n>max_iter</span>
<a id=__codelineno-0-1991 name=__codelineno-0-1991></a>        <span class=bp>self</span><span class=o>.</span><span class=n>bounds</span> <span class=o>=</span> <span class=n>bounds</span>
<a id=__codelineno-0-1992 name=__codelineno-0-1992></a>        <span class=bp>self</span><span class=o>.</span><span class=n>method</span> <span class=o>=</span> <span class=n>method</span>
<a id=__codelineno-0-1993 name=__codelineno-0-1993></a>        <span class=bp>self</span><span class=o>.</span><span class=n>tol</span> <span class=o>=</span> <span class=n>tol</span>
<a id=__codelineno-0-1994 name=__codelineno-0-1994></a>        <span class=bp>self</span><span class=o>.</span><span class=n>lsq_solver</span> <span class=o>=</span> <span class=n>lsq_solver</span>
<a id=__codelineno-0-1995 name=__codelineno-0-1995></a>        <span class=bp>self</span><span class=o>.</span><span class=n>lsmr_tol</span> <span class=o>=</span> <span class=n>lsmr_tol</span>
<a id=__codelineno-0-1996 name=__codelineno-0-1996></a>        <span class=bp>self</span><span class=o>.</span><span class=n>verbose</span> <span class=o>=</span> <span class=n>verbose</span>
<a id=__codelineno-0-1997 name=__codelineno-0-1997></a>        <span class=bp>self</span><span class=o>.</span><span class=n>lsmr_maxiter</span> <span class=o>=</span> <span class=n>lsmr_maxiter</span>
<a id=__codelineno-0-1998 name=__codelineno-0-1998></a>
<a id=__codelineno-0-1999 name=__codelineno-0-1999></a>    <span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
<a id=__codelineno-0-2000 name=__codelineno-0-2000></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Parameter estimation using the BoundedVariableLeastSquares algorithm.</span>
<a id=__codelineno-0-2001 name=__codelineno-0-2001></a>
<a id=__codelineno-0-2002 name=__codelineno-0-2002></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-2003 name=__codelineno-0-2003></a><span class=sd>        ----------</span>
<a id=__codelineno-0-2004 name=__codelineno-0-2004></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-2005 name=__codelineno-0-2005></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-2006 name=__codelineno-0-2006></a><span class=sd>        y : ndarray of floats of shape (n_samples, 1)</span>
<a id=__codelineno-0-2007 name=__codelineno-0-2007></a><span class=sd>            The data used to train the model.</span>
<a id=__codelineno-0-2008 name=__codelineno-0-2008></a>
<a id=__codelineno-0-2009 name=__codelineno-0-2009></a><span class=sd>        Returns</span>
<a id=__codelineno-0-2010 name=__codelineno-0-2010></a><span class=sd>        -------</span>
<a id=__codelineno-0-2011 name=__codelineno-0-2011></a><span class=sd>        theta : array-like of shape = number_of_model_elements</span>
<a id=__codelineno-0-2012 name=__codelineno-0-2012></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-2013 name=__codelineno-0-2013></a>
<a id=__codelineno-0-2014 name=__codelineno-0-2014></a><span class=sd>        Notes</span>
<a id=__codelineno-0-2015 name=__codelineno-0-2015></a><span class=sd>        -----</span>
<a id=__codelineno-0-2016 name=__codelineno-0-2016></a><span class=sd>        This is a wrapper class for the `scipy.optimize.lsq_linear` method.</span>
<a id=__codelineno-0-2017 name=__codelineno-0-2017></a>
<a id=__codelineno-0-2018 name=__codelineno-0-2018></a><span class=sd>        References</span>
<a id=__codelineno-0-2019 name=__codelineno-0-2019></a><span class=sd>        ----------</span>
<a id=__codelineno-0-2020 name=__codelineno-0-2020></a><span class=sd>        .. [1] scipy, https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.lsq_linear.html</span>
<a id=__codelineno-0-2021 name=__codelineno-0-2021></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-2022 name=__codelineno-0-2022></a>        <span class=n>theta</span> <span class=o>=</span> <span class=n>lsq_linear</span><span class=p>(</span>
<a id=__codelineno-0-2023 name=__codelineno-0-2023></a>            <span class=n>psi</span><span class=p>,</span>
<a id=__codelineno-0-2024 name=__codelineno-0-2024></a>            <span class=n>y</span><span class=o>.</span><span class=n>ravel</span><span class=p>(),</span>
<a id=__codelineno-0-2025 name=__codelineno-0-2025></a>            <span class=n>bounds</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>bounds</span><span class=p>,</span>
<a id=__codelineno-0-2026 name=__codelineno-0-2026></a>            <span class=n>method</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>method</span><span class=p>,</span>
<a id=__codelineno-0-2027 name=__codelineno-0-2027></a>            <span class=n>tol</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>tol</span><span class=p>,</span>
<a id=__codelineno-0-2028 name=__codelineno-0-2028></a>            <span class=n>lsq_solver</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>lsq_solver</span><span class=p>,</span>
<a id=__codelineno-0-2029 name=__codelineno-0-2029></a>            <span class=n>lsmr_tol</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>lsmr_tol</span><span class=p>,</span>
<a id=__codelineno-0-2030 name=__codelineno-0-2030></a>            <span class=n>max_iter</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>max_iter</span><span class=p>,</span>
<a id=__codelineno-0-2031 name=__codelineno-0-2031></a>            <span class=n>verbose</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>verbose</span><span class=p>,</span>
<a id=__codelineno-0-2032 name=__codelineno-0-2032></a>            <span class=n>lsmr_maxiter</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>lsmr_maxiter</span><span class=p>,</span>
<a id=__codelineno-0-2033 name=__codelineno-0-2033></a>        <span class=p>)</span>
<a id=__codelineno-0-2034 name=__codelineno-0-2034></a>        <span class=k>return</span> <span class=n>theta</span><span class=o>.</span><span class=n>x</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.BoundedVariableLeastSquares.optimize class="doc doc-heading"> <code class="highlight language-python"><span class=n>optimize</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.BoundedVariableLeastSquares.optimize class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Parameter estimation using the BoundedVariableLeastSquares algorithm.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>ndarray of floats of shape (n_samples, 1)</code> </td> <td> <div class=doc-md-description> <p>The data used to train the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>array-like of shape = number_of_model_elements</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=note open> <summary>Notes</summary> <p>This is a wrapper class for the <code>scipy.optimize.lsq_linear</code> method.</p> </details> <details class=references open> <summary>References</summary> <p>.. [1] scipy, <a href=https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.lsq_linear.html>https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.lsq_linear.html</a></p> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-1999>1999</a></span>
<span class=normal><a href=#__codelineno-0-2000>2000</a></span>
<span class=normal><a href=#__codelineno-0-2001>2001</a></span>
<span class=normal><a href=#__codelineno-0-2002>2002</a></span>
<span class=normal><a href=#__codelineno-0-2003>2003</a></span>
<span class=normal><a href=#__codelineno-0-2004>2004</a></span>
<span class=normal><a href=#__codelineno-0-2005>2005</a></span>
<span class=normal><a href=#__codelineno-0-2006>2006</a></span>
<span class=normal><a href=#__codelineno-0-2007>2007</a></span>
<span class=normal><a href=#__codelineno-0-2008>2008</a></span>
<span class=normal><a href=#__codelineno-0-2009>2009</a></span>
<span class=normal><a href=#__codelineno-0-2010>2010</a></span>
<span class=normal><a href=#__codelineno-0-2011>2011</a></span>
<span class=normal><a href=#__codelineno-0-2012>2012</a></span>
<span class=normal><a href=#__codelineno-0-2013>2013</a></span>
<span class=normal><a href=#__codelineno-0-2014>2014</a></span>
<span class=normal><a href=#__codelineno-0-2015>2015</a></span>
<span class=normal><a href=#__codelineno-0-2016>2016</a></span>
<span class=normal><a href=#__codelineno-0-2017>2017</a></span>
<span class=normal><a href=#__codelineno-0-2018>2018</a></span>
<span class=normal><a href=#__codelineno-0-2019>2019</a></span>
<span class=normal><a href=#__codelineno-0-2020>2020</a></span>
<span class=normal><a href=#__codelineno-0-2021>2021</a></span>
<span class=normal><a href=#__codelineno-0-2022>2022</a></span>
<span class=normal><a href=#__codelineno-0-2023>2023</a></span>
<span class=normal><a href=#__codelineno-0-2024>2024</a></span>
<span class=normal><a href=#__codelineno-0-2025>2025</a></span>
<span class=normal><a href=#__codelineno-0-2026>2026</a></span>
<span class=normal><a href=#__codelineno-0-2027>2027</a></span>
<span class=normal><a href=#__codelineno-0-2028>2028</a></span>
<span class=normal><a href=#__codelineno-0-2029>2029</a></span>
<span class=normal><a href=#__codelineno-0-2030>2030</a></span>
<span class=normal><a href=#__codelineno-0-2031>2031</a></span>
<span class=normal><a href=#__codelineno-0-2032>2032</a></span>
<span class=normal><a href=#__codelineno-0-2033>2033</a></span>
<span class=normal><a href=#__codelineno-0-2034>2034</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-1999 name=__codelineno-0-1999></a><span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
<a id=__codelineno-0-2000 name=__codelineno-0-2000></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Parameter estimation using the BoundedVariableLeastSquares algorithm.</span>
<a id=__codelineno-0-2001 name=__codelineno-0-2001></a>
<a id=__codelineno-0-2002 name=__codelineno-0-2002></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-2003 name=__codelineno-0-2003></a><span class=sd>    ----------</span>
<a id=__codelineno-0-2004 name=__codelineno-0-2004></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-2005 name=__codelineno-0-2005></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-2006 name=__codelineno-0-2006></a><span class=sd>    y : ndarray of floats of shape (n_samples, 1)</span>
<a id=__codelineno-0-2007 name=__codelineno-0-2007></a><span class=sd>        The data used to train the model.</span>
<a id=__codelineno-0-2008 name=__codelineno-0-2008></a>
<a id=__codelineno-0-2009 name=__codelineno-0-2009></a><span class=sd>    Returns</span>
<a id=__codelineno-0-2010 name=__codelineno-0-2010></a><span class=sd>    -------</span>
<a id=__codelineno-0-2011 name=__codelineno-0-2011></a><span class=sd>    theta : array-like of shape = number_of_model_elements</span>
<a id=__codelineno-0-2012 name=__codelineno-0-2012></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-2013 name=__codelineno-0-2013></a>
<a id=__codelineno-0-2014 name=__codelineno-0-2014></a><span class=sd>    Notes</span>
<a id=__codelineno-0-2015 name=__codelineno-0-2015></a><span class=sd>    -----</span>
<a id=__codelineno-0-2016 name=__codelineno-0-2016></a><span class=sd>    This is a wrapper class for the `scipy.optimize.lsq_linear` method.</span>
<a id=__codelineno-0-2017 name=__codelineno-0-2017></a>
<a id=__codelineno-0-2018 name=__codelineno-0-2018></a><span class=sd>    References</span>
<a id=__codelineno-0-2019 name=__codelineno-0-2019></a><span class=sd>    ----------</span>
<a id=__codelineno-0-2020 name=__codelineno-0-2020></a><span class=sd>    .. [1] scipy, https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.lsq_linear.html</span>
<a id=__codelineno-0-2021 name=__codelineno-0-2021></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-2022 name=__codelineno-0-2022></a>    <span class=n>theta</span> <span class=o>=</span> <span class=n>lsq_linear</span><span class=p>(</span>
<a id=__codelineno-0-2023 name=__codelineno-0-2023></a>        <span class=n>psi</span><span class=p>,</span>
<a id=__codelineno-0-2024 name=__codelineno-0-2024></a>        <span class=n>y</span><span class=o>.</span><span class=n>ravel</span><span class=p>(),</span>
<a id=__codelineno-0-2025 name=__codelineno-0-2025></a>        <span class=n>bounds</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>bounds</span><span class=p>,</span>
<a id=__codelineno-0-2026 name=__codelineno-0-2026></a>        <span class=n>method</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>method</span><span class=p>,</span>
<a id=__codelineno-0-2027 name=__codelineno-0-2027></a>        <span class=n>tol</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>tol</span><span class=p>,</span>
<a id=__codelineno-0-2028 name=__codelineno-0-2028></a>        <span class=n>lsq_solver</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>lsq_solver</span><span class=p>,</span>
<a id=__codelineno-0-2029 name=__codelineno-0-2029></a>        <span class=n>lsmr_tol</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>lsmr_tol</span><span class=p>,</span>
<a id=__codelineno-0-2030 name=__codelineno-0-2030></a>        <span class=n>max_iter</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>max_iter</span><span class=p>,</span>
<a id=__codelineno-0-2031 name=__codelineno-0-2031></a>        <span class=n>verbose</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>verbose</span><span class=p>,</span>
<a id=__codelineno-0-2032 name=__codelineno-0-2032></a>        <span class=n>lsmr_maxiter</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>lsmr_maxiter</span><span class=p>,</span>
<a id=__codelineno-0-2033 name=__codelineno-0-2033></a>    <span class=p>)</span>
<a id=__codelineno-0-2034 name=__codelineno-0-2034></a>    <span class=k>return</span> <span class=n>theta</span><span class=o>.</span><span class=n>x</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.EstimatorError class="doc doc-heading"> <code>EstimatorError</code> <a href=#sysidentpy.parameter_estimation.estimators.EstimatorError class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=Exception>Exception</span></code></p> <p>Generic Python-exception-derived object raised by estimator functions.</p> <p>General purpose exception class, derived from Python's ValueError class, programmatically raised in estimators functions when a Estimator-related condition would prevent further correct execution of the function.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>None</code> </td> <td> </td> <td> <div class=doc-md-description> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-24>24</a></span>
<span class=normal><a href=#__codelineno-0-25>25</a></span>
<span class=normal><a href=#__codelineno-0-26>26</a></span>
<span class=normal><a href=#__codelineno-0-27>27</a></span>
<span class=normal><a href=#__codelineno-0-28>28</a></span>
<span class=normal><a href=#__codelineno-0-29>29</a></span>
<span class=normal><a href=#__codelineno-0-30>30</a></span>
<span class=normal><a href=#__codelineno-0-31>31</a></span>
<span class=normal><a href=#__codelineno-0-32>32</a></span>
<span class=normal><a href=#__codelineno-0-33>33</a></span>
<span class=normal><a href=#__codelineno-0-34>34</a></span>
<span class=normal><a href=#__codelineno-0-35>35</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-24 name=__codelineno-0-24></a><span class=k>class</span><span class=w> </span><span class=nc>EstimatorError</span><span class=p>(</span><span class=ne>Exception</span><span class=p>):</span>
<a id=__codelineno-0-25 name=__codelineno-0-25></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Generic Python-exception-derived object raised by estimator functions.</span>
<a id=__codelineno-0-26 name=__codelineno-0-26></a>
<a id=__codelineno-0-27 name=__codelineno-0-27></a><span class=sd>    General purpose exception class, derived from Python&#39;s ValueError</span>
<a id=__codelineno-0-28 name=__codelineno-0-28></a><span class=sd>    class, programmatically raised in estimators functions when a Estimator-related</span>
<a id=__codelineno-0-29 name=__codelineno-0-29></a><span class=sd>    condition would prevent further correct execution of the function.</span>
<a id=__codelineno-0-30 name=__codelineno-0-30></a>
<a id=__codelineno-0-31 name=__codelineno-0-31></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-32 name=__codelineno-0-32></a><span class=sd>    ----------</span>
<a id=__codelineno-0-33 name=__codelineno-0-33></a><span class=sd>    None</span>
<a id=__codelineno-0-34 name=__codelineno-0-34></a>
<a id=__codelineno-0-35 name=__codelineno-0-35></a><span class=sd>    &quot;&quot;&quot;</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.LeastMeanSquareMixedNorm class="doc doc-heading"> <code>LeastMeanSquareMixedNorm</code> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquareMixedNorm class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=sysidentpy.parameter_estimation.estimators_base.BaseEstimator>BaseEstimator</span></code></p> <p>Least Mean Square Mixed Norm (LMS-MN) Adaptive Filter.</p> <p>This class implements the Mixed-norm Least Mean Square (LMS) adaptive filter algorithm, which incorporates an additional weight factor to control the proportions of the error norms, thus providing an extra degree of freedom in the adaptation process.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>mu</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The adaptation step size. Default is 0.01.</p> </div> </td> <td> <code>0.01</code> </td> </tr> <tr class=doc-section-item> <td> <code>weight</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The weight factor for mixed-norm control. This factor controls the proportions of the error norms and offers an extra degree of freedom within the adaptation of the LMS mixed norm method.</p> </div> </td> <td> <code>0.02</code> </td> </tr> <tr class=doc-section-item> <td> <code>unbiased</code> </td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>If True, applies an unbiased estimator. Default is False.</p> </div> </td> <td> <code>False</code> </td> </tr> <tr class=doc-section-item> <td> <code>uiter</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of iterations for the unbiased estimator. Default is 30.</p> </div> </td> <td> <code>30</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Attributes:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquareMixedNorm.mu>mu</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The adaptation step size.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquareMixedNorm.weight>weight</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The weight factor for mixed-norm control.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquareMixedNorm.xi>xi</span></code></td> <td> <code><span title=ndarray>ndarray</span> or None</code> </td> <td> <div class=doc-md-description> <p>The error signal, initialized to None.</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Methods:</span></p> <table> <thead> <tr> <th>Name</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><a class="autorefs autorefs-internal" title="<code>sysidentpy.parameter_estimation.estimators.LeastMeanSquareMixedNorm.optimize</code>" href=../../../../user-guide/API/parameter-estimation/#sysidentpy.parameter_estimation.estimators.LeastMeanSquareMixedNorm.optimize>optimize</a></code></td> <td> <div class=doc-md-description> <p>Estimate the model parameters using the LMSF filter.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Chambers, J. A., Tanrikulu, O., &amp; Constantinides, A. G. (1994). Least mean mixed-norm adaptive filtering. Electronics letters, 30(19), 1574-1575. <a href=https://ieeexplore.ieee.org/document/326382>https://ieeexplore.ieee.org/document/326382</a></li> <li>Dissertation (Portuguese): Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de algoritmos LMS de passo variável.</li> <li>Wikipedia entry on Least Mean Squares <a href=https://en.wikipedia.org/wiki/Least_mean_squares_filter>https://en.wikipedia.org/wiki/Least_mean_squares_filter</a></li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-1645>1645</a></span>
<span class=normal><a href=#__codelineno-0-1646>1646</a></span>
<span class=normal><a href=#__codelineno-0-1647>1647</a></span>
<span class=normal><a href=#__codelineno-0-1648>1648</a></span>
<span class=normal><a href=#__codelineno-0-1649>1649</a></span>
<span class=normal><a href=#__codelineno-0-1650>1650</a></span>
<span class=normal><a href=#__codelineno-0-1651>1651</a></span>
<span class=normal><a href=#__codelineno-0-1652>1652</a></span>
<span class=normal><a href=#__codelineno-0-1653>1653</a></span>
<span class=normal><a href=#__codelineno-0-1654>1654</a></span>
<span class=normal><a href=#__codelineno-0-1655>1655</a></span>
<span class=normal><a href=#__codelineno-0-1656>1656</a></span>
<span class=normal><a href=#__codelineno-0-1657>1657</a></span>
<span class=normal><a href=#__codelineno-0-1658>1658</a></span>
<span class=normal><a href=#__codelineno-0-1659>1659</a></span>
<span class=normal><a href=#__codelineno-0-1660>1660</a></span>
<span class=normal><a href=#__codelineno-0-1661>1661</a></span>
<span class=normal><a href=#__codelineno-0-1662>1662</a></span>
<span class=normal><a href=#__codelineno-0-1663>1663</a></span>
<span class=normal><a href=#__codelineno-0-1664>1664</a></span>
<span class=normal><a href=#__codelineno-0-1665>1665</a></span>
<span class=normal><a href=#__codelineno-0-1666>1666</a></span>
<span class=normal><a href=#__codelineno-0-1667>1667</a></span>
<span class=normal><a href=#__codelineno-0-1668>1668</a></span>
<span class=normal><a href=#__codelineno-0-1669>1669</a></span>
<span class=normal><a href=#__codelineno-0-1670>1670</a></span>
<span class=normal><a href=#__codelineno-0-1671>1671</a></span>
<span class=normal><a href=#__codelineno-0-1672>1672</a></span>
<span class=normal><a href=#__codelineno-0-1673>1673</a></span>
<span class=normal><a href=#__codelineno-0-1674>1674</a></span>
<span class=normal><a href=#__codelineno-0-1675>1675</a></span>
<span class=normal><a href=#__codelineno-0-1676>1676</a></span>
<span class=normal><a href=#__codelineno-0-1677>1677</a></span>
<span class=normal><a href=#__codelineno-0-1678>1678</a></span>
<span class=normal><a href=#__codelineno-0-1679>1679</a></span>
<span class=normal><a href=#__codelineno-0-1680>1680</a></span>
<span class=normal><a href=#__codelineno-0-1681>1681</a></span>
<span class=normal><a href=#__codelineno-0-1682>1682</a></span>
<span class=normal><a href=#__codelineno-0-1683>1683</a></span>
<span class=normal><a href=#__codelineno-0-1684>1684</a></span>
<span class=normal><a href=#__codelineno-0-1685>1685</a></span>
<span class=normal><a href=#__codelineno-0-1686>1686</a></span>
<span class=normal><a href=#__codelineno-0-1687>1687</a></span>
<span class=normal><a href=#__codelineno-0-1688>1688</a></span>
<span class=normal><a href=#__codelineno-0-1689>1689</a></span>
<span class=normal><a href=#__codelineno-0-1690>1690</a></span>
<span class=normal><a href=#__codelineno-0-1691>1691</a></span>
<span class=normal><a href=#__codelineno-0-1692>1692</a></span>
<span class=normal><a href=#__codelineno-0-1693>1693</a></span>
<span class=normal><a href=#__codelineno-0-1694>1694</a></span>
<span class=normal><a href=#__codelineno-0-1695>1695</a></span>
<span class=normal><a href=#__codelineno-0-1696>1696</a></span>
<span class=normal><a href=#__codelineno-0-1697>1697</a></span>
<span class=normal><a href=#__codelineno-0-1698>1698</a></span>
<span class=normal><a href=#__codelineno-0-1699>1699</a></span>
<span class=normal><a href=#__codelineno-0-1700>1700</a></span>
<span class=normal><a href=#__codelineno-0-1701>1701</a></span>
<span class=normal><a href=#__codelineno-0-1702>1702</a></span>
<span class=normal><a href=#__codelineno-0-1703>1703</a></span>
<span class=normal><a href=#__codelineno-0-1704>1704</a></span>
<span class=normal><a href=#__codelineno-0-1705>1705</a></span>
<span class=normal><a href=#__codelineno-0-1706>1706</a></span>
<span class=normal><a href=#__codelineno-0-1707>1707</a></span>
<span class=normal><a href=#__codelineno-0-1708>1708</a></span>
<span class=normal><a href=#__codelineno-0-1709>1709</a></span>
<span class=normal><a href=#__codelineno-0-1710>1710</a></span>
<span class=normal><a href=#__codelineno-0-1711>1711</a></span>
<span class=normal><a href=#__codelineno-0-1712>1712</a></span>
<span class=normal><a href=#__codelineno-0-1713>1713</a></span>
<span class=normal><a href=#__codelineno-0-1714>1714</a></span>
<span class=normal><a href=#__codelineno-0-1715>1715</a></span>
<span class=normal><a href=#__codelineno-0-1716>1716</a></span>
<span class=normal><a href=#__codelineno-0-1717>1717</a></span>
<span class=normal><a href=#__codelineno-0-1718>1718</a></span>
<span class=normal><a href=#__codelineno-0-1719>1719</a></span>
<span class=normal><a href=#__codelineno-0-1720>1720</a></span>
<span class=normal><a href=#__codelineno-0-1721>1721</a></span>
<span class=normal><a href=#__codelineno-0-1722>1722</a></span>
<span class=normal><a href=#__codelineno-0-1723>1723</a></span>
<span class=normal><a href=#__codelineno-0-1724>1724</a></span>
<span class=normal><a href=#__codelineno-0-1725>1725</a></span>
<span class=normal><a href=#__codelineno-0-1726>1726</a></span>
<span class=normal><a href=#__codelineno-0-1727>1727</a></span>
<span class=normal><a href=#__codelineno-0-1728>1728</a></span>
<span class=normal><a href=#__codelineno-0-1729>1729</a></span>
<span class=normal><a href=#__codelineno-0-1730>1730</a></span>
<span class=normal><a href=#__codelineno-0-1731>1731</a></span>
<span class=normal><a href=#__codelineno-0-1732>1732</a></span>
<span class=normal><a href=#__codelineno-0-1733>1733</a></span>
<span class=normal><a href=#__codelineno-0-1734>1734</a></span>
<span class=normal><a href=#__codelineno-0-1735>1735</a></span>
<span class=normal><a href=#__codelineno-0-1736>1736</a></span>
<span class=normal><a href=#__codelineno-0-1737>1737</a></span>
<span class=normal><a href=#__codelineno-0-1738>1738</a></span>
<span class=normal><a href=#__codelineno-0-1739>1739</a></span>
<span class=normal><a href=#__codelineno-0-1740>1740</a></span>
<span class=normal><a href=#__codelineno-0-1741>1741</a></span>
<span class=normal><a href=#__codelineno-0-1742>1742</a></span>
<span class=normal><a href=#__codelineno-0-1743>1743</a></span>
<span class=normal><a href=#__codelineno-0-1744>1744</a></span>
<span class=normal><a href=#__codelineno-0-1745>1745</a></span>
<span class=normal><a href=#__codelineno-0-1746>1746</a></span>
<span class=normal><a href=#__codelineno-0-1747>1747</a></span>
<span class=normal><a href=#__codelineno-0-1748>1748</a></span>
<span class=normal><a href=#__codelineno-0-1749>1749</a></span>
<span class=normal><a href=#__codelineno-0-1750>1750</a></span>
<span class=normal><a href=#__codelineno-0-1751>1751</a></span>
<span class=normal><a href=#__codelineno-0-1752>1752</a></span>
<span class=normal><a href=#__codelineno-0-1753>1753</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-1645 name=__codelineno-0-1645></a><span class=k>class</span><span class=w> </span><span class=nc>LeastMeanSquareMixedNorm</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>):</span>
<a id=__codelineno-0-1646 name=__codelineno-0-1646></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Least Mean Square Mixed Norm (LMS-MN) Adaptive Filter.</span>
<a id=__codelineno-0-1647 name=__codelineno-0-1647></a>
<a id=__codelineno-0-1648 name=__codelineno-0-1648></a><span class=sd>    This class implements the Mixed-norm Least Mean Square (LMS) adaptive filter</span>
<a id=__codelineno-0-1649 name=__codelineno-0-1649></a><span class=sd>    algorithm, which incorporates an additional weight factor to control the</span>
<a id=__codelineno-0-1650 name=__codelineno-0-1650></a><span class=sd>    proportions of the error norms, thus providing an extra degree of freedom</span>
<a id=__codelineno-0-1651 name=__codelineno-0-1651></a><span class=sd>    in the adaptation process.</span>
<a id=__codelineno-0-1652 name=__codelineno-0-1652></a>
<a id=__codelineno-0-1653 name=__codelineno-0-1653></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-1654 name=__codelineno-0-1654></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1655 name=__codelineno-0-1655></a><span class=sd>    mu : float, optional</span>
<a id=__codelineno-0-1656 name=__codelineno-0-1656></a><span class=sd>        The adaptation step size. Default is 0.01.</span>
<a id=__codelineno-0-1657 name=__codelineno-0-1657></a><span class=sd>    weight : float, optional</span>
<a id=__codelineno-0-1658 name=__codelineno-0-1658></a><span class=sd>        The weight factor for mixed-norm control. This factor controls the</span>
<a id=__codelineno-0-1659 name=__codelineno-0-1659></a><span class=sd>        proportions of the error norms and offers an extra degree of freedom</span>
<a id=__codelineno-0-1660 name=__codelineno-0-1660></a><span class=sd>        within the adaptation of the LMS mixed norm method.</span>
<a id=__codelineno-0-1661 name=__codelineno-0-1661></a><span class=sd>    unbiased : bool, optional</span>
<a id=__codelineno-0-1662 name=__codelineno-0-1662></a><span class=sd>        If True, applies an unbiased estimator. Default is False.</span>
<a id=__codelineno-0-1663 name=__codelineno-0-1663></a><span class=sd>    uiter : int, optional</span>
<a id=__codelineno-0-1664 name=__codelineno-0-1664></a><span class=sd>        Number of iterations for the unbiased estimator. Default is 30.</span>
<a id=__codelineno-0-1665 name=__codelineno-0-1665></a>
<a id=__codelineno-0-1666 name=__codelineno-0-1666></a><span class=sd>    Attributes</span>
<a id=__codelineno-0-1667 name=__codelineno-0-1667></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1668 name=__codelineno-0-1668></a><span class=sd>    mu : float</span>
<a id=__codelineno-0-1669 name=__codelineno-0-1669></a><span class=sd>        The adaptation step size.</span>
<a id=__codelineno-0-1670 name=__codelineno-0-1670></a><span class=sd>    weight : float</span>
<a id=__codelineno-0-1671 name=__codelineno-0-1671></a><span class=sd>        The weight factor for mixed-norm control.</span>
<a id=__codelineno-0-1672 name=__codelineno-0-1672></a><span class=sd>    xi : ndarray or None</span>
<a id=__codelineno-0-1673 name=__codelineno-0-1673></a><span class=sd>        The error signal, initialized to None.</span>
<a id=__codelineno-0-1674 name=__codelineno-0-1674></a>
<a id=__codelineno-0-1675 name=__codelineno-0-1675></a><span class=sd>    Methods</span>
<a id=__codelineno-0-1676 name=__codelineno-0-1676></a><span class=sd>    -------</span>
<a id=__codelineno-0-1677 name=__codelineno-0-1677></a><span class=sd>    optimize(psi: np.ndarray, y: np.ndarray) -&gt; np.ndarray</span>
<a id=__codelineno-0-1678 name=__codelineno-0-1678></a><span class=sd>        Estimate the model parameters using the LMSF filter.</span>
<a id=__codelineno-0-1679 name=__codelineno-0-1679></a>
<a id=__codelineno-0-1680 name=__codelineno-0-1680></a><span class=sd>    References</span>
<a id=__codelineno-0-1681 name=__codelineno-0-1681></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1682 name=__codelineno-0-1682></a><span class=sd>    - Chambers, J. A., Tanrikulu, O., &amp; Constantinides, A. G. (1994).</span>
<a id=__codelineno-0-1683 name=__codelineno-0-1683></a><span class=sd>      Least mean mixed-norm adaptive filtering.</span>
<a id=__codelineno-0-1684 name=__codelineno-0-1684></a><span class=sd>      Electronics letters, 30(19), 1574-1575.</span>
<a id=__codelineno-0-1685 name=__codelineno-0-1685></a><span class=sd>      https://ieeexplore.ieee.org/document/326382</span>
<a id=__codelineno-0-1686 name=__codelineno-0-1686></a><span class=sd>    - Dissertation (Portuguese): Zipf, J. G. F. (2011). Classificação,</span>
<a id=__codelineno-0-1687 name=__codelineno-0-1687></a><span class=sd>      análise estatística e novas estratégias de algoritmos LMS de passo</span>
<a id=__codelineno-0-1688 name=__codelineno-0-1688></a><span class=sd>      variável.</span>
<a id=__codelineno-0-1689 name=__codelineno-0-1689></a><span class=sd>    - Wikipedia entry on Least Mean Squares</span>
<a id=__codelineno-0-1690 name=__codelineno-0-1690></a><span class=sd>      https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>
<a id=__codelineno-0-1691 name=__codelineno-0-1691></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-1692 name=__codelineno-0-1692></a>
<a id=__codelineno-0-1693 name=__codelineno-0-1693></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span>
<a id=__codelineno-0-1694 name=__codelineno-0-1694></a>        <span class=bp>self</span><span class=p>,</span>
<a id=__codelineno-0-1695 name=__codelineno-0-1695></a>        <span class=o>*</span><span class=p>,</span>
<a id=__codelineno-0-1696 name=__codelineno-0-1696></a>        <span class=n>mu</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.01</span><span class=p>,</span>
<a id=__codelineno-0-1697 name=__codelineno-0-1697></a>        <span class=n>weight</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.02</span><span class=p>,</span>
<a id=__codelineno-0-1698 name=__codelineno-0-1698></a>        <span class=n>unbiased</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>
<a id=__codelineno-0-1699 name=__codelineno-0-1699></a>        <span class=n>uiter</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>30</span><span class=p>,</span>
<a id=__codelineno-0-1700 name=__codelineno-0-1700></a>    <span class=p>):</span>
<a id=__codelineno-0-1701 name=__codelineno-0-1701></a>        <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>=</span> <span class=n>mu</span>
<a id=__codelineno-0-1702 name=__codelineno-0-1702></a>        <span class=bp>self</span><span class=o>.</span><span class=n>weight</span> <span class=o>=</span> <span class=n>weight</span>
<a id=__codelineno-0-1703 name=__codelineno-0-1703></a>        <span class=bp>self</span><span class=o>.</span><span class=n>unbiased</span> <span class=o>=</span> <span class=n>unbiased</span>
<a id=__codelineno-0-1704 name=__codelineno-0-1704></a>        <span class=bp>self</span><span class=o>.</span><span class=n>uiter</span> <span class=o>=</span> <span class=n>uiter</span>
<a id=__codelineno-0-1705 name=__codelineno-0-1705></a>        <span class=n>_validate_params</span><span class=p>(</span><span class=nb>vars</span><span class=p>(</span><span class=bp>self</span><span class=p>))</span>
<a id=__codelineno-0-1706 name=__codelineno-0-1706></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
<a id=__codelineno-0-1707 name=__codelineno-0-1707></a>
<a id=__codelineno-0-1708 name=__codelineno-0-1708></a>    <span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-1709 name=__codelineno-0-1709></a><span class=w>        </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Mixed-norm LMS filter.</span>
<a id=__codelineno-0-1710 name=__codelineno-0-1710></a>
<a id=__codelineno-0-1711 name=__codelineno-0-1711></a><span class=sd>        The LMS-MN algorithm updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-1712 name=__codelineno-0-1712></a>
<a id=__codelineno-0-1713 name=__codelineno-0-1713></a><span class=sd>        1. Compute the estimation error:</span>
<a id=__codelineno-0-1714 name=__codelineno-0-1714></a>
<a id=__codelineno-0-1715 name=__codelineno-0-1715></a><span class=sd>           $$</span>
<a id=__codelineno-0-1716 name=__codelineno-0-1716></a><span class=sd>           \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-1717 name=__codelineno-0-1717></a><span class=sd>           $$</span>
<a id=__codelineno-0-1718 name=__codelineno-0-1718></a>
<a id=__codelineno-0-1719 name=__codelineno-0-1719></a><span class=sd>        2. Update the parameter vector:</span>
<a id=__codelineno-0-1720 name=__codelineno-0-1720></a>
<a id=__codelineno-0-1721 name=__codelineno-0-1721></a><span class=sd>           $$</span>
<a id=__codelineno-0-1722 name=__codelineno-0-1722></a><span class=sd>           \theta_i = \theta_{i-1} + \mu \psi_i \xi_i (\text{weight}</span>
<a id=__codelineno-0-1723 name=__codelineno-0-1723></a><span class=sd>           + (1 - \text{weight}) \xi_i^2)</span>
<a id=__codelineno-0-1724 name=__codelineno-0-1724></a><span class=sd>           $$</span>
<a id=__codelineno-0-1725 name=__codelineno-0-1725></a>
<a id=__codelineno-0-1726 name=__codelineno-0-1726></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-1727 name=__codelineno-0-1727></a><span class=sd>        ----------</span>
<a id=__codelineno-0-1728 name=__codelineno-0-1728></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-1729 name=__codelineno-0-1729></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-1730 name=__codelineno-0-1730></a><span class=sd>        y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-1731 name=__codelineno-0-1731></a><span class=sd>            The data used to train the model.</span>
<a id=__codelineno-0-1732 name=__codelineno-0-1732></a>
<a id=__codelineno-0-1733 name=__codelineno-0-1733></a><span class=sd>        Returns</span>
<a id=__codelineno-0-1734 name=__codelineno-0-1734></a><span class=sd>        -------</span>
<a id=__codelineno-0-1735 name=__codelineno-0-1735></a><span class=sd>        theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-1736 name=__codelineno-0-1736></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-1737 name=__codelineno-0-1737></a>
<a id=__codelineno-0-1738 name=__codelineno-0-1738></a><span class=sd>        Notes</span>
<a id=__codelineno-0-1739 name=__codelineno-0-1739></a><span class=sd>        -----</span>
<a id=__codelineno-0-1740 name=__codelineno-0-1740></a><span class=sd>        A more in-depth documentation of all methods for parameter estimation</span>
<a id=__codelineno-0-1741 name=__codelineno-0-1741></a><span class=sd>        will be available soon. For now, please refer to the mentioned references.</span>
<a id=__codelineno-0-1742 name=__codelineno-0-1742></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-1743 name=__codelineno-0-1743></a>        <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-1744 name=__codelineno-0-1744></a>
<a id=__codelineno-0-1745 name=__codelineno-0-1745></a>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-1746 name=__codelineno-0-1746></a>            <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-1747 name=__codelineno-0-1747></a>            <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-1748 name=__codelineno-0-1748></a>            <span class=n>tmp_list</span> <span class=o>=</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=n>psi_tmp</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span>
<a id=__codelineno-0-1749 name=__codelineno-0-1749></a>                <span class=n>i</span><span class=p>,</span> <span class=mi>0</span>
<a id=__codelineno-0-1750 name=__codelineno-0-1750></a>            <span class=p>]</span> <span class=o>*</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>weight</span> <span class=o>+</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>weight</span><span class=p>)</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>**</span> <span class=mi>2</span><span class=p>)</span>
<a id=__codelineno-0-1751 name=__codelineno-0-1751></a>            <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-1752 name=__codelineno-0-1752></a>
<a id=__codelineno-0-1753 name=__codelineno-0-1753></a>        <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.LeastMeanSquareMixedNorm.optimize class="doc doc-heading"> <code class="highlight language-python"><span class=n>optimize</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquareMixedNorm.optimize class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Parameter estimation using the Mixed-norm LMS filter.</p> <p>The LMS-MN algorithm updates the parameter estimates recursively as follows:</p> <ol> <li>Compute the estimation error:</li> </ol> <p>$$ \xi_i = y_i - \psi_i^T \theta_{i-1} $$</p> <ol> <li>Update the parameter vector:</li> </ol> <p>$$ \theta_i = \theta_{i-1} + \mu \psi_i \xi_i (\text{weight} + (1 - \text{weight}) \xi_i^2) $$</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>array-like of shape (n_samples, 1)</code> </td> <td> <div class=doc-md-description> <p>The data used to train the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>array-like of shape (n_features, 1)</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=note open> <summary>Notes</summary> <p>A more in-depth documentation of all methods for parameter estimation will be available soon. For now, please refer to the mentioned references.</p> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-1708>1708</a></span>
<span class=normal><a href=#__codelineno-0-1709>1709</a></span>
<span class=normal><a href=#__codelineno-0-1710>1710</a></span>
<span class=normal><a href=#__codelineno-0-1711>1711</a></span>
<span class=normal><a href=#__codelineno-0-1712>1712</a></span>
<span class=normal><a href=#__codelineno-0-1713>1713</a></span>
<span class=normal><a href=#__codelineno-0-1714>1714</a></span>
<span class=normal><a href=#__codelineno-0-1715>1715</a></span>
<span class=normal><a href=#__codelineno-0-1716>1716</a></span>
<span class=normal><a href=#__codelineno-0-1717>1717</a></span>
<span class=normal><a href=#__codelineno-0-1718>1718</a></span>
<span class=normal><a href=#__codelineno-0-1719>1719</a></span>
<span class=normal><a href=#__codelineno-0-1720>1720</a></span>
<span class=normal><a href=#__codelineno-0-1721>1721</a></span>
<span class=normal><a href=#__codelineno-0-1722>1722</a></span>
<span class=normal><a href=#__codelineno-0-1723>1723</a></span>
<span class=normal><a href=#__codelineno-0-1724>1724</a></span>
<span class=normal><a href=#__codelineno-0-1725>1725</a></span>
<span class=normal><a href=#__codelineno-0-1726>1726</a></span>
<span class=normal><a href=#__codelineno-0-1727>1727</a></span>
<span class=normal><a href=#__codelineno-0-1728>1728</a></span>
<span class=normal><a href=#__codelineno-0-1729>1729</a></span>
<span class=normal><a href=#__codelineno-0-1730>1730</a></span>
<span class=normal><a href=#__codelineno-0-1731>1731</a></span>
<span class=normal><a href=#__codelineno-0-1732>1732</a></span>
<span class=normal><a href=#__codelineno-0-1733>1733</a></span>
<span class=normal><a href=#__codelineno-0-1734>1734</a></span>
<span class=normal><a href=#__codelineno-0-1735>1735</a></span>
<span class=normal><a href=#__codelineno-0-1736>1736</a></span>
<span class=normal><a href=#__codelineno-0-1737>1737</a></span>
<span class=normal><a href=#__codelineno-0-1738>1738</a></span>
<span class=normal><a href=#__codelineno-0-1739>1739</a></span>
<span class=normal><a href=#__codelineno-0-1740>1740</a></span>
<span class=normal><a href=#__codelineno-0-1741>1741</a></span>
<span class=normal><a href=#__codelineno-0-1742>1742</a></span>
<span class=normal><a href=#__codelineno-0-1743>1743</a></span>
<span class=normal><a href=#__codelineno-0-1744>1744</a></span>
<span class=normal><a href=#__codelineno-0-1745>1745</a></span>
<span class=normal><a href=#__codelineno-0-1746>1746</a></span>
<span class=normal><a href=#__codelineno-0-1747>1747</a></span>
<span class=normal><a href=#__codelineno-0-1748>1748</a></span>
<span class=normal><a href=#__codelineno-0-1749>1749</a></span>
<span class=normal><a href=#__codelineno-0-1750>1750</a></span>
<span class=normal><a href=#__codelineno-0-1751>1751</a></span>
<span class=normal><a href=#__codelineno-0-1752>1752</a></span>
<span class=normal><a href=#__codelineno-0-1753>1753</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-1708 name=__codelineno-0-1708></a><span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-1709 name=__codelineno-0-1709></a><span class=w>    </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Mixed-norm LMS filter.</span>
<a id=__codelineno-0-1710 name=__codelineno-0-1710></a>
<a id=__codelineno-0-1711 name=__codelineno-0-1711></a><span class=sd>    The LMS-MN algorithm updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-1712 name=__codelineno-0-1712></a>
<a id=__codelineno-0-1713 name=__codelineno-0-1713></a><span class=sd>    1. Compute the estimation error:</span>
<a id=__codelineno-0-1714 name=__codelineno-0-1714></a>
<a id=__codelineno-0-1715 name=__codelineno-0-1715></a><span class=sd>       $$</span>
<a id=__codelineno-0-1716 name=__codelineno-0-1716></a><span class=sd>       \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-1717 name=__codelineno-0-1717></a><span class=sd>       $$</span>
<a id=__codelineno-0-1718 name=__codelineno-0-1718></a>
<a id=__codelineno-0-1719 name=__codelineno-0-1719></a><span class=sd>    2. Update the parameter vector:</span>
<a id=__codelineno-0-1720 name=__codelineno-0-1720></a>
<a id=__codelineno-0-1721 name=__codelineno-0-1721></a><span class=sd>       $$</span>
<a id=__codelineno-0-1722 name=__codelineno-0-1722></a><span class=sd>       \theta_i = \theta_{i-1} + \mu \psi_i \xi_i (\text{weight}</span>
<a id=__codelineno-0-1723 name=__codelineno-0-1723></a><span class=sd>       + (1 - \text{weight}) \xi_i^2)</span>
<a id=__codelineno-0-1724 name=__codelineno-0-1724></a><span class=sd>       $$</span>
<a id=__codelineno-0-1725 name=__codelineno-0-1725></a>
<a id=__codelineno-0-1726 name=__codelineno-0-1726></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-1727 name=__codelineno-0-1727></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1728 name=__codelineno-0-1728></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-1729 name=__codelineno-0-1729></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-1730 name=__codelineno-0-1730></a><span class=sd>    y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-1731 name=__codelineno-0-1731></a><span class=sd>        The data used to train the model.</span>
<a id=__codelineno-0-1732 name=__codelineno-0-1732></a>
<a id=__codelineno-0-1733 name=__codelineno-0-1733></a><span class=sd>    Returns</span>
<a id=__codelineno-0-1734 name=__codelineno-0-1734></a><span class=sd>    -------</span>
<a id=__codelineno-0-1735 name=__codelineno-0-1735></a><span class=sd>    theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-1736 name=__codelineno-0-1736></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-1737 name=__codelineno-0-1737></a>
<a id=__codelineno-0-1738 name=__codelineno-0-1738></a><span class=sd>    Notes</span>
<a id=__codelineno-0-1739 name=__codelineno-0-1739></a><span class=sd>    -----</span>
<a id=__codelineno-0-1740 name=__codelineno-0-1740></a><span class=sd>    A more in-depth documentation of all methods for parameter estimation</span>
<a id=__codelineno-0-1741 name=__codelineno-0-1741></a><span class=sd>    will be available soon. For now, please refer to the mentioned references.</span>
<a id=__codelineno-0-1742 name=__codelineno-0-1742></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-1743 name=__codelineno-0-1743></a>    <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-1744 name=__codelineno-0-1744></a>
<a id=__codelineno-0-1745 name=__codelineno-0-1745></a>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-1746 name=__codelineno-0-1746></a>        <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-1747 name=__codelineno-0-1747></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-1748 name=__codelineno-0-1748></a>        <span class=n>tmp_list</span> <span class=o>=</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=n>psi_tmp</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span>
<a id=__codelineno-0-1749 name=__codelineno-0-1749></a>            <span class=n>i</span><span class=p>,</span> <span class=mi>0</span>
<a id=__codelineno-0-1750 name=__codelineno-0-1750></a>        <span class=p>]</span> <span class=o>*</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>weight</span> <span class=o>+</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>weight</span><span class=p>)</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>**</span> <span class=mi>2</span><span class=p>)</span>
<a id=__codelineno-0-1751 name=__codelineno-0-1751></a>        <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-1752 name=__codelineno-0-1752></a>
<a id=__codelineno-0-1753 name=__codelineno-0-1753></a>    <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.LeastMeanSquares class="doc doc-heading"> <code>LeastMeanSquares</code> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquares class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=sysidentpy.parameter_estimation.estimators_base.BaseEstimator>BaseEstimator</span></code></p> <p>Least Mean Squares (LMS) filter for parameter estimation in adaptive filtering.</p> <p>The LMS algorithm is an adaptive filter used to estimate the parameters of a model by minimizing the mean square error between the observed and predicted values.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>mu</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> <td> <code>0.01</code> </td> </tr> <tr class=doc-section-item> <td> <code>unbiased</code> </td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>If True, applies an unbiased estimator. Default is False.</p> </div> </td> <td> <code>False</code> </td> </tr> <tr class=doc-section-item> <td> <code>uiter</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of iterations for the unbiased estimator. Default is 30.</p> </div> </td> <td> <code>30</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Attributes:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquares.mu>mu</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquares.unbiased>unbiased</span></code></td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>Indicates whether an unbiased estimator is applied.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquares.uiter>uiter</span></code></td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of iterations for the unbiased estimator.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquares.xi>xi</span></code></td> <td> <code><span title=numpy.ndarray>ndarray</span> or None</code> </td> <td> <div class=doc-md-description> <p>The estimation error at each iteration. Initialized as None and updated during optimization.</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Methods:</span></p> <table> <thead> <tr> <th>Name</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><a class="autorefs autorefs-internal" title="<code>sysidentpy.parameter_estimation.estimators.LeastMeanSquares.optimize</code>" href=../../../../user-guide/API/parameter-estimation/#sysidentpy.parameter_estimation.estimators.LeastMeanSquares.optimize>optimize</a></code></td> <td> <div class=doc-md-description> <p>Estimate the model parameters using the LMS filter.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Haykin, S., &amp; Widrow, B. (Eds.). (2003). Least-mean-square adaptive filters (Vol. 31). John Wiley &amp; Sons.</li> <li>Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de algoritmos LMS de passo variável.</li> <li>Wikipedia entry on Least Mean Squares: <a href=https://en.wikipedia.org/wiki/Least_mean_squares_filter>https://en.wikipedia.org/wiki/Least_mean_squares_filter</a></li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-552>552</a></span>
<span class=normal><a href=#__codelineno-0-553>553</a></span>
<span class=normal><a href=#__codelineno-0-554>554</a></span>
<span class=normal><a href=#__codelineno-0-555>555</a></span>
<span class=normal><a href=#__codelineno-0-556>556</a></span>
<span class=normal><a href=#__codelineno-0-557>557</a></span>
<span class=normal><a href=#__codelineno-0-558>558</a></span>
<span class=normal><a href=#__codelineno-0-559>559</a></span>
<span class=normal><a href=#__codelineno-0-560>560</a></span>
<span class=normal><a href=#__codelineno-0-561>561</a></span>
<span class=normal><a href=#__codelineno-0-562>562</a></span>
<span class=normal><a href=#__codelineno-0-563>563</a></span>
<span class=normal><a href=#__codelineno-0-564>564</a></span>
<span class=normal><a href=#__codelineno-0-565>565</a></span>
<span class=normal><a href=#__codelineno-0-566>566</a></span>
<span class=normal><a href=#__codelineno-0-567>567</a></span>
<span class=normal><a href=#__codelineno-0-568>568</a></span>
<span class=normal><a href=#__codelineno-0-569>569</a></span>
<span class=normal><a href=#__codelineno-0-570>570</a></span>
<span class=normal><a href=#__codelineno-0-571>571</a></span>
<span class=normal><a href=#__codelineno-0-572>572</a></span>
<span class=normal><a href=#__codelineno-0-573>573</a></span>
<span class=normal><a href=#__codelineno-0-574>574</a></span>
<span class=normal><a href=#__codelineno-0-575>575</a></span>
<span class=normal><a href=#__codelineno-0-576>576</a></span>
<span class=normal><a href=#__codelineno-0-577>577</a></span>
<span class=normal><a href=#__codelineno-0-578>578</a></span>
<span class=normal><a href=#__codelineno-0-579>579</a></span>
<span class=normal><a href=#__codelineno-0-580>580</a></span>
<span class=normal><a href=#__codelineno-0-581>581</a></span>
<span class=normal><a href=#__codelineno-0-582>582</a></span>
<span class=normal><a href=#__codelineno-0-583>583</a></span>
<span class=normal><a href=#__codelineno-0-584>584</a></span>
<span class=normal><a href=#__codelineno-0-585>585</a></span>
<span class=normal><a href=#__codelineno-0-586>586</a></span>
<span class=normal><a href=#__codelineno-0-587>587</a></span>
<span class=normal><a href=#__codelineno-0-588>588</a></span>
<span class=normal><a href=#__codelineno-0-589>589</a></span>
<span class=normal><a href=#__codelineno-0-590>590</a></span>
<span class=normal><a href=#__codelineno-0-591>591</a></span>
<span class=normal><a href=#__codelineno-0-592>592</a></span>
<span class=normal><a href=#__codelineno-0-593>593</a></span>
<span class=normal><a href=#__codelineno-0-594>594</a></span>
<span class=normal><a href=#__codelineno-0-595>595</a></span>
<span class=normal><a href=#__codelineno-0-596>596</a></span>
<span class=normal><a href=#__codelineno-0-597>597</a></span>
<span class=normal><a href=#__codelineno-0-598>598</a></span>
<span class=normal><a href=#__codelineno-0-599>599</a></span>
<span class=normal><a href=#__codelineno-0-600>600</a></span>
<span class=normal><a href=#__codelineno-0-601>601</a></span>
<span class=normal><a href=#__codelineno-0-602>602</a></span>
<span class=normal><a href=#__codelineno-0-603>603</a></span>
<span class=normal><a href=#__codelineno-0-604>604</a></span>
<span class=normal><a href=#__codelineno-0-605>605</a></span>
<span class=normal><a href=#__codelineno-0-606>606</a></span>
<span class=normal><a href=#__codelineno-0-607>607</a></span>
<span class=normal><a href=#__codelineno-0-608>608</a></span>
<span class=normal><a href=#__codelineno-0-609>609</a></span>
<span class=normal><a href=#__codelineno-0-610>610</a></span>
<span class=normal><a href=#__codelineno-0-611>611</a></span>
<span class=normal><a href=#__codelineno-0-612>612</a></span>
<span class=normal><a href=#__codelineno-0-613>613</a></span>
<span class=normal><a href=#__codelineno-0-614>614</a></span>
<span class=normal><a href=#__codelineno-0-615>615</a></span>
<span class=normal><a href=#__codelineno-0-616>616</a></span>
<span class=normal><a href=#__codelineno-0-617>617</a></span>
<span class=normal><a href=#__codelineno-0-618>618</a></span>
<span class=normal><a href=#__codelineno-0-619>619</a></span>
<span class=normal><a href=#__codelineno-0-620>620</a></span>
<span class=normal><a href=#__codelineno-0-621>621</a></span>
<span class=normal><a href=#__codelineno-0-622>622</a></span>
<span class=normal><a href=#__codelineno-0-623>623</a></span>
<span class=normal><a href=#__codelineno-0-624>624</a></span>
<span class=normal><a href=#__codelineno-0-625>625</a></span>
<span class=normal><a href=#__codelineno-0-626>626</a></span>
<span class=normal><a href=#__codelineno-0-627>627</a></span>
<span class=normal><a href=#__codelineno-0-628>628</a></span>
<span class=normal><a href=#__codelineno-0-629>629</a></span>
<span class=normal><a href=#__codelineno-0-630>630</a></span>
<span class=normal><a href=#__codelineno-0-631>631</a></span>
<span class=normal><a href=#__codelineno-0-632>632</a></span>
<span class=normal><a href=#__codelineno-0-633>633</a></span>
<span class=normal><a href=#__codelineno-0-634>634</a></span>
<span class=normal><a href=#__codelineno-0-635>635</a></span>
<span class=normal><a href=#__codelineno-0-636>636</a></span>
<span class=normal><a href=#__codelineno-0-637>637</a></span>
<span class=normal><a href=#__codelineno-0-638>638</a></span>
<span class=normal><a href=#__codelineno-0-639>639</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-552 name=__codelineno-0-552></a><span class=k>class</span><span class=w> </span><span class=nc>LeastMeanSquares</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>):</span>
<a id=__codelineno-0-553 name=__codelineno-0-553></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Least Mean Squares (LMS) filter for parameter estimation in adaptive filtering.</span>
<a id=__codelineno-0-554 name=__codelineno-0-554></a>
<a id=__codelineno-0-555 name=__codelineno-0-555></a><span class=sd>    The LMS algorithm is an adaptive filter used to estimate the parameters of a model</span>
<a id=__codelineno-0-556 name=__codelineno-0-556></a><span class=sd>    by minimizing the mean square error between the observed and predicted values.</span>
<a id=__codelineno-0-557 name=__codelineno-0-557></a>
<a id=__codelineno-0-558 name=__codelineno-0-558></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-559 name=__codelineno-0-559></a><span class=sd>    ----------</span>
<a id=__codelineno-0-560 name=__codelineno-0-560></a><span class=sd>    mu : float, default=0.01</span>
<a id=__codelineno-0-561 name=__codelineno-0-561></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-562 name=__codelineno-0-562></a><span class=sd>    unbiased : bool, optional</span>
<a id=__codelineno-0-563 name=__codelineno-0-563></a><span class=sd>        If True, applies an unbiased estimator. Default is False.</span>
<a id=__codelineno-0-564 name=__codelineno-0-564></a><span class=sd>    uiter : int, optional</span>
<a id=__codelineno-0-565 name=__codelineno-0-565></a><span class=sd>        Number of iterations for the unbiased estimator. Default is 30.</span>
<a id=__codelineno-0-566 name=__codelineno-0-566></a>
<a id=__codelineno-0-567 name=__codelineno-0-567></a><span class=sd>    Attributes</span>
<a id=__codelineno-0-568 name=__codelineno-0-568></a><span class=sd>    ----------</span>
<a id=__codelineno-0-569 name=__codelineno-0-569></a><span class=sd>    mu : float</span>
<a id=__codelineno-0-570 name=__codelineno-0-570></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-571 name=__codelineno-0-571></a><span class=sd>    unbiased : bool</span>
<a id=__codelineno-0-572 name=__codelineno-0-572></a><span class=sd>        Indicates whether an unbiased estimator is applied.</span>
<a id=__codelineno-0-573 name=__codelineno-0-573></a><span class=sd>    uiter : int</span>
<a id=__codelineno-0-574 name=__codelineno-0-574></a><span class=sd>        Number of iterations for the unbiased estimator.</span>
<a id=__codelineno-0-575 name=__codelineno-0-575></a><span class=sd>    xi : np.ndarray or None</span>
<a id=__codelineno-0-576 name=__codelineno-0-576></a><span class=sd>        The estimation error at each iteration. Initialized as None and updated during</span>
<a id=__codelineno-0-577 name=__codelineno-0-577></a><span class=sd>        optimization.</span>
<a id=__codelineno-0-578 name=__codelineno-0-578></a>
<a id=__codelineno-0-579 name=__codelineno-0-579></a><span class=sd>    Methods</span>
<a id=__codelineno-0-580 name=__codelineno-0-580></a><span class=sd>    -------</span>
<a id=__codelineno-0-581 name=__codelineno-0-581></a><span class=sd>    optimize(psi: np.ndarray, y: np.ndarray) -&gt; np.ndarray</span>
<a id=__codelineno-0-582 name=__codelineno-0-582></a><span class=sd>        Estimate the model parameters using the LMS filter.</span>
<a id=__codelineno-0-583 name=__codelineno-0-583></a>
<a id=__codelineno-0-584 name=__codelineno-0-584></a><span class=sd>    References</span>
<a id=__codelineno-0-585 name=__codelineno-0-585></a><span class=sd>    ----------</span>
<a id=__codelineno-0-586 name=__codelineno-0-586></a><span class=sd>    - Haykin, S., &amp; Widrow, B. (Eds.). (2003). Least-mean-square adaptive filters</span>
<a id=__codelineno-0-587 name=__codelineno-0-587></a><span class=sd>    (Vol. 31). John Wiley &amp; Sons.</span>
<a id=__codelineno-0-588 name=__codelineno-0-588></a><span class=sd>    - Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de</span>
<a id=__codelineno-0-589 name=__codelineno-0-589></a><span class=sd>    algoritmos LMS de passo variável.</span>
<a id=__codelineno-0-590 name=__codelineno-0-590></a><span class=sd>    - Wikipedia entry on Least Mean Squares: https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>
<a id=__codelineno-0-591 name=__codelineno-0-591></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-592 name=__codelineno-0-592></a>
<a id=__codelineno-0-593 name=__codelineno-0-593></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=o>*</span><span class=p>,</span> <span class=n>mu</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.01</span><span class=p>,</span> <span class=n>unbiased</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span> <span class=n>uiter</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>30</span><span class=p>):</span>
<a id=__codelineno-0-594 name=__codelineno-0-594></a>        <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>=</span> <span class=n>mu</span>
<a id=__codelineno-0-595 name=__codelineno-0-595></a>        <span class=bp>self</span><span class=o>.</span><span class=n>unbiased</span> <span class=o>=</span> <span class=n>unbiased</span>
<a id=__codelineno-0-596 name=__codelineno-0-596></a>        <span class=bp>self</span><span class=o>.</span><span class=n>uiter</span> <span class=o>=</span> <span class=n>uiter</span>
<a id=__codelineno-0-597 name=__codelineno-0-597></a>        <span class=n>_validate_params</span><span class=p>(</span><span class=nb>vars</span><span class=p>(</span><span class=bp>self</span><span class=p>))</span>
<a id=__codelineno-0-598 name=__codelineno-0-598></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
<a id=__codelineno-0-599 name=__codelineno-0-599></a>
<a id=__codelineno-0-600 name=__codelineno-0-600></a>    <span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-601 name=__codelineno-0-601></a><span class=w>        </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Estimate the model parameters using the Least Mean Squares filter.</span>
<a id=__codelineno-0-602 name=__codelineno-0-602></a>
<a id=__codelineno-0-603 name=__codelineno-0-603></a><span class=sd>        The LMS algorithm updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-604 name=__codelineno-0-604></a>
<a id=__codelineno-0-605 name=__codelineno-0-605></a><span class=sd>        1. Compute the estimation error:</span>
<a id=__codelineno-0-606 name=__codelineno-0-606></a>
<a id=__codelineno-0-607 name=__codelineno-0-607></a><span class=sd>           $$</span>
<a id=__codelineno-0-608 name=__codelineno-0-608></a><span class=sd>           \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-609 name=__codelineno-0-609></a><span class=sd>           $$</span>
<a id=__codelineno-0-610 name=__codelineno-0-610></a>
<a id=__codelineno-0-611 name=__codelineno-0-611></a><span class=sd>        2. Update the parameter vector:</span>
<a id=__codelineno-0-612 name=__codelineno-0-612></a>
<a id=__codelineno-0-613 name=__codelineno-0-613></a><span class=sd>           $$</span>
<a id=__codelineno-0-614 name=__codelineno-0-614></a><span class=sd>           \theta_i = \theta_{i-1} + 2 \mu \xi_i \psi_i</span>
<a id=__codelineno-0-615 name=__codelineno-0-615></a><span class=sd>           $$</span>
<a id=__codelineno-0-616 name=__codelineno-0-616></a>
<a id=__codelineno-0-617 name=__codelineno-0-617></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-618 name=__codelineno-0-618></a><span class=sd>        ----------</span>
<a id=__codelineno-0-619 name=__codelineno-0-619></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-620 name=__codelineno-0-620></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-621 name=__codelineno-0-621></a><span class=sd>        y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-622 name=__codelineno-0-622></a><span class=sd>            The data used to train the model.</span>
<a id=__codelineno-0-623 name=__codelineno-0-623></a>
<a id=__codelineno-0-624 name=__codelineno-0-624></a><span class=sd>        Returns</span>
<a id=__codelineno-0-625 name=__codelineno-0-625></a><span class=sd>        -------</span>
<a id=__codelineno-0-626 name=__codelineno-0-626></a><span class=sd>        theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-627 name=__codelineno-0-627></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-628 name=__codelineno-0-628></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-629 name=__codelineno-0-629></a>        <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-630 name=__codelineno-0-630></a>
<a id=__codelineno-0-631 name=__codelineno-0-631></a>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-632 name=__codelineno-0-632></a>            <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-633 name=__codelineno-0-633></a>            <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-634 name=__codelineno-0-634></a>            <span class=n>tmp_list</span> <span class=o>=</span> <span class=p>(</span>
<a id=__codelineno-0-635 name=__codelineno-0-635></a>                <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=mi>2</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>psi_tmp</span>
<a id=__codelineno-0-636 name=__codelineno-0-636></a>            <span class=p>)</span>
<a id=__codelineno-0-637 name=__codelineno-0-637></a>            <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-638 name=__codelineno-0-638></a>
<a id=__codelineno-0-639 name=__codelineno-0-639></a>        <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.LeastMeanSquares.optimize class="doc doc-heading"> <code class="highlight language-python"><span class=n>optimize</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquares.optimize class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Estimate the model parameters using the Least Mean Squares filter.</p> <p>The LMS algorithm updates the parameter estimates recursively as follows:</p> <ol> <li>Compute the estimation error:</li> </ol> <p>$$ \xi_i = y_i - \psi_i^T \theta_{i-1} $$</p> <ol> <li>Update the parameter vector:</li> </ol> <p>$$ \theta_i = \theta_{i-1} + 2 \mu \xi_i \psi_i $$</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>array-like of shape (n_samples, 1)</code> </td> <td> <div class=doc-md-description> <p>The data used to train the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>array-like of shape (n_features, 1)</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-600>600</a></span>
<span class=normal><a href=#__codelineno-0-601>601</a></span>
<span class=normal><a href=#__codelineno-0-602>602</a></span>
<span class=normal><a href=#__codelineno-0-603>603</a></span>
<span class=normal><a href=#__codelineno-0-604>604</a></span>
<span class=normal><a href=#__codelineno-0-605>605</a></span>
<span class=normal><a href=#__codelineno-0-606>606</a></span>
<span class=normal><a href=#__codelineno-0-607>607</a></span>
<span class=normal><a href=#__codelineno-0-608>608</a></span>
<span class=normal><a href=#__codelineno-0-609>609</a></span>
<span class=normal><a href=#__codelineno-0-610>610</a></span>
<span class=normal><a href=#__codelineno-0-611>611</a></span>
<span class=normal><a href=#__codelineno-0-612>612</a></span>
<span class=normal><a href=#__codelineno-0-613>613</a></span>
<span class=normal><a href=#__codelineno-0-614>614</a></span>
<span class=normal><a href=#__codelineno-0-615>615</a></span>
<span class=normal><a href=#__codelineno-0-616>616</a></span>
<span class=normal><a href=#__codelineno-0-617>617</a></span>
<span class=normal><a href=#__codelineno-0-618>618</a></span>
<span class=normal><a href=#__codelineno-0-619>619</a></span>
<span class=normal><a href=#__codelineno-0-620>620</a></span>
<span class=normal><a href=#__codelineno-0-621>621</a></span>
<span class=normal><a href=#__codelineno-0-622>622</a></span>
<span class=normal><a href=#__codelineno-0-623>623</a></span>
<span class=normal><a href=#__codelineno-0-624>624</a></span>
<span class=normal><a href=#__codelineno-0-625>625</a></span>
<span class=normal><a href=#__codelineno-0-626>626</a></span>
<span class=normal><a href=#__codelineno-0-627>627</a></span>
<span class=normal><a href=#__codelineno-0-628>628</a></span>
<span class=normal><a href=#__codelineno-0-629>629</a></span>
<span class=normal><a href=#__codelineno-0-630>630</a></span>
<span class=normal><a href=#__codelineno-0-631>631</a></span>
<span class=normal><a href=#__codelineno-0-632>632</a></span>
<span class=normal><a href=#__codelineno-0-633>633</a></span>
<span class=normal><a href=#__codelineno-0-634>634</a></span>
<span class=normal><a href=#__codelineno-0-635>635</a></span>
<span class=normal><a href=#__codelineno-0-636>636</a></span>
<span class=normal><a href=#__codelineno-0-637>637</a></span>
<span class=normal><a href=#__codelineno-0-638>638</a></span>
<span class=normal><a href=#__codelineno-0-639>639</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-600 name=__codelineno-0-600></a><span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-601 name=__codelineno-0-601></a><span class=w>    </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Estimate the model parameters using the Least Mean Squares filter.</span>
<a id=__codelineno-0-602 name=__codelineno-0-602></a>
<a id=__codelineno-0-603 name=__codelineno-0-603></a><span class=sd>    The LMS algorithm updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-604 name=__codelineno-0-604></a>
<a id=__codelineno-0-605 name=__codelineno-0-605></a><span class=sd>    1. Compute the estimation error:</span>
<a id=__codelineno-0-606 name=__codelineno-0-606></a>
<a id=__codelineno-0-607 name=__codelineno-0-607></a><span class=sd>       $$</span>
<a id=__codelineno-0-608 name=__codelineno-0-608></a><span class=sd>       \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-609 name=__codelineno-0-609></a><span class=sd>       $$</span>
<a id=__codelineno-0-610 name=__codelineno-0-610></a>
<a id=__codelineno-0-611 name=__codelineno-0-611></a><span class=sd>    2. Update the parameter vector:</span>
<a id=__codelineno-0-612 name=__codelineno-0-612></a>
<a id=__codelineno-0-613 name=__codelineno-0-613></a><span class=sd>       $$</span>
<a id=__codelineno-0-614 name=__codelineno-0-614></a><span class=sd>       \theta_i = \theta_{i-1} + 2 \mu \xi_i \psi_i</span>
<a id=__codelineno-0-615 name=__codelineno-0-615></a><span class=sd>       $$</span>
<a id=__codelineno-0-616 name=__codelineno-0-616></a>
<a id=__codelineno-0-617 name=__codelineno-0-617></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-618 name=__codelineno-0-618></a><span class=sd>    ----------</span>
<a id=__codelineno-0-619 name=__codelineno-0-619></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-620 name=__codelineno-0-620></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-621 name=__codelineno-0-621></a><span class=sd>    y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-622 name=__codelineno-0-622></a><span class=sd>        The data used to train the model.</span>
<a id=__codelineno-0-623 name=__codelineno-0-623></a>
<a id=__codelineno-0-624 name=__codelineno-0-624></a><span class=sd>    Returns</span>
<a id=__codelineno-0-625 name=__codelineno-0-625></a><span class=sd>    -------</span>
<a id=__codelineno-0-626 name=__codelineno-0-626></a><span class=sd>    theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-627 name=__codelineno-0-627></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-628 name=__codelineno-0-628></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-629 name=__codelineno-0-629></a>    <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-630 name=__codelineno-0-630></a>
<a id=__codelineno-0-631 name=__codelineno-0-631></a>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-632 name=__codelineno-0-632></a>        <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-633 name=__codelineno-0-633></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-634 name=__codelineno-0-634></a>        <span class=n>tmp_list</span> <span class=o>=</span> <span class=p>(</span>
<a id=__codelineno-0-635 name=__codelineno-0-635></a>            <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=mi>2</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>psi_tmp</span>
<a id=__codelineno-0-636 name=__codelineno-0-636></a>        <span class=p>)</span>
<a id=__codelineno-0-637 name=__codelineno-0-637></a>        <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-638 name=__codelineno-0-638></a>
<a id=__codelineno-0-639 name=__codelineno-0-639></a>    <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresFourth class="doc doc-heading"> <code>LeastMeanSquaresFourth</code> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresFourth class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=sysidentpy.parameter_estimation.estimators_base.BaseEstimator>BaseEstimator</span></code></p> <p>Least Mean Squares Fourth (LMSF) filter for parameter estimation.</p> <p>The LMSF algorithm is an adaptive filter used to estimate the parameters of a model by using the mean fourth error cost function to eliminate the noise effectively.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>mu</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> <td> <code>0.5</code> </td> </tr> <tr class=doc-section-item> <td> <code>unbiased</code> </td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>If True, applies an unbiased estimator. Default is False.</p> </div> </td> <td> <code>False</code> </td> </tr> <tr class=doc-section-item> <td> <code>uiter</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of iterations for the unbiased estimator. Default is 30.</p> </div> </td> <td> <code>30</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Attributes:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresFourth.mu>mu</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresFourth.unbiased>unbiased</span></code></td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>Indicates whether an unbiased estimator is applied.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresFourth.uiter>uiter</span></code></td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of iterations for the unbiased estimator.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresFourth.xi>xi</span></code></td> <td> <code><span title=numpy.ndarray>ndarray</span> or None</code> </td> <td> <div class=doc-md-description> <p>The estimation error at each iteration. Initialized as None and updated during optimization.</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Methods:</span></p> <table> <thead> <tr> <th>Name</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><a class="autorefs autorefs-internal" title="<code>sysidentpy.parameter_estimation.estimators.LeastMeanSquaresFourth.optimize</code>" href=../../../../user-guide/API/parameter-estimation/#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresFourth.optimize>optimize</a></code></td> <td> <div class=doc-md-description> <p>Estimate the model parameters using the LMSF filter.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Hayes, M. H. (2009). Statistical digital signal processing and modeling. John Wiley &amp; Sons.</li> <li>Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de algoritmos LMS de passo variável.</li> <li>Gui, G., Mehbodniya, A., &amp; Adachi, F. (2013). Least mean square/fourth algorithm with application to sparse channel estimation. arXiv preprint arXiv:1304.3911. <a href=https://arxiv.org/pdf/1304.3911.pdf>https://arxiv.org/pdf/1304.3911.pdf</a></li> <li>Nascimento, V. H., &amp; Bermudez, J. C. M. (2005, March). When is the least-mean fourth algorithm mean-square stable? In Proceedings.(ICASSP'05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005. (Vol. 4, pp. iv-341). IEEE. <a href=http://www.lps.usp.br/vitor/artigos/icassp05.pdf>http://www.lps.usp.br/vitor/artigos/icassp05.pdf</a></li> <li>Wikipedia entry on Least Mean Squares: <a href=https://en.wikipedia.org/wiki/Least_mean_squares_filter>https://en.wikipedia.org/wiki/Least_mean_squares_filter</a></li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-1548>1548</a></span>
<span class=normal><a href=#__codelineno-0-1549>1549</a></span>
<span class=normal><a href=#__codelineno-0-1550>1550</a></span>
<span class=normal><a href=#__codelineno-0-1551>1551</a></span>
<span class=normal><a href=#__codelineno-0-1552>1552</a></span>
<span class=normal><a href=#__codelineno-0-1553>1553</a></span>
<span class=normal><a href=#__codelineno-0-1554>1554</a></span>
<span class=normal><a href=#__codelineno-0-1555>1555</a></span>
<span class=normal><a href=#__codelineno-0-1556>1556</a></span>
<span class=normal><a href=#__codelineno-0-1557>1557</a></span>
<span class=normal><a href=#__codelineno-0-1558>1558</a></span>
<span class=normal><a href=#__codelineno-0-1559>1559</a></span>
<span class=normal><a href=#__codelineno-0-1560>1560</a></span>
<span class=normal><a href=#__codelineno-0-1561>1561</a></span>
<span class=normal><a href=#__codelineno-0-1562>1562</a></span>
<span class=normal><a href=#__codelineno-0-1563>1563</a></span>
<span class=normal><a href=#__codelineno-0-1564>1564</a></span>
<span class=normal><a href=#__codelineno-0-1565>1565</a></span>
<span class=normal><a href=#__codelineno-0-1566>1566</a></span>
<span class=normal><a href=#__codelineno-0-1567>1567</a></span>
<span class=normal><a href=#__codelineno-0-1568>1568</a></span>
<span class=normal><a href=#__codelineno-0-1569>1569</a></span>
<span class=normal><a href=#__codelineno-0-1570>1570</a></span>
<span class=normal><a href=#__codelineno-0-1571>1571</a></span>
<span class=normal><a href=#__codelineno-0-1572>1572</a></span>
<span class=normal><a href=#__codelineno-0-1573>1573</a></span>
<span class=normal><a href=#__codelineno-0-1574>1574</a></span>
<span class=normal><a href=#__codelineno-0-1575>1575</a></span>
<span class=normal><a href=#__codelineno-0-1576>1576</a></span>
<span class=normal><a href=#__codelineno-0-1577>1577</a></span>
<span class=normal><a href=#__codelineno-0-1578>1578</a></span>
<span class=normal><a href=#__codelineno-0-1579>1579</a></span>
<span class=normal><a href=#__codelineno-0-1580>1580</a></span>
<span class=normal><a href=#__codelineno-0-1581>1581</a></span>
<span class=normal><a href=#__codelineno-0-1582>1582</a></span>
<span class=normal><a href=#__codelineno-0-1583>1583</a></span>
<span class=normal><a href=#__codelineno-0-1584>1584</a></span>
<span class=normal><a href=#__codelineno-0-1585>1585</a></span>
<span class=normal><a href=#__codelineno-0-1586>1586</a></span>
<span class=normal><a href=#__codelineno-0-1587>1587</a></span>
<span class=normal><a href=#__codelineno-0-1588>1588</a></span>
<span class=normal><a href=#__codelineno-0-1589>1589</a></span>
<span class=normal><a href=#__codelineno-0-1590>1590</a></span>
<span class=normal><a href=#__codelineno-0-1591>1591</a></span>
<span class=normal><a href=#__codelineno-0-1592>1592</a></span>
<span class=normal><a href=#__codelineno-0-1593>1593</a></span>
<span class=normal><a href=#__codelineno-0-1594>1594</a></span>
<span class=normal><a href=#__codelineno-0-1595>1595</a></span>
<span class=normal><a href=#__codelineno-0-1596>1596</a></span>
<span class=normal><a href=#__codelineno-0-1597>1597</a></span>
<span class=normal><a href=#__codelineno-0-1598>1598</a></span>
<span class=normal><a href=#__codelineno-0-1599>1599</a></span>
<span class=normal><a href=#__codelineno-0-1600>1600</a></span>
<span class=normal><a href=#__codelineno-0-1601>1601</a></span>
<span class=normal><a href=#__codelineno-0-1602>1602</a></span>
<span class=normal><a href=#__codelineno-0-1603>1603</a></span>
<span class=normal><a href=#__codelineno-0-1604>1604</a></span>
<span class=normal><a href=#__codelineno-0-1605>1605</a></span>
<span class=normal><a href=#__codelineno-0-1606>1606</a></span>
<span class=normal><a href=#__codelineno-0-1607>1607</a></span>
<span class=normal><a href=#__codelineno-0-1608>1608</a></span>
<span class=normal><a href=#__codelineno-0-1609>1609</a></span>
<span class=normal><a href=#__codelineno-0-1610>1610</a></span>
<span class=normal><a href=#__codelineno-0-1611>1611</a></span>
<span class=normal><a href=#__codelineno-0-1612>1612</a></span>
<span class=normal><a href=#__codelineno-0-1613>1613</a></span>
<span class=normal><a href=#__codelineno-0-1614>1614</a></span>
<span class=normal><a href=#__codelineno-0-1615>1615</a></span>
<span class=normal><a href=#__codelineno-0-1616>1616</a></span>
<span class=normal><a href=#__codelineno-0-1617>1617</a></span>
<span class=normal><a href=#__codelineno-0-1618>1618</a></span>
<span class=normal><a href=#__codelineno-0-1619>1619</a></span>
<span class=normal><a href=#__codelineno-0-1620>1620</a></span>
<span class=normal><a href=#__codelineno-0-1621>1621</a></span>
<span class=normal><a href=#__codelineno-0-1622>1622</a></span>
<span class=normal><a href=#__codelineno-0-1623>1623</a></span>
<span class=normal><a href=#__codelineno-0-1624>1624</a></span>
<span class=normal><a href=#__codelineno-0-1625>1625</a></span>
<span class=normal><a href=#__codelineno-0-1626>1626</a></span>
<span class=normal><a href=#__codelineno-0-1627>1627</a></span>
<span class=normal><a href=#__codelineno-0-1628>1628</a></span>
<span class=normal><a href=#__codelineno-0-1629>1629</a></span>
<span class=normal><a href=#__codelineno-0-1630>1630</a></span>
<span class=normal><a href=#__codelineno-0-1631>1631</a></span>
<span class=normal><a href=#__codelineno-0-1632>1632</a></span>
<span class=normal><a href=#__codelineno-0-1633>1633</a></span>
<span class=normal><a href=#__codelineno-0-1634>1634</a></span>
<span class=normal><a href=#__codelineno-0-1635>1635</a></span>
<span class=normal><a href=#__codelineno-0-1636>1636</a></span>
<span class=normal><a href=#__codelineno-0-1637>1637</a></span>
<span class=normal><a href=#__codelineno-0-1638>1638</a></span>
<span class=normal><a href=#__codelineno-0-1639>1639</a></span>
<span class=normal><a href=#__codelineno-0-1640>1640</a></span>
<span class=normal><a href=#__codelineno-0-1641>1641</a></span>
<span class=normal><a href=#__codelineno-0-1642>1642</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-1548 name=__codelineno-0-1548></a><span class=k>class</span><span class=w> </span><span class=nc>LeastMeanSquaresFourth</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>):</span>
<a id=__codelineno-0-1549 name=__codelineno-0-1549></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Least Mean Squares Fourth (LMSF) filter for parameter estimation.</span>
<a id=__codelineno-0-1550 name=__codelineno-0-1550></a>
<a id=__codelineno-0-1551 name=__codelineno-0-1551></a><span class=sd>    The LMSF algorithm is an adaptive filter used to estimate the parameters of a model</span>
<a id=__codelineno-0-1552 name=__codelineno-0-1552></a><span class=sd>    by using the mean fourth error cost function to eliminate the noise effectively.</span>
<a id=__codelineno-0-1553 name=__codelineno-0-1553></a>
<a id=__codelineno-0-1554 name=__codelineno-0-1554></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-1555 name=__codelineno-0-1555></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1556 name=__codelineno-0-1556></a><span class=sd>    mu : float, default=0.5</span>
<a id=__codelineno-0-1557 name=__codelineno-0-1557></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-1558 name=__codelineno-0-1558></a><span class=sd>    unbiased : bool, optional</span>
<a id=__codelineno-0-1559 name=__codelineno-0-1559></a><span class=sd>        If True, applies an unbiased estimator. Default is False.</span>
<a id=__codelineno-0-1560 name=__codelineno-0-1560></a><span class=sd>    uiter : int, optional</span>
<a id=__codelineno-0-1561 name=__codelineno-0-1561></a><span class=sd>        Number of iterations for the unbiased estimator. Default is 30.</span>
<a id=__codelineno-0-1562 name=__codelineno-0-1562></a>
<a id=__codelineno-0-1563 name=__codelineno-0-1563></a><span class=sd>    Attributes</span>
<a id=__codelineno-0-1564 name=__codelineno-0-1564></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1565 name=__codelineno-0-1565></a><span class=sd>    mu : float</span>
<a id=__codelineno-0-1566 name=__codelineno-0-1566></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-1567 name=__codelineno-0-1567></a><span class=sd>    unbiased : bool</span>
<a id=__codelineno-0-1568 name=__codelineno-0-1568></a><span class=sd>        Indicates whether an unbiased estimator is applied.</span>
<a id=__codelineno-0-1569 name=__codelineno-0-1569></a><span class=sd>    uiter : int</span>
<a id=__codelineno-0-1570 name=__codelineno-0-1570></a><span class=sd>        Number of iterations for the unbiased estimator.</span>
<a id=__codelineno-0-1571 name=__codelineno-0-1571></a><span class=sd>    xi : np.ndarray or None</span>
<a id=__codelineno-0-1572 name=__codelineno-0-1572></a><span class=sd>        The estimation error at each iteration. Initialized as None and updated during</span>
<a id=__codelineno-0-1573 name=__codelineno-0-1573></a><span class=sd>        optimization.</span>
<a id=__codelineno-0-1574 name=__codelineno-0-1574></a>
<a id=__codelineno-0-1575 name=__codelineno-0-1575></a><span class=sd>    Methods</span>
<a id=__codelineno-0-1576 name=__codelineno-0-1576></a><span class=sd>    -------</span>
<a id=__codelineno-0-1577 name=__codelineno-0-1577></a><span class=sd>    optimize(psi: np.ndarray, y: np.ndarray) -&gt; np.ndarray</span>
<a id=__codelineno-0-1578 name=__codelineno-0-1578></a><span class=sd>        Estimate the model parameters using the LMSF filter.</span>
<a id=__codelineno-0-1579 name=__codelineno-0-1579></a>
<a id=__codelineno-0-1580 name=__codelineno-0-1580></a><span class=sd>    References</span>
<a id=__codelineno-0-1581 name=__codelineno-0-1581></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1582 name=__codelineno-0-1582></a><span class=sd>    - Hayes, M. H. (2009). Statistical digital signal processing and modeling.</span>
<a id=__codelineno-0-1583 name=__codelineno-0-1583></a><span class=sd>      John Wiley &amp; Sons.</span>
<a id=__codelineno-0-1584 name=__codelineno-0-1584></a><span class=sd>    - Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de</span>
<a id=__codelineno-0-1585 name=__codelineno-0-1585></a><span class=sd>      algoritmos LMS de passo variável.</span>
<a id=__codelineno-0-1586 name=__codelineno-0-1586></a><span class=sd>    - Gui, G., Mehbodniya, A., &amp; Adachi, F. (2013). Least mean square/fourth algorithm</span>
<a id=__codelineno-0-1587 name=__codelineno-0-1587></a><span class=sd>      with application to sparse channel estimation. arXiv preprint arXiv:1304.3911.</span>
<a id=__codelineno-0-1588 name=__codelineno-0-1588></a><span class=sd>      https://arxiv.org/pdf/1304.3911.pdf</span>
<a id=__codelineno-0-1589 name=__codelineno-0-1589></a><span class=sd>    - Nascimento, V. H., &amp; Bermudez, J. C. M. (2005, March). When is the least-mean</span>
<a id=__codelineno-0-1590 name=__codelineno-0-1590></a><span class=sd>      fourth algorithm mean-square stable? In Proceedings.(ICASSP&#39;05). IEEE</span>
<a id=__codelineno-0-1591 name=__codelineno-0-1591></a><span class=sd>      International Conference on Acoustics, Speech, and Signal Processing, 2005.</span>
<a id=__codelineno-0-1592 name=__codelineno-0-1592></a><span class=sd>      (Vol. 4, pp. iv-341). IEEE. http://www.lps.usp.br/vitor/artigos/icassp05.pdf</span>
<a id=__codelineno-0-1593 name=__codelineno-0-1593></a><span class=sd>    - Wikipedia entry on Least Mean Squares: https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>
<a id=__codelineno-0-1594 name=__codelineno-0-1594></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-1595 name=__codelineno-0-1595></a>
<a id=__codelineno-0-1596 name=__codelineno-0-1596></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=o>*</span><span class=p>,</span> <span class=n>mu</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.5</span><span class=p>,</span> <span class=n>unbiased</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span> <span class=n>uiter</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>30</span><span class=p>):</span>
<a id=__codelineno-0-1597 name=__codelineno-0-1597></a>        <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>=</span> <span class=n>mu</span>
<a id=__codelineno-0-1598 name=__codelineno-0-1598></a>        <span class=bp>self</span><span class=o>.</span><span class=n>unbiased</span> <span class=o>=</span> <span class=n>unbiased</span>
<a id=__codelineno-0-1599 name=__codelineno-0-1599></a>        <span class=bp>self</span><span class=o>.</span><span class=n>uiter</span> <span class=o>=</span> <span class=n>uiter</span>
<a id=__codelineno-0-1600 name=__codelineno-0-1600></a>        <span class=n>_validate_params</span><span class=p>(</span><span class=nb>vars</span><span class=p>(</span><span class=bp>self</span><span class=p>))</span>
<a id=__codelineno-0-1601 name=__codelineno-0-1601></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
<a id=__codelineno-0-1602 name=__codelineno-0-1602></a>
<a id=__codelineno-0-1603 name=__codelineno-0-1603></a>    <span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-1604 name=__codelineno-0-1604></a><span class=w>        </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the LMS Fourth filter.</span>
<a id=__codelineno-0-1605 name=__codelineno-0-1605></a>
<a id=__codelineno-0-1606 name=__codelineno-0-1606></a><span class=sd>        The LMSF algorithm updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-1607 name=__codelineno-0-1607></a>
<a id=__codelineno-0-1608 name=__codelineno-0-1608></a><span class=sd>        1. Compute the estimation error:</span>
<a id=__codelineno-0-1609 name=__codelineno-0-1609></a>
<a id=__codelineno-0-1610 name=__codelineno-0-1610></a><span class=sd>           $$</span>
<a id=__codelineno-0-1611 name=__codelineno-0-1611></a><span class=sd>           \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-1612 name=__codelineno-0-1612></a><span class=sd>           $$</span>
<a id=__codelineno-0-1613 name=__codelineno-0-1613></a>
<a id=__codelineno-0-1614 name=__codelineno-0-1614></a><span class=sd>        2. Update the parameter vector:</span>
<a id=__codelineno-0-1615 name=__codelineno-0-1615></a>
<a id=__codelineno-0-1616 name=__codelineno-0-1616></a><span class=sd>           $$</span>
<a id=__codelineno-0-1617 name=__codelineno-0-1617></a><span class=sd>           \theta_i = \theta_{i-1} + \mu \psi_i \xi_i^3</span>
<a id=__codelineno-0-1618 name=__codelineno-0-1618></a><span class=sd>           $$</span>
<a id=__codelineno-0-1619 name=__codelineno-0-1619></a>
<a id=__codelineno-0-1620 name=__codelineno-0-1620></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-1621 name=__codelineno-0-1621></a><span class=sd>        ----------</span>
<a id=__codelineno-0-1622 name=__codelineno-0-1622></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-1623 name=__codelineno-0-1623></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-1624 name=__codelineno-0-1624></a><span class=sd>        y : ndarray of floats of shape (n_samples, 1)</span>
<a id=__codelineno-0-1625 name=__codelineno-0-1625></a><span class=sd>            The data used to train the model.</span>
<a id=__codelineno-0-1626 name=__codelineno-0-1626></a>
<a id=__codelineno-0-1627 name=__codelineno-0-1627></a><span class=sd>        Returns</span>
<a id=__codelineno-0-1628 name=__codelineno-0-1628></a><span class=sd>        -------</span>
<a id=__codelineno-0-1629 name=__codelineno-0-1629></a><span class=sd>        theta : ndarray of floats of shape (n_features, 1)</span>
<a id=__codelineno-0-1630 name=__codelineno-0-1630></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-1631 name=__codelineno-0-1631></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-1632 name=__codelineno-0-1632></a>        <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-1633 name=__codelineno-0-1633></a>
<a id=__codelineno-0-1634 name=__codelineno-0-1634></a>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-1635 name=__codelineno-0-1635></a>            <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-1636 name=__codelineno-0-1636></a>            <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-1637 name=__codelineno-0-1637></a>            <span class=n>tmp_list</span> <span class=o>=</span> <span class=p>(</span>
<a id=__codelineno-0-1638 name=__codelineno-0-1638></a>                <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=n>psi_tmp</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>**</span> <span class=mi>3</span>
<a id=__codelineno-0-1639 name=__codelineno-0-1639></a>            <span class=p>)</span>
<a id=__codelineno-0-1640 name=__codelineno-0-1640></a>            <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-1641 name=__codelineno-0-1641></a>
<a id=__codelineno-0-1642 name=__codelineno-0-1642></a>        <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresFourth.optimize class="doc doc-heading"> <code class="highlight language-python"><span class=n>optimize</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresFourth.optimize class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Parameter estimation using the LMS Fourth filter.</p> <p>The LMSF algorithm updates the parameter estimates recursively as follows:</p> <ol> <li>Compute the estimation error:</li> </ol> <p>$$ \xi_i = y_i - \psi_i^T \theta_{i-1} $$</p> <ol> <li>Update the parameter vector:</li> </ol> <p>$$ \theta_i = \theta_{i-1} + \mu \psi_i \xi_i^3 $$</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>ndarray of floats of shape (n_samples, 1)</code> </td> <td> <div class=doc-md-description> <p>The data used to train the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>ndarray of floats of shape (n_features, 1)</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-1603>1603</a></span>
<span class=normal><a href=#__codelineno-0-1604>1604</a></span>
<span class=normal><a href=#__codelineno-0-1605>1605</a></span>
<span class=normal><a href=#__codelineno-0-1606>1606</a></span>
<span class=normal><a href=#__codelineno-0-1607>1607</a></span>
<span class=normal><a href=#__codelineno-0-1608>1608</a></span>
<span class=normal><a href=#__codelineno-0-1609>1609</a></span>
<span class=normal><a href=#__codelineno-0-1610>1610</a></span>
<span class=normal><a href=#__codelineno-0-1611>1611</a></span>
<span class=normal><a href=#__codelineno-0-1612>1612</a></span>
<span class=normal><a href=#__codelineno-0-1613>1613</a></span>
<span class=normal><a href=#__codelineno-0-1614>1614</a></span>
<span class=normal><a href=#__codelineno-0-1615>1615</a></span>
<span class=normal><a href=#__codelineno-0-1616>1616</a></span>
<span class=normal><a href=#__codelineno-0-1617>1617</a></span>
<span class=normal><a href=#__codelineno-0-1618>1618</a></span>
<span class=normal><a href=#__codelineno-0-1619>1619</a></span>
<span class=normal><a href=#__codelineno-0-1620>1620</a></span>
<span class=normal><a href=#__codelineno-0-1621>1621</a></span>
<span class=normal><a href=#__codelineno-0-1622>1622</a></span>
<span class=normal><a href=#__codelineno-0-1623>1623</a></span>
<span class=normal><a href=#__codelineno-0-1624>1624</a></span>
<span class=normal><a href=#__codelineno-0-1625>1625</a></span>
<span class=normal><a href=#__codelineno-0-1626>1626</a></span>
<span class=normal><a href=#__codelineno-0-1627>1627</a></span>
<span class=normal><a href=#__codelineno-0-1628>1628</a></span>
<span class=normal><a href=#__codelineno-0-1629>1629</a></span>
<span class=normal><a href=#__codelineno-0-1630>1630</a></span>
<span class=normal><a href=#__codelineno-0-1631>1631</a></span>
<span class=normal><a href=#__codelineno-0-1632>1632</a></span>
<span class=normal><a href=#__codelineno-0-1633>1633</a></span>
<span class=normal><a href=#__codelineno-0-1634>1634</a></span>
<span class=normal><a href=#__codelineno-0-1635>1635</a></span>
<span class=normal><a href=#__codelineno-0-1636>1636</a></span>
<span class=normal><a href=#__codelineno-0-1637>1637</a></span>
<span class=normal><a href=#__codelineno-0-1638>1638</a></span>
<span class=normal><a href=#__codelineno-0-1639>1639</a></span>
<span class=normal><a href=#__codelineno-0-1640>1640</a></span>
<span class=normal><a href=#__codelineno-0-1641>1641</a></span>
<span class=normal><a href=#__codelineno-0-1642>1642</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-1603 name=__codelineno-0-1603></a><span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-1604 name=__codelineno-0-1604></a><span class=w>    </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the LMS Fourth filter.</span>
<a id=__codelineno-0-1605 name=__codelineno-0-1605></a>
<a id=__codelineno-0-1606 name=__codelineno-0-1606></a><span class=sd>    The LMSF algorithm updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-1607 name=__codelineno-0-1607></a>
<a id=__codelineno-0-1608 name=__codelineno-0-1608></a><span class=sd>    1. Compute the estimation error:</span>
<a id=__codelineno-0-1609 name=__codelineno-0-1609></a>
<a id=__codelineno-0-1610 name=__codelineno-0-1610></a><span class=sd>       $$</span>
<a id=__codelineno-0-1611 name=__codelineno-0-1611></a><span class=sd>       \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-1612 name=__codelineno-0-1612></a><span class=sd>       $$</span>
<a id=__codelineno-0-1613 name=__codelineno-0-1613></a>
<a id=__codelineno-0-1614 name=__codelineno-0-1614></a><span class=sd>    2. Update the parameter vector:</span>
<a id=__codelineno-0-1615 name=__codelineno-0-1615></a>
<a id=__codelineno-0-1616 name=__codelineno-0-1616></a><span class=sd>       $$</span>
<a id=__codelineno-0-1617 name=__codelineno-0-1617></a><span class=sd>       \theta_i = \theta_{i-1} + \mu \psi_i \xi_i^3</span>
<a id=__codelineno-0-1618 name=__codelineno-0-1618></a><span class=sd>       $$</span>
<a id=__codelineno-0-1619 name=__codelineno-0-1619></a>
<a id=__codelineno-0-1620 name=__codelineno-0-1620></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-1621 name=__codelineno-0-1621></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1622 name=__codelineno-0-1622></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-1623 name=__codelineno-0-1623></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-1624 name=__codelineno-0-1624></a><span class=sd>    y : ndarray of floats of shape (n_samples, 1)</span>
<a id=__codelineno-0-1625 name=__codelineno-0-1625></a><span class=sd>        The data used to train the model.</span>
<a id=__codelineno-0-1626 name=__codelineno-0-1626></a>
<a id=__codelineno-0-1627 name=__codelineno-0-1627></a><span class=sd>    Returns</span>
<a id=__codelineno-0-1628 name=__codelineno-0-1628></a><span class=sd>    -------</span>
<a id=__codelineno-0-1629 name=__codelineno-0-1629></a><span class=sd>    theta : ndarray of floats of shape (n_features, 1)</span>
<a id=__codelineno-0-1630 name=__codelineno-0-1630></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-1631 name=__codelineno-0-1631></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-1632 name=__codelineno-0-1632></a>    <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-1633 name=__codelineno-0-1633></a>
<a id=__codelineno-0-1634 name=__codelineno-0-1634></a>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-1635 name=__codelineno-0-1635></a>        <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-1636 name=__codelineno-0-1636></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-1637 name=__codelineno-0-1637></a>        <span class=n>tmp_list</span> <span class=o>=</span> <span class=p>(</span>
<a id=__codelineno-0-1638 name=__codelineno-0-1638></a>            <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=n>psi_tmp</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>**</span> <span class=mi>3</span>
<a id=__codelineno-0-1639 name=__codelineno-0-1639></a>        <span class=p>)</span>
<a id=__codelineno-0-1640 name=__codelineno-0-1640></a>        <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-1641 name=__codelineno-0-1641></a>
<a id=__codelineno-0-1642 name=__codelineno-0-1642></a>    <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresLeaky class="doc doc-heading"> <code>LeastMeanSquaresLeaky</code> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresLeaky class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=sysidentpy.parameter_estimation.estimators_base.BaseEstimator>BaseEstimator</span></code></p> <p>Least Mean Squares Leaky (LMSL) filter for parameter estimation.</p> <p>The LMSL algorithm is an adaptive filter used to estimate the parameters of a model by minimizing the mean square error between the observed and predicted values. The leakage factor helps to prevent coefficient drift.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>mu</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> <td> <code>0.01</code> </td> </tr> <tr class=doc-section-item> <td> <code>gama</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The leakage factor of the Leaky LMS method.</p> </div> </td> <td> <code>0.2</code> </td> </tr> <tr class=doc-section-item> <td> <code>unbiased</code> </td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>If True, applies an unbiased estimator. Default is False.</p> </div> </td> <td> <code>False</code> </td> </tr> <tr class=doc-section-item> <td> <code>uiter</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of iterations for the unbiased estimator. Default is 30.</p> </div> </td> <td> <code>30</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Attributes:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresLeaky.mu>mu</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresLeaky.gama>gama</span></code></td> <td> <code>float, default=0.2</code> </td> <td> <div class=doc-md-description> <p>The leakage factor of the Leaky LMS method.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresLeaky.xi>xi</span></code></td> <td> <code><span title=numpy.ndarray>ndarray</span> or None</code> </td> <td> <div class=doc-md-description> <p>The estimation error at each iteration. Initialized as None and updated during optimization.</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Methods:</span></p> <table> <thead> <tr> <th>Name</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><a class="autorefs autorefs-internal" title="<code>sysidentpy.parameter_estimation.estimators.LeastMeanSquaresLeaky.optimize</code>" href=../../../../user-guide/API/parameter-estimation/#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresLeaky.optimize>optimize</a></code></td> <td> <div class=doc-md-description> <p>Estimate the model parameters using the LMSL filter.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Hayes, M. H. (2009). Statistical digital signal processing and modeling. John Wiley &amp; Sons.</li> <li>Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de algoritmos LMS de passo variável.</li> <li>Wikipedia entry on Least Mean Squares: <a href=https://en.wikipedia.org/wiki/Least_mean_squares_filter>https://en.wikipedia.org/wiki/Least_mean_squares_filter</a></li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-1437>1437</a></span>
<span class=normal><a href=#__codelineno-0-1438>1438</a></span>
<span class=normal><a href=#__codelineno-0-1439>1439</a></span>
<span class=normal><a href=#__codelineno-0-1440>1440</a></span>
<span class=normal><a href=#__codelineno-0-1441>1441</a></span>
<span class=normal><a href=#__codelineno-0-1442>1442</a></span>
<span class=normal><a href=#__codelineno-0-1443>1443</a></span>
<span class=normal><a href=#__codelineno-0-1444>1444</a></span>
<span class=normal><a href=#__codelineno-0-1445>1445</a></span>
<span class=normal><a href=#__codelineno-0-1446>1446</a></span>
<span class=normal><a href=#__codelineno-0-1447>1447</a></span>
<span class=normal><a href=#__codelineno-0-1448>1448</a></span>
<span class=normal><a href=#__codelineno-0-1449>1449</a></span>
<span class=normal><a href=#__codelineno-0-1450>1450</a></span>
<span class=normal><a href=#__codelineno-0-1451>1451</a></span>
<span class=normal><a href=#__codelineno-0-1452>1452</a></span>
<span class=normal><a href=#__codelineno-0-1453>1453</a></span>
<span class=normal><a href=#__codelineno-0-1454>1454</a></span>
<span class=normal><a href=#__codelineno-0-1455>1455</a></span>
<span class=normal><a href=#__codelineno-0-1456>1456</a></span>
<span class=normal><a href=#__codelineno-0-1457>1457</a></span>
<span class=normal><a href=#__codelineno-0-1458>1458</a></span>
<span class=normal><a href=#__codelineno-0-1459>1459</a></span>
<span class=normal><a href=#__codelineno-0-1460>1460</a></span>
<span class=normal><a href=#__codelineno-0-1461>1461</a></span>
<span class=normal><a href=#__codelineno-0-1462>1462</a></span>
<span class=normal><a href=#__codelineno-0-1463>1463</a></span>
<span class=normal><a href=#__codelineno-0-1464>1464</a></span>
<span class=normal><a href=#__codelineno-0-1465>1465</a></span>
<span class=normal><a href=#__codelineno-0-1466>1466</a></span>
<span class=normal><a href=#__codelineno-0-1467>1467</a></span>
<span class=normal><a href=#__codelineno-0-1468>1468</a></span>
<span class=normal><a href=#__codelineno-0-1469>1469</a></span>
<span class=normal><a href=#__codelineno-0-1470>1470</a></span>
<span class=normal><a href=#__codelineno-0-1471>1471</a></span>
<span class=normal><a href=#__codelineno-0-1472>1472</a></span>
<span class=normal><a href=#__codelineno-0-1473>1473</a></span>
<span class=normal><a href=#__codelineno-0-1474>1474</a></span>
<span class=normal><a href=#__codelineno-0-1475>1475</a></span>
<span class=normal><a href=#__codelineno-0-1476>1476</a></span>
<span class=normal><a href=#__codelineno-0-1477>1477</a></span>
<span class=normal><a href=#__codelineno-0-1478>1478</a></span>
<span class=normal><a href=#__codelineno-0-1479>1479</a></span>
<span class=normal><a href=#__codelineno-0-1480>1480</a></span>
<span class=normal><a href=#__codelineno-0-1481>1481</a></span>
<span class=normal><a href=#__codelineno-0-1482>1482</a></span>
<span class=normal><a href=#__codelineno-0-1483>1483</a></span>
<span class=normal><a href=#__codelineno-0-1484>1484</a></span>
<span class=normal><a href=#__codelineno-0-1485>1485</a></span>
<span class=normal><a href=#__codelineno-0-1486>1486</a></span>
<span class=normal><a href=#__codelineno-0-1487>1487</a></span>
<span class=normal><a href=#__codelineno-0-1488>1488</a></span>
<span class=normal><a href=#__codelineno-0-1489>1489</a></span>
<span class=normal><a href=#__codelineno-0-1490>1490</a></span>
<span class=normal><a href=#__codelineno-0-1491>1491</a></span>
<span class=normal><a href=#__codelineno-0-1492>1492</a></span>
<span class=normal><a href=#__codelineno-0-1493>1493</a></span>
<span class=normal><a href=#__codelineno-0-1494>1494</a></span>
<span class=normal><a href=#__codelineno-0-1495>1495</a></span>
<span class=normal><a href=#__codelineno-0-1496>1496</a></span>
<span class=normal><a href=#__codelineno-0-1497>1497</a></span>
<span class=normal><a href=#__codelineno-0-1498>1498</a></span>
<span class=normal><a href=#__codelineno-0-1499>1499</a></span>
<span class=normal><a href=#__codelineno-0-1500>1500</a></span>
<span class=normal><a href=#__codelineno-0-1501>1501</a></span>
<span class=normal><a href=#__codelineno-0-1502>1502</a></span>
<span class=normal><a href=#__codelineno-0-1503>1503</a></span>
<span class=normal><a href=#__codelineno-0-1504>1504</a></span>
<span class=normal><a href=#__codelineno-0-1505>1505</a></span>
<span class=normal><a href=#__codelineno-0-1506>1506</a></span>
<span class=normal><a href=#__codelineno-0-1507>1507</a></span>
<span class=normal><a href=#__codelineno-0-1508>1508</a></span>
<span class=normal><a href=#__codelineno-0-1509>1509</a></span>
<span class=normal><a href=#__codelineno-0-1510>1510</a></span>
<span class=normal><a href=#__codelineno-0-1511>1511</a></span>
<span class=normal><a href=#__codelineno-0-1512>1512</a></span>
<span class=normal><a href=#__codelineno-0-1513>1513</a></span>
<span class=normal><a href=#__codelineno-0-1514>1514</a></span>
<span class=normal><a href=#__codelineno-0-1515>1515</a></span>
<span class=normal><a href=#__codelineno-0-1516>1516</a></span>
<span class=normal><a href=#__codelineno-0-1517>1517</a></span>
<span class=normal><a href=#__codelineno-0-1518>1518</a></span>
<span class=normal><a href=#__codelineno-0-1519>1519</a></span>
<span class=normal><a href=#__codelineno-0-1520>1520</a></span>
<span class=normal><a href=#__codelineno-0-1521>1521</a></span>
<span class=normal><a href=#__codelineno-0-1522>1522</a></span>
<span class=normal><a href=#__codelineno-0-1523>1523</a></span>
<span class=normal><a href=#__codelineno-0-1524>1524</a></span>
<span class=normal><a href=#__codelineno-0-1525>1525</a></span>
<span class=normal><a href=#__codelineno-0-1526>1526</a></span>
<span class=normal><a href=#__codelineno-0-1527>1527</a></span>
<span class=normal><a href=#__codelineno-0-1528>1528</a></span>
<span class=normal><a href=#__codelineno-0-1529>1529</a></span>
<span class=normal><a href=#__codelineno-0-1530>1530</a></span>
<span class=normal><a href=#__codelineno-0-1531>1531</a></span>
<span class=normal><a href=#__codelineno-0-1532>1532</a></span>
<span class=normal><a href=#__codelineno-0-1533>1533</a></span>
<span class=normal><a href=#__codelineno-0-1534>1534</a></span>
<span class=normal><a href=#__codelineno-0-1535>1535</a></span>
<span class=normal><a href=#__codelineno-0-1536>1536</a></span>
<span class=normal><a href=#__codelineno-0-1537>1537</a></span>
<span class=normal><a href=#__codelineno-0-1538>1538</a></span>
<span class=normal><a href=#__codelineno-0-1539>1539</a></span>
<span class=normal><a href=#__codelineno-0-1540>1540</a></span>
<span class=normal><a href=#__codelineno-0-1541>1541</a></span>
<span class=normal><a href=#__codelineno-0-1542>1542</a></span>
<span class=normal><a href=#__codelineno-0-1543>1543</a></span>
<span class=normal><a href=#__codelineno-0-1544>1544</a></span>
<span class=normal><a href=#__codelineno-0-1545>1545</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-1437 name=__codelineno-0-1437></a><span class=k>class</span><span class=w> </span><span class=nc>LeastMeanSquaresLeaky</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>):</span>
<a id=__codelineno-0-1438 name=__codelineno-0-1438></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Least Mean Squares Leaky (LMSL) filter for parameter estimation.</span>
<a id=__codelineno-0-1439 name=__codelineno-0-1439></a>
<a id=__codelineno-0-1440 name=__codelineno-0-1440></a><span class=sd>    The LMSL algorithm is an adaptive filter used to estimate the parameters of a model</span>
<a id=__codelineno-0-1441 name=__codelineno-0-1441></a><span class=sd>    by minimizing the mean square error between the observed and predicted values. The</span>
<a id=__codelineno-0-1442 name=__codelineno-0-1442></a><span class=sd>    leakage factor helps to prevent coefficient drift.</span>
<a id=__codelineno-0-1443 name=__codelineno-0-1443></a>
<a id=__codelineno-0-1444 name=__codelineno-0-1444></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-1445 name=__codelineno-0-1445></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1446 name=__codelineno-0-1446></a><span class=sd>    mu : float, default=0.01</span>
<a id=__codelineno-0-1447 name=__codelineno-0-1447></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-1448 name=__codelineno-0-1448></a><span class=sd>    gama : float, default=0.2</span>
<a id=__codelineno-0-1449 name=__codelineno-0-1449></a><span class=sd>        The leakage factor of the Leaky LMS method.</span>
<a id=__codelineno-0-1450 name=__codelineno-0-1450></a><span class=sd>    unbiased : bool, optional</span>
<a id=__codelineno-0-1451 name=__codelineno-0-1451></a><span class=sd>        If True, applies an unbiased estimator. Default is False.</span>
<a id=__codelineno-0-1452 name=__codelineno-0-1452></a><span class=sd>    uiter : int, optional</span>
<a id=__codelineno-0-1453 name=__codelineno-0-1453></a><span class=sd>        Number of iterations for the unbiased estimator. Default is 30.</span>
<a id=__codelineno-0-1454 name=__codelineno-0-1454></a>
<a id=__codelineno-0-1455 name=__codelineno-0-1455></a><span class=sd>    Attributes</span>
<a id=__codelineno-0-1456 name=__codelineno-0-1456></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1457 name=__codelineno-0-1457></a><span class=sd>    mu : float</span>
<a id=__codelineno-0-1458 name=__codelineno-0-1458></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-1459 name=__codelineno-0-1459></a><span class=sd>    gama : float, default=0.2</span>
<a id=__codelineno-0-1460 name=__codelineno-0-1460></a><span class=sd>        The leakage factor of the Leaky LMS method.</span>
<a id=__codelineno-0-1461 name=__codelineno-0-1461></a><span class=sd>    xi : np.ndarray or None</span>
<a id=__codelineno-0-1462 name=__codelineno-0-1462></a><span class=sd>        The estimation error at each iteration. Initialized as None and updated during</span>
<a id=__codelineno-0-1463 name=__codelineno-0-1463></a><span class=sd>        optimization.</span>
<a id=__codelineno-0-1464 name=__codelineno-0-1464></a>
<a id=__codelineno-0-1465 name=__codelineno-0-1465></a><span class=sd>    Methods</span>
<a id=__codelineno-0-1466 name=__codelineno-0-1466></a><span class=sd>    -------</span>
<a id=__codelineno-0-1467 name=__codelineno-0-1467></a><span class=sd>    optimize(psi: np.ndarray, y: np.ndarray) -&gt; np.ndarray</span>
<a id=__codelineno-0-1468 name=__codelineno-0-1468></a><span class=sd>        Estimate the model parameters using the LMSL filter.</span>
<a id=__codelineno-0-1469 name=__codelineno-0-1469></a>
<a id=__codelineno-0-1470 name=__codelineno-0-1470></a><span class=sd>    References</span>
<a id=__codelineno-0-1471 name=__codelineno-0-1471></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1472 name=__codelineno-0-1472></a><span class=sd>    - Hayes, M. H. (2009). Statistical digital signal processing and modeling.</span>
<a id=__codelineno-0-1473 name=__codelineno-0-1473></a><span class=sd>      John Wiley &amp; Sons.</span>
<a id=__codelineno-0-1474 name=__codelineno-0-1474></a><span class=sd>    - Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de</span>
<a id=__codelineno-0-1475 name=__codelineno-0-1475></a><span class=sd>      algoritmos LMS de passo variável.</span>
<a id=__codelineno-0-1476 name=__codelineno-0-1476></a><span class=sd>    - Wikipedia entry on Least Mean Squares: https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>
<a id=__codelineno-0-1477 name=__codelineno-0-1477></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-1478 name=__codelineno-0-1478></a>
<a id=__codelineno-0-1479 name=__codelineno-0-1479></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span>
<a id=__codelineno-0-1480 name=__codelineno-0-1480></a>        <span class=bp>self</span><span class=p>,</span>
<a id=__codelineno-0-1481 name=__codelineno-0-1481></a>        <span class=o>*</span><span class=p>,</span>
<a id=__codelineno-0-1482 name=__codelineno-0-1482></a>        <span class=n>mu</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.01</span><span class=p>,</span>
<a id=__codelineno-0-1483 name=__codelineno-0-1483></a>        <span class=n>gama</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.001</span><span class=p>,</span>
<a id=__codelineno-0-1484 name=__codelineno-0-1484></a>        <span class=n>unbiased</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>
<a id=__codelineno-0-1485 name=__codelineno-0-1485></a>        <span class=n>uiter</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>30</span><span class=p>,</span>
<a id=__codelineno-0-1486 name=__codelineno-0-1486></a>    <span class=p>):</span>
<a id=__codelineno-0-1487 name=__codelineno-0-1487></a>        <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>=</span> <span class=n>mu</span>
<a id=__codelineno-0-1488 name=__codelineno-0-1488></a>        <span class=bp>self</span><span class=o>.</span><span class=n>gama</span> <span class=o>=</span> <span class=n>gama</span>
<a id=__codelineno-0-1489 name=__codelineno-0-1489></a>        <span class=bp>self</span><span class=o>.</span><span class=n>unbiased</span> <span class=o>=</span> <span class=n>unbiased</span>
<a id=__codelineno-0-1490 name=__codelineno-0-1490></a>        <span class=bp>self</span><span class=o>.</span><span class=n>uiter</span> <span class=o>=</span> <span class=n>uiter</span>
<a id=__codelineno-0-1491 name=__codelineno-0-1491></a>        <span class=n>_validate_params</span><span class=p>(</span><span class=nb>vars</span><span class=p>(</span><span class=bp>self</span><span class=p>))</span>
<a id=__codelineno-0-1492 name=__codelineno-0-1492></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
<a id=__codelineno-0-1493 name=__codelineno-0-1493></a>
<a id=__codelineno-0-1494 name=__codelineno-0-1494></a>    <span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-1495 name=__codelineno-0-1495></a><span class=w>        </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Leaky LMS filter.</span>
<a id=__codelineno-0-1496 name=__codelineno-0-1496></a>
<a id=__codelineno-0-1497 name=__codelineno-0-1497></a><span class=sd>        The LMSL algorithm updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-1498 name=__codelineno-0-1498></a>
<a id=__codelineno-0-1499 name=__codelineno-0-1499></a><span class=sd>        1. Compute the estimation error:</span>
<a id=__codelineno-0-1500 name=__codelineno-0-1500></a>
<a id=__codelineno-0-1501 name=__codelineno-0-1501></a><span class=sd>           $$</span>
<a id=__codelineno-0-1502 name=__codelineno-0-1502></a><span class=sd>           \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-1503 name=__codelineno-0-1503></a><span class=sd>           $$</span>
<a id=__codelineno-0-1504 name=__codelineno-0-1504></a>
<a id=__codelineno-0-1505 name=__codelineno-0-1505></a><span class=sd>        2. Update the parameter vector:</span>
<a id=__codelineno-0-1506 name=__codelineno-0-1506></a>
<a id=__codelineno-0-1507 name=__codelineno-0-1507></a><span class=sd>           $$</span>
<a id=__codelineno-0-1508 name=__codelineno-0-1508></a><span class=sd>           \theta_i = \theta_{i-1} (1 - \mu \gamma) + \mu \xi_i \psi_i</span>
<a id=__codelineno-0-1509 name=__codelineno-0-1509></a><span class=sd>           $$</span>
<a id=__codelineno-0-1510 name=__codelineno-0-1510></a>
<a id=__codelineno-0-1511 name=__codelineno-0-1511></a><span class=sd>        When the leakage factor, $\gamma$, is set to 0, there is no leakage in the</span>
<a id=__codelineno-0-1512 name=__codelineno-0-1512></a><span class=sd>        estimation process.</span>
<a id=__codelineno-0-1513 name=__codelineno-0-1513></a>
<a id=__codelineno-0-1514 name=__codelineno-0-1514></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-1515 name=__codelineno-0-1515></a><span class=sd>        ----------</span>
<a id=__codelineno-0-1516 name=__codelineno-0-1516></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-1517 name=__codelineno-0-1517></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-1518 name=__codelineno-0-1518></a><span class=sd>        y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-1519 name=__codelineno-0-1519></a><span class=sd>            The data used to train the model.</span>
<a id=__codelineno-0-1520 name=__codelineno-0-1520></a>
<a id=__codelineno-0-1521 name=__codelineno-0-1521></a><span class=sd>        Returns</span>
<a id=__codelineno-0-1522 name=__codelineno-0-1522></a><span class=sd>        -------</span>
<a id=__codelineno-0-1523 name=__codelineno-0-1523></a><span class=sd>        theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-1524 name=__codelineno-0-1524></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-1525 name=__codelineno-0-1525></a>
<a id=__codelineno-0-1526 name=__codelineno-0-1526></a><span class=sd>        References</span>
<a id=__codelineno-0-1527 name=__codelineno-0-1527></a><span class=sd>        ----------</span>
<a id=__codelineno-0-1528 name=__codelineno-0-1528></a><span class=sd>        - Hayes, M. H. (2009). Statistical digital signal processing and modeling.</span>
<a id=__codelineno-0-1529 name=__codelineno-0-1529></a><span class=sd>          John Wiley &amp; Sons.</span>
<a id=__codelineno-0-1530 name=__codelineno-0-1530></a><span class=sd>        - Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias</span>
<a id=__codelineno-0-1531 name=__codelineno-0-1531></a><span class=sd>          de algoritmos LMS de passo variável.</span>
<a id=__codelineno-0-1532 name=__codelineno-0-1532></a><span class=sd>        - Wikipedia entry on Least Mean Squares: https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>
<a id=__codelineno-0-1533 name=__codelineno-0-1533></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-1534 name=__codelineno-0-1534></a>        <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-1535 name=__codelineno-0-1535></a>
<a id=__codelineno-0-1536 name=__codelineno-0-1536></a>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-1537 name=__codelineno-0-1537></a>            <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-1538 name=__codelineno-0-1538></a>            <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-1539 name=__codelineno-0-1539></a>            <span class=n>tmp_list</span> <span class=o>=</span> <span class=p>(</span>
<a id=__codelineno-0-1540 name=__codelineno-0-1540></a>                <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>gama</span><span class=p>)</span>
<a id=__codelineno-0-1541 name=__codelineno-0-1541></a>                <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>psi_tmp</span>
<a id=__codelineno-0-1542 name=__codelineno-0-1542></a>            <span class=p>)</span>
<a id=__codelineno-0-1543 name=__codelineno-0-1543></a>            <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-1544 name=__codelineno-0-1544></a>
<a id=__codelineno-0-1545 name=__codelineno-0-1545></a>        <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresLeaky.optimize class="doc doc-heading"> <code class="highlight language-python"><span class=n>optimize</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresLeaky.optimize class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Parameter estimation using the Leaky LMS filter.</p> <p>The LMSL algorithm updates the parameter estimates recursively as follows:</p> <ol> <li>Compute the estimation error:</li> </ol> <p>$$ \xi_i = y_i - \psi_i^T \theta_{i-1} $$</p> <ol> <li>Update the parameter vector:</li> </ol> <p>$$ \theta_i = \theta_{i-1} (1 - \mu \gamma) + \mu \xi_i \psi_i $$</p> <p>When the leakage factor, <span class=arithmatex>\(\gamma\)</span>, is set to 0, there is no leakage in the estimation process.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>array-like of shape (n_samples, 1)</code> </td> <td> <div class=doc-md-description> <p>The data used to train the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>array-like of shape (n_features, 1)</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Hayes, M. H. (2009). Statistical digital signal processing and modeling. John Wiley &amp; Sons.</li> <li>Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de algoritmos LMS de passo variável.</li> <li>Wikipedia entry on Least Mean Squares: <a href=https://en.wikipedia.org/wiki/Least_mean_squares_filter>https://en.wikipedia.org/wiki/Least_mean_squares_filter</a></li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-1494>1494</a></span>
<span class=normal><a href=#__codelineno-0-1495>1495</a></span>
<span class=normal><a href=#__codelineno-0-1496>1496</a></span>
<span class=normal><a href=#__codelineno-0-1497>1497</a></span>
<span class=normal><a href=#__codelineno-0-1498>1498</a></span>
<span class=normal><a href=#__codelineno-0-1499>1499</a></span>
<span class=normal><a href=#__codelineno-0-1500>1500</a></span>
<span class=normal><a href=#__codelineno-0-1501>1501</a></span>
<span class=normal><a href=#__codelineno-0-1502>1502</a></span>
<span class=normal><a href=#__codelineno-0-1503>1503</a></span>
<span class=normal><a href=#__codelineno-0-1504>1504</a></span>
<span class=normal><a href=#__codelineno-0-1505>1505</a></span>
<span class=normal><a href=#__codelineno-0-1506>1506</a></span>
<span class=normal><a href=#__codelineno-0-1507>1507</a></span>
<span class=normal><a href=#__codelineno-0-1508>1508</a></span>
<span class=normal><a href=#__codelineno-0-1509>1509</a></span>
<span class=normal><a href=#__codelineno-0-1510>1510</a></span>
<span class=normal><a href=#__codelineno-0-1511>1511</a></span>
<span class=normal><a href=#__codelineno-0-1512>1512</a></span>
<span class=normal><a href=#__codelineno-0-1513>1513</a></span>
<span class=normal><a href=#__codelineno-0-1514>1514</a></span>
<span class=normal><a href=#__codelineno-0-1515>1515</a></span>
<span class=normal><a href=#__codelineno-0-1516>1516</a></span>
<span class=normal><a href=#__codelineno-0-1517>1517</a></span>
<span class=normal><a href=#__codelineno-0-1518>1518</a></span>
<span class=normal><a href=#__codelineno-0-1519>1519</a></span>
<span class=normal><a href=#__codelineno-0-1520>1520</a></span>
<span class=normal><a href=#__codelineno-0-1521>1521</a></span>
<span class=normal><a href=#__codelineno-0-1522>1522</a></span>
<span class=normal><a href=#__codelineno-0-1523>1523</a></span>
<span class=normal><a href=#__codelineno-0-1524>1524</a></span>
<span class=normal><a href=#__codelineno-0-1525>1525</a></span>
<span class=normal><a href=#__codelineno-0-1526>1526</a></span>
<span class=normal><a href=#__codelineno-0-1527>1527</a></span>
<span class=normal><a href=#__codelineno-0-1528>1528</a></span>
<span class=normal><a href=#__codelineno-0-1529>1529</a></span>
<span class=normal><a href=#__codelineno-0-1530>1530</a></span>
<span class=normal><a href=#__codelineno-0-1531>1531</a></span>
<span class=normal><a href=#__codelineno-0-1532>1532</a></span>
<span class=normal><a href=#__codelineno-0-1533>1533</a></span>
<span class=normal><a href=#__codelineno-0-1534>1534</a></span>
<span class=normal><a href=#__codelineno-0-1535>1535</a></span>
<span class=normal><a href=#__codelineno-0-1536>1536</a></span>
<span class=normal><a href=#__codelineno-0-1537>1537</a></span>
<span class=normal><a href=#__codelineno-0-1538>1538</a></span>
<span class=normal><a href=#__codelineno-0-1539>1539</a></span>
<span class=normal><a href=#__codelineno-0-1540>1540</a></span>
<span class=normal><a href=#__codelineno-0-1541>1541</a></span>
<span class=normal><a href=#__codelineno-0-1542>1542</a></span>
<span class=normal><a href=#__codelineno-0-1543>1543</a></span>
<span class=normal><a href=#__codelineno-0-1544>1544</a></span>
<span class=normal><a href=#__codelineno-0-1545>1545</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-1494 name=__codelineno-0-1494></a><span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-1495 name=__codelineno-0-1495></a><span class=w>    </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Leaky LMS filter.</span>
<a id=__codelineno-0-1496 name=__codelineno-0-1496></a>
<a id=__codelineno-0-1497 name=__codelineno-0-1497></a><span class=sd>    The LMSL algorithm updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-1498 name=__codelineno-0-1498></a>
<a id=__codelineno-0-1499 name=__codelineno-0-1499></a><span class=sd>    1. Compute the estimation error:</span>
<a id=__codelineno-0-1500 name=__codelineno-0-1500></a>
<a id=__codelineno-0-1501 name=__codelineno-0-1501></a><span class=sd>       $$</span>
<a id=__codelineno-0-1502 name=__codelineno-0-1502></a><span class=sd>       \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-1503 name=__codelineno-0-1503></a><span class=sd>       $$</span>
<a id=__codelineno-0-1504 name=__codelineno-0-1504></a>
<a id=__codelineno-0-1505 name=__codelineno-0-1505></a><span class=sd>    2. Update the parameter vector:</span>
<a id=__codelineno-0-1506 name=__codelineno-0-1506></a>
<a id=__codelineno-0-1507 name=__codelineno-0-1507></a><span class=sd>       $$</span>
<a id=__codelineno-0-1508 name=__codelineno-0-1508></a><span class=sd>       \theta_i = \theta_{i-1} (1 - \mu \gamma) + \mu \xi_i \psi_i</span>
<a id=__codelineno-0-1509 name=__codelineno-0-1509></a><span class=sd>       $$</span>
<a id=__codelineno-0-1510 name=__codelineno-0-1510></a>
<a id=__codelineno-0-1511 name=__codelineno-0-1511></a><span class=sd>    When the leakage factor, $\gamma$, is set to 0, there is no leakage in the</span>
<a id=__codelineno-0-1512 name=__codelineno-0-1512></a><span class=sd>    estimation process.</span>
<a id=__codelineno-0-1513 name=__codelineno-0-1513></a>
<a id=__codelineno-0-1514 name=__codelineno-0-1514></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-1515 name=__codelineno-0-1515></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1516 name=__codelineno-0-1516></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-1517 name=__codelineno-0-1517></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-1518 name=__codelineno-0-1518></a><span class=sd>    y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-1519 name=__codelineno-0-1519></a><span class=sd>        The data used to train the model.</span>
<a id=__codelineno-0-1520 name=__codelineno-0-1520></a>
<a id=__codelineno-0-1521 name=__codelineno-0-1521></a><span class=sd>    Returns</span>
<a id=__codelineno-0-1522 name=__codelineno-0-1522></a><span class=sd>    -------</span>
<a id=__codelineno-0-1523 name=__codelineno-0-1523></a><span class=sd>    theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-1524 name=__codelineno-0-1524></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-1525 name=__codelineno-0-1525></a>
<a id=__codelineno-0-1526 name=__codelineno-0-1526></a><span class=sd>    References</span>
<a id=__codelineno-0-1527 name=__codelineno-0-1527></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1528 name=__codelineno-0-1528></a><span class=sd>    - Hayes, M. H. (2009). Statistical digital signal processing and modeling.</span>
<a id=__codelineno-0-1529 name=__codelineno-0-1529></a><span class=sd>      John Wiley &amp; Sons.</span>
<a id=__codelineno-0-1530 name=__codelineno-0-1530></a><span class=sd>    - Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias</span>
<a id=__codelineno-0-1531 name=__codelineno-0-1531></a><span class=sd>      de algoritmos LMS de passo variável.</span>
<a id=__codelineno-0-1532 name=__codelineno-0-1532></a><span class=sd>    - Wikipedia entry on Least Mean Squares: https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>
<a id=__codelineno-0-1533 name=__codelineno-0-1533></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-1534 name=__codelineno-0-1534></a>    <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-1535 name=__codelineno-0-1535></a>
<a id=__codelineno-0-1536 name=__codelineno-0-1536></a>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-1537 name=__codelineno-0-1537></a>        <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-1538 name=__codelineno-0-1538></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-1539 name=__codelineno-0-1539></a>        <span class=n>tmp_list</span> <span class=o>=</span> <span class=p>(</span>
<a id=__codelineno-0-1540 name=__codelineno-0-1540></a>            <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>gama</span><span class=p>)</span>
<a id=__codelineno-0-1541 name=__codelineno-0-1541></a>            <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>psi_tmp</span>
<a id=__codelineno-0-1542 name=__codelineno-0-1542></a>        <span class=p>)</span>
<a id=__codelineno-0-1543 name=__codelineno-0-1543></a>        <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-1544 name=__codelineno-0-1544></a>
<a id=__codelineno-0-1545 name=__codelineno-0-1545></a>    <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedLeaky class="doc doc-heading"> <code>LeastMeanSquaresNormalizedLeaky</code> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedLeaky class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=sysidentpy.parameter_estimation.estimators_base.BaseEstimator>BaseEstimator</span></code></p> <p>Normalized Least Mean Squares Leaky (NLMSL) filter for parameter estimation.</p> <p>The NLMSL algorithm is an adaptive filter used to estimate the parameters of a model by minimizing the mean square error between the observed and predicted values. The normalization is used to avoid numerical instability when updating the estimated parameters, and the leakage factor helps to prevent coefficient drift.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>mu</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> <td> <code>0.01</code> </td> </tr> <tr class=doc-section-item> <td> <code>eps</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>Normalization factor of the normalized filters.</p> </div> </td> <td> <code>np.finfo(np.float64).eps</code> </td> </tr> <tr class=doc-section-item> <td> <code>gama</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The leakage factor of the Leaky LMS method.</p> </div> </td> <td> <code>0.2</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Attributes:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedLeaky.mu>mu</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedLeaky.eps>eps</span></code></td> <td> <code>float, default=np.finfo(np.float64).eps</code> </td> <td> <div class=doc-md-description> <p>Normalization factor of the normalized filters.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedLeaky.gama>gama</span></code></td> <td> <code>float, default=0.2</code> </td> <td> <div class=doc-md-description> <p>The leakage factor of the Leaky LMS method.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedLeaky.xi>xi</span></code></td> <td> <code><span title=numpy.ndarray>ndarray</span> or None</code> </td> <td> <div class=doc-md-description> <p>The estimation error at each iteration. Initialized as None and updated during optimization.</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Methods:</span></p> <table> <thead> <tr> <th>Name</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><a class="autorefs autorefs-internal" title="<code>sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedLeaky.optimize</code>" href=../../../../user-guide/API/parameter-estimation/#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedLeaky.optimize>optimize</a></code></td> <td> <div class=doc-md-description> <p>Estimate the model parameters using the NLMSL filter.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Hayes, M. H. (2009). Statistical digital signal processing and modeling. John Wiley &amp; Sons.</li> <li>Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de algoritmos LMS de passo variável.</li> <li>Wikipedia entry on Least Mean Squares: <a href=https://en.wikipedia.org/wiki/Least_mean_squares_filter>https://en.wikipedia.org/wiki/Least_mean_squares_filter</a></li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-1321>1321</a></span>
<span class=normal><a href=#__codelineno-0-1322>1322</a></span>
<span class=normal><a href=#__codelineno-0-1323>1323</a></span>
<span class=normal><a href=#__codelineno-0-1324>1324</a></span>
<span class=normal><a href=#__codelineno-0-1325>1325</a></span>
<span class=normal><a href=#__codelineno-0-1326>1326</a></span>
<span class=normal><a href=#__codelineno-0-1327>1327</a></span>
<span class=normal><a href=#__codelineno-0-1328>1328</a></span>
<span class=normal><a href=#__codelineno-0-1329>1329</a></span>
<span class=normal><a href=#__codelineno-0-1330>1330</a></span>
<span class=normal><a href=#__codelineno-0-1331>1331</a></span>
<span class=normal><a href=#__codelineno-0-1332>1332</a></span>
<span class=normal><a href=#__codelineno-0-1333>1333</a></span>
<span class=normal><a href=#__codelineno-0-1334>1334</a></span>
<span class=normal><a href=#__codelineno-0-1335>1335</a></span>
<span class=normal><a href=#__codelineno-0-1336>1336</a></span>
<span class=normal><a href=#__codelineno-0-1337>1337</a></span>
<span class=normal><a href=#__codelineno-0-1338>1338</a></span>
<span class=normal><a href=#__codelineno-0-1339>1339</a></span>
<span class=normal><a href=#__codelineno-0-1340>1340</a></span>
<span class=normal><a href=#__codelineno-0-1341>1341</a></span>
<span class=normal><a href=#__codelineno-0-1342>1342</a></span>
<span class=normal><a href=#__codelineno-0-1343>1343</a></span>
<span class=normal><a href=#__codelineno-0-1344>1344</a></span>
<span class=normal><a href=#__codelineno-0-1345>1345</a></span>
<span class=normal><a href=#__codelineno-0-1346>1346</a></span>
<span class=normal><a href=#__codelineno-0-1347>1347</a></span>
<span class=normal><a href=#__codelineno-0-1348>1348</a></span>
<span class=normal><a href=#__codelineno-0-1349>1349</a></span>
<span class=normal><a href=#__codelineno-0-1350>1350</a></span>
<span class=normal><a href=#__codelineno-0-1351>1351</a></span>
<span class=normal><a href=#__codelineno-0-1352>1352</a></span>
<span class=normal><a href=#__codelineno-0-1353>1353</a></span>
<span class=normal><a href=#__codelineno-0-1354>1354</a></span>
<span class=normal><a href=#__codelineno-0-1355>1355</a></span>
<span class=normal><a href=#__codelineno-0-1356>1356</a></span>
<span class=normal><a href=#__codelineno-0-1357>1357</a></span>
<span class=normal><a href=#__codelineno-0-1358>1358</a></span>
<span class=normal><a href=#__codelineno-0-1359>1359</a></span>
<span class=normal><a href=#__codelineno-0-1360>1360</a></span>
<span class=normal><a href=#__codelineno-0-1361>1361</a></span>
<span class=normal><a href=#__codelineno-0-1362>1362</a></span>
<span class=normal><a href=#__codelineno-0-1363>1363</a></span>
<span class=normal><a href=#__codelineno-0-1364>1364</a></span>
<span class=normal><a href=#__codelineno-0-1365>1365</a></span>
<span class=normal><a href=#__codelineno-0-1366>1366</a></span>
<span class=normal><a href=#__codelineno-0-1367>1367</a></span>
<span class=normal><a href=#__codelineno-0-1368>1368</a></span>
<span class=normal><a href=#__codelineno-0-1369>1369</a></span>
<span class=normal><a href=#__codelineno-0-1370>1370</a></span>
<span class=normal><a href=#__codelineno-0-1371>1371</a></span>
<span class=normal><a href=#__codelineno-0-1372>1372</a></span>
<span class=normal><a href=#__codelineno-0-1373>1373</a></span>
<span class=normal><a href=#__codelineno-0-1374>1374</a></span>
<span class=normal><a href=#__codelineno-0-1375>1375</a></span>
<span class=normal><a href=#__codelineno-0-1376>1376</a></span>
<span class=normal><a href=#__codelineno-0-1377>1377</a></span>
<span class=normal><a href=#__codelineno-0-1378>1378</a></span>
<span class=normal><a href=#__codelineno-0-1379>1379</a></span>
<span class=normal><a href=#__codelineno-0-1380>1380</a></span>
<span class=normal><a href=#__codelineno-0-1381>1381</a></span>
<span class=normal><a href=#__codelineno-0-1382>1382</a></span>
<span class=normal><a href=#__codelineno-0-1383>1383</a></span>
<span class=normal><a href=#__codelineno-0-1384>1384</a></span>
<span class=normal><a href=#__codelineno-0-1385>1385</a></span>
<span class=normal><a href=#__codelineno-0-1386>1386</a></span>
<span class=normal><a href=#__codelineno-0-1387>1387</a></span>
<span class=normal><a href=#__codelineno-0-1388>1388</a></span>
<span class=normal><a href=#__codelineno-0-1389>1389</a></span>
<span class=normal><a href=#__codelineno-0-1390>1390</a></span>
<span class=normal><a href=#__codelineno-0-1391>1391</a></span>
<span class=normal><a href=#__codelineno-0-1392>1392</a></span>
<span class=normal><a href=#__codelineno-0-1393>1393</a></span>
<span class=normal><a href=#__codelineno-0-1394>1394</a></span>
<span class=normal><a href=#__codelineno-0-1395>1395</a></span>
<span class=normal><a href=#__codelineno-0-1396>1396</a></span>
<span class=normal><a href=#__codelineno-0-1397>1397</a></span>
<span class=normal><a href=#__codelineno-0-1398>1398</a></span>
<span class=normal><a href=#__codelineno-0-1399>1399</a></span>
<span class=normal><a href=#__codelineno-0-1400>1400</a></span>
<span class=normal><a href=#__codelineno-0-1401>1401</a></span>
<span class=normal><a href=#__codelineno-0-1402>1402</a></span>
<span class=normal><a href=#__codelineno-0-1403>1403</a></span>
<span class=normal><a href=#__codelineno-0-1404>1404</a></span>
<span class=normal><a href=#__codelineno-0-1405>1405</a></span>
<span class=normal><a href=#__codelineno-0-1406>1406</a></span>
<span class=normal><a href=#__codelineno-0-1407>1407</a></span>
<span class=normal><a href=#__codelineno-0-1408>1408</a></span>
<span class=normal><a href=#__codelineno-0-1409>1409</a></span>
<span class=normal><a href=#__codelineno-0-1410>1410</a></span>
<span class=normal><a href=#__codelineno-0-1411>1411</a></span>
<span class=normal><a href=#__codelineno-0-1412>1412</a></span>
<span class=normal><a href=#__codelineno-0-1413>1413</a></span>
<span class=normal><a href=#__codelineno-0-1414>1414</a></span>
<span class=normal><a href=#__codelineno-0-1415>1415</a></span>
<span class=normal><a href=#__codelineno-0-1416>1416</a></span>
<span class=normal><a href=#__codelineno-0-1417>1417</a></span>
<span class=normal><a href=#__codelineno-0-1418>1418</a></span>
<span class=normal><a href=#__codelineno-0-1419>1419</a></span>
<span class=normal><a href=#__codelineno-0-1420>1420</a></span>
<span class=normal><a href=#__codelineno-0-1421>1421</a></span>
<span class=normal><a href=#__codelineno-0-1422>1422</a></span>
<span class=normal><a href=#__codelineno-0-1423>1423</a></span>
<span class=normal><a href=#__codelineno-0-1424>1424</a></span>
<span class=normal><a href=#__codelineno-0-1425>1425</a></span>
<span class=normal><a href=#__codelineno-0-1426>1426</a></span>
<span class=normal><a href=#__codelineno-0-1427>1427</a></span>
<span class=normal><a href=#__codelineno-0-1428>1428</a></span>
<span class=normal><a href=#__codelineno-0-1429>1429</a></span>
<span class=normal><a href=#__codelineno-0-1430>1430</a></span>
<span class=normal><a href=#__codelineno-0-1431>1431</a></span>
<span class=normal><a href=#__codelineno-0-1432>1432</a></span>
<span class=normal><a href=#__codelineno-0-1433>1433</a></span>
<span class=normal><a href=#__codelineno-0-1434>1434</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-1321 name=__codelineno-0-1321></a><span class=k>class</span><span class=w> </span><span class=nc>LeastMeanSquaresNormalizedLeaky</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>):</span>
<a id=__codelineno-0-1322 name=__codelineno-0-1322></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Normalized Least Mean Squares Leaky (NLMSL) filter for parameter estimation.</span>
<a id=__codelineno-0-1323 name=__codelineno-0-1323></a>
<a id=__codelineno-0-1324 name=__codelineno-0-1324></a><span class=sd>    The NLMSL algorithm is an adaptive filter used to estimate the parameters of a model</span>
<a id=__codelineno-0-1325 name=__codelineno-0-1325></a><span class=sd>    by minimizing the mean square error between the observed and predicted values. The</span>
<a id=__codelineno-0-1326 name=__codelineno-0-1326></a><span class=sd>    normalization is used to avoid numerical instability when updating the estimated</span>
<a id=__codelineno-0-1327 name=__codelineno-0-1327></a><span class=sd>    parameters, and the leakage factor helps to prevent coefficient drift.</span>
<a id=__codelineno-0-1328 name=__codelineno-0-1328></a>
<a id=__codelineno-0-1329 name=__codelineno-0-1329></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-1330 name=__codelineno-0-1330></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1331 name=__codelineno-0-1331></a><span class=sd>    mu : float, default=0.01</span>
<a id=__codelineno-0-1332 name=__codelineno-0-1332></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-1333 name=__codelineno-0-1333></a><span class=sd>    eps : float, default=np.finfo(np.float64).eps</span>
<a id=__codelineno-0-1334 name=__codelineno-0-1334></a><span class=sd>        Normalization factor of the normalized filters.</span>
<a id=__codelineno-0-1335 name=__codelineno-0-1335></a><span class=sd>    gama : float, default=0.2</span>
<a id=__codelineno-0-1336 name=__codelineno-0-1336></a><span class=sd>        The leakage factor of the Leaky LMS method.</span>
<a id=__codelineno-0-1337 name=__codelineno-0-1337></a>
<a id=__codelineno-0-1338 name=__codelineno-0-1338></a><span class=sd>    Attributes</span>
<a id=__codelineno-0-1339 name=__codelineno-0-1339></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1340 name=__codelineno-0-1340></a><span class=sd>    mu : float</span>
<a id=__codelineno-0-1341 name=__codelineno-0-1341></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-1342 name=__codelineno-0-1342></a><span class=sd>    eps : float, default=np.finfo(np.float64).eps</span>
<a id=__codelineno-0-1343 name=__codelineno-0-1343></a><span class=sd>        Normalization factor of the normalized filters.</span>
<a id=__codelineno-0-1344 name=__codelineno-0-1344></a><span class=sd>    gama : float, default=0.2</span>
<a id=__codelineno-0-1345 name=__codelineno-0-1345></a><span class=sd>        The leakage factor of the Leaky LMS method.</span>
<a id=__codelineno-0-1346 name=__codelineno-0-1346></a><span class=sd>    xi : np.ndarray or None</span>
<a id=__codelineno-0-1347 name=__codelineno-0-1347></a><span class=sd>        The estimation error at each iteration. Initialized as None and updated during</span>
<a id=__codelineno-0-1348 name=__codelineno-0-1348></a><span class=sd>        optimization.</span>
<a id=__codelineno-0-1349 name=__codelineno-0-1349></a>
<a id=__codelineno-0-1350 name=__codelineno-0-1350></a><span class=sd>    Methods</span>
<a id=__codelineno-0-1351 name=__codelineno-0-1351></a><span class=sd>    -------</span>
<a id=__codelineno-0-1352 name=__codelineno-0-1352></a><span class=sd>    optimize(psi: np.ndarray, y: np.ndarray) -&gt; np.ndarray</span>
<a id=__codelineno-0-1353 name=__codelineno-0-1353></a><span class=sd>        Estimate the model parameters using the NLMSL filter.</span>
<a id=__codelineno-0-1354 name=__codelineno-0-1354></a>
<a id=__codelineno-0-1355 name=__codelineno-0-1355></a><span class=sd>    References</span>
<a id=__codelineno-0-1356 name=__codelineno-0-1356></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1357 name=__codelineno-0-1357></a><span class=sd>    - Hayes, M. H. (2009). Statistical digital signal processing and modeling.</span>
<a id=__codelineno-0-1358 name=__codelineno-0-1358></a><span class=sd>      John Wiley &amp; Sons.</span>
<a id=__codelineno-0-1359 name=__codelineno-0-1359></a><span class=sd>    - Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de</span>
<a id=__codelineno-0-1360 name=__codelineno-0-1360></a><span class=sd>      algoritmos LMS de passo variável.</span>
<a id=__codelineno-0-1361 name=__codelineno-0-1361></a><span class=sd>    - Wikipedia entry on Least Mean Squares: https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>
<a id=__codelineno-0-1362 name=__codelineno-0-1362></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-1363 name=__codelineno-0-1363></a>
<a id=__codelineno-0-1364 name=__codelineno-0-1364></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span>
<a id=__codelineno-0-1365 name=__codelineno-0-1365></a>        <span class=bp>self</span><span class=p>,</span>
<a id=__codelineno-0-1366 name=__codelineno-0-1366></a>        <span class=o>*</span><span class=p>,</span>
<a id=__codelineno-0-1367 name=__codelineno-0-1367></a>        <span class=n>mu</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.01</span><span class=p>,</span>
<a id=__codelineno-0-1368 name=__codelineno-0-1368></a>        <span class=n>gama</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.2</span><span class=p>,</span>
<a id=__codelineno-0-1369 name=__codelineno-0-1369></a>        <span class=n>eps</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>float64</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>finfo</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float64</span><span class=p>)</span><span class=o>.</span><span class=n>eps</span><span class=p>,</span>
<a id=__codelineno-0-1370 name=__codelineno-0-1370></a>        <span class=n>unbiased</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>
<a id=__codelineno-0-1371 name=__codelineno-0-1371></a>        <span class=n>uiter</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>30</span><span class=p>,</span>
<a id=__codelineno-0-1372 name=__codelineno-0-1372></a>    <span class=p>):</span>
<a id=__codelineno-0-1373 name=__codelineno-0-1373></a>        <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>=</span> <span class=n>mu</span>
<a id=__codelineno-0-1374 name=__codelineno-0-1374></a>        <span class=bp>self</span><span class=o>.</span><span class=n>eps</span> <span class=o>=</span> <span class=n>eps</span>
<a id=__codelineno-0-1375 name=__codelineno-0-1375></a>        <span class=bp>self</span><span class=o>.</span><span class=n>gama</span> <span class=o>=</span> <span class=n>gama</span>
<a id=__codelineno-0-1376 name=__codelineno-0-1376></a>        <span class=bp>self</span><span class=o>.</span><span class=n>unbiased</span> <span class=o>=</span> <span class=n>unbiased</span>
<a id=__codelineno-0-1377 name=__codelineno-0-1377></a>        <span class=bp>self</span><span class=o>.</span><span class=n>uiter</span> <span class=o>=</span> <span class=n>uiter</span>
<a id=__codelineno-0-1378 name=__codelineno-0-1378></a>        <span class=n>_validate_params</span><span class=p>(</span><span class=nb>vars</span><span class=p>(</span><span class=bp>self</span><span class=p>))</span>
<a id=__codelineno-0-1379 name=__codelineno-0-1379></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
<a id=__codelineno-0-1380 name=__codelineno-0-1380></a>
<a id=__codelineno-0-1381 name=__codelineno-0-1381></a>    <span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-1382 name=__codelineno-0-1382></a><span class=w>        </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Normalized Leaky LMS filter.</span>
<a id=__codelineno-0-1383 name=__codelineno-0-1383></a>
<a id=__codelineno-0-1384 name=__codelineno-0-1384></a><span class=sd>        The NLMSL algorithm updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-1385 name=__codelineno-0-1385></a>
<a id=__codelineno-0-1386 name=__codelineno-0-1386></a><span class=sd>        1. Compute the estimation error:</span>
<a id=__codelineno-0-1387 name=__codelineno-0-1387></a>
<a id=__codelineno-0-1388 name=__codelineno-0-1388></a><span class=sd>           $$</span>
<a id=__codelineno-0-1389 name=__codelineno-0-1389></a><span class=sd>           \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-1390 name=__codelineno-0-1390></a><span class=sd>           $$</span>
<a id=__codelineno-0-1391 name=__codelineno-0-1391></a>
<a id=__codelineno-0-1392 name=__codelineno-0-1392></a><span class=sd>        2. Update the parameter vector:</span>
<a id=__codelineno-0-1393 name=__codelineno-0-1393></a>
<a id=__codelineno-0-1394 name=__codelineno-0-1394></a><span class=sd>           $$</span>
<a id=__codelineno-0-1395 name=__codelineno-0-1395></a><span class=sd>           \theta_i = \theta_{i-1} (1 - \mu \gamma) + \mu \frac{\xi_i \psi_i}{\epsilon</span>
<a id=__codelineno-0-1396 name=__codelineno-0-1396></a><span class=sd>           + \psi_i^T \psi_i}</span>
<a id=__codelineno-0-1397 name=__codelineno-0-1397></a><span class=sd>           $$</span>
<a id=__codelineno-0-1398 name=__codelineno-0-1398></a>
<a id=__codelineno-0-1399 name=__codelineno-0-1399></a><span class=sd>        When the leakage factor, $\gamma$, is set to 0, there is no leakage in the</span>
<a id=__codelineno-0-1400 name=__codelineno-0-1400></a><span class=sd>        estimation process.</span>
<a id=__codelineno-0-1401 name=__codelineno-0-1401></a>
<a id=__codelineno-0-1402 name=__codelineno-0-1402></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-1403 name=__codelineno-0-1403></a><span class=sd>        ----------</span>
<a id=__codelineno-0-1404 name=__codelineno-0-1404></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-1405 name=__codelineno-0-1405></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-1406 name=__codelineno-0-1406></a><span class=sd>        y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-1407 name=__codelineno-0-1407></a><span class=sd>            The data used to train the model.</span>
<a id=__codelineno-0-1408 name=__codelineno-0-1408></a>
<a id=__codelineno-0-1409 name=__codelineno-0-1409></a><span class=sd>        Returns</span>
<a id=__codelineno-0-1410 name=__codelineno-0-1410></a><span class=sd>        -------</span>
<a id=__codelineno-0-1411 name=__codelineno-0-1411></a><span class=sd>        theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-1412 name=__codelineno-0-1412></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-1413 name=__codelineno-0-1413></a>
<a id=__codelineno-0-1414 name=__codelineno-0-1414></a><span class=sd>        References</span>
<a id=__codelineno-0-1415 name=__codelineno-0-1415></a><span class=sd>        ----------</span>
<a id=__codelineno-0-1416 name=__codelineno-0-1416></a><span class=sd>        - Hayes, M. H. (2009). Statistical digital signal processing and modeling.</span>
<a id=__codelineno-0-1417 name=__codelineno-0-1417></a><span class=sd>          John Wiley &amp; Sons.</span>
<a id=__codelineno-0-1418 name=__codelineno-0-1418></a><span class=sd>        - Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias</span>
<a id=__codelineno-0-1419 name=__codelineno-0-1419></a><span class=sd>          de algoritmos LMS de passo variável.</span>
<a id=__codelineno-0-1420 name=__codelineno-0-1420></a><span class=sd>        - Wikipedia entry on Least Mean Squares: https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>
<a id=__codelineno-0-1421 name=__codelineno-0-1421></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-1422 name=__codelineno-0-1422></a>        <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-1423 name=__codelineno-0-1423></a>
<a id=__codelineno-0-1424 name=__codelineno-0-1424></a>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-1425 name=__codelineno-0-1425></a>            <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-1426 name=__codelineno-0-1426></a>            <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-1427 name=__codelineno-0-1427></a>            <span class=n>tmp_list</span> <span class=o>=</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span>
<a id=__codelineno-0-1428 name=__codelineno-0-1428></a>                <span class=mi>1</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>gama</span>
<a id=__codelineno-0-1429 name=__codelineno-0-1429></a>            <span class=p>)</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>psi_tmp</span> <span class=o>/</span> <span class=p>(</span>
<a id=__codelineno-0-1430 name=__codelineno-0-1430></a>                <span class=bp>self</span><span class=o>.</span><span class=n>eps</span> <span class=o>+</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>psi_tmp</span><span class=p>)</span>
<a id=__codelineno-0-1431 name=__codelineno-0-1431></a>            <span class=p>)</span>
<a id=__codelineno-0-1432 name=__codelineno-0-1432></a>            <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-1433 name=__codelineno-0-1433></a>
<a id=__codelineno-0-1434 name=__codelineno-0-1434></a>        <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedLeaky.optimize class="doc doc-heading"> <code class="highlight language-python"><span class=n>optimize</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedLeaky.optimize class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Parameter estimation using the Normalized Leaky LMS filter.</p> <p>The NLMSL algorithm updates the parameter estimates recursively as follows:</p> <ol> <li>Compute the estimation error:</li> </ol> <p>$$ \xi_i = y_i - \psi_i^T \theta_{i-1} $$</p> <ol> <li>Update the parameter vector:</li> </ol> <p>$$ \theta_i = \theta_{i-1} (1 - \mu \gamma) + \mu \frac{\xi_i \psi_i}{\epsilon + \psi_i^T \psi_i} $$</p> <p>When the leakage factor, <span class=arithmatex>\(\gamma\)</span>, is set to 0, there is no leakage in the estimation process.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>array-like of shape (n_samples, 1)</code> </td> <td> <div class=doc-md-description> <p>The data used to train the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>array-like of shape (n_features, 1)</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Hayes, M. H. (2009). Statistical digital signal processing and modeling. John Wiley &amp; Sons.</li> <li>Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de algoritmos LMS de passo variável.</li> <li>Wikipedia entry on Least Mean Squares: <a href=https://en.wikipedia.org/wiki/Least_mean_squares_filter>https://en.wikipedia.org/wiki/Least_mean_squares_filter</a></li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-1381>1381</a></span>
<span class=normal><a href=#__codelineno-0-1382>1382</a></span>
<span class=normal><a href=#__codelineno-0-1383>1383</a></span>
<span class=normal><a href=#__codelineno-0-1384>1384</a></span>
<span class=normal><a href=#__codelineno-0-1385>1385</a></span>
<span class=normal><a href=#__codelineno-0-1386>1386</a></span>
<span class=normal><a href=#__codelineno-0-1387>1387</a></span>
<span class=normal><a href=#__codelineno-0-1388>1388</a></span>
<span class=normal><a href=#__codelineno-0-1389>1389</a></span>
<span class=normal><a href=#__codelineno-0-1390>1390</a></span>
<span class=normal><a href=#__codelineno-0-1391>1391</a></span>
<span class=normal><a href=#__codelineno-0-1392>1392</a></span>
<span class=normal><a href=#__codelineno-0-1393>1393</a></span>
<span class=normal><a href=#__codelineno-0-1394>1394</a></span>
<span class=normal><a href=#__codelineno-0-1395>1395</a></span>
<span class=normal><a href=#__codelineno-0-1396>1396</a></span>
<span class=normal><a href=#__codelineno-0-1397>1397</a></span>
<span class=normal><a href=#__codelineno-0-1398>1398</a></span>
<span class=normal><a href=#__codelineno-0-1399>1399</a></span>
<span class=normal><a href=#__codelineno-0-1400>1400</a></span>
<span class=normal><a href=#__codelineno-0-1401>1401</a></span>
<span class=normal><a href=#__codelineno-0-1402>1402</a></span>
<span class=normal><a href=#__codelineno-0-1403>1403</a></span>
<span class=normal><a href=#__codelineno-0-1404>1404</a></span>
<span class=normal><a href=#__codelineno-0-1405>1405</a></span>
<span class=normal><a href=#__codelineno-0-1406>1406</a></span>
<span class=normal><a href=#__codelineno-0-1407>1407</a></span>
<span class=normal><a href=#__codelineno-0-1408>1408</a></span>
<span class=normal><a href=#__codelineno-0-1409>1409</a></span>
<span class=normal><a href=#__codelineno-0-1410>1410</a></span>
<span class=normal><a href=#__codelineno-0-1411>1411</a></span>
<span class=normal><a href=#__codelineno-0-1412>1412</a></span>
<span class=normal><a href=#__codelineno-0-1413>1413</a></span>
<span class=normal><a href=#__codelineno-0-1414>1414</a></span>
<span class=normal><a href=#__codelineno-0-1415>1415</a></span>
<span class=normal><a href=#__codelineno-0-1416>1416</a></span>
<span class=normal><a href=#__codelineno-0-1417>1417</a></span>
<span class=normal><a href=#__codelineno-0-1418>1418</a></span>
<span class=normal><a href=#__codelineno-0-1419>1419</a></span>
<span class=normal><a href=#__codelineno-0-1420>1420</a></span>
<span class=normal><a href=#__codelineno-0-1421>1421</a></span>
<span class=normal><a href=#__codelineno-0-1422>1422</a></span>
<span class=normal><a href=#__codelineno-0-1423>1423</a></span>
<span class=normal><a href=#__codelineno-0-1424>1424</a></span>
<span class=normal><a href=#__codelineno-0-1425>1425</a></span>
<span class=normal><a href=#__codelineno-0-1426>1426</a></span>
<span class=normal><a href=#__codelineno-0-1427>1427</a></span>
<span class=normal><a href=#__codelineno-0-1428>1428</a></span>
<span class=normal><a href=#__codelineno-0-1429>1429</a></span>
<span class=normal><a href=#__codelineno-0-1430>1430</a></span>
<span class=normal><a href=#__codelineno-0-1431>1431</a></span>
<span class=normal><a href=#__codelineno-0-1432>1432</a></span>
<span class=normal><a href=#__codelineno-0-1433>1433</a></span>
<span class=normal><a href=#__codelineno-0-1434>1434</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-1381 name=__codelineno-0-1381></a><span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-1382 name=__codelineno-0-1382></a><span class=w>    </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Normalized Leaky LMS filter.</span>
<a id=__codelineno-0-1383 name=__codelineno-0-1383></a>
<a id=__codelineno-0-1384 name=__codelineno-0-1384></a><span class=sd>    The NLMSL algorithm updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-1385 name=__codelineno-0-1385></a>
<a id=__codelineno-0-1386 name=__codelineno-0-1386></a><span class=sd>    1. Compute the estimation error:</span>
<a id=__codelineno-0-1387 name=__codelineno-0-1387></a>
<a id=__codelineno-0-1388 name=__codelineno-0-1388></a><span class=sd>       $$</span>
<a id=__codelineno-0-1389 name=__codelineno-0-1389></a><span class=sd>       \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-1390 name=__codelineno-0-1390></a><span class=sd>       $$</span>
<a id=__codelineno-0-1391 name=__codelineno-0-1391></a>
<a id=__codelineno-0-1392 name=__codelineno-0-1392></a><span class=sd>    2. Update the parameter vector:</span>
<a id=__codelineno-0-1393 name=__codelineno-0-1393></a>
<a id=__codelineno-0-1394 name=__codelineno-0-1394></a><span class=sd>       $$</span>
<a id=__codelineno-0-1395 name=__codelineno-0-1395></a><span class=sd>       \theta_i = \theta_{i-1} (1 - \mu \gamma) + \mu \frac{\xi_i \psi_i}{\epsilon</span>
<a id=__codelineno-0-1396 name=__codelineno-0-1396></a><span class=sd>       + \psi_i^T \psi_i}</span>
<a id=__codelineno-0-1397 name=__codelineno-0-1397></a><span class=sd>       $$</span>
<a id=__codelineno-0-1398 name=__codelineno-0-1398></a>
<a id=__codelineno-0-1399 name=__codelineno-0-1399></a><span class=sd>    When the leakage factor, $\gamma$, is set to 0, there is no leakage in the</span>
<a id=__codelineno-0-1400 name=__codelineno-0-1400></a><span class=sd>    estimation process.</span>
<a id=__codelineno-0-1401 name=__codelineno-0-1401></a>
<a id=__codelineno-0-1402 name=__codelineno-0-1402></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-1403 name=__codelineno-0-1403></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1404 name=__codelineno-0-1404></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-1405 name=__codelineno-0-1405></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-1406 name=__codelineno-0-1406></a><span class=sd>    y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-1407 name=__codelineno-0-1407></a><span class=sd>        The data used to train the model.</span>
<a id=__codelineno-0-1408 name=__codelineno-0-1408></a>
<a id=__codelineno-0-1409 name=__codelineno-0-1409></a><span class=sd>    Returns</span>
<a id=__codelineno-0-1410 name=__codelineno-0-1410></a><span class=sd>    -------</span>
<a id=__codelineno-0-1411 name=__codelineno-0-1411></a><span class=sd>    theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-1412 name=__codelineno-0-1412></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-1413 name=__codelineno-0-1413></a>
<a id=__codelineno-0-1414 name=__codelineno-0-1414></a><span class=sd>    References</span>
<a id=__codelineno-0-1415 name=__codelineno-0-1415></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1416 name=__codelineno-0-1416></a><span class=sd>    - Hayes, M. H. (2009). Statistical digital signal processing and modeling.</span>
<a id=__codelineno-0-1417 name=__codelineno-0-1417></a><span class=sd>      John Wiley &amp; Sons.</span>
<a id=__codelineno-0-1418 name=__codelineno-0-1418></a><span class=sd>    - Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias</span>
<a id=__codelineno-0-1419 name=__codelineno-0-1419></a><span class=sd>      de algoritmos LMS de passo variável.</span>
<a id=__codelineno-0-1420 name=__codelineno-0-1420></a><span class=sd>    - Wikipedia entry on Least Mean Squares: https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>
<a id=__codelineno-0-1421 name=__codelineno-0-1421></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-1422 name=__codelineno-0-1422></a>    <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-1423 name=__codelineno-0-1423></a>
<a id=__codelineno-0-1424 name=__codelineno-0-1424></a>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-1425 name=__codelineno-0-1425></a>        <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-1426 name=__codelineno-0-1426></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-1427 name=__codelineno-0-1427></a>        <span class=n>tmp_list</span> <span class=o>=</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span>
<a id=__codelineno-0-1428 name=__codelineno-0-1428></a>            <span class=mi>1</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>gama</span>
<a id=__codelineno-0-1429 name=__codelineno-0-1429></a>        <span class=p>)</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>psi_tmp</span> <span class=o>/</span> <span class=p>(</span>
<a id=__codelineno-0-1430 name=__codelineno-0-1430></a>            <span class=bp>self</span><span class=o>.</span><span class=n>eps</span> <span class=o>+</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>psi_tmp</span><span class=p>)</span>
<a id=__codelineno-0-1431 name=__codelineno-0-1431></a>        <span class=p>)</span>
<a id=__codelineno-0-1432 name=__codelineno-0-1432></a>        <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-1433 name=__codelineno-0-1433></a>
<a id=__codelineno-0-1434 name=__codelineno-0-1434></a>    <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignRegressor class="doc doc-heading"> <code>LeastMeanSquaresNormalizedSignRegressor</code> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignRegressor class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=sysidentpy.parameter_estimation.estimators_base.BaseEstimator>BaseEstimator</span></code></p> <p>Normalized Least Mean Squares SignRegressor filter for parameter estimation.</p> <p>The Normalized Sign-Regressor LMS algorithm updates the parameter estimates recursively by normalizing the input signal to avoid numerical instability and using the sign of the information matrix to adjust the filter coefficients.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>mu</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> <td> <code>0.01</code> </td> </tr> <tr class=doc-section-item> <td> <code>eps</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>Normalization factor of the normalized filters.</p> </div> </td> <td> <code>np.finfo(np.float64).eps</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Attributes:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignRegressor.mu>mu</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignRegressor.eps>eps</span></code></td> <td> <code>float, default=np.finfo(np.float64).eps</code> </td> <td> <div class=doc-md-description> <p>Normalization factor of the normalized filters.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignRegressor.xi>xi</span></code></td> <td> <code><span title=numpy.ndarray>ndarray</span> or None</code> </td> <td> <div class=doc-md-description> <p>The estimation error at each iteration. Initialized as None and updated during optimization.</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Methods:</span></p> <table> <thead> <tr> <th>Name</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><a class="autorefs autorefs-internal" title="<code>sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignRegressor.optimize</code>" href=../../../../user-guide/API/parameter-estimation/#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignRegressor.optimize>optimize</a></code></td> <td> <div class=doc-md-description> <p>Estimate the model parameters using the Normalized Sign-Regressor LMS filter.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Hayes, M. H. (2009). Statistical digital signal processing and modeling. John Wiley &amp; Sons.</li> <li>Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de algoritmos LMS de passo variável.</li> <li>Wikipedia entry on Least Mean Squares <a href=https://en.wikipedia.org/wiki/Least_mean_squares_filter>https://en.wikipedia.org/wiki/Least_mean_squares_filter</a></li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-1022>1022</a></span>
<span class=normal><a href=#__codelineno-0-1023>1023</a></span>
<span class=normal><a href=#__codelineno-0-1024>1024</a></span>
<span class=normal><a href=#__codelineno-0-1025>1025</a></span>
<span class=normal><a href=#__codelineno-0-1026>1026</a></span>
<span class=normal><a href=#__codelineno-0-1027>1027</a></span>
<span class=normal><a href=#__codelineno-0-1028>1028</a></span>
<span class=normal><a href=#__codelineno-0-1029>1029</a></span>
<span class=normal><a href=#__codelineno-0-1030>1030</a></span>
<span class=normal><a href=#__codelineno-0-1031>1031</a></span>
<span class=normal><a href=#__codelineno-0-1032>1032</a></span>
<span class=normal><a href=#__codelineno-0-1033>1033</a></span>
<span class=normal><a href=#__codelineno-0-1034>1034</a></span>
<span class=normal><a href=#__codelineno-0-1035>1035</a></span>
<span class=normal><a href=#__codelineno-0-1036>1036</a></span>
<span class=normal><a href=#__codelineno-0-1037>1037</a></span>
<span class=normal><a href=#__codelineno-0-1038>1038</a></span>
<span class=normal><a href=#__codelineno-0-1039>1039</a></span>
<span class=normal><a href=#__codelineno-0-1040>1040</a></span>
<span class=normal><a href=#__codelineno-0-1041>1041</a></span>
<span class=normal><a href=#__codelineno-0-1042>1042</a></span>
<span class=normal><a href=#__codelineno-0-1043>1043</a></span>
<span class=normal><a href=#__codelineno-0-1044>1044</a></span>
<span class=normal><a href=#__codelineno-0-1045>1045</a></span>
<span class=normal><a href=#__codelineno-0-1046>1046</a></span>
<span class=normal><a href=#__codelineno-0-1047>1047</a></span>
<span class=normal><a href=#__codelineno-0-1048>1048</a></span>
<span class=normal><a href=#__codelineno-0-1049>1049</a></span>
<span class=normal><a href=#__codelineno-0-1050>1050</a></span>
<span class=normal><a href=#__codelineno-0-1051>1051</a></span>
<span class=normal><a href=#__codelineno-0-1052>1052</a></span>
<span class=normal><a href=#__codelineno-0-1053>1053</a></span>
<span class=normal><a href=#__codelineno-0-1054>1054</a></span>
<span class=normal><a href=#__codelineno-0-1055>1055</a></span>
<span class=normal><a href=#__codelineno-0-1056>1056</a></span>
<span class=normal><a href=#__codelineno-0-1057>1057</a></span>
<span class=normal><a href=#__codelineno-0-1058>1058</a></span>
<span class=normal><a href=#__codelineno-0-1059>1059</a></span>
<span class=normal><a href=#__codelineno-0-1060>1060</a></span>
<span class=normal><a href=#__codelineno-0-1061>1061</a></span>
<span class=normal><a href=#__codelineno-0-1062>1062</a></span>
<span class=normal><a href=#__codelineno-0-1063>1063</a></span>
<span class=normal><a href=#__codelineno-0-1064>1064</a></span>
<span class=normal><a href=#__codelineno-0-1065>1065</a></span>
<span class=normal><a href=#__codelineno-0-1066>1066</a></span>
<span class=normal><a href=#__codelineno-0-1067>1067</a></span>
<span class=normal><a href=#__codelineno-0-1068>1068</a></span>
<span class=normal><a href=#__codelineno-0-1069>1069</a></span>
<span class=normal><a href=#__codelineno-0-1070>1070</a></span>
<span class=normal><a href=#__codelineno-0-1071>1071</a></span>
<span class=normal><a href=#__codelineno-0-1072>1072</a></span>
<span class=normal><a href=#__codelineno-0-1073>1073</a></span>
<span class=normal><a href=#__codelineno-0-1074>1074</a></span>
<span class=normal><a href=#__codelineno-0-1075>1075</a></span>
<span class=normal><a href=#__codelineno-0-1076>1076</a></span>
<span class=normal><a href=#__codelineno-0-1077>1077</a></span>
<span class=normal><a href=#__codelineno-0-1078>1078</a></span>
<span class=normal><a href=#__codelineno-0-1079>1079</a></span>
<span class=normal><a href=#__codelineno-0-1080>1080</a></span>
<span class=normal><a href=#__codelineno-0-1081>1081</a></span>
<span class=normal><a href=#__codelineno-0-1082>1082</a></span>
<span class=normal><a href=#__codelineno-0-1083>1083</a></span>
<span class=normal><a href=#__codelineno-0-1084>1084</a></span>
<span class=normal><a href=#__codelineno-0-1085>1085</a></span>
<span class=normal><a href=#__codelineno-0-1086>1086</a></span>
<span class=normal><a href=#__codelineno-0-1087>1087</a></span>
<span class=normal><a href=#__codelineno-0-1088>1088</a></span>
<span class=normal><a href=#__codelineno-0-1089>1089</a></span>
<span class=normal><a href=#__codelineno-0-1090>1090</a></span>
<span class=normal><a href=#__codelineno-0-1091>1091</a></span>
<span class=normal><a href=#__codelineno-0-1092>1092</a></span>
<span class=normal><a href=#__codelineno-0-1093>1093</a></span>
<span class=normal><a href=#__codelineno-0-1094>1094</a></span>
<span class=normal><a href=#__codelineno-0-1095>1095</a></span>
<span class=normal><a href=#__codelineno-0-1096>1096</a></span>
<span class=normal><a href=#__codelineno-0-1097>1097</a></span>
<span class=normal><a href=#__codelineno-0-1098>1098</a></span>
<span class=normal><a href=#__codelineno-0-1099>1099</a></span>
<span class=normal><a href=#__codelineno-0-1100>1100</a></span>
<span class=normal><a href=#__codelineno-0-1101>1101</a></span>
<span class=normal><a href=#__codelineno-0-1102>1102</a></span>
<span class=normal><a href=#__codelineno-0-1103>1103</a></span>
<span class=normal><a href=#__codelineno-0-1104>1104</a></span>
<span class=normal><a href=#__codelineno-0-1105>1105</a></span>
<span class=normal><a href=#__codelineno-0-1106>1106</a></span>
<span class=normal><a href=#__codelineno-0-1107>1107</a></span>
<span class=normal><a href=#__codelineno-0-1108>1108</a></span>
<span class=normal><a href=#__codelineno-0-1109>1109</a></span>
<span class=normal><a href=#__codelineno-0-1110>1110</a></span>
<span class=normal><a href=#__codelineno-0-1111>1111</a></span>
<span class=normal><a href=#__codelineno-0-1112>1112</a></span>
<span class=normal><a href=#__codelineno-0-1113>1113</a></span>
<span class=normal><a href=#__codelineno-0-1114>1114</a></span>
<span class=normal><a href=#__codelineno-0-1115>1115</a></span>
<span class=normal><a href=#__codelineno-0-1116>1116</a></span>
<span class=normal><a href=#__codelineno-0-1117>1117</a></span>
<span class=normal><a href=#__codelineno-0-1118>1118</a></span>
<span class=normal><a href=#__codelineno-0-1119>1119</a></span>
<span class=normal><a href=#__codelineno-0-1120>1120</a></span>
<span class=normal><a href=#__codelineno-0-1121>1121</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-1022 name=__codelineno-0-1022></a><span class=k>class</span><span class=w> </span><span class=nc>LeastMeanSquaresNormalizedSignRegressor</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>):</span>
<a id=__codelineno-0-1023 name=__codelineno-0-1023></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Normalized Least Mean Squares SignRegressor filter for parameter estimation.</span>
<a id=__codelineno-0-1024 name=__codelineno-0-1024></a>
<a id=__codelineno-0-1025 name=__codelineno-0-1025></a><span class=sd>    The Normalized Sign-Regressor LMS algorithm updates the parameter estimates</span>
<a id=__codelineno-0-1026 name=__codelineno-0-1026></a><span class=sd>    recursively by normalizing the input signal to avoid numerical instability</span>
<a id=__codelineno-0-1027 name=__codelineno-0-1027></a><span class=sd>    and using the sign of the information matrix to adjust the filter coefficients.</span>
<a id=__codelineno-0-1028 name=__codelineno-0-1028></a>
<a id=__codelineno-0-1029 name=__codelineno-0-1029></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-1030 name=__codelineno-0-1030></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1031 name=__codelineno-0-1031></a><span class=sd>    mu : float, default=0.01</span>
<a id=__codelineno-0-1032 name=__codelineno-0-1032></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-1033 name=__codelineno-0-1033></a><span class=sd>    eps : float, default=np.finfo(np.float64).eps</span>
<a id=__codelineno-0-1034 name=__codelineno-0-1034></a><span class=sd>        Normalization factor of the normalized filters.</span>
<a id=__codelineno-0-1035 name=__codelineno-0-1035></a>
<a id=__codelineno-0-1036 name=__codelineno-0-1036></a><span class=sd>    Attributes</span>
<a id=__codelineno-0-1037 name=__codelineno-0-1037></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1038 name=__codelineno-0-1038></a><span class=sd>    mu : float</span>
<a id=__codelineno-0-1039 name=__codelineno-0-1039></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-1040 name=__codelineno-0-1040></a><span class=sd>    eps : float, default=np.finfo(np.float64).eps</span>
<a id=__codelineno-0-1041 name=__codelineno-0-1041></a><span class=sd>        Normalization factor of the normalized filters.</span>
<a id=__codelineno-0-1042 name=__codelineno-0-1042></a><span class=sd>    xi : np.ndarray or None</span>
<a id=__codelineno-0-1043 name=__codelineno-0-1043></a><span class=sd>        The estimation error at each iteration. Initialized as None and updated during</span>
<a id=__codelineno-0-1044 name=__codelineno-0-1044></a><span class=sd>        optimization.</span>
<a id=__codelineno-0-1045 name=__codelineno-0-1045></a>
<a id=__codelineno-0-1046 name=__codelineno-0-1046></a><span class=sd>    Methods</span>
<a id=__codelineno-0-1047 name=__codelineno-0-1047></a><span class=sd>    -------</span>
<a id=__codelineno-0-1048 name=__codelineno-0-1048></a><span class=sd>    optimize(psi: np.ndarray, y: np.ndarray) -&gt; np.ndarray</span>
<a id=__codelineno-0-1049 name=__codelineno-0-1049></a><span class=sd>        Estimate the model parameters using the Normalized Sign-Regressor LMS filter.</span>
<a id=__codelineno-0-1050 name=__codelineno-0-1050></a>
<a id=__codelineno-0-1051 name=__codelineno-0-1051></a><span class=sd>    References</span>
<a id=__codelineno-0-1052 name=__codelineno-0-1052></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1053 name=__codelineno-0-1053></a><span class=sd>    - Hayes, M. H. (2009). Statistical digital signal processing and modeling.</span>
<a id=__codelineno-0-1054 name=__codelineno-0-1054></a><span class=sd>      John Wiley &amp; Sons.</span>
<a id=__codelineno-0-1055 name=__codelineno-0-1055></a><span class=sd>    - Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de</span>
<a id=__codelineno-0-1056 name=__codelineno-0-1056></a><span class=sd>      algoritmos LMS de passo variável.</span>
<a id=__codelineno-0-1057 name=__codelineno-0-1057></a><span class=sd>    - Wikipedia entry on Least Mean Squares</span>
<a id=__codelineno-0-1058 name=__codelineno-0-1058></a><span class=sd>      https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>
<a id=__codelineno-0-1059 name=__codelineno-0-1059></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-1060 name=__codelineno-0-1060></a>
<a id=__codelineno-0-1061 name=__codelineno-0-1061></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span>
<a id=__codelineno-0-1062 name=__codelineno-0-1062></a>        <span class=bp>self</span><span class=p>,</span>
<a id=__codelineno-0-1063 name=__codelineno-0-1063></a>        <span class=o>*</span><span class=p>,</span>
<a id=__codelineno-0-1064 name=__codelineno-0-1064></a>        <span class=n>mu</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.01</span><span class=p>,</span>
<a id=__codelineno-0-1065 name=__codelineno-0-1065></a>        <span class=n>eps</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>float64</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>finfo</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float64</span><span class=p>)</span><span class=o>.</span><span class=n>eps</span><span class=p>,</span>
<a id=__codelineno-0-1066 name=__codelineno-0-1066></a>        <span class=n>unbiased</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>
<a id=__codelineno-0-1067 name=__codelineno-0-1067></a>        <span class=n>uiter</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>30</span><span class=p>,</span>
<a id=__codelineno-0-1068 name=__codelineno-0-1068></a>    <span class=p>):</span>
<a id=__codelineno-0-1069 name=__codelineno-0-1069></a>        <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>=</span> <span class=n>mu</span>
<a id=__codelineno-0-1070 name=__codelineno-0-1070></a>        <span class=bp>self</span><span class=o>.</span><span class=n>eps</span> <span class=o>=</span> <span class=n>eps</span>
<a id=__codelineno-0-1071 name=__codelineno-0-1071></a>        <span class=bp>self</span><span class=o>.</span><span class=n>unbiased</span> <span class=o>=</span> <span class=n>unbiased</span>
<a id=__codelineno-0-1072 name=__codelineno-0-1072></a>        <span class=bp>self</span><span class=o>.</span><span class=n>uiter</span> <span class=o>=</span> <span class=n>uiter</span>
<a id=__codelineno-0-1073 name=__codelineno-0-1073></a>        <span class=n>_validate_params</span><span class=p>(</span><span class=nb>vars</span><span class=p>(</span><span class=bp>self</span><span class=p>))</span>
<a id=__codelineno-0-1074 name=__codelineno-0-1074></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
<a id=__codelineno-0-1075 name=__codelineno-0-1075></a>
<a id=__codelineno-0-1076 name=__codelineno-0-1076></a>    <span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-1077 name=__codelineno-0-1077></a><span class=w>        </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Normalized Sign-Regressor LMS filter.</span>
<a id=__codelineno-0-1078 name=__codelineno-0-1078></a>
<a id=__codelineno-0-1079 name=__codelineno-0-1079></a><span class=sd>        The Normalized Sign-Regressor LMS algorithm updates the parameter estimates</span>
<a id=__codelineno-0-1080 name=__codelineno-0-1080></a><span class=sd>        recursively as follows:</span>
<a id=__codelineno-0-1081 name=__codelineno-0-1081></a>
<a id=__codelineno-0-1082 name=__codelineno-0-1082></a><span class=sd>        1. Compute the estimation error:</span>
<a id=__codelineno-0-1083 name=__codelineno-0-1083></a>
<a id=__codelineno-0-1084 name=__codelineno-0-1084></a><span class=sd>           $$</span>
<a id=__codelineno-0-1085 name=__codelineno-0-1085></a><span class=sd>           \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-1086 name=__codelineno-0-1086></a><span class=sd>           $$</span>
<a id=__codelineno-0-1087 name=__codelineno-0-1087></a>
<a id=__codelineno-0-1088 name=__codelineno-0-1088></a><span class=sd>        2. Update the parameter vector:</span>
<a id=__codelineno-0-1089 name=__codelineno-0-1089></a>
<a id=__codelineno-0-1090 name=__codelineno-0-1090></a><span class=sd>           $$</span>
<a id=__codelineno-0-1091 name=__codelineno-0-1091></a><span class=sd>           \theta_i = \theta_{i-1} + \mu \cdot \xi_i \cdot</span>
<a id=__codelineno-0-1092 name=__codelineno-0-1092></a><span class=sd>           \frac{\text{sign}(\psi_i)}{\epsilon + \psi_i^T \psi_i}</span>
<a id=__codelineno-0-1093 name=__codelineno-0-1093></a><span class=sd>           $$</span>
<a id=__codelineno-0-1094 name=__codelineno-0-1094></a>
<a id=__codelineno-0-1095 name=__codelineno-0-1095></a><span class=sd>        The normalization is used to avoid numerical instability when updating</span>
<a id=__codelineno-0-1096 name=__codelineno-0-1096></a><span class=sd>        the estimated parameters and the sign of the information matrix is</span>
<a id=__codelineno-0-1097 name=__codelineno-0-1097></a><span class=sd>        used to change the filter coefficients.</span>
<a id=__codelineno-0-1098 name=__codelineno-0-1098></a>
<a id=__codelineno-0-1099 name=__codelineno-0-1099></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-1100 name=__codelineno-0-1100></a><span class=sd>        ----------</span>
<a id=__codelineno-0-1101 name=__codelineno-0-1101></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-1102 name=__codelineno-0-1102></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-1103 name=__codelineno-0-1103></a><span class=sd>        y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-1104 name=__codelineno-0-1104></a><span class=sd>            The data used to train the model.</span>
<a id=__codelineno-0-1105 name=__codelineno-0-1105></a>
<a id=__codelineno-0-1106 name=__codelineno-0-1106></a><span class=sd>        Returns</span>
<a id=__codelineno-0-1107 name=__codelineno-0-1107></a><span class=sd>        -------</span>
<a id=__codelineno-0-1108 name=__codelineno-0-1108></a><span class=sd>        theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-1109 name=__codelineno-0-1109></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-1110 name=__codelineno-0-1110></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-1111 name=__codelineno-0-1111></a>        <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-1112 name=__codelineno-0-1112></a>
<a id=__codelineno-0-1113 name=__codelineno-0-1113></a>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-1114 name=__codelineno-0-1114></a>            <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-1115 name=__codelineno-0-1115></a>            <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-1116 name=__codelineno-0-1116></a>            <span class=n>tmp_list</span> <span class=o>=</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=p>(</span>
<a id=__codelineno-0-1117 name=__codelineno-0-1117></a>                <span class=n>np</span><span class=o>.</span><span class=n>sign</span><span class=p>(</span><span class=n>psi_tmp</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>eps</span> <span class=o>+</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>psi_tmp</span><span class=p>))</span>
<a id=__codelineno-0-1118 name=__codelineno-0-1118></a>            <span class=p>)</span>
<a id=__codelineno-0-1119 name=__codelineno-0-1119></a>            <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-1120 name=__codelineno-0-1120></a>
<a id=__codelineno-0-1121 name=__codelineno-0-1121></a>        <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignRegressor.optimize class="doc doc-heading"> <code class="highlight language-python"><span class=n>optimize</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignRegressor.optimize class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Parameter estimation using the Normalized Sign-Regressor LMS filter.</p> <p>The Normalized Sign-Regressor LMS algorithm updates the parameter estimates recursively as follows:</p> <ol> <li>Compute the estimation error:</li> </ol> <p>$$ \xi_i = y_i - \psi_i^T \theta_{i-1} $$</p> <ol> <li>Update the parameter vector:</li> </ol> <p>$$ \theta_i = \theta_{i-1} + \mu \cdot \xi_i \cdot \frac{\text{sign}(\psi_i)}{\epsilon + \psi_i^T \psi_i} $$</p> <p>The normalization is used to avoid numerical instability when updating the estimated parameters and the sign of the information matrix is used to change the filter coefficients.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>array-like of shape (n_samples, 1)</code> </td> <td> <div class=doc-md-description> <p>The data used to train the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>array-like of shape (n_features, 1)</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-1076>1076</a></span>
<span class=normal><a href=#__codelineno-0-1077>1077</a></span>
<span class=normal><a href=#__codelineno-0-1078>1078</a></span>
<span class=normal><a href=#__codelineno-0-1079>1079</a></span>
<span class=normal><a href=#__codelineno-0-1080>1080</a></span>
<span class=normal><a href=#__codelineno-0-1081>1081</a></span>
<span class=normal><a href=#__codelineno-0-1082>1082</a></span>
<span class=normal><a href=#__codelineno-0-1083>1083</a></span>
<span class=normal><a href=#__codelineno-0-1084>1084</a></span>
<span class=normal><a href=#__codelineno-0-1085>1085</a></span>
<span class=normal><a href=#__codelineno-0-1086>1086</a></span>
<span class=normal><a href=#__codelineno-0-1087>1087</a></span>
<span class=normal><a href=#__codelineno-0-1088>1088</a></span>
<span class=normal><a href=#__codelineno-0-1089>1089</a></span>
<span class=normal><a href=#__codelineno-0-1090>1090</a></span>
<span class=normal><a href=#__codelineno-0-1091>1091</a></span>
<span class=normal><a href=#__codelineno-0-1092>1092</a></span>
<span class=normal><a href=#__codelineno-0-1093>1093</a></span>
<span class=normal><a href=#__codelineno-0-1094>1094</a></span>
<span class=normal><a href=#__codelineno-0-1095>1095</a></span>
<span class=normal><a href=#__codelineno-0-1096>1096</a></span>
<span class=normal><a href=#__codelineno-0-1097>1097</a></span>
<span class=normal><a href=#__codelineno-0-1098>1098</a></span>
<span class=normal><a href=#__codelineno-0-1099>1099</a></span>
<span class=normal><a href=#__codelineno-0-1100>1100</a></span>
<span class=normal><a href=#__codelineno-0-1101>1101</a></span>
<span class=normal><a href=#__codelineno-0-1102>1102</a></span>
<span class=normal><a href=#__codelineno-0-1103>1103</a></span>
<span class=normal><a href=#__codelineno-0-1104>1104</a></span>
<span class=normal><a href=#__codelineno-0-1105>1105</a></span>
<span class=normal><a href=#__codelineno-0-1106>1106</a></span>
<span class=normal><a href=#__codelineno-0-1107>1107</a></span>
<span class=normal><a href=#__codelineno-0-1108>1108</a></span>
<span class=normal><a href=#__codelineno-0-1109>1109</a></span>
<span class=normal><a href=#__codelineno-0-1110>1110</a></span>
<span class=normal><a href=#__codelineno-0-1111>1111</a></span>
<span class=normal><a href=#__codelineno-0-1112>1112</a></span>
<span class=normal><a href=#__codelineno-0-1113>1113</a></span>
<span class=normal><a href=#__codelineno-0-1114>1114</a></span>
<span class=normal><a href=#__codelineno-0-1115>1115</a></span>
<span class=normal><a href=#__codelineno-0-1116>1116</a></span>
<span class=normal><a href=#__codelineno-0-1117>1117</a></span>
<span class=normal><a href=#__codelineno-0-1118>1118</a></span>
<span class=normal><a href=#__codelineno-0-1119>1119</a></span>
<span class=normal><a href=#__codelineno-0-1120>1120</a></span>
<span class=normal><a href=#__codelineno-0-1121>1121</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-1076 name=__codelineno-0-1076></a><span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-1077 name=__codelineno-0-1077></a><span class=w>    </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Normalized Sign-Regressor LMS filter.</span>
<a id=__codelineno-0-1078 name=__codelineno-0-1078></a>
<a id=__codelineno-0-1079 name=__codelineno-0-1079></a><span class=sd>    The Normalized Sign-Regressor LMS algorithm updates the parameter estimates</span>
<a id=__codelineno-0-1080 name=__codelineno-0-1080></a><span class=sd>    recursively as follows:</span>
<a id=__codelineno-0-1081 name=__codelineno-0-1081></a>
<a id=__codelineno-0-1082 name=__codelineno-0-1082></a><span class=sd>    1. Compute the estimation error:</span>
<a id=__codelineno-0-1083 name=__codelineno-0-1083></a>
<a id=__codelineno-0-1084 name=__codelineno-0-1084></a><span class=sd>       $$</span>
<a id=__codelineno-0-1085 name=__codelineno-0-1085></a><span class=sd>       \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-1086 name=__codelineno-0-1086></a><span class=sd>       $$</span>
<a id=__codelineno-0-1087 name=__codelineno-0-1087></a>
<a id=__codelineno-0-1088 name=__codelineno-0-1088></a><span class=sd>    2. Update the parameter vector:</span>
<a id=__codelineno-0-1089 name=__codelineno-0-1089></a>
<a id=__codelineno-0-1090 name=__codelineno-0-1090></a><span class=sd>       $$</span>
<a id=__codelineno-0-1091 name=__codelineno-0-1091></a><span class=sd>       \theta_i = \theta_{i-1} + \mu \cdot \xi_i \cdot</span>
<a id=__codelineno-0-1092 name=__codelineno-0-1092></a><span class=sd>       \frac{\text{sign}(\psi_i)}{\epsilon + \psi_i^T \psi_i}</span>
<a id=__codelineno-0-1093 name=__codelineno-0-1093></a><span class=sd>       $$</span>
<a id=__codelineno-0-1094 name=__codelineno-0-1094></a>
<a id=__codelineno-0-1095 name=__codelineno-0-1095></a><span class=sd>    The normalization is used to avoid numerical instability when updating</span>
<a id=__codelineno-0-1096 name=__codelineno-0-1096></a><span class=sd>    the estimated parameters and the sign of the information matrix is</span>
<a id=__codelineno-0-1097 name=__codelineno-0-1097></a><span class=sd>    used to change the filter coefficients.</span>
<a id=__codelineno-0-1098 name=__codelineno-0-1098></a>
<a id=__codelineno-0-1099 name=__codelineno-0-1099></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-1100 name=__codelineno-0-1100></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1101 name=__codelineno-0-1101></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-1102 name=__codelineno-0-1102></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-1103 name=__codelineno-0-1103></a><span class=sd>    y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-1104 name=__codelineno-0-1104></a><span class=sd>        The data used to train the model.</span>
<a id=__codelineno-0-1105 name=__codelineno-0-1105></a>
<a id=__codelineno-0-1106 name=__codelineno-0-1106></a><span class=sd>    Returns</span>
<a id=__codelineno-0-1107 name=__codelineno-0-1107></a><span class=sd>    -------</span>
<a id=__codelineno-0-1108 name=__codelineno-0-1108></a><span class=sd>    theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-1109 name=__codelineno-0-1109></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-1110 name=__codelineno-0-1110></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-1111 name=__codelineno-0-1111></a>    <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-1112 name=__codelineno-0-1112></a>
<a id=__codelineno-0-1113 name=__codelineno-0-1113></a>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-1114 name=__codelineno-0-1114></a>        <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-1115 name=__codelineno-0-1115></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-1116 name=__codelineno-0-1116></a>        <span class=n>tmp_list</span> <span class=o>=</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=p>(</span>
<a id=__codelineno-0-1117 name=__codelineno-0-1117></a>            <span class=n>np</span><span class=o>.</span><span class=n>sign</span><span class=p>(</span><span class=n>psi_tmp</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>eps</span> <span class=o>+</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>psi_tmp</span><span class=p>))</span>
<a id=__codelineno-0-1118 name=__codelineno-0-1118></a>        <span class=p>)</span>
<a id=__codelineno-0-1119 name=__codelineno-0-1119></a>        <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-1120 name=__codelineno-0-1120></a>
<a id=__codelineno-0-1121 name=__codelineno-0-1121></a>    <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignSign class="doc doc-heading"> <code>LeastMeanSquaresNormalizedSignSign</code> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignSign class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=sysidentpy.parameter_estimation.estimators_base.BaseEstimator>BaseEstimator</span></code></p> <p>Normalized Least Mean Squares SignSign (NLMSSS) filter for parameter estimation.</p> <p>The NLMSSS algorithm updates the parameter estimates recursively by normalizing the input signal to avoid numerical instability and using both the sign of the information matrix and the sign of the error vector to adjust the filter coefficients.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>mu</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> <td> <code>0.01</code> </td> </tr> <tr class=doc-section-item> <td> <code>eps</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>Normalization factor of the normalized filters.</p> </div> </td> <td> <code>np.finfo(np.float64).eps</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Attributes:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignSign.mu>mu</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignSign.eps>eps</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>Normalization factor of the normalized filters.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignSign.xi>xi</span></code></td> <td> <code><span title=numpy.ndarray>ndarray</span> or None</code> </td> <td> <div class=doc-md-description> <p>The estimation error at each iteration. Initialized as None and updated during optimization.</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Methods:</span></p> <table> <thead> <tr> <th>Name</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><a class="autorefs autorefs-internal" title="<code>sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignSign.optimize</code>" href=../../../../user-guide/API/parameter-estimation/#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignSign.optimize>optimize</a></code></td> <td> <div class=doc-md-description> <p>Estimate the model parameters using the NLMSSS filter.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Hayes, M. H. (2009). Statistical digital signal processing and modeling. John Wiley &amp; Sons.</li> <li>Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de algoritmos LMS de passo variável.</li> <li>Wikipedia entry on Least Mean Squares: <a href=https://en.wikipedia.org/wiki/Least_mean_squares_filter>https://en.wikipedia.org/wiki/Least_mean_squares_filter</a></li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-1211>1211</a></span>
<span class=normal><a href=#__codelineno-0-1212>1212</a></span>
<span class=normal><a href=#__codelineno-0-1213>1213</a></span>
<span class=normal><a href=#__codelineno-0-1214>1214</a></span>
<span class=normal><a href=#__codelineno-0-1215>1215</a></span>
<span class=normal><a href=#__codelineno-0-1216>1216</a></span>
<span class=normal><a href=#__codelineno-0-1217>1217</a></span>
<span class=normal><a href=#__codelineno-0-1218>1218</a></span>
<span class=normal><a href=#__codelineno-0-1219>1219</a></span>
<span class=normal><a href=#__codelineno-0-1220>1220</a></span>
<span class=normal><a href=#__codelineno-0-1221>1221</a></span>
<span class=normal><a href=#__codelineno-0-1222>1222</a></span>
<span class=normal><a href=#__codelineno-0-1223>1223</a></span>
<span class=normal><a href=#__codelineno-0-1224>1224</a></span>
<span class=normal><a href=#__codelineno-0-1225>1225</a></span>
<span class=normal><a href=#__codelineno-0-1226>1226</a></span>
<span class=normal><a href=#__codelineno-0-1227>1227</a></span>
<span class=normal><a href=#__codelineno-0-1228>1228</a></span>
<span class=normal><a href=#__codelineno-0-1229>1229</a></span>
<span class=normal><a href=#__codelineno-0-1230>1230</a></span>
<span class=normal><a href=#__codelineno-0-1231>1231</a></span>
<span class=normal><a href=#__codelineno-0-1232>1232</a></span>
<span class=normal><a href=#__codelineno-0-1233>1233</a></span>
<span class=normal><a href=#__codelineno-0-1234>1234</a></span>
<span class=normal><a href=#__codelineno-0-1235>1235</a></span>
<span class=normal><a href=#__codelineno-0-1236>1236</a></span>
<span class=normal><a href=#__codelineno-0-1237>1237</a></span>
<span class=normal><a href=#__codelineno-0-1238>1238</a></span>
<span class=normal><a href=#__codelineno-0-1239>1239</a></span>
<span class=normal><a href=#__codelineno-0-1240>1240</a></span>
<span class=normal><a href=#__codelineno-0-1241>1241</a></span>
<span class=normal><a href=#__codelineno-0-1242>1242</a></span>
<span class=normal><a href=#__codelineno-0-1243>1243</a></span>
<span class=normal><a href=#__codelineno-0-1244>1244</a></span>
<span class=normal><a href=#__codelineno-0-1245>1245</a></span>
<span class=normal><a href=#__codelineno-0-1246>1246</a></span>
<span class=normal><a href=#__codelineno-0-1247>1247</a></span>
<span class=normal><a href=#__codelineno-0-1248>1248</a></span>
<span class=normal><a href=#__codelineno-0-1249>1249</a></span>
<span class=normal><a href=#__codelineno-0-1250>1250</a></span>
<span class=normal><a href=#__codelineno-0-1251>1251</a></span>
<span class=normal><a href=#__codelineno-0-1252>1252</a></span>
<span class=normal><a href=#__codelineno-0-1253>1253</a></span>
<span class=normal><a href=#__codelineno-0-1254>1254</a></span>
<span class=normal><a href=#__codelineno-0-1255>1255</a></span>
<span class=normal><a href=#__codelineno-0-1256>1256</a></span>
<span class=normal><a href=#__codelineno-0-1257>1257</a></span>
<span class=normal><a href=#__codelineno-0-1258>1258</a></span>
<span class=normal><a href=#__codelineno-0-1259>1259</a></span>
<span class=normal><a href=#__codelineno-0-1260>1260</a></span>
<span class=normal><a href=#__codelineno-0-1261>1261</a></span>
<span class=normal><a href=#__codelineno-0-1262>1262</a></span>
<span class=normal><a href=#__codelineno-0-1263>1263</a></span>
<span class=normal><a href=#__codelineno-0-1264>1264</a></span>
<span class=normal><a href=#__codelineno-0-1265>1265</a></span>
<span class=normal><a href=#__codelineno-0-1266>1266</a></span>
<span class=normal><a href=#__codelineno-0-1267>1267</a></span>
<span class=normal><a href=#__codelineno-0-1268>1268</a></span>
<span class=normal><a href=#__codelineno-0-1269>1269</a></span>
<span class=normal><a href=#__codelineno-0-1270>1270</a></span>
<span class=normal><a href=#__codelineno-0-1271>1271</a></span>
<span class=normal><a href=#__codelineno-0-1272>1272</a></span>
<span class=normal><a href=#__codelineno-0-1273>1273</a></span>
<span class=normal><a href=#__codelineno-0-1274>1274</a></span>
<span class=normal><a href=#__codelineno-0-1275>1275</a></span>
<span class=normal><a href=#__codelineno-0-1276>1276</a></span>
<span class=normal><a href=#__codelineno-0-1277>1277</a></span>
<span class=normal><a href=#__codelineno-0-1278>1278</a></span>
<span class=normal><a href=#__codelineno-0-1279>1279</a></span>
<span class=normal><a href=#__codelineno-0-1280>1280</a></span>
<span class=normal><a href=#__codelineno-0-1281>1281</a></span>
<span class=normal><a href=#__codelineno-0-1282>1282</a></span>
<span class=normal><a href=#__codelineno-0-1283>1283</a></span>
<span class=normal><a href=#__codelineno-0-1284>1284</a></span>
<span class=normal><a href=#__codelineno-0-1285>1285</a></span>
<span class=normal><a href=#__codelineno-0-1286>1286</a></span>
<span class=normal><a href=#__codelineno-0-1287>1287</a></span>
<span class=normal><a href=#__codelineno-0-1288>1288</a></span>
<span class=normal><a href=#__codelineno-0-1289>1289</a></span>
<span class=normal><a href=#__codelineno-0-1290>1290</a></span>
<span class=normal><a href=#__codelineno-0-1291>1291</a></span>
<span class=normal><a href=#__codelineno-0-1292>1292</a></span>
<span class=normal><a href=#__codelineno-0-1293>1293</a></span>
<span class=normal><a href=#__codelineno-0-1294>1294</a></span>
<span class=normal><a href=#__codelineno-0-1295>1295</a></span>
<span class=normal><a href=#__codelineno-0-1296>1296</a></span>
<span class=normal><a href=#__codelineno-0-1297>1297</a></span>
<span class=normal><a href=#__codelineno-0-1298>1298</a></span>
<span class=normal><a href=#__codelineno-0-1299>1299</a></span>
<span class=normal><a href=#__codelineno-0-1300>1300</a></span>
<span class=normal><a href=#__codelineno-0-1301>1301</a></span>
<span class=normal><a href=#__codelineno-0-1302>1302</a></span>
<span class=normal><a href=#__codelineno-0-1303>1303</a></span>
<span class=normal><a href=#__codelineno-0-1304>1304</a></span>
<span class=normal><a href=#__codelineno-0-1305>1305</a></span>
<span class=normal><a href=#__codelineno-0-1306>1306</a></span>
<span class=normal><a href=#__codelineno-0-1307>1307</a></span>
<span class=normal><a href=#__codelineno-0-1308>1308</a></span>
<span class=normal><a href=#__codelineno-0-1309>1309</a></span>
<span class=normal><a href=#__codelineno-0-1310>1310</a></span>
<span class=normal><a href=#__codelineno-0-1311>1311</a></span>
<span class=normal><a href=#__codelineno-0-1312>1312</a></span>
<span class=normal><a href=#__codelineno-0-1313>1313</a></span>
<span class=normal><a href=#__codelineno-0-1314>1314</a></span>
<span class=normal><a href=#__codelineno-0-1315>1315</a></span>
<span class=normal><a href=#__codelineno-0-1316>1316</a></span>
<span class=normal><a href=#__codelineno-0-1317>1317</a></span>
<span class=normal><a href=#__codelineno-0-1318>1318</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-1211 name=__codelineno-0-1211></a><span class=k>class</span><span class=w> </span><span class=nc>LeastMeanSquaresNormalizedSignSign</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>):</span>
<a id=__codelineno-0-1212 name=__codelineno-0-1212></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Normalized Least Mean Squares SignSign (NLMSSS) filter for parameter estimation.</span>
<a id=__codelineno-0-1213 name=__codelineno-0-1213></a>
<a id=__codelineno-0-1214 name=__codelineno-0-1214></a><span class=sd>    The NLMSSS algorithm updates the parameter estimates recursively by normalizing</span>
<a id=__codelineno-0-1215 name=__codelineno-0-1215></a><span class=sd>    the input signal to avoid numerical instability and using both the sign of the</span>
<a id=__codelineno-0-1216 name=__codelineno-0-1216></a><span class=sd>    information matrix and the sign of the error vector to adjust the filter</span>
<a id=__codelineno-0-1217 name=__codelineno-0-1217></a><span class=sd>    coefficients.</span>
<a id=__codelineno-0-1218 name=__codelineno-0-1218></a>
<a id=__codelineno-0-1219 name=__codelineno-0-1219></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-1220 name=__codelineno-0-1220></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1221 name=__codelineno-0-1221></a><span class=sd>    mu : float, default=0.01</span>
<a id=__codelineno-0-1222 name=__codelineno-0-1222></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-1223 name=__codelineno-0-1223></a><span class=sd>    eps : float, default=np.finfo(np.float64).eps</span>
<a id=__codelineno-0-1224 name=__codelineno-0-1224></a><span class=sd>        Normalization factor of the normalized filters.</span>
<a id=__codelineno-0-1225 name=__codelineno-0-1225></a>
<a id=__codelineno-0-1226 name=__codelineno-0-1226></a><span class=sd>    Attributes</span>
<a id=__codelineno-0-1227 name=__codelineno-0-1227></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1228 name=__codelineno-0-1228></a><span class=sd>    mu : float</span>
<a id=__codelineno-0-1229 name=__codelineno-0-1229></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-1230 name=__codelineno-0-1230></a><span class=sd>    eps : float</span>
<a id=__codelineno-0-1231 name=__codelineno-0-1231></a><span class=sd>        Normalization factor of the normalized filters.</span>
<a id=__codelineno-0-1232 name=__codelineno-0-1232></a><span class=sd>    xi : np.ndarray or None</span>
<a id=__codelineno-0-1233 name=__codelineno-0-1233></a><span class=sd>        The estimation error at each iteration. Initialized as None and updated during</span>
<a id=__codelineno-0-1234 name=__codelineno-0-1234></a><span class=sd>        optimization.</span>
<a id=__codelineno-0-1235 name=__codelineno-0-1235></a>
<a id=__codelineno-0-1236 name=__codelineno-0-1236></a><span class=sd>    Methods</span>
<a id=__codelineno-0-1237 name=__codelineno-0-1237></a><span class=sd>    -------</span>
<a id=__codelineno-0-1238 name=__codelineno-0-1238></a><span class=sd>    optimize(psi: np.ndarray, y: np.ndarray) -&gt; np.ndarray</span>
<a id=__codelineno-0-1239 name=__codelineno-0-1239></a><span class=sd>        Estimate the model parameters using the NLMSSS filter.</span>
<a id=__codelineno-0-1240 name=__codelineno-0-1240></a>
<a id=__codelineno-0-1241 name=__codelineno-0-1241></a><span class=sd>    References</span>
<a id=__codelineno-0-1242 name=__codelineno-0-1242></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1243 name=__codelineno-0-1243></a><span class=sd>    - Hayes, M. H. (2009). Statistical digital signal processing and modeling.</span>
<a id=__codelineno-0-1244 name=__codelineno-0-1244></a><span class=sd>      John Wiley &amp; Sons.</span>
<a id=__codelineno-0-1245 name=__codelineno-0-1245></a><span class=sd>    - Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de</span>
<a id=__codelineno-0-1246 name=__codelineno-0-1246></a><span class=sd>      algoritmos LMS de passo variável.</span>
<a id=__codelineno-0-1247 name=__codelineno-0-1247></a><span class=sd>    - Wikipedia entry on Least Mean Squares: https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>
<a id=__codelineno-0-1248 name=__codelineno-0-1248></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-1249 name=__codelineno-0-1249></a>
<a id=__codelineno-0-1250 name=__codelineno-0-1250></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span>
<a id=__codelineno-0-1251 name=__codelineno-0-1251></a>        <span class=bp>self</span><span class=p>,</span>
<a id=__codelineno-0-1252 name=__codelineno-0-1252></a>        <span class=o>*</span><span class=p>,</span>
<a id=__codelineno-0-1253 name=__codelineno-0-1253></a>        <span class=n>mu</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.01</span><span class=p>,</span>
<a id=__codelineno-0-1254 name=__codelineno-0-1254></a>        <span class=n>eps</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>float64</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>finfo</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float64</span><span class=p>)</span><span class=o>.</span><span class=n>eps</span><span class=p>,</span>
<a id=__codelineno-0-1255 name=__codelineno-0-1255></a>        <span class=n>unbiased</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>
<a id=__codelineno-0-1256 name=__codelineno-0-1256></a>        <span class=n>uiter</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>30</span><span class=p>,</span>
<a id=__codelineno-0-1257 name=__codelineno-0-1257></a>    <span class=p>):</span>
<a id=__codelineno-0-1258 name=__codelineno-0-1258></a>        <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>=</span> <span class=n>mu</span>
<a id=__codelineno-0-1259 name=__codelineno-0-1259></a>        <span class=bp>self</span><span class=o>.</span><span class=n>eps</span> <span class=o>=</span> <span class=n>eps</span>
<a id=__codelineno-0-1260 name=__codelineno-0-1260></a>        <span class=bp>self</span><span class=o>.</span><span class=n>unbiased</span> <span class=o>=</span> <span class=n>unbiased</span>
<a id=__codelineno-0-1261 name=__codelineno-0-1261></a>        <span class=bp>self</span><span class=o>.</span><span class=n>uiter</span> <span class=o>=</span> <span class=n>uiter</span>
<a id=__codelineno-0-1262 name=__codelineno-0-1262></a>        <span class=n>_validate_params</span><span class=p>(</span><span class=nb>vars</span><span class=p>(</span><span class=bp>self</span><span class=p>))</span>
<a id=__codelineno-0-1263 name=__codelineno-0-1263></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
<a id=__codelineno-0-1264 name=__codelineno-0-1264></a>
<a id=__codelineno-0-1265 name=__codelineno-0-1265></a>    <span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-1266 name=__codelineno-0-1266></a><span class=w>        </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Normalized Sign-Sign LMS filter.</span>
<a id=__codelineno-0-1267 name=__codelineno-0-1267></a>
<a id=__codelineno-0-1268 name=__codelineno-0-1268></a><span class=sd>        The NLMSSS algorithm updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-1269 name=__codelineno-0-1269></a>
<a id=__codelineno-0-1270 name=__codelineno-0-1270></a><span class=sd>        1. Compute the estimation error:</span>
<a id=__codelineno-0-1271 name=__codelineno-0-1271></a>
<a id=__codelineno-0-1272 name=__codelineno-0-1272></a><span class=sd>           $$</span>
<a id=__codelineno-0-1273 name=__codelineno-0-1273></a><span class=sd>           \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-1274 name=__codelineno-0-1274></a><span class=sd>           $$</span>
<a id=__codelineno-0-1275 name=__codelineno-0-1275></a>
<a id=__codelineno-0-1276 name=__codelineno-0-1276></a><span class=sd>        2. Update the parameter vector:</span>
<a id=__codelineno-0-1277 name=__codelineno-0-1277></a>
<a id=__codelineno-0-1278 name=__codelineno-0-1278></a><span class=sd>           $$</span>
<a id=__codelineno-0-1279 name=__codelineno-0-1279></a><span class=sd>           \theta_i = \theta_{i-1} + 2 \mu \cdot \text{sign}(\xi_i) \cdot</span>
<a id=__codelineno-0-1280 name=__codelineno-0-1280></a><span class=sd>           \frac{\text{sign}(\psi_i)}{\epsilon + \psi_i^T \psi_i}</span>
<a id=__codelineno-0-1281 name=__codelineno-0-1281></a><span class=sd>           $$</span>
<a id=__codelineno-0-1282 name=__codelineno-0-1282></a>
<a id=__codelineno-0-1283 name=__codelineno-0-1283></a><span class=sd>        The normalization is used to avoid numerical instability when updating</span>
<a id=__codelineno-0-1284 name=__codelineno-0-1284></a><span class=sd>        the estimated parameters and both the sign of the information matrix</span>
<a id=__codelineno-0-1285 name=__codelineno-0-1285></a><span class=sd>        and the sign of the error vector are used to change the filter</span>
<a id=__codelineno-0-1286 name=__codelineno-0-1286></a><span class=sd>        coefficients.</span>
<a id=__codelineno-0-1287 name=__codelineno-0-1287></a>
<a id=__codelineno-0-1288 name=__codelineno-0-1288></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-1289 name=__codelineno-0-1289></a><span class=sd>        ----------</span>
<a id=__codelineno-0-1290 name=__codelineno-0-1290></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-1291 name=__codelineno-0-1291></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-1292 name=__codelineno-0-1292></a><span class=sd>        y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-1293 name=__codelineno-0-1293></a><span class=sd>            The data used to train the model.</span>
<a id=__codelineno-0-1294 name=__codelineno-0-1294></a>
<a id=__codelineno-0-1295 name=__codelineno-0-1295></a><span class=sd>        Returns</span>
<a id=__codelineno-0-1296 name=__codelineno-0-1296></a><span class=sd>        -------</span>
<a id=__codelineno-0-1297 name=__codelineno-0-1297></a><span class=sd>        theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-1298 name=__codelineno-0-1298></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-1299 name=__codelineno-0-1299></a>
<a id=__codelineno-0-1300 name=__codelineno-0-1300></a><span class=sd>        References</span>
<a id=__codelineno-0-1301 name=__codelineno-0-1301></a><span class=sd>        ----------</span>
<a id=__codelineno-0-1302 name=__codelineno-0-1302></a><span class=sd>        - Hayes, M. H. (2009). Statistical digital signal processing and modeling.</span>
<a id=__codelineno-0-1303 name=__codelineno-0-1303></a><span class=sd>          John Wiley &amp; Sons.</span>
<a id=__codelineno-0-1304 name=__codelineno-0-1304></a><span class=sd>        - Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias</span>
<a id=__codelineno-0-1305 name=__codelineno-0-1305></a><span class=sd>        de algoritmos LMS de passo variável.</span>
<a id=__codelineno-0-1306 name=__codelineno-0-1306></a><span class=sd>        - Wikipedia entry on Least Mean Squares: https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>
<a id=__codelineno-0-1307 name=__codelineno-0-1307></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-1308 name=__codelineno-0-1308></a>        <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-1309 name=__codelineno-0-1309></a>
<a id=__codelineno-0-1310 name=__codelineno-0-1310></a>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-1311 name=__codelineno-0-1311></a>            <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-1312 name=__codelineno-0-1312></a>            <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-1313 name=__codelineno-0-1313></a>            <span class=n>tmp_list</span> <span class=o>=</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=mi>2</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>sign</span><span class=p>(</span>
<a id=__codelineno-0-1314 name=__codelineno-0-1314></a>                <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-1315 name=__codelineno-0-1315></a>            <span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>sign</span><span class=p>(</span><span class=n>psi_tmp</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>eps</span> <span class=o>+</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>psi_tmp</span><span class=p>)))</span>
<a id=__codelineno-0-1316 name=__codelineno-0-1316></a>            <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-1317 name=__codelineno-0-1317></a>
<a id=__codelineno-0-1318 name=__codelineno-0-1318></a>        <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignSign.optimize class="doc doc-heading"> <code class="highlight language-python"><span class=n>optimize</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresNormalizedSignSign.optimize class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Parameter estimation using the Normalized Sign-Sign LMS filter.</p> <p>The NLMSSS algorithm updates the parameter estimates recursively as follows:</p> <ol> <li>Compute the estimation error:</li> </ol> <p>$$ \xi_i = y_i - \psi_i^T \theta_{i-1} $$</p> <ol> <li>Update the parameter vector:</li> </ol> <p>$$ \theta_i = \theta_{i-1} + 2 \mu \cdot \text{sign}(\xi_i) \cdot \frac{\text{sign}(\psi_i)}{\epsilon + \psi_i^T \psi_i} $$</p> <p>The normalization is used to avoid numerical instability when updating the estimated parameters and both the sign of the information matrix and the sign of the error vector are used to change the filter coefficients.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>array-like of shape (n_samples, 1)</code> </td> <td> <div class=doc-md-description> <p>The data used to train the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>array-like of shape (n_features, 1)</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Hayes, M. H. (2009). Statistical digital signal processing and modeling. John Wiley &amp; Sons.</li> <li>Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de algoritmos LMS de passo variável.</li> <li>Wikipedia entry on Least Mean Squares: <a href=https://en.wikipedia.org/wiki/Least_mean_squares_filter>https://en.wikipedia.org/wiki/Least_mean_squares_filter</a></li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-1265>1265</a></span>
<span class=normal><a href=#__codelineno-0-1266>1266</a></span>
<span class=normal><a href=#__codelineno-0-1267>1267</a></span>
<span class=normal><a href=#__codelineno-0-1268>1268</a></span>
<span class=normal><a href=#__codelineno-0-1269>1269</a></span>
<span class=normal><a href=#__codelineno-0-1270>1270</a></span>
<span class=normal><a href=#__codelineno-0-1271>1271</a></span>
<span class=normal><a href=#__codelineno-0-1272>1272</a></span>
<span class=normal><a href=#__codelineno-0-1273>1273</a></span>
<span class=normal><a href=#__codelineno-0-1274>1274</a></span>
<span class=normal><a href=#__codelineno-0-1275>1275</a></span>
<span class=normal><a href=#__codelineno-0-1276>1276</a></span>
<span class=normal><a href=#__codelineno-0-1277>1277</a></span>
<span class=normal><a href=#__codelineno-0-1278>1278</a></span>
<span class=normal><a href=#__codelineno-0-1279>1279</a></span>
<span class=normal><a href=#__codelineno-0-1280>1280</a></span>
<span class=normal><a href=#__codelineno-0-1281>1281</a></span>
<span class=normal><a href=#__codelineno-0-1282>1282</a></span>
<span class=normal><a href=#__codelineno-0-1283>1283</a></span>
<span class=normal><a href=#__codelineno-0-1284>1284</a></span>
<span class=normal><a href=#__codelineno-0-1285>1285</a></span>
<span class=normal><a href=#__codelineno-0-1286>1286</a></span>
<span class=normal><a href=#__codelineno-0-1287>1287</a></span>
<span class=normal><a href=#__codelineno-0-1288>1288</a></span>
<span class=normal><a href=#__codelineno-0-1289>1289</a></span>
<span class=normal><a href=#__codelineno-0-1290>1290</a></span>
<span class=normal><a href=#__codelineno-0-1291>1291</a></span>
<span class=normal><a href=#__codelineno-0-1292>1292</a></span>
<span class=normal><a href=#__codelineno-0-1293>1293</a></span>
<span class=normal><a href=#__codelineno-0-1294>1294</a></span>
<span class=normal><a href=#__codelineno-0-1295>1295</a></span>
<span class=normal><a href=#__codelineno-0-1296>1296</a></span>
<span class=normal><a href=#__codelineno-0-1297>1297</a></span>
<span class=normal><a href=#__codelineno-0-1298>1298</a></span>
<span class=normal><a href=#__codelineno-0-1299>1299</a></span>
<span class=normal><a href=#__codelineno-0-1300>1300</a></span>
<span class=normal><a href=#__codelineno-0-1301>1301</a></span>
<span class=normal><a href=#__codelineno-0-1302>1302</a></span>
<span class=normal><a href=#__codelineno-0-1303>1303</a></span>
<span class=normal><a href=#__codelineno-0-1304>1304</a></span>
<span class=normal><a href=#__codelineno-0-1305>1305</a></span>
<span class=normal><a href=#__codelineno-0-1306>1306</a></span>
<span class=normal><a href=#__codelineno-0-1307>1307</a></span>
<span class=normal><a href=#__codelineno-0-1308>1308</a></span>
<span class=normal><a href=#__codelineno-0-1309>1309</a></span>
<span class=normal><a href=#__codelineno-0-1310>1310</a></span>
<span class=normal><a href=#__codelineno-0-1311>1311</a></span>
<span class=normal><a href=#__codelineno-0-1312>1312</a></span>
<span class=normal><a href=#__codelineno-0-1313>1313</a></span>
<span class=normal><a href=#__codelineno-0-1314>1314</a></span>
<span class=normal><a href=#__codelineno-0-1315>1315</a></span>
<span class=normal><a href=#__codelineno-0-1316>1316</a></span>
<span class=normal><a href=#__codelineno-0-1317>1317</a></span>
<span class=normal><a href=#__codelineno-0-1318>1318</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-1265 name=__codelineno-0-1265></a><span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-1266 name=__codelineno-0-1266></a><span class=w>    </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Normalized Sign-Sign LMS filter.</span>
<a id=__codelineno-0-1267 name=__codelineno-0-1267></a>
<a id=__codelineno-0-1268 name=__codelineno-0-1268></a><span class=sd>    The NLMSSS algorithm updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-1269 name=__codelineno-0-1269></a>
<a id=__codelineno-0-1270 name=__codelineno-0-1270></a><span class=sd>    1. Compute the estimation error:</span>
<a id=__codelineno-0-1271 name=__codelineno-0-1271></a>
<a id=__codelineno-0-1272 name=__codelineno-0-1272></a><span class=sd>       $$</span>
<a id=__codelineno-0-1273 name=__codelineno-0-1273></a><span class=sd>       \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-1274 name=__codelineno-0-1274></a><span class=sd>       $$</span>
<a id=__codelineno-0-1275 name=__codelineno-0-1275></a>
<a id=__codelineno-0-1276 name=__codelineno-0-1276></a><span class=sd>    2. Update the parameter vector:</span>
<a id=__codelineno-0-1277 name=__codelineno-0-1277></a>
<a id=__codelineno-0-1278 name=__codelineno-0-1278></a><span class=sd>       $$</span>
<a id=__codelineno-0-1279 name=__codelineno-0-1279></a><span class=sd>       \theta_i = \theta_{i-1} + 2 \mu \cdot \text{sign}(\xi_i) \cdot</span>
<a id=__codelineno-0-1280 name=__codelineno-0-1280></a><span class=sd>       \frac{\text{sign}(\psi_i)}{\epsilon + \psi_i^T \psi_i}</span>
<a id=__codelineno-0-1281 name=__codelineno-0-1281></a><span class=sd>       $$</span>
<a id=__codelineno-0-1282 name=__codelineno-0-1282></a>
<a id=__codelineno-0-1283 name=__codelineno-0-1283></a><span class=sd>    The normalization is used to avoid numerical instability when updating</span>
<a id=__codelineno-0-1284 name=__codelineno-0-1284></a><span class=sd>    the estimated parameters and both the sign of the information matrix</span>
<a id=__codelineno-0-1285 name=__codelineno-0-1285></a><span class=sd>    and the sign of the error vector are used to change the filter</span>
<a id=__codelineno-0-1286 name=__codelineno-0-1286></a><span class=sd>    coefficients.</span>
<a id=__codelineno-0-1287 name=__codelineno-0-1287></a>
<a id=__codelineno-0-1288 name=__codelineno-0-1288></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-1289 name=__codelineno-0-1289></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1290 name=__codelineno-0-1290></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-1291 name=__codelineno-0-1291></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-1292 name=__codelineno-0-1292></a><span class=sd>    y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-1293 name=__codelineno-0-1293></a><span class=sd>        The data used to train the model.</span>
<a id=__codelineno-0-1294 name=__codelineno-0-1294></a>
<a id=__codelineno-0-1295 name=__codelineno-0-1295></a><span class=sd>    Returns</span>
<a id=__codelineno-0-1296 name=__codelineno-0-1296></a><span class=sd>    -------</span>
<a id=__codelineno-0-1297 name=__codelineno-0-1297></a><span class=sd>    theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-1298 name=__codelineno-0-1298></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-1299 name=__codelineno-0-1299></a>
<a id=__codelineno-0-1300 name=__codelineno-0-1300></a><span class=sd>    References</span>
<a id=__codelineno-0-1301 name=__codelineno-0-1301></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1302 name=__codelineno-0-1302></a><span class=sd>    - Hayes, M. H. (2009). Statistical digital signal processing and modeling.</span>
<a id=__codelineno-0-1303 name=__codelineno-0-1303></a><span class=sd>      John Wiley &amp; Sons.</span>
<a id=__codelineno-0-1304 name=__codelineno-0-1304></a><span class=sd>    - Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias</span>
<a id=__codelineno-0-1305 name=__codelineno-0-1305></a><span class=sd>    de algoritmos LMS de passo variável.</span>
<a id=__codelineno-0-1306 name=__codelineno-0-1306></a><span class=sd>    - Wikipedia entry on Least Mean Squares: https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>
<a id=__codelineno-0-1307 name=__codelineno-0-1307></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-1308 name=__codelineno-0-1308></a>    <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-1309 name=__codelineno-0-1309></a>
<a id=__codelineno-0-1310 name=__codelineno-0-1310></a>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-1311 name=__codelineno-0-1311></a>        <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-1312 name=__codelineno-0-1312></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-1313 name=__codelineno-0-1313></a>        <span class=n>tmp_list</span> <span class=o>=</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=mi>2</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>sign</span><span class=p>(</span>
<a id=__codelineno-0-1314 name=__codelineno-0-1314></a>            <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-1315 name=__codelineno-0-1315></a>        <span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>sign</span><span class=p>(</span><span class=n>psi_tmp</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>eps</span> <span class=o>+</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>psi_tmp</span><span class=p>)))</span>
<a id=__codelineno-0-1316 name=__codelineno-0-1316></a>        <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-1317 name=__codelineno-0-1317></a>
<a id=__codelineno-0-1318 name=__codelineno-0-1318></a>    <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignError class="doc doc-heading"> <code>LeastMeanSquaresSignError</code> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignError class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=sysidentpy.parameter_estimation.estimators_base.BaseEstimator>BaseEstimator</span></code></p> <p>Least Mean Squares (LMS) filter for parameter estimation using sign-error.</p> <p>The sign-error LMS algorithm uses the sign of the error vector to update the filter coefficients.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>mu</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> <td> <code>0.01</code> </td> </tr> <tr class=doc-section-item> <td> <code>unbiased</code> </td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>If True, applies an unbiased estimator. Default is False.</p> </div> </td> <td> <code>False</code> </td> </tr> <tr class=doc-section-item> <td> <code>uiter</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of iterations for the unbiased estimator. Default is 30.</p> </div> </td> <td> <code>30</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Attributes:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignError.mu>mu</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignError.xi>xi</span></code></td> <td> <code><span title=numpy.ndarray>ndarray</span> or None</code> </td> <td> <div class=doc-md-description> <p>The estimation error at each iteration. Initialized as None and updated during optimization.</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Methods:</span></p> <table> <thead> <tr> <th>Name</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><a class="autorefs autorefs-internal" title="<code>sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignError.optimize</code>" href=../../../../user-guide/API/parameter-estimation/#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignError.optimize>optimize</a></code></td> <td> <div class=doc-md-description> <p>Estimate the model parameters using the LMS filter.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Hayes, M. H. (2009). Statistical digital signal processing and modeling. John Wiley &amp; Sons.</li> <li>Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de algoritmos LMS de passo variável.</li> <li>Wikipedia entry on Least Mean Squares: <a href=https://en.wikipedia.org/wiki/Least_mean_squares_filter>https://en.wikipedia.org/wiki/Least_mean_squares_filter</a></li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-642>642</a></span>
<span class=normal><a href=#__codelineno-0-643>643</a></span>
<span class=normal><a href=#__codelineno-0-644>644</a></span>
<span class=normal><a href=#__codelineno-0-645>645</a></span>
<span class=normal><a href=#__codelineno-0-646>646</a></span>
<span class=normal><a href=#__codelineno-0-647>647</a></span>
<span class=normal><a href=#__codelineno-0-648>648</a></span>
<span class=normal><a href=#__codelineno-0-649>649</a></span>
<span class=normal><a href=#__codelineno-0-650>650</a></span>
<span class=normal><a href=#__codelineno-0-651>651</a></span>
<span class=normal><a href=#__codelineno-0-652>652</a></span>
<span class=normal><a href=#__codelineno-0-653>653</a></span>
<span class=normal><a href=#__codelineno-0-654>654</a></span>
<span class=normal><a href=#__codelineno-0-655>655</a></span>
<span class=normal><a href=#__codelineno-0-656>656</a></span>
<span class=normal><a href=#__codelineno-0-657>657</a></span>
<span class=normal><a href=#__codelineno-0-658>658</a></span>
<span class=normal><a href=#__codelineno-0-659>659</a></span>
<span class=normal><a href=#__codelineno-0-660>660</a></span>
<span class=normal><a href=#__codelineno-0-661>661</a></span>
<span class=normal><a href=#__codelineno-0-662>662</a></span>
<span class=normal><a href=#__codelineno-0-663>663</a></span>
<span class=normal><a href=#__codelineno-0-664>664</a></span>
<span class=normal><a href=#__codelineno-0-665>665</a></span>
<span class=normal><a href=#__codelineno-0-666>666</a></span>
<span class=normal><a href=#__codelineno-0-667>667</a></span>
<span class=normal><a href=#__codelineno-0-668>668</a></span>
<span class=normal><a href=#__codelineno-0-669>669</a></span>
<span class=normal><a href=#__codelineno-0-670>670</a></span>
<span class=normal><a href=#__codelineno-0-671>671</a></span>
<span class=normal><a href=#__codelineno-0-672>672</a></span>
<span class=normal><a href=#__codelineno-0-673>673</a></span>
<span class=normal><a href=#__codelineno-0-674>674</a></span>
<span class=normal><a href=#__codelineno-0-675>675</a></span>
<span class=normal><a href=#__codelineno-0-676>676</a></span>
<span class=normal><a href=#__codelineno-0-677>677</a></span>
<span class=normal><a href=#__codelineno-0-678>678</a></span>
<span class=normal><a href=#__codelineno-0-679>679</a></span>
<span class=normal><a href=#__codelineno-0-680>680</a></span>
<span class=normal><a href=#__codelineno-0-681>681</a></span>
<span class=normal><a href=#__codelineno-0-682>682</a></span>
<span class=normal><a href=#__codelineno-0-683>683</a></span>
<span class=normal><a href=#__codelineno-0-684>684</a></span>
<span class=normal><a href=#__codelineno-0-685>685</a></span>
<span class=normal><a href=#__codelineno-0-686>686</a></span>
<span class=normal><a href=#__codelineno-0-687>687</a></span>
<span class=normal><a href=#__codelineno-0-688>688</a></span>
<span class=normal><a href=#__codelineno-0-689>689</a></span>
<span class=normal><a href=#__codelineno-0-690>690</a></span>
<span class=normal><a href=#__codelineno-0-691>691</a></span>
<span class=normal><a href=#__codelineno-0-692>692</a></span>
<span class=normal><a href=#__codelineno-0-693>693</a></span>
<span class=normal><a href=#__codelineno-0-694>694</a></span>
<span class=normal><a href=#__codelineno-0-695>695</a></span>
<span class=normal><a href=#__codelineno-0-696>696</a></span>
<span class=normal><a href=#__codelineno-0-697>697</a></span>
<span class=normal><a href=#__codelineno-0-698>698</a></span>
<span class=normal><a href=#__codelineno-0-699>699</a></span>
<span class=normal><a href=#__codelineno-0-700>700</a></span>
<span class=normal><a href=#__codelineno-0-701>701</a></span>
<span class=normal><a href=#__codelineno-0-702>702</a></span>
<span class=normal><a href=#__codelineno-0-703>703</a></span>
<span class=normal><a href=#__codelineno-0-704>704</a></span>
<span class=normal><a href=#__codelineno-0-705>705</a></span>
<span class=normal><a href=#__codelineno-0-706>706</a></span>
<span class=normal><a href=#__codelineno-0-707>707</a></span>
<span class=normal><a href=#__codelineno-0-708>708</a></span>
<span class=normal><a href=#__codelineno-0-709>709</a></span>
<span class=normal><a href=#__codelineno-0-710>710</a></span>
<span class=normal><a href=#__codelineno-0-711>711</a></span>
<span class=normal><a href=#__codelineno-0-712>712</a></span>
<span class=normal><a href=#__codelineno-0-713>713</a></span>
<span class=normal><a href=#__codelineno-0-714>714</a></span>
<span class=normal><a href=#__codelineno-0-715>715</a></span>
<span class=normal><a href=#__codelineno-0-716>716</a></span>
<span class=normal><a href=#__codelineno-0-717>717</a></span>
<span class=normal><a href=#__codelineno-0-718>718</a></span>
<span class=normal><a href=#__codelineno-0-719>719</a></span>
<span class=normal><a href=#__codelineno-0-720>720</a></span>
<span class=normal><a href=#__codelineno-0-721>721</a></span>
<span class=normal><a href=#__codelineno-0-722>722</a></span>
<span class=normal><a href=#__codelineno-0-723>723</a></span>
<span class=normal><a href=#__codelineno-0-724>724</a></span>
<span class=normal><a href=#__codelineno-0-725>725</a></span>
<span class=normal><a href=#__codelineno-0-726>726</a></span>
<span class=normal><a href=#__codelineno-0-727>727</a></span>
<span class=normal><a href=#__codelineno-0-728>728</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-642 name=__codelineno-0-642></a><span class=k>class</span><span class=w> </span><span class=nc>LeastMeanSquaresSignError</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>):</span>
<a id=__codelineno-0-643 name=__codelineno-0-643></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Least Mean Squares (LMS) filter for parameter estimation using sign-error.</span>
<a id=__codelineno-0-644 name=__codelineno-0-644></a>
<a id=__codelineno-0-645 name=__codelineno-0-645></a><span class=sd>    The sign-error LMS algorithm uses the sign of the error vector to update the filter</span>
<a id=__codelineno-0-646 name=__codelineno-0-646></a><span class=sd>    coefficients.</span>
<a id=__codelineno-0-647 name=__codelineno-0-647></a>
<a id=__codelineno-0-648 name=__codelineno-0-648></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-649 name=__codelineno-0-649></a><span class=sd>    ----------</span>
<a id=__codelineno-0-650 name=__codelineno-0-650></a><span class=sd>    mu : float, default=0.01</span>
<a id=__codelineno-0-651 name=__codelineno-0-651></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-652 name=__codelineno-0-652></a><span class=sd>    unbiased : bool, optional</span>
<a id=__codelineno-0-653 name=__codelineno-0-653></a><span class=sd>        If True, applies an unbiased estimator. Default is False.</span>
<a id=__codelineno-0-654 name=__codelineno-0-654></a><span class=sd>    uiter : int, optional</span>
<a id=__codelineno-0-655 name=__codelineno-0-655></a><span class=sd>        Number of iterations for the unbiased estimator. Default is 30.</span>
<a id=__codelineno-0-656 name=__codelineno-0-656></a>
<a id=__codelineno-0-657 name=__codelineno-0-657></a><span class=sd>    Attributes</span>
<a id=__codelineno-0-658 name=__codelineno-0-658></a><span class=sd>    ----------</span>
<a id=__codelineno-0-659 name=__codelineno-0-659></a><span class=sd>    mu : float</span>
<a id=__codelineno-0-660 name=__codelineno-0-660></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-661 name=__codelineno-0-661></a><span class=sd>    xi : np.ndarray or None</span>
<a id=__codelineno-0-662 name=__codelineno-0-662></a><span class=sd>        The estimation error at each iteration. Initialized as None and updated during</span>
<a id=__codelineno-0-663 name=__codelineno-0-663></a><span class=sd>        optimization.</span>
<a id=__codelineno-0-664 name=__codelineno-0-664></a>
<a id=__codelineno-0-665 name=__codelineno-0-665></a><span class=sd>    Methods</span>
<a id=__codelineno-0-666 name=__codelineno-0-666></a><span class=sd>    -------</span>
<a id=__codelineno-0-667 name=__codelineno-0-667></a><span class=sd>    optimize(psi: np.ndarray, y: np.ndarray) -&gt; np.ndarray</span>
<a id=__codelineno-0-668 name=__codelineno-0-668></a><span class=sd>        Estimate the model parameters using the LMS filter.</span>
<a id=__codelineno-0-669 name=__codelineno-0-669></a>
<a id=__codelineno-0-670 name=__codelineno-0-670></a><span class=sd>    References</span>
<a id=__codelineno-0-671 name=__codelineno-0-671></a><span class=sd>    ----------</span>
<a id=__codelineno-0-672 name=__codelineno-0-672></a><span class=sd>    - Hayes, M. H. (2009). Statistical digital signal processing and modeling.</span>
<a id=__codelineno-0-673 name=__codelineno-0-673></a><span class=sd>    John Wiley &amp; Sons.</span>
<a id=__codelineno-0-674 name=__codelineno-0-674></a><span class=sd>    - Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de</span>
<a id=__codelineno-0-675 name=__codelineno-0-675></a><span class=sd>    algoritmos LMS de passo variável.</span>
<a id=__codelineno-0-676 name=__codelineno-0-676></a><span class=sd>    - Wikipedia entry on Least Mean Squares: https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>
<a id=__codelineno-0-677 name=__codelineno-0-677></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-678 name=__codelineno-0-678></a>
<a id=__codelineno-0-679 name=__codelineno-0-679></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=o>*</span><span class=p>,</span> <span class=n>mu</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.01</span><span class=p>,</span> <span class=n>unbiased</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span> <span class=n>uiter</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>30</span><span class=p>):</span>
<a id=__codelineno-0-680 name=__codelineno-0-680></a>        <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>=</span> <span class=n>mu</span>
<a id=__codelineno-0-681 name=__codelineno-0-681></a>        <span class=bp>self</span><span class=o>.</span><span class=n>uiter</span> <span class=o>=</span> <span class=n>uiter</span>
<a id=__codelineno-0-682 name=__codelineno-0-682></a>        <span class=bp>self</span><span class=o>.</span><span class=n>unbiased</span> <span class=o>=</span> <span class=n>unbiased</span>
<a id=__codelineno-0-683 name=__codelineno-0-683></a>        <span class=n>_validate_params</span><span class=p>(</span><span class=nb>vars</span><span class=p>(</span><span class=bp>self</span><span class=p>))</span>
<a id=__codelineno-0-684 name=__codelineno-0-684></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
<a id=__codelineno-0-685 name=__codelineno-0-685></a>
<a id=__codelineno-0-686 name=__codelineno-0-686></a>    <span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-687 name=__codelineno-0-687></a><span class=w>        </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Sign-Error Least Mean Squares filter.</span>
<a id=__codelineno-0-688 name=__codelineno-0-688></a>
<a id=__codelineno-0-689 name=__codelineno-0-689></a><span class=sd>        The sign-error LMS algorithm updates the parameter estimates recursively as</span>
<a id=__codelineno-0-690 name=__codelineno-0-690></a><span class=sd>        follows:</span>
<a id=__codelineno-0-691 name=__codelineno-0-691></a>
<a id=__codelineno-0-692 name=__codelineno-0-692></a><span class=sd>        1. Compute the estimation error:</span>
<a id=__codelineno-0-693 name=__codelineno-0-693></a>
<a id=__codelineno-0-694 name=__codelineno-0-694></a><span class=sd>           $$</span>
<a id=__codelineno-0-695 name=__codelineno-0-695></a><span class=sd>           \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-696 name=__codelineno-0-696></a><span class=sd>           $$</span>
<a id=__codelineno-0-697 name=__codelineno-0-697></a>
<a id=__codelineno-0-698 name=__codelineno-0-698></a><span class=sd>        2. Update the parameter vector:</span>
<a id=__codelineno-0-699 name=__codelineno-0-699></a>
<a id=__codelineno-0-700 name=__codelineno-0-700></a><span class=sd>           $$</span>
<a id=__codelineno-0-701 name=__codelineno-0-701></a><span class=sd>           \theta_i = \theta_{i-1} + \mu \cdot \text{sign}(\xi_i) \cdot \psi_i</span>
<a id=__codelineno-0-702 name=__codelineno-0-702></a><span class=sd>           $$</span>
<a id=__codelineno-0-703 name=__codelineno-0-703></a>
<a id=__codelineno-0-704 name=__codelineno-0-704></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-705 name=__codelineno-0-705></a><span class=sd>        ----------</span>
<a id=__codelineno-0-706 name=__codelineno-0-706></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-707 name=__codelineno-0-707></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-708 name=__codelineno-0-708></a><span class=sd>        y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-709 name=__codelineno-0-709></a><span class=sd>            The data used to train the model.</span>
<a id=__codelineno-0-710 name=__codelineno-0-710></a>
<a id=__codelineno-0-711 name=__codelineno-0-711></a><span class=sd>        Returns</span>
<a id=__codelineno-0-712 name=__codelineno-0-712></a><span class=sd>        -------</span>
<a id=__codelineno-0-713 name=__codelineno-0-713></a><span class=sd>        theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-714 name=__codelineno-0-714></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-715 name=__codelineno-0-715></a>
<a id=__codelineno-0-716 name=__codelineno-0-716></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-717 name=__codelineno-0-717></a>        <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-718 name=__codelineno-0-718></a>
<a id=__codelineno-0-719 name=__codelineno-0-719></a>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-720 name=__codelineno-0-720></a>            <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-721 name=__codelineno-0-721></a>            <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-722 name=__codelineno-0-722></a>            <span class=n>tmp_list</span> <span class=o>=</span> <span class=p>(</span>
<a id=__codelineno-0-723 name=__codelineno-0-723></a>                <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-724 name=__codelineno-0-724></a>                <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>sign</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>])</span> <span class=o>*</span> <span class=n>psi_tmp</span>
<a id=__codelineno-0-725 name=__codelineno-0-725></a>            <span class=p>)</span>
<a id=__codelineno-0-726 name=__codelineno-0-726></a>            <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-727 name=__codelineno-0-727></a>
<a id=__codelineno-0-728 name=__codelineno-0-728></a>        <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignError.optimize class="doc doc-heading"> <code class="highlight language-python"><span class=n>optimize</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignError.optimize class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Parameter estimation using the Sign-Error Least Mean Squares filter.</p> <p>The sign-error LMS algorithm updates the parameter estimates recursively as follows:</p> <ol> <li>Compute the estimation error:</li> </ol> <p>$$ \xi_i = y_i - \psi_i^T \theta_{i-1} $$</p> <ol> <li>Update the parameter vector:</li> </ol> <p>$$ \theta_i = \theta_{i-1} + \mu \cdot \text{sign}(\xi_i) \cdot \psi_i $$</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>array-like of shape (n_samples, 1)</code> </td> <td> <div class=doc-md-description> <p>The data used to train the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>array-like of shape (n_features, 1)</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-686>686</a></span>
<span class=normal><a href=#__codelineno-0-687>687</a></span>
<span class=normal><a href=#__codelineno-0-688>688</a></span>
<span class=normal><a href=#__codelineno-0-689>689</a></span>
<span class=normal><a href=#__codelineno-0-690>690</a></span>
<span class=normal><a href=#__codelineno-0-691>691</a></span>
<span class=normal><a href=#__codelineno-0-692>692</a></span>
<span class=normal><a href=#__codelineno-0-693>693</a></span>
<span class=normal><a href=#__codelineno-0-694>694</a></span>
<span class=normal><a href=#__codelineno-0-695>695</a></span>
<span class=normal><a href=#__codelineno-0-696>696</a></span>
<span class=normal><a href=#__codelineno-0-697>697</a></span>
<span class=normal><a href=#__codelineno-0-698>698</a></span>
<span class=normal><a href=#__codelineno-0-699>699</a></span>
<span class=normal><a href=#__codelineno-0-700>700</a></span>
<span class=normal><a href=#__codelineno-0-701>701</a></span>
<span class=normal><a href=#__codelineno-0-702>702</a></span>
<span class=normal><a href=#__codelineno-0-703>703</a></span>
<span class=normal><a href=#__codelineno-0-704>704</a></span>
<span class=normal><a href=#__codelineno-0-705>705</a></span>
<span class=normal><a href=#__codelineno-0-706>706</a></span>
<span class=normal><a href=#__codelineno-0-707>707</a></span>
<span class=normal><a href=#__codelineno-0-708>708</a></span>
<span class=normal><a href=#__codelineno-0-709>709</a></span>
<span class=normal><a href=#__codelineno-0-710>710</a></span>
<span class=normal><a href=#__codelineno-0-711>711</a></span>
<span class=normal><a href=#__codelineno-0-712>712</a></span>
<span class=normal><a href=#__codelineno-0-713>713</a></span>
<span class=normal><a href=#__codelineno-0-714>714</a></span>
<span class=normal><a href=#__codelineno-0-715>715</a></span>
<span class=normal><a href=#__codelineno-0-716>716</a></span>
<span class=normal><a href=#__codelineno-0-717>717</a></span>
<span class=normal><a href=#__codelineno-0-718>718</a></span>
<span class=normal><a href=#__codelineno-0-719>719</a></span>
<span class=normal><a href=#__codelineno-0-720>720</a></span>
<span class=normal><a href=#__codelineno-0-721>721</a></span>
<span class=normal><a href=#__codelineno-0-722>722</a></span>
<span class=normal><a href=#__codelineno-0-723>723</a></span>
<span class=normal><a href=#__codelineno-0-724>724</a></span>
<span class=normal><a href=#__codelineno-0-725>725</a></span>
<span class=normal><a href=#__codelineno-0-726>726</a></span>
<span class=normal><a href=#__codelineno-0-727>727</a></span>
<span class=normal><a href=#__codelineno-0-728>728</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-686 name=__codelineno-0-686></a><span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-687 name=__codelineno-0-687></a><span class=w>    </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Sign-Error Least Mean Squares filter.</span>
<a id=__codelineno-0-688 name=__codelineno-0-688></a>
<a id=__codelineno-0-689 name=__codelineno-0-689></a><span class=sd>    The sign-error LMS algorithm updates the parameter estimates recursively as</span>
<a id=__codelineno-0-690 name=__codelineno-0-690></a><span class=sd>    follows:</span>
<a id=__codelineno-0-691 name=__codelineno-0-691></a>
<a id=__codelineno-0-692 name=__codelineno-0-692></a><span class=sd>    1. Compute the estimation error:</span>
<a id=__codelineno-0-693 name=__codelineno-0-693></a>
<a id=__codelineno-0-694 name=__codelineno-0-694></a><span class=sd>       $$</span>
<a id=__codelineno-0-695 name=__codelineno-0-695></a><span class=sd>       \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-696 name=__codelineno-0-696></a><span class=sd>       $$</span>
<a id=__codelineno-0-697 name=__codelineno-0-697></a>
<a id=__codelineno-0-698 name=__codelineno-0-698></a><span class=sd>    2. Update the parameter vector:</span>
<a id=__codelineno-0-699 name=__codelineno-0-699></a>
<a id=__codelineno-0-700 name=__codelineno-0-700></a><span class=sd>       $$</span>
<a id=__codelineno-0-701 name=__codelineno-0-701></a><span class=sd>       \theta_i = \theta_{i-1} + \mu \cdot \text{sign}(\xi_i) \cdot \psi_i</span>
<a id=__codelineno-0-702 name=__codelineno-0-702></a><span class=sd>       $$</span>
<a id=__codelineno-0-703 name=__codelineno-0-703></a>
<a id=__codelineno-0-704 name=__codelineno-0-704></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-705 name=__codelineno-0-705></a><span class=sd>    ----------</span>
<a id=__codelineno-0-706 name=__codelineno-0-706></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-707 name=__codelineno-0-707></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-708 name=__codelineno-0-708></a><span class=sd>    y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-709 name=__codelineno-0-709></a><span class=sd>        The data used to train the model.</span>
<a id=__codelineno-0-710 name=__codelineno-0-710></a>
<a id=__codelineno-0-711 name=__codelineno-0-711></a><span class=sd>    Returns</span>
<a id=__codelineno-0-712 name=__codelineno-0-712></a><span class=sd>    -------</span>
<a id=__codelineno-0-713 name=__codelineno-0-713></a><span class=sd>    theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-714 name=__codelineno-0-714></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-715 name=__codelineno-0-715></a>
<a id=__codelineno-0-716 name=__codelineno-0-716></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-717 name=__codelineno-0-717></a>    <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-718 name=__codelineno-0-718></a>
<a id=__codelineno-0-719 name=__codelineno-0-719></a>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-720 name=__codelineno-0-720></a>        <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-721 name=__codelineno-0-721></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-722 name=__codelineno-0-722></a>        <span class=n>tmp_list</span> <span class=o>=</span> <span class=p>(</span>
<a id=__codelineno-0-723 name=__codelineno-0-723></a>            <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-724 name=__codelineno-0-724></a>            <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>sign</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>])</span> <span class=o>*</span> <span class=n>psi_tmp</span>
<a id=__codelineno-0-725 name=__codelineno-0-725></a>        <span class=p>)</span>
<a id=__codelineno-0-726 name=__codelineno-0-726></a>        <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-727 name=__codelineno-0-727></a>
<a id=__codelineno-0-728 name=__codelineno-0-728></a>    <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignRegressor class="doc doc-heading"> <code>LeastMeanSquaresSignRegressor</code> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignRegressor class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=sysidentpy.parameter_estimation.estimators_base.BaseEstimator>BaseEstimator</span></code></p> <p>Least Mean Squares (LMSSR) filter for parameter estimation.</p> <p>The sign-regressor LMS algorithm uses the sign of the matrix information to change the filter coefficients.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>mu</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> <td> <code>0.01</code> </td> </tr> <tr class=doc-section-item> <td> <code>unbiased</code> </td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>If True, applies an unbiased estimator. Default is False.</p> </div> </td> <td> <code>False</code> </td> </tr> <tr class=doc-section-item> <td> <code>uiter</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of iterations for the unbiased estimator. Default is 30.</p> </div> </td> <td> <code>30</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Attributes:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignRegressor.mu>mu</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignRegressor.unbiased>unbiased</span></code></td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>Indicates whether an unbiased estimator is applied.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignRegressor.uiter>uiter</span></code></td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of iterations for the unbiased estimator.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignRegressor.xi>xi</span></code></td> <td> <code><span title=numpy.ndarray>ndarray</span> or None</code> </td> <td> <div class=doc-md-description> <p>The estimation error at each iteration. Initialized as None and updated during optimization.</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Methods:</span></p> <table> <thead> <tr> <th>Name</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><a class="autorefs autorefs-internal" title="<code>sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignRegressor.optimize</code>" href=../../../../user-guide/API/parameter-estimation/#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignRegressor.optimize>optimize</a></code></td> <td> <div class=doc-md-description> <p>Estimate the model parameters using the LMS filter.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Hayes, M. H. (2009). Statistical digital signal processing and modeling. John Wiley &amp; Sons.</li> <li>Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de algoritmos LMS de passo variável.</li> <li>Wikipedia entry on Least Mean Squares: <a href=https://en.wikipedia.org/wiki/Least_mean_squares_filter>https://en.wikipedia.org/wiki/Least_mean_squares_filter</a></li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-931> 931</a></span>
<span class=normal><a href=#__codelineno-0-932> 932</a></span>
<span class=normal><a href=#__codelineno-0-933> 933</a></span>
<span class=normal><a href=#__codelineno-0-934> 934</a></span>
<span class=normal><a href=#__codelineno-0-935> 935</a></span>
<span class=normal><a href=#__codelineno-0-936> 936</a></span>
<span class=normal><a href=#__codelineno-0-937> 937</a></span>
<span class=normal><a href=#__codelineno-0-938> 938</a></span>
<span class=normal><a href=#__codelineno-0-939> 939</a></span>
<span class=normal><a href=#__codelineno-0-940> 940</a></span>
<span class=normal><a href=#__codelineno-0-941> 941</a></span>
<span class=normal><a href=#__codelineno-0-942> 942</a></span>
<span class=normal><a href=#__codelineno-0-943> 943</a></span>
<span class=normal><a href=#__codelineno-0-944> 944</a></span>
<span class=normal><a href=#__codelineno-0-945> 945</a></span>
<span class=normal><a href=#__codelineno-0-946> 946</a></span>
<span class=normal><a href=#__codelineno-0-947> 947</a></span>
<span class=normal><a href=#__codelineno-0-948> 948</a></span>
<span class=normal><a href=#__codelineno-0-949> 949</a></span>
<span class=normal><a href=#__codelineno-0-950> 950</a></span>
<span class=normal><a href=#__codelineno-0-951> 951</a></span>
<span class=normal><a href=#__codelineno-0-952> 952</a></span>
<span class=normal><a href=#__codelineno-0-953> 953</a></span>
<span class=normal><a href=#__codelineno-0-954> 954</a></span>
<span class=normal><a href=#__codelineno-0-955> 955</a></span>
<span class=normal><a href=#__codelineno-0-956> 956</a></span>
<span class=normal><a href=#__codelineno-0-957> 957</a></span>
<span class=normal><a href=#__codelineno-0-958> 958</a></span>
<span class=normal><a href=#__codelineno-0-959> 959</a></span>
<span class=normal><a href=#__codelineno-0-960> 960</a></span>
<span class=normal><a href=#__codelineno-0-961> 961</a></span>
<span class=normal><a href=#__codelineno-0-962> 962</a></span>
<span class=normal><a href=#__codelineno-0-963> 963</a></span>
<span class=normal><a href=#__codelineno-0-964> 964</a></span>
<span class=normal><a href=#__codelineno-0-965> 965</a></span>
<span class=normal><a href=#__codelineno-0-966> 966</a></span>
<span class=normal><a href=#__codelineno-0-967> 967</a></span>
<span class=normal><a href=#__codelineno-0-968> 968</a></span>
<span class=normal><a href=#__codelineno-0-969> 969</a></span>
<span class=normal><a href=#__codelineno-0-970> 970</a></span>
<span class=normal><a href=#__codelineno-0-971> 971</a></span>
<span class=normal><a href=#__codelineno-0-972> 972</a></span>
<span class=normal><a href=#__codelineno-0-973> 973</a></span>
<span class=normal><a href=#__codelineno-0-974> 974</a></span>
<span class=normal><a href=#__codelineno-0-975> 975</a></span>
<span class=normal><a href=#__codelineno-0-976> 976</a></span>
<span class=normal><a href=#__codelineno-0-977> 977</a></span>
<span class=normal><a href=#__codelineno-0-978> 978</a></span>
<span class=normal><a href=#__codelineno-0-979> 979</a></span>
<span class=normal><a href=#__codelineno-0-980> 980</a></span>
<span class=normal><a href=#__codelineno-0-981> 981</a></span>
<span class=normal><a href=#__codelineno-0-982> 982</a></span>
<span class=normal><a href=#__codelineno-0-983> 983</a></span>
<span class=normal><a href=#__codelineno-0-984> 984</a></span>
<span class=normal><a href=#__codelineno-0-985> 985</a></span>
<span class=normal><a href=#__codelineno-0-986> 986</a></span>
<span class=normal><a href=#__codelineno-0-987> 987</a></span>
<span class=normal><a href=#__codelineno-0-988> 988</a></span>
<span class=normal><a href=#__codelineno-0-989> 989</a></span>
<span class=normal><a href=#__codelineno-0-990> 990</a></span>
<span class=normal><a href=#__codelineno-0-991> 991</a></span>
<span class=normal><a href=#__codelineno-0-992> 992</a></span>
<span class=normal><a href=#__codelineno-0-993> 993</a></span>
<span class=normal><a href=#__codelineno-0-994> 994</a></span>
<span class=normal><a href=#__codelineno-0-995> 995</a></span>
<span class=normal><a href=#__codelineno-0-996> 996</a></span>
<span class=normal><a href=#__codelineno-0-997> 997</a></span>
<span class=normal><a href=#__codelineno-0-998> 998</a></span>
<span class=normal><a href=#__codelineno-0-999> 999</a></span>
<span class=normal><a href=#__codelineno-0-1000>1000</a></span>
<span class=normal><a href=#__codelineno-0-1001>1001</a></span>
<span class=normal><a href=#__codelineno-0-1002>1002</a></span>
<span class=normal><a href=#__codelineno-0-1003>1003</a></span>
<span class=normal><a href=#__codelineno-0-1004>1004</a></span>
<span class=normal><a href=#__codelineno-0-1005>1005</a></span>
<span class=normal><a href=#__codelineno-0-1006>1006</a></span>
<span class=normal><a href=#__codelineno-0-1007>1007</a></span>
<span class=normal><a href=#__codelineno-0-1008>1008</a></span>
<span class=normal><a href=#__codelineno-0-1009>1009</a></span>
<span class=normal><a href=#__codelineno-0-1010>1010</a></span>
<span class=normal><a href=#__codelineno-0-1011>1011</a></span>
<span class=normal><a href=#__codelineno-0-1012>1012</a></span>
<span class=normal><a href=#__codelineno-0-1013>1013</a></span>
<span class=normal><a href=#__codelineno-0-1014>1014</a></span>
<span class=normal><a href=#__codelineno-0-1015>1015</a></span>
<span class=normal><a href=#__codelineno-0-1016>1016</a></span>
<span class=normal><a href=#__codelineno-0-1017>1017</a></span>
<span class=normal><a href=#__codelineno-0-1018>1018</a></span>
<span class=normal><a href=#__codelineno-0-1019>1019</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-931 name=__codelineno-0-931></a><span class=k>class</span><span class=w> </span><span class=nc>LeastMeanSquaresSignRegressor</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>):</span>
<a id=__codelineno-0-932 name=__codelineno-0-932></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Least Mean Squares (LMSSR) filter for parameter estimation.</span>
<a id=__codelineno-0-933 name=__codelineno-0-933></a>
<a id=__codelineno-0-934 name=__codelineno-0-934></a><span class=sd>    The sign-regressor LMS algorithm uses the sign of the matrix</span>
<a id=__codelineno-0-935 name=__codelineno-0-935></a><span class=sd>    information to change the filter coefficients.</span>
<a id=__codelineno-0-936 name=__codelineno-0-936></a>
<a id=__codelineno-0-937 name=__codelineno-0-937></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-938 name=__codelineno-0-938></a><span class=sd>    ----------</span>
<a id=__codelineno-0-939 name=__codelineno-0-939></a><span class=sd>    mu : float, default=0.01</span>
<a id=__codelineno-0-940 name=__codelineno-0-940></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-941 name=__codelineno-0-941></a><span class=sd>    unbiased : bool, optional</span>
<a id=__codelineno-0-942 name=__codelineno-0-942></a><span class=sd>        If True, applies an unbiased estimator. Default is False.</span>
<a id=__codelineno-0-943 name=__codelineno-0-943></a><span class=sd>    uiter : int, optional</span>
<a id=__codelineno-0-944 name=__codelineno-0-944></a><span class=sd>        Number of iterations for the unbiased estimator. Default is 30.</span>
<a id=__codelineno-0-945 name=__codelineno-0-945></a>
<a id=__codelineno-0-946 name=__codelineno-0-946></a><span class=sd>    Attributes</span>
<a id=__codelineno-0-947 name=__codelineno-0-947></a><span class=sd>    ----------</span>
<a id=__codelineno-0-948 name=__codelineno-0-948></a><span class=sd>    mu : float</span>
<a id=__codelineno-0-949 name=__codelineno-0-949></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-950 name=__codelineno-0-950></a><span class=sd>    unbiased : bool</span>
<a id=__codelineno-0-951 name=__codelineno-0-951></a><span class=sd>        Indicates whether an unbiased estimator is applied.</span>
<a id=__codelineno-0-952 name=__codelineno-0-952></a><span class=sd>    uiter : int</span>
<a id=__codelineno-0-953 name=__codelineno-0-953></a><span class=sd>        Number of iterations for the unbiased estimator.</span>
<a id=__codelineno-0-954 name=__codelineno-0-954></a><span class=sd>    xi : np.ndarray or None</span>
<a id=__codelineno-0-955 name=__codelineno-0-955></a><span class=sd>        The estimation error at each iteration. Initialized as None and updated during</span>
<a id=__codelineno-0-956 name=__codelineno-0-956></a><span class=sd>        optimization.</span>
<a id=__codelineno-0-957 name=__codelineno-0-957></a>
<a id=__codelineno-0-958 name=__codelineno-0-958></a><span class=sd>    Methods</span>
<a id=__codelineno-0-959 name=__codelineno-0-959></a><span class=sd>    -------</span>
<a id=__codelineno-0-960 name=__codelineno-0-960></a><span class=sd>    optimize(psi: np.ndarray, y: np.ndarray) -&gt; np.ndarray</span>
<a id=__codelineno-0-961 name=__codelineno-0-961></a><span class=sd>        Estimate the model parameters using the LMS filter.</span>
<a id=__codelineno-0-962 name=__codelineno-0-962></a>
<a id=__codelineno-0-963 name=__codelineno-0-963></a><span class=sd>    References</span>
<a id=__codelineno-0-964 name=__codelineno-0-964></a><span class=sd>    ----------</span>
<a id=__codelineno-0-965 name=__codelineno-0-965></a><span class=sd>    - Hayes, M. H. (2009). Statistical digital signal processing and modeling.</span>
<a id=__codelineno-0-966 name=__codelineno-0-966></a><span class=sd>      John Wiley &amp; Sons.</span>
<a id=__codelineno-0-967 name=__codelineno-0-967></a><span class=sd>    - Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de</span>
<a id=__codelineno-0-968 name=__codelineno-0-968></a><span class=sd>      algoritmos LMS de passo variável.</span>
<a id=__codelineno-0-969 name=__codelineno-0-969></a><span class=sd>    - Wikipedia entry on Least Mean Squares: https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>
<a id=__codelineno-0-970 name=__codelineno-0-970></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-971 name=__codelineno-0-971></a>
<a id=__codelineno-0-972 name=__codelineno-0-972></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=o>*</span><span class=p>,</span> <span class=n>mu</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.01</span><span class=p>,</span> <span class=n>unbiased</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span> <span class=n>uiter</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>30</span><span class=p>):</span>
<a id=__codelineno-0-973 name=__codelineno-0-973></a>        <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>=</span> <span class=n>mu</span>
<a id=__codelineno-0-974 name=__codelineno-0-974></a>        <span class=bp>self</span><span class=o>.</span><span class=n>unbiased</span> <span class=o>=</span> <span class=n>unbiased</span>
<a id=__codelineno-0-975 name=__codelineno-0-975></a>        <span class=bp>self</span><span class=o>.</span><span class=n>uiter</span> <span class=o>=</span> <span class=n>uiter</span>
<a id=__codelineno-0-976 name=__codelineno-0-976></a>        <span class=n>_validate_params</span><span class=p>(</span><span class=nb>vars</span><span class=p>(</span><span class=bp>self</span><span class=p>))</span>
<a id=__codelineno-0-977 name=__codelineno-0-977></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
<a id=__codelineno-0-978 name=__codelineno-0-978></a>
<a id=__codelineno-0-979 name=__codelineno-0-979></a>    <span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-980 name=__codelineno-0-980></a><span class=w>        </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Sign-Regressor LMS filter.</span>
<a id=__codelineno-0-981 name=__codelineno-0-981></a>
<a id=__codelineno-0-982 name=__codelineno-0-982></a><span class=sd>        The sign-regressor LMS algorithm updates the parameter estimates recursively</span>
<a id=__codelineno-0-983 name=__codelineno-0-983></a><span class=sd>        as follows:</span>
<a id=__codelineno-0-984 name=__codelineno-0-984></a>
<a id=__codelineno-0-985 name=__codelineno-0-985></a><span class=sd>        1. Compute the estimation error:</span>
<a id=__codelineno-0-986 name=__codelineno-0-986></a>
<a id=__codelineno-0-987 name=__codelineno-0-987></a><span class=sd>           $$</span>
<a id=__codelineno-0-988 name=__codelineno-0-988></a><span class=sd>           \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-989 name=__codelineno-0-989></a><span class=sd>           $$</span>
<a id=__codelineno-0-990 name=__codelineno-0-990></a>
<a id=__codelineno-0-991 name=__codelineno-0-991></a><span class=sd>        2. Update the parameter vector:</span>
<a id=__codelineno-0-992 name=__codelineno-0-992></a>
<a id=__codelineno-0-993 name=__codelineno-0-993></a><span class=sd>           $$</span>
<a id=__codelineno-0-994 name=__codelineno-0-994></a><span class=sd>           \theta_i = \theta_{i-1} + \mu \cdot \xi_i \cdot \text{sign}(\psi_i)</span>
<a id=__codelineno-0-995 name=__codelineno-0-995></a><span class=sd>           $$</span>
<a id=__codelineno-0-996 name=__codelineno-0-996></a>
<a id=__codelineno-0-997 name=__codelineno-0-997></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-998 name=__codelineno-0-998></a><span class=sd>        ----------</span>
<a id=__codelineno-0-999 name=__codelineno-0-999></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-1000 name=__codelineno-0-1000></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-1001 name=__codelineno-0-1001></a><span class=sd>        y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-1002 name=__codelineno-0-1002></a><span class=sd>            The data used to train the model.</span>
<a id=__codelineno-0-1003 name=__codelineno-0-1003></a>
<a id=__codelineno-0-1004 name=__codelineno-0-1004></a><span class=sd>        Returns</span>
<a id=__codelineno-0-1005 name=__codelineno-0-1005></a><span class=sd>        -------</span>
<a id=__codelineno-0-1006 name=__codelineno-0-1006></a><span class=sd>        theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-1007 name=__codelineno-0-1007></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-1008 name=__codelineno-0-1008></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-1009 name=__codelineno-0-1009></a>        <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-1010 name=__codelineno-0-1010></a>
<a id=__codelineno-0-1011 name=__codelineno-0-1011></a>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-1012 name=__codelineno-0-1012></a>            <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-1013 name=__codelineno-0-1013></a>            <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-1014 name=__codelineno-0-1014></a>            <span class=n>tmp_list</span> <span class=o>=</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span>
<a id=__codelineno-0-1015 name=__codelineno-0-1015></a>                <span class=n>i</span><span class=p>,</span> <span class=mi>0</span>
<a id=__codelineno-0-1016 name=__codelineno-0-1016></a>            <span class=p>]</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>sign</span><span class=p>(</span><span class=n>psi_tmp</span><span class=p>)</span>
<a id=__codelineno-0-1017 name=__codelineno-0-1017></a>            <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-1018 name=__codelineno-0-1018></a>
<a id=__codelineno-0-1019 name=__codelineno-0-1019></a>        <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignRegressor.optimize class="doc doc-heading"> <code class="highlight language-python"><span class=n>optimize</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignRegressor.optimize class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Parameter estimation using the Sign-Regressor LMS filter.</p> <p>The sign-regressor LMS algorithm updates the parameter estimates recursively as follows:</p> <ol> <li>Compute the estimation error:</li> </ol> <p>$$ \xi_i = y_i - \psi_i^T \theta_{i-1} $$</p> <ol> <li>Update the parameter vector:</li> </ol> <p>$$ \theta_i = \theta_{i-1} + \mu \cdot \xi_i \cdot \text{sign}(\psi_i) $$</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>array-like of shape (n_samples, 1)</code> </td> <td> <div class=doc-md-description> <p>The data used to train the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>array-like of shape (n_features, 1)</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-979> 979</a></span>
<span class=normal><a href=#__codelineno-0-980> 980</a></span>
<span class=normal><a href=#__codelineno-0-981> 981</a></span>
<span class=normal><a href=#__codelineno-0-982> 982</a></span>
<span class=normal><a href=#__codelineno-0-983> 983</a></span>
<span class=normal><a href=#__codelineno-0-984> 984</a></span>
<span class=normal><a href=#__codelineno-0-985> 985</a></span>
<span class=normal><a href=#__codelineno-0-986> 986</a></span>
<span class=normal><a href=#__codelineno-0-987> 987</a></span>
<span class=normal><a href=#__codelineno-0-988> 988</a></span>
<span class=normal><a href=#__codelineno-0-989> 989</a></span>
<span class=normal><a href=#__codelineno-0-990> 990</a></span>
<span class=normal><a href=#__codelineno-0-991> 991</a></span>
<span class=normal><a href=#__codelineno-0-992> 992</a></span>
<span class=normal><a href=#__codelineno-0-993> 993</a></span>
<span class=normal><a href=#__codelineno-0-994> 994</a></span>
<span class=normal><a href=#__codelineno-0-995> 995</a></span>
<span class=normal><a href=#__codelineno-0-996> 996</a></span>
<span class=normal><a href=#__codelineno-0-997> 997</a></span>
<span class=normal><a href=#__codelineno-0-998> 998</a></span>
<span class=normal><a href=#__codelineno-0-999> 999</a></span>
<span class=normal><a href=#__codelineno-0-1000>1000</a></span>
<span class=normal><a href=#__codelineno-0-1001>1001</a></span>
<span class=normal><a href=#__codelineno-0-1002>1002</a></span>
<span class=normal><a href=#__codelineno-0-1003>1003</a></span>
<span class=normal><a href=#__codelineno-0-1004>1004</a></span>
<span class=normal><a href=#__codelineno-0-1005>1005</a></span>
<span class=normal><a href=#__codelineno-0-1006>1006</a></span>
<span class=normal><a href=#__codelineno-0-1007>1007</a></span>
<span class=normal><a href=#__codelineno-0-1008>1008</a></span>
<span class=normal><a href=#__codelineno-0-1009>1009</a></span>
<span class=normal><a href=#__codelineno-0-1010>1010</a></span>
<span class=normal><a href=#__codelineno-0-1011>1011</a></span>
<span class=normal><a href=#__codelineno-0-1012>1012</a></span>
<span class=normal><a href=#__codelineno-0-1013>1013</a></span>
<span class=normal><a href=#__codelineno-0-1014>1014</a></span>
<span class=normal><a href=#__codelineno-0-1015>1015</a></span>
<span class=normal><a href=#__codelineno-0-1016>1016</a></span>
<span class=normal><a href=#__codelineno-0-1017>1017</a></span>
<span class=normal><a href=#__codelineno-0-1018>1018</a></span>
<span class=normal><a href=#__codelineno-0-1019>1019</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-979 name=__codelineno-0-979></a><span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-980 name=__codelineno-0-980></a><span class=w>    </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Sign-Regressor LMS filter.</span>
<a id=__codelineno-0-981 name=__codelineno-0-981></a>
<a id=__codelineno-0-982 name=__codelineno-0-982></a><span class=sd>    The sign-regressor LMS algorithm updates the parameter estimates recursively</span>
<a id=__codelineno-0-983 name=__codelineno-0-983></a><span class=sd>    as follows:</span>
<a id=__codelineno-0-984 name=__codelineno-0-984></a>
<a id=__codelineno-0-985 name=__codelineno-0-985></a><span class=sd>    1. Compute the estimation error:</span>
<a id=__codelineno-0-986 name=__codelineno-0-986></a>
<a id=__codelineno-0-987 name=__codelineno-0-987></a><span class=sd>       $$</span>
<a id=__codelineno-0-988 name=__codelineno-0-988></a><span class=sd>       \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-989 name=__codelineno-0-989></a><span class=sd>       $$</span>
<a id=__codelineno-0-990 name=__codelineno-0-990></a>
<a id=__codelineno-0-991 name=__codelineno-0-991></a><span class=sd>    2. Update the parameter vector:</span>
<a id=__codelineno-0-992 name=__codelineno-0-992></a>
<a id=__codelineno-0-993 name=__codelineno-0-993></a><span class=sd>       $$</span>
<a id=__codelineno-0-994 name=__codelineno-0-994></a><span class=sd>       \theta_i = \theta_{i-1} + \mu \cdot \xi_i \cdot \text{sign}(\psi_i)</span>
<a id=__codelineno-0-995 name=__codelineno-0-995></a><span class=sd>       $$</span>
<a id=__codelineno-0-996 name=__codelineno-0-996></a>
<a id=__codelineno-0-997 name=__codelineno-0-997></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-998 name=__codelineno-0-998></a><span class=sd>    ----------</span>
<a id=__codelineno-0-999 name=__codelineno-0-999></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-1000 name=__codelineno-0-1000></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-1001 name=__codelineno-0-1001></a><span class=sd>    y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-1002 name=__codelineno-0-1002></a><span class=sd>        The data used to train the model.</span>
<a id=__codelineno-0-1003 name=__codelineno-0-1003></a>
<a id=__codelineno-0-1004 name=__codelineno-0-1004></a><span class=sd>    Returns</span>
<a id=__codelineno-0-1005 name=__codelineno-0-1005></a><span class=sd>    -------</span>
<a id=__codelineno-0-1006 name=__codelineno-0-1006></a><span class=sd>    theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-1007 name=__codelineno-0-1007></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-1008 name=__codelineno-0-1008></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-1009 name=__codelineno-0-1009></a>    <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-1010 name=__codelineno-0-1010></a>
<a id=__codelineno-0-1011 name=__codelineno-0-1011></a>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-1012 name=__codelineno-0-1012></a>        <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-1013 name=__codelineno-0-1013></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-1014 name=__codelineno-0-1014></a>        <span class=n>tmp_list</span> <span class=o>=</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span>
<a id=__codelineno-0-1015 name=__codelineno-0-1015></a>            <span class=n>i</span><span class=p>,</span> <span class=mi>0</span>
<a id=__codelineno-0-1016 name=__codelineno-0-1016></a>        <span class=p>]</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>sign</span><span class=p>(</span><span class=n>psi_tmp</span><span class=p>)</span>
<a id=__codelineno-0-1017 name=__codelineno-0-1017></a>        <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-1018 name=__codelineno-0-1018></a>
<a id=__codelineno-0-1019 name=__codelineno-0-1019></a>    <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignSign class="doc doc-heading"> <code>LeastMeanSquaresSignSign</code> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignSign class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=sysidentpy.parameter_estimation.estimators_base.BaseEstimator>BaseEstimator</span></code></p> <p>Least Mean Squares Sign-Sign (LMSSS) filter for parameter estimation.</p> <p>The LMSSS algorithm uses both the sign of the matrix information and the sign of the error vector to update the filter coefficients.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>mu</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> <td> <code>0.01</code> </td> </tr> <tr class=doc-section-item> <td> <code>unbiased</code> </td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>If True, applies an unbiased estimator. Default is False.</p> </div> </td> <td> <code>False</code> </td> </tr> <tr class=doc-section-item> <td> <code>uiter</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of iterations for the unbiased estimator. Default is 30.</p> </div> </td> <td> <code>30</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Attributes:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignSign.mu>mu</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignSign.xi>xi</span></code></td> <td> <code><span title=numpy.ndarray>ndarray</span> or None</code> </td> <td> <div class=doc-md-description> <p>The estimation error at each iteration. Initialized as None and updated during optimization.</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Methods:</span></p> <table> <thead> <tr> <th>Name</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><a class="autorefs autorefs-internal" title="<code>sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignSign.optimize</code>" href=../../../../user-guide/API/parameter-estimation/#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignSign.optimize>optimize</a></code></td> <td> <div class=doc-md-description> <p>Estimate the model parameters using the LMSSS filter.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Hayes, M. H. (2009). Statistical digital signal processing and modeling. John Wiley &amp; Sons.</li> <li>Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de algoritmos LMS de passo variável.</li> <li>Wikipedia entry on Least Mean Squares: <a href=https://en.wikipedia.org/wiki/Least_mean_squares_filter>https://en.wikipedia.org/wiki/Least_mean_squares_filter</a></li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-1124>1124</a></span>
<span class=normal><a href=#__codelineno-0-1125>1125</a></span>
<span class=normal><a href=#__codelineno-0-1126>1126</a></span>
<span class=normal><a href=#__codelineno-0-1127>1127</a></span>
<span class=normal><a href=#__codelineno-0-1128>1128</a></span>
<span class=normal><a href=#__codelineno-0-1129>1129</a></span>
<span class=normal><a href=#__codelineno-0-1130>1130</a></span>
<span class=normal><a href=#__codelineno-0-1131>1131</a></span>
<span class=normal><a href=#__codelineno-0-1132>1132</a></span>
<span class=normal><a href=#__codelineno-0-1133>1133</a></span>
<span class=normal><a href=#__codelineno-0-1134>1134</a></span>
<span class=normal><a href=#__codelineno-0-1135>1135</a></span>
<span class=normal><a href=#__codelineno-0-1136>1136</a></span>
<span class=normal><a href=#__codelineno-0-1137>1137</a></span>
<span class=normal><a href=#__codelineno-0-1138>1138</a></span>
<span class=normal><a href=#__codelineno-0-1139>1139</a></span>
<span class=normal><a href=#__codelineno-0-1140>1140</a></span>
<span class=normal><a href=#__codelineno-0-1141>1141</a></span>
<span class=normal><a href=#__codelineno-0-1142>1142</a></span>
<span class=normal><a href=#__codelineno-0-1143>1143</a></span>
<span class=normal><a href=#__codelineno-0-1144>1144</a></span>
<span class=normal><a href=#__codelineno-0-1145>1145</a></span>
<span class=normal><a href=#__codelineno-0-1146>1146</a></span>
<span class=normal><a href=#__codelineno-0-1147>1147</a></span>
<span class=normal><a href=#__codelineno-0-1148>1148</a></span>
<span class=normal><a href=#__codelineno-0-1149>1149</a></span>
<span class=normal><a href=#__codelineno-0-1150>1150</a></span>
<span class=normal><a href=#__codelineno-0-1151>1151</a></span>
<span class=normal><a href=#__codelineno-0-1152>1152</a></span>
<span class=normal><a href=#__codelineno-0-1153>1153</a></span>
<span class=normal><a href=#__codelineno-0-1154>1154</a></span>
<span class=normal><a href=#__codelineno-0-1155>1155</a></span>
<span class=normal><a href=#__codelineno-0-1156>1156</a></span>
<span class=normal><a href=#__codelineno-0-1157>1157</a></span>
<span class=normal><a href=#__codelineno-0-1158>1158</a></span>
<span class=normal><a href=#__codelineno-0-1159>1159</a></span>
<span class=normal><a href=#__codelineno-0-1160>1160</a></span>
<span class=normal><a href=#__codelineno-0-1161>1161</a></span>
<span class=normal><a href=#__codelineno-0-1162>1162</a></span>
<span class=normal><a href=#__codelineno-0-1163>1163</a></span>
<span class=normal><a href=#__codelineno-0-1164>1164</a></span>
<span class=normal><a href=#__codelineno-0-1165>1165</a></span>
<span class=normal><a href=#__codelineno-0-1166>1166</a></span>
<span class=normal><a href=#__codelineno-0-1167>1167</a></span>
<span class=normal><a href=#__codelineno-0-1168>1168</a></span>
<span class=normal><a href=#__codelineno-0-1169>1169</a></span>
<span class=normal><a href=#__codelineno-0-1170>1170</a></span>
<span class=normal><a href=#__codelineno-0-1171>1171</a></span>
<span class=normal><a href=#__codelineno-0-1172>1172</a></span>
<span class=normal><a href=#__codelineno-0-1173>1173</a></span>
<span class=normal><a href=#__codelineno-0-1174>1174</a></span>
<span class=normal><a href=#__codelineno-0-1175>1175</a></span>
<span class=normal><a href=#__codelineno-0-1176>1176</a></span>
<span class=normal><a href=#__codelineno-0-1177>1177</a></span>
<span class=normal><a href=#__codelineno-0-1178>1178</a></span>
<span class=normal><a href=#__codelineno-0-1179>1179</a></span>
<span class=normal><a href=#__codelineno-0-1180>1180</a></span>
<span class=normal><a href=#__codelineno-0-1181>1181</a></span>
<span class=normal><a href=#__codelineno-0-1182>1182</a></span>
<span class=normal><a href=#__codelineno-0-1183>1183</a></span>
<span class=normal><a href=#__codelineno-0-1184>1184</a></span>
<span class=normal><a href=#__codelineno-0-1185>1185</a></span>
<span class=normal><a href=#__codelineno-0-1186>1186</a></span>
<span class=normal><a href=#__codelineno-0-1187>1187</a></span>
<span class=normal><a href=#__codelineno-0-1188>1188</a></span>
<span class=normal><a href=#__codelineno-0-1189>1189</a></span>
<span class=normal><a href=#__codelineno-0-1190>1190</a></span>
<span class=normal><a href=#__codelineno-0-1191>1191</a></span>
<span class=normal><a href=#__codelineno-0-1192>1192</a></span>
<span class=normal><a href=#__codelineno-0-1193>1193</a></span>
<span class=normal><a href=#__codelineno-0-1194>1194</a></span>
<span class=normal><a href=#__codelineno-0-1195>1195</a></span>
<span class=normal><a href=#__codelineno-0-1196>1196</a></span>
<span class=normal><a href=#__codelineno-0-1197>1197</a></span>
<span class=normal><a href=#__codelineno-0-1198>1198</a></span>
<span class=normal><a href=#__codelineno-0-1199>1199</a></span>
<span class=normal><a href=#__codelineno-0-1200>1200</a></span>
<span class=normal><a href=#__codelineno-0-1201>1201</a></span>
<span class=normal><a href=#__codelineno-0-1202>1202</a></span>
<span class=normal><a href=#__codelineno-0-1203>1203</a></span>
<span class=normal><a href=#__codelineno-0-1204>1204</a></span>
<span class=normal><a href=#__codelineno-0-1205>1205</a></span>
<span class=normal><a href=#__codelineno-0-1206>1206</a></span>
<span class=normal><a href=#__codelineno-0-1207>1207</a></span>
<span class=normal><a href=#__codelineno-0-1208>1208</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-1124 name=__codelineno-0-1124></a><span class=k>class</span><span class=w> </span><span class=nc>LeastMeanSquaresSignSign</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>):</span>
<a id=__codelineno-0-1125 name=__codelineno-0-1125></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Least Mean Squares Sign-Sign (LMSSS) filter for parameter estimation.</span>
<a id=__codelineno-0-1126 name=__codelineno-0-1126></a>
<a id=__codelineno-0-1127 name=__codelineno-0-1127></a><span class=sd>    The LMSSS algorithm uses both the sign of the matrix information and the sign of</span>
<a id=__codelineno-0-1128 name=__codelineno-0-1128></a><span class=sd>    the error vector to update the filter coefficients.</span>
<a id=__codelineno-0-1129 name=__codelineno-0-1129></a>
<a id=__codelineno-0-1130 name=__codelineno-0-1130></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-1131 name=__codelineno-0-1131></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1132 name=__codelineno-0-1132></a><span class=sd>    mu : float, default=0.01</span>
<a id=__codelineno-0-1133 name=__codelineno-0-1133></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-1134 name=__codelineno-0-1134></a><span class=sd>    unbiased : bool, optional</span>
<a id=__codelineno-0-1135 name=__codelineno-0-1135></a><span class=sd>        If True, applies an unbiased estimator. Default is False.</span>
<a id=__codelineno-0-1136 name=__codelineno-0-1136></a><span class=sd>    uiter : int, optional</span>
<a id=__codelineno-0-1137 name=__codelineno-0-1137></a><span class=sd>        Number of iterations for the unbiased estimator. Default is 30.</span>
<a id=__codelineno-0-1138 name=__codelineno-0-1138></a>
<a id=__codelineno-0-1139 name=__codelineno-0-1139></a><span class=sd>    Attributes</span>
<a id=__codelineno-0-1140 name=__codelineno-0-1140></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1141 name=__codelineno-0-1141></a><span class=sd>    mu : float</span>
<a id=__codelineno-0-1142 name=__codelineno-0-1142></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-1143 name=__codelineno-0-1143></a><span class=sd>    xi : np.ndarray or None</span>
<a id=__codelineno-0-1144 name=__codelineno-0-1144></a><span class=sd>        The estimation error at each iteration. Initialized as None and updated during</span>
<a id=__codelineno-0-1145 name=__codelineno-0-1145></a><span class=sd>        optimization.</span>
<a id=__codelineno-0-1146 name=__codelineno-0-1146></a>
<a id=__codelineno-0-1147 name=__codelineno-0-1147></a><span class=sd>    Methods</span>
<a id=__codelineno-0-1148 name=__codelineno-0-1148></a><span class=sd>    -------</span>
<a id=__codelineno-0-1149 name=__codelineno-0-1149></a><span class=sd>    optimize(psi: np.ndarray, y: np.ndarray) -&gt; np.ndarray</span>
<a id=__codelineno-0-1150 name=__codelineno-0-1150></a><span class=sd>        Estimate the model parameters using the LMSSS filter.</span>
<a id=__codelineno-0-1151 name=__codelineno-0-1151></a>
<a id=__codelineno-0-1152 name=__codelineno-0-1152></a><span class=sd>    References</span>
<a id=__codelineno-0-1153 name=__codelineno-0-1153></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1154 name=__codelineno-0-1154></a><span class=sd>    - Hayes, M. H. (2009). Statistical digital signal processing and modeling.</span>
<a id=__codelineno-0-1155 name=__codelineno-0-1155></a><span class=sd>    John Wiley &amp; Sons.</span>
<a id=__codelineno-0-1156 name=__codelineno-0-1156></a><span class=sd>    - Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de</span>
<a id=__codelineno-0-1157 name=__codelineno-0-1157></a><span class=sd>    algoritmos LMS de passo variável.</span>
<a id=__codelineno-0-1158 name=__codelineno-0-1158></a><span class=sd>    - Wikipedia entry on Least Mean Squares: https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>
<a id=__codelineno-0-1159 name=__codelineno-0-1159></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-1160 name=__codelineno-0-1160></a>
<a id=__codelineno-0-1161 name=__codelineno-0-1161></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=o>*</span><span class=p>,</span> <span class=n>mu</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.01</span><span class=p>,</span> <span class=n>unbiased</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span> <span class=n>uiter</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>30</span><span class=p>):</span>
<a id=__codelineno-0-1162 name=__codelineno-0-1162></a>        <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>=</span> <span class=n>mu</span>
<a id=__codelineno-0-1163 name=__codelineno-0-1163></a>        <span class=bp>self</span><span class=o>.</span><span class=n>unbiased</span> <span class=o>=</span> <span class=n>unbiased</span>
<a id=__codelineno-0-1164 name=__codelineno-0-1164></a>        <span class=bp>self</span><span class=o>.</span><span class=n>uiter</span> <span class=o>=</span> <span class=n>uiter</span>
<a id=__codelineno-0-1165 name=__codelineno-0-1165></a>        <span class=n>_validate_params</span><span class=p>(</span><span class=nb>vars</span><span class=p>(</span><span class=bp>self</span><span class=p>))</span>
<a id=__codelineno-0-1166 name=__codelineno-0-1166></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
<a id=__codelineno-0-1167 name=__codelineno-0-1167></a>
<a id=__codelineno-0-1168 name=__codelineno-0-1168></a>    <span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-1169 name=__codelineno-0-1169></a><span class=w>        </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Sign-Sign LMS filter.</span>
<a id=__codelineno-0-1170 name=__codelineno-0-1170></a>
<a id=__codelineno-0-1171 name=__codelineno-0-1171></a><span class=sd>        The LMSSS algorithm updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-1172 name=__codelineno-0-1172></a>
<a id=__codelineno-0-1173 name=__codelineno-0-1173></a><span class=sd>        1. Compute the estimation error:</span>
<a id=__codelineno-0-1174 name=__codelineno-0-1174></a>
<a id=__codelineno-0-1175 name=__codelineno-0-1175></a><span class=sd>           $$</span>
<a id=__codelineno-0-1176 name=__codelineno-0-1176></a><span class=sd>           \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-1177 name=__codelineno-0-1177></a><span class=sd>           $$</span>
<a id=__codelineno-0-1178 name=__codelineno-0-1178></a>
<a id=__codelineno-0-1179 name=__codelineno-0-1179></a><span class=sd>        2. Update the parameter vector:</span>
<a id=__codelineno-0-1180 name=__codelineno-0-1180></a>
<a id=__codelineno-0-1181 name=__codelineno-0-1181></a><span class=sd>           $$</span>
<a id=__codelineno-0-1182 name=__codelineno-0-1182></a><span class=sd>           \theta_i = \theta_{i-1} + 2* \mu \cdot \text{sign}(\xi_i)</span>
<a id=__codelineno-0-1183 name=__codelineno-0-1183></a><span class=sd>           \cdot \text{sign}(\psi_i)</span>
<a id=__codelineno-0-1184 name=__codelineno-0-1184></a><span class=sd>           $$</span>
<a id=__codelineno-0-1185 name=__codelineno-0-1185></a>
<a id=__codelineno-0-1186 name=__codelineno-0-1186></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-1187 name=__codelineno-0-1187></a><span class=sd>        ----------</span>
<a id=__codelineno-0-1188 name=__codelineno-0-1188></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-1189 name=__codelineno-0-1189></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-1190 name=__codelineno-0-1190></a><span class=sd>        y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-1191 name=__codelineno-0-1191></a><span class=sd>            The data used to train the model.</span>
<a id=__codelineno-0-1192 name=__codelineno-0-1192></a>
<a id=__codelineno-0-1193 name=__codelineno-0-1193></a><span class=sd>        Returns</span>
<a id=__codelineno-0-1194 name=__codelineno-0-1194></a><span class=sd>        -------</span>
<a id=__codelineno-0-1195 name=__codelineno-0-1195></a><span class=sd>        theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-1196 name=__codelineno-0-1196></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-1197 name=__codelineno-0-1197></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-1198 name=__codelineno-0-1198></a>        <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-1199 name=__codelineno-0-1199></a>
<a id=__codelineno-0-1200 name=__codelineno-0-1200></a>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-1201 name=__codelineno-0-1201></a>            <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-1202 name=__codelineno-0-1202></a>            <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-1203 name=__codelineno-0-1203></a>            <span class=n>tmp_list</span> <span class=o>=</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=mi>2</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>sign</span><span class=p>(</span>
<a id=__codelineno-0-1204 name=__codelineno-0-1204></a>                <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-1205 name=__codelineno-0-1205></a>            <span class=p>)</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>sign</span><span class=p>(</span><span class=n>psi_tmp</span><span class=p>)</span>
<a id=__codelineno-0-1206 name=__codelineno-0-1206></a>            <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-1207 name=__codelineno-0-1207></a>
<a id=__codelineno-0-1208 name=__codelineno-0-1208></a>        <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignSign.optimize class="doc doc-heading"> <code class="highlight language-python"><span class=n>optimize</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.LeastMeanSquaresSignSign.optimize class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Parameter estimation using the Sign-Sign LMS filter.</p> <p>The LMSSS algorithm updates the parameter estimates recursively as follows:</p> <ol> <li>Compute the estimation error:</li> </ol> <p>$$ \xi_i = y_i - \psi_i^T \theta_{i-1} $$</p> <ol> <li>Update the parameter vector:</li> </ol> <p>$$ \theta_i = \theta_{i-1} + 2* \mu \cdot \text{sign}(\xi_i) \cdot \text{sign}(\psi_i) $$</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>array-like of shape (n_samples, 1)</code> </td> <td> <div class=doc-md-description> <p>The data used to train the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>array-like of shape (n_features, 1)</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-1168>1168</a></span>
<span class=normal><a href=#__codelineno-0-1169>1169</a></span>
<span class=normal><a href=#__codelineno-0-1170>1170</a></span>
<span class=normal><a href=#__codelineno-0-1171>1171</a></span>
<span class=normal><a href=#__codelineno-0-1172>1172</a></span>
<span class=normal><a href=#__codelineno-0-1173>1173</a></span>
<span class=normal><a href=#__codelineno-0-1174>1174</a></span>
<span class=normal><a href=#__codelineno-0-1175>1175</a></span>
<span class=normal><a href=#__codelineno-0-1176>1176</a></span>
<span class=normal><a href=#__codelineno-0-1177>1177</a></span>
<span class=normal><a href=#__codelineno-0-1178>1178</a></span>
<span class=normal><a href=#__codelineno-0-1179>1179</a></span>
<span class=normal><a href=#__codelineno-0-1180>1180</a></span>
<span class=normal><a href=#__codelineno-0-1181>1181</a></span>
<span class=normal><a href=#__codelineno-0-1182>1182</a></span>
<span class=normal><a href=#__codelineno-0-1183>1183</a></span>
<span class=normal><a href=#__codelineno-0-1184>1184</a></span>
<span class=normal><a href=#__codelineno-0-1185>1185</a></span>
<span class=normal><a href=#__codelineno-0-1186>1186</a></span>
<span class=normal><a href=#__codelineno-0-1187>1187</a></span>
<span class=normal><a href=#__codelineno-0-1188>1188</a></span>
<span class=normal><a href=#__codelineno-0-1189>1189</a></span>
<span class=normal><a href=#__codelineno-0-1190>1190</a></span>
<span class=normal><a href=#__codelineno-0-1191>1191</a></span>
<span class=normal><a href=#__codelineno-0-1192>1192</a></span>
<span class=normal><a href=#__codelineno-0-1193>1193</a></span>
<span class=normal><a href=#__codelineno-0-1194>1194</a></span>
<span class=normal><a href=#__codelineno-0-1195>1195</a></span>
<span class=normal><a href=#__codelineno-0-1196>1196</a></span>
<span class=normal><a href=#__codelineno-0-1197>1197</a></span>
<span class=normal><a href=#__codelineno-0-1198>1198</a></span>
<span class=normal><a href=#__codelineno-0-1199>1199</a></span>
<span class=normal><a href=#__codelineno-0-1200>1200</a></span>
<span class=normal><a href=#__codelineno-0-1201>1201</a></span>
<span class=normal><a href=#__codelineno-0-1202>1202</a></span>
<span class=normal><a href=#__codelineno-0-1203>1203</a></span>
<span class=normal><a href=#__codelineno-0-1204>1204</a></span>
<span class=normal><a href=#__codelineno-0-1205>1205</a></span>
<span class=normal><a href=#__codelineno-0-1206>1206</a></span>
<span class=normal><a href=#__codelineno-0-1207>1207</a></span>
<span class=normal><a href=#__codelineno-0-1208>1208</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-1168 name=__codelineno-0-1168></a><span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-1169 name=__codelineno-0-1169></a><span class=w>    </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Sign-Sign LMS filter.</span>
<a id=__codelineno-0-1170 name=__codelineno-0-1170></a>
<a id=__codelineno-0-1171 name=__codelineno-0-1171></a><span class=sd>    The LMSSS algorithm updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-1172 name=__codelineno-0-1172></a>
<a id=__codelineno-0-1173 name=__codelineno-0-1173></a><span class=sd>    1. Compute the estimation error:</span>
<a id=__codelineno-0-1174 name=__codelineno-0-1174></a>
<a id=__codelineno-0-1175 name=__codelineno-0-1175></a><span class=sd>       $$</span>
<a id=__codelineno-0-1176 name=__codelineno-0-1176></a><span class=sd>       \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-1177 name=__codelineno-0-1177></a><span class=sd>       $$</span>
<a id=__codelineno-0-1178 name=__codelineno-0-1178></a>
<a id=__codelineno-0-1179 name=__codelineno-0-1179></a><span class=sd>    2. Update the parameter vector:</span>
<a id=__codelineno-0-1180 name=__codelineno-0-1180></a>
<a id=__codelineno-0-1181 name=__codelineno-0-1181></a><span class=sd>       $$</span>
<a id=__codelineno-0-1182 name=__codelineno-0-1182></a><span class=sd>       \theta_i = \theta_{i-1} + 2* \mu \cdot \text{sign}(\xi_i)</span>
<a id=__codelineno-0-1183 name=__codelineno-0-1183></a><span class=sd>       \cdot \text{sign}(\psi_i)</span>
<a id=__codelineno-0-1184 name=__codelineno-0-1184></a><span class=sd>       $$</span>
<a id=__codelineno-0-1185 name=__codelineno-0-1185></a>
<a id=__codelineno-0-1186 name=__codelineno-0-1186></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-1187 name=__codelineno-0-1187></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1188 name=__codelineno-0-1188></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-1189 name=__codelineno-0-1189></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-1190 name=__codelineno-0-1190></a><span class=sd>    y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-1191 name=__codelineno-0-1191></a><span class=sd>        The data used to train the model.</span>
<a id=__codelineno-0-1192 name=__codelineno-0-1192></a>
<a id=__codelineno-0-1193 name=__codelineno-0-1193></a><span class=sd>    Returns</span>
<a id=__codelineno-0-1194 name=__codelineno-0-1194></a><span class=sd>    -------</span>
<a id=__codelineno-0-1195 name=__codelineno-0-1195></a><span class=sd>    theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-1196 name=__codelineno-0-1196></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-1197 name=__codelineno-0-1197></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-1198 name=__codelineno-0-1198></a>    <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-1199 name=__codelineno-0-1199></a>
<a id=__codelineno-0-1200 name=__codelineno-0-1200></a>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-1201 name=__codelineno-0-1201></a>        <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-1202 name=__codelineno-0-1202></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-1203 name=__codelineno-0-1203></a>        <span class=n>tmp_list</span> <span class=o>=</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=mi>2</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>sign</span><span class=p>(</span>
<a id=__codelineno-0-1204 name=__codelineno-0-1204></a>            <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-1205 name=__codelineno-0-1205></a>        <span class=p>)</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>sign</span><span class=p>(</span><span class=n>psi_tmp</span><span class=p>)</span>
<a id=__codelineno-0-1206 name=__codelineno-0-1206></a>        <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-1207 name=__codelineno-0-1207></a>
<a id=__codelineno-0-1208 name=__codelineno-0-1208></a>    <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.LeastSquares class="doc doc-heading"> <code>LeastSquares</code> <a href=#sysidentpy.parameter_estimation.estimators.LeastSquares class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=sysidentpy.parameter_estimation.estimators_base.BaseEstimator>BaseEstimator</span></code></p> <p>Ordinary Least Squares for linear parameter estimation.</p> <p>The Least Squares method minimizes the sum of the squared differences between the observed and predicted values. It is used to estimate the parameters of a linear model.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>unbiased</code> </td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>If True, applies an unbiased estimator. Default is False.</p> </div> </td> <td> <code>False</code> </td> </tr> <tr class=doc-section-item> <td> <code>uiter</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of iterations for the unbiased estimator. Default is 20.</p> </div> </td> <td> <code>20</code> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Sorenson, H. W. (1970). Least-squares estimation: from Gauss to Kalman. IEEE spectrum, 7(7), 63-68. <a href=http://pzs.dstu.dp.ua/DataMining/mls/bibl/Gauss2Kalman.pdf>http://pzs.dstu.dp.ua/DataMining/mls/bibl/Gauss2Kalman.pdf</a></li> <li>Aguirre, L. A. (2007). Introdução identificação de sistemas: técnicas lineares e não-lineares aplicadas a sistemas reais. Editora da UFMG. 3a edição.</li> <li>Markovsky, I., &amp; Van Huffel, S. (2007). Overview of total least-squares methods. Signal processing, 87(10), 2283-2302. <a href=https://eprints.soton.ac.uk/263855/1/tls_overview.pdf>https://eprints.soton.ac.uk/263855/1/tls_overview.pdf</a></li> <li>Wikipedia entry on Least Squares <a href=https://en.wikipedia.org/wiki/Least_squares>https://en.wikipedia.org/wiki/Least_squares</a></li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-38>38</a></span>
<span class=normal><a href=#__codelineno-0-39>39</a></span>
<span class=normal><a href=#__codelineno-0-40>40</a></span>
<span class=normal><a href=#__codelineno-0-41>41</a></span>
<span class=normal><a href=#__codelineno-0-42>42</a></span>
<span class=normal><a href=#__codelineno-0-43>43</a></span>
<span class=normal><a href=#__codelineno-0-44>44</a></span>
<span class=normal><a href=#__codelineno-0-45>45</a></span>
<span class=normal><a href=#__codelineno-0-46>46</a></span>
<span class=normal><a href=#__codelineno-0-47>47</a></span>
<span class=normal><a href=#__codelineno-0-48>48</a></span>
<span class=normal><a href=#__codelineno-0-49>49</a></span>
<span class=normal><a href=#__codelineno-0-50>50</a></span>
<span class=normal><a href=#__codelineno-0-51>51</a></span>
<span class=normal><a href=#__codelineno-0-52>52</a></span>
<span class=normal><a href=#__codelineno-0-53>53</a></span>
<span class=normal><a href=#__codelineno-0-54>54</a></span>
<span class=normal><a href=#__codelineno-0-55>55</a></span>
<span class=normal><a href=#__codelineno-0-56>56</a></span>
<span class=normal><a href=#__codelineno-0-57>57</a></span>
<span class=normal><a href=#__codelineno-0-58>58</a></span>
<span class=normal><a href=#__codelineno-0-59>59</a></span>
<span class=normal><a href=#__codelineno-0-60>60</a></span>
<span class=normal><a href=#__codelineno-0-61>61</a></span>
<span class=normal><a href=#__codelineno-0-62>62</a></span>
<span class=normal><a href=#__codelineno-0-63>63</a></span>
<span class=normal><a href=#__codelineno-0-64>64</a></span>
<span class=normal><a href=#__codelineno-0-65>65</a></span>
<span class=normal><a href=#__codelineno-0-66>66</a></span>
<span class=normal><a href=#__codelineno-0-67>67</a></span>
<span class=normal><a href=#__codelineno-0-68>68</a></span>
<span class=normal><a href=#__codelineno-0-69>69</a></span>
<span class=normal><a href=#__codelineno-0-70>70</a></span>
<span class=normal><a href=#__codelineno-0-71>71</a></span>
<span class=normal><a href=#__codelineno-0-72>72</a></span>
<span class=normal><a href=#__codelineno-0-73>73</a></span>
<span class=normal><a href=#__codelineno-0-74>74</a></span>
<span class=normal><a href=#__codelineno-0-75>75</a></span>
<span class=normal><a href=#__codelineno-0-76>76</a></span>
<span class=normal><a href=#__codelineno-0-77>77</a></span>
<span class=normal><a href=#__codelineno-0-78>78</a></span>
<span class=normal><a href=#__codelineno-0-79>79</a></span>
<span class=normal><a href=#__codelineno-0-80>80</a></span>
<span class=normal><a href=#__codelineno-0-81>81</a></span>
<span class=normal><a href=#__codelineno-0-82>82</a></span>
<span class=normal><a href=#__codelineno-0-83>83</a></span>
<span class=normal><a href=#__codelineno-0-84>84</a></span>
<span class=normal><a href=#__codelineno-0-85>85</a></span>
<span class=normal><a href=#__codelineno-0-86>86</a></span>
<span class=normal><a href=#__codelineno-0-87>87</a></span>
<span class=normal><a href=#__codelineno-0-88>88</a></span>
<span class=normal><a href=#__codelineno-0-89>89</a></span>
<span class=normal><a href=#__codelineno-0-90>90</a></span>
<span class=normal><a href=#__codelineno-0-91>91</a></span>
<span class=normal><a href=#__codelineno-0-92>92</a></span>
<span class=normal><a href=#__codelineno-0-93>93</a></span>
<span class=normal><a href=#__codelineno-0-94>94</a></span>
<span class=normal><a href=#__codelineno-0-95>95</a></span>
<span class=normal><a href=#__codelineno-0-96>96</a></span>
<span class=normal><a href=#__codelineno-0-97>97</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-38 name=__codelineno-0-38></a><span class=k>class</span><span class=w> </span><span class=nc>LeastSquares</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>):</span>
<a id=__codelineno-0-39 name=__codelineno-0-39></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Ordinary Least Squares for linear parameter estimation.</span>
<a id=__codelineno-0-40 name=__codelineno-0-40></a>
<a id=__codelineno-0-41 name=__codelineno-0-41></a><span class=sd>    The Least Squares method minimizes the sum of the squared differences</span>
<a id=__codelineno-0-42 name=__codelineno-0-42></a><span class=sd>    between the observed and predicted values. It is used to estimate the</span>
<a id=__codelineno-0-43 name=__codelineno-0-43></a><span class=sd>    parameters of a linear model.</span>
<a id=__codelineno-0-44 name=__codelineno-0-44></a>
<a id=__codelineno-0-45 name=__codelineno-0-45></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-46 name=__codelineno-0-46></a><span class=sd>    ----------</span>
<a id=__codelineno-0-47 name=__codelineno-0-47></a><span class=sd>    unbiased : bool, optional</span>
<a id=__codelineno-0-48 name=__codelineno-0-48></a><span class=sd>        If True, applies an unbiased estimator. Default is False.</span>
<a id=__codelineno-0-49 name=__codelineno-0-49></a><span class=sd>    uiter : int, optional</span>
<a id=__codelineno-0-50 name=__codelineno-0-50></a><span class=sd>        Number of iterations for the unbiased estimator. Default is 20.</span>
<a id=__codelineno-0-51 name=__codelineno-0-51></a>
<a id=__codelineno-0-52 name=__codelineno-0-52></a><span class=sd>    References</span>
<a id=__codelineno-0-53 name=__codelineno-0-53></a><span class=sd>    ----------</span>
<a id=__codelineno-0-54 name=__codelineno-0-54></a><span class=sd>    - Sorenson, H. W. (1970). Least-squares estimation: from Gauss to Kalman.</span>
<a id=__codelineno-0-55 name=__codelineno-0-55></a><span class=sd>      IEEE spectrum, 7(7), 63-68.</span>
<a id=__codelineno-0-56 name=__codelineno-0-56></a><span class=sd>      http://pzs.dstu.dp.ua/DataMining/mls/bibl/Gauss2Kalman.pdf</span>
<a id=__codelineno-0-57 name=__codelineno-0-57></a><span class=sd>    - Aguirre, L. A. (2007). Introdução identificação de sistemas: técnicas</span>
<a id=__codelineno-0-58 name=__codelineno-0-58></a><span class=sd>      lineares e não-lineares aplicadas a sistemas reais. Editora da UFMG. 3a edição.</span>
<a id=__codelineno-0-59 name=__codelineno-0-59></a><span class=sd>    - Markovsky, I., &amp; Van Huffel, S. (2007). Overview of total least-squares methods.</span>
<a id=__codelineno-0-60 name=__codelineno-0-60></a><span class=sd>      Signal processing, 87(10), 2283-2302.</span>
<a id=__codelineno-0-61 name=__codelineno-0-61></a><span class=sd>      https://eprints.soton.ac.uk/263855/1/tls_overview.pdf</span>
<a id=__codelineno-0-62 name=__codelineno-0-62></a><span class=sd>    - Wikipedia entry on Least Squares</span>
<a id=__codelineno-0-63 name=__codelineno-0-63></a><span class=sd>      https://en.wikipedia.org/wiki/Least_squares</span>
<a id=__codelineno-0-64 name=__codelineno-0-64></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-65 name=__codelineno-0-65></a>
<a id=__codelineno-0-66 name=__codelineno-0-66></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=o>*</span><span class=p>,</span> <span class=n>unbiased</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span> <span class=n>uiter</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>20</span><span class=p>):</span>
<a id=__codelineno-0-67 name=__codelineno-0-67></a>        <span class=bp>self</span><span class=o>.</span><span class=n>unbiased</span> <span class=o>=</span> <span class=n>unbiased</span>
<a id=__codelineno-0-68 name=__codelineno-0-68></a>        <span class=bp>self</span><span class=o>.</span><span class=n>uiter</span> <span class=o>=</span> <span class=n>uiter</span>
<a id=__codelineno-0-69 name=__codelineno-0-69></a>        <span class=n>_validate_params</span><span class=p>(</span><span class=nb>vars</span><span class=p>(</span><span class=bp>self</span><span class=p>))</span>
<a id=__codelineno-0-70 name=__codelineno-0-70></a>
<a id=__codelineno-0-71 name=__codelineno-0-71></a>    <span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-72 name=__codelineno-0-72></a><span class=w>        </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Estimate the model parameters using the Least Squares method.</span>
<a id=__codelineno-0-73 name=__codelineno-0-73></a>
<a id=__codelineno-0-74 name=__codelineno-0-74></a><span class=sd>        The Least Squares method solves the following optimization problem:</span>
<a id=__codelineno-0-75 name=__codelineno-0-75></a>
<a id=__codelineno-0-76 name=__codelineno-0-76></a><span class=sd>        $$</span>
<a id=__codelineno-0-77 name=__codelineno-0-77></a><span class=sd>        \min_{\theta} \| \psi \theta - y \|_2^2</span>
<a id=__codelineno-0-78 name=__codelineno-0-78></a><span class=sd>        $$</span>
<a id=__codelineno-0-79 name=__codelineno-0-79></a>
<a id=__codelineno-0-80 name=__codelineno-0-80></a><span class=sd>        where $\psi$ is the information matrix, $y$ is the observed data,</span>
<a id=__codelineno-0-81 name=__codelineno-0-81></a><span class=sd>        and $\theta$ are the model parameters to be estimated.</span>
<a id=__codelineno-0-82 name=__codelineno-0-82></a>
<a id=__codelineno-0-83 name=__codelineno-0-83></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-84 name=__codelineno-0-84></a><span class=sd>        ----------</span>
<a id=__codelineno-0-85 name=__codelineno-0-85></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-86 name=__codelineno-0-86></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-87 name=__codelineno-0-87></a><span class=sd>        y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-88 name=__codelineno-0-88></a><span class=sd>            The data used to train the model.</span>
<a id=__codelineno-0-89 name=__codelineno-0-89></a>
<a id=__codelineno-0-90 name=__codelineno-0-90></a><span class=sd>        Returns</span>
<a id=__codelineno-0-91 name=__codelineno-0-91></a><span class=sd>        -------</span>
<a id=__codelineno-0-92 name=__codelineno-0-92></a><span class=sd>        theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-93 name=__codelineno-0-93></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-94 name=__codelineno-0-94></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-95 name=__codelineno-0-95></a>        <span class=n>check_linear_dependence_rows</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-96 name=__codelineno-0-96></a>        <span class=n>theta</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>lstsq</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>rcond</span><span class=o>=</span><span class=kc>None</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-97 name=__codelineno-0-97></a>        <span class=k>return</span> <span class=n>theta</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.LeastSquares.optimize class="doc doc-heading"> <code class="highlight language-python"><span class=n>optimize</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.LeastSquares.optimize class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Estimate the model parameters using the Least Squares method.</p> <p>The Least Squares method solves the following optimization problem:</p> <div class=arithmatex>\[ \min_{\theta} \| \psi \theta - y \|_2^2 \]</div> <p>where <span class=arithmatex>\(\psi\)</span> is the information matrix, <span class=arithmatex>\(y\)</span> is the observed data, and <span class=arithmatex>\(\theta\)</span> are the model parameters to be estimated.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>array-like of shape (n_samples, 1)</code> </td> <td> <div class=doc-md-description> <p>The data used to train the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>array-like of shape (n_features, 1)</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-71>71</a></span>
<span class=normal><a href=#__codelineno-0-72>72</a></span>
<span class=normal><a href=#__codelineno-0-73>73</a></span>
<span class=normal><a href=#__codelineno-0-74>74</a></span>
<span class=normal><a href=#__codelineno-0-75>75</a></span>
<span class=normal><a href=#__codelineno-0-76>76</a></span>
<span class=normal><a href=#__codelineno-0-77>77</a></span>
<span class=normal><a href=#__codelineno-0-78>78</a></span>
<span class=normal><a href=#__codelineno-0-79>79</a></span>
<span class=normal><a href=#__codelineno-0-80>80</a></span>
<span class=normal><a href=#__codelineno-0-81>81</a></span>
<span class=normal><a href=#__codelineno-0-82>82</a></span>
<span class=normal><a href=#__codelineno-0-83>83</a></span>
<span class=normal><a href=#__codelineno-0-84>84</a></span>
<span class=normal><a href=#__codelineno-0-85>85</a></span>
<span class=normal><a href=#__codelineno-0-86>86</a></span>
<span class=normal><a href=#__codelineno-0-87>87</a></span>
<span class=normal><a href=#__codelineno-0-88>88</a></span>
<span class=normal><a href=#__codelineno-0-89>89</a></span>
<span class=normal><a href=#__codelineno-0-90>90</a></span>
<span class=normal><a href=#__codelineno-0-91>91</a></span>
<span class=normal><a href=#__codelineno-0-92>92</a></span>
<span class=normal><a href=#__codelineno-0-93>93</a></span>
<span class=normal><a href=#__codelineno-0-94>94</a></span>
<span class=normal><a href=#__codelineno-0-95>95</a></span>
<span class=normal><a href=#__codelineno-0-96>96</a></span>
<span class=normal><a href=#__codelineno-0-97>97</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-71 name=__codelineno-0-71></a><span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-72 name=__codelineno-0-72></a><span class=w>    </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Estimate the model parameters using the Least Squares method.</span>
<a id=__codelineno-0-73 name=__codelineno-0-73></a>
<a id=__codelineno-0-74 name=__codelineno-0-74></a><span class=sd>    The Least Squares method solves the following optimization problem:</span>
<a id=__codelineno-0-75 name=__codelineno-0-75></a>
<a id=__codelineno-0-76 name=__codelineno-0-76></a><span class=sd>    $$</span>
<a id=__codelineno-0-77 name=__codelineno-0-77></a><span class=sd>    \min_{\theta} \| \psi \theta - y \|_2^2</span>
<a id=__codelineno-0-78 name=__codelineno-0-78></a><span class=sd>    $$</span>
<a id=__codelineno-0-79 name=__codelineno-0-79></a>
<a id=__codelineno-0-80 name=__codelineno-0-80></a><span class=sd>    where $\psi$ is the information matrix, $y$ is the observed data,</span>
<a id=__codelineno-0-81 name=__codelineno-0-81></a><span class=sd>    and $\theta$ are the model parameters to be estimated.</span>
<a id=__codelineno-0-82 name=__codelineno-0-82></a>
<a id=__codelineno-0-83 name=__codelineno-0-83></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-84 name=__codelineno-0-84></a><span class=sd>    ----------</span>
<a id=__codelineno-0-85 name=__codelineno-0-85></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-86 name=__codelineno-0-86></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-87 name=__codelineno-0-87></a><span class=sd>    y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-88 name=__codelineno-0-88></a><span class=sd>        The data used to train the model.</span>
<a id=__codelineno-0-89 name=__codelineno-0-89></a>
<a id=__codelineno-0-90 name=__codelineno-0-90></a><span class=sd>    Returns</span>
<a id=__codelineno-0-91 name=__codelineno-0-91></a><span class=sd>    -------</span>
<a id=__codelineno-0-92 name=__codelineno-0-92></a><span class=sd>    theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-93 name=__codelineno-0-93></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-94 name=__codelineno-0-94></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-95 name=__codelineno-0-95></a>    <span class=n>check_linear_dependence_rows</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-96 name=__codelineno-0-96></a>    <span class=n>theta</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>lstsq</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>rcond</span><span class=o>=</span><span class=kc>None</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-97 name=__codelineno-0-97></a>    <span class=k>return</span> <span class=n>theta</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.LeastSquaresMinimalResidual class="doc doc-heading"> <code>LeastSquaresMinimalResidual</code> <a href=#sysidentpy.parameter_estimation.estimators.LeastSquaresMinimalResidual class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=sysidentpy.parameter_estimation.estimators_base.BaseEstimator>BaseEstimator</span></code></p> <p>Iterative solver for least-squares minimal residual problems.</p> <p>This is a wrapper class for the <code>scipy.sparse.linalg.lsmr</code> method.</p> <p>lsmr solves the system of linear equations <code>Ax = b</code>. If the system is inconsistent, it solves the least-squares problem <code>min ||b - Ax||_2</code>. <code>A</code> is a rectangular matrix of dimension m-by-n, where all cases are allowed: m = n, m &gt; n, or m &lt; n. <code>b</code> is a vector of length m. The matrix A may be dense or sparse (usually sparse).</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>unbiased</code> </td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>If True, applies an unbiased estimator. Default is False.</p> </div> </td> <td> <code>False</code> </td> </tr> <tr class=doc-section-item> <td> <code>uiter</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of iterations for the unbiased estimator. Default is 30.</p> </div> </td> <td> <code>30</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Attributes:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastSquaresMinimalResidual.unbiased>unbiased</span></code></td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>Indicates whether an unbiased estimator is applied.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastSquaresMinimalResidual.uiter>uiter</span></code></td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of iterations for the unbiased estimator.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastSquaresMinimalResidual.damp>damp</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>Damping factor for regularized least-squares. <code>lsmr</code> solves the regularized least-squares problem::</p> <p>min ||(b) - ( A )x|| ||(0) (damp*I) ||_2</p> <p>where damp is a scalar. If damp is None or 0, the system is solved without regularization. Default is 0.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title="sysidentpy.parameter_estimation.estimators.LeastSquaresMinimalResidual.atol, btol">atol, btol</span></code></td> <td> <code>(<span title=float>float</span>, <span title=optional>optional</span>)</code> </td> <td> <div class=doc-md-description> <p>Stopping tolerances. <code>lsmr</code> continues iterations until a certain backward error estimate is smaller than some quantity depending on atol and btol. Let <code>r = b - Ax</code> be the residual vector for the current approximate solution <code>x</code>. If <code>Ax = b</code> seems to be consistent, <code>lsmr</code> terminates when <code>norm(r) &lt;= atol * norm(A) * norm(x) + btol * norm(b)</code>. Otherwise, <code>lsmr</code> terminates when <code>norm(A^H r) &lt;= atol * norm(A) * norm(r)</code>. If both tolerances are 1.0e-6 (default), the final <code>norm(r)</code> should be accurate to about 6 digits. (The final <code>x</code> will usually have fewer correct digits, depending on <code>cond(A)</code> and the size of LAMBDA.) If <code>atol</code> or <code>btol</code> is None, a default value of 1.0e-6 will be used. Ideally, they should be estimates of the relative error in the entries of <code>A</code> and <code>b</code> respectively. For example, if the entries of <code>A</code> have 7 correct digits, set <code>atol = 1e-7</code>. This prevents the algorithm from doing unnecessary work beyond the uncertainty of the input data.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastSquaresMinimalResidual.conlim>conlim</span></code></td> <td> <code>(<span title=float>float</span>, <span title=optional>optional</span>)</code> </td> <td> <div class=doc-md-description> <p><code>lsmr</code> terminates if an estimate of <code>cond(A)</code> exceeds <code>conlim</code>. For compatible systems <code>Ax = b</code>, conlim could be as large as 1.0e+12 (say). For least-squares problems, <code>conlim</code> should be less than 1.0e+8. If <code>conlim</code> is None, the default value is 1e+8. Maximum precision can be obtained by setting <code>atol = btol = conlim = 0</code>, but the number of iterations may then be excessive. Default is 1e8.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastSquaresMinimalResidual.maxiter>maxiter</span></code></td> <td> <code>(<span title=int>int</span>, <span title=optional>optional</span>)</code> </td> <td> <div class=doc-md-description> <p><code>lsmr</code> terminates if the number of iterations reaches <code>maxiter</code>. The default is <code>maxiter = min(m, n)</code>. For ill-conditioned systems, a larger value of <code>maxiter</code> may be needed. Default is False.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastSquaresMinimalResidual.show>show</span></code></td> <td> <code>(<span title=bool>bool</span>, <span title=optional>optional</span>)</code> </td> <td> <div class=doc-md-description> <p>Print iterations logs if <code>show=True</code>. Default is False.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.LeastSquaresMinimalResidual.x0>x0</span></code></td> <td> <code>(<span title=array_like>array_like</span>, <span title=shape>shape</span>(<span title=n>n</span>), <span title=optional>optional</span>)</code> </td> <td> <div class=doc-md-description> <p>Initial guess of <code>x</code>, if None zeros are used. Default is None.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <p>.. [1] D. C.-L. Fong and M. A. Saunders, "LSMR: An iterative algorithm for sparse least-squares problems", SIAM J. Sci. Comput., vol. 33, pp. 2950-2971, 2011. :arxiv:<code>1006.0758</code> .. [2] LSMR Software, <a href=https://web.stanford.edu/group/SOL/software/lsmr/ >https://web.stanford.edu/group/SOL/software/lsmr/</a></p> </details> <details class=note open> <summary>Notes</summary> <p>This docstring is adapted from the <code>scipy.sparse.linalg.lsmr</code> method.</p> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-2037>2037</a></span>
<span class=normal><a href=#__codelineno-0-2038>2038</a></span>
<span class=normal><a href=#__codelineno-0-2039>2039</a></span>
<span class=normal><a href=#__codelineno-0-2040>2040</a></span>
<span class=normal><a href=#__codelineno-0-2041>2041</a></span>
<span class=normal><a href=#__codelineno-0-2042>2042</a></span>
<span class=normal><a href=#__codelineno-0-2043>2043</a></span>
<span class=normal><a href=#__codelineno-0-2044>2044</a></span>
<span class=normal><a href=#__codelineno-0-2045>2045</a></span>
<span class=normal><a href=#__codelineno-0-2046>2046</a></span>
<span class=normal><a href=#__codelineno-0-2047>2047</a></span>
<span class=normal><a href=#__codelineno-0-2048>2048</a></span>
<span class=normal><a href=#__codelineno-0-2049>2049</a></span>
<span class=normal><a href=#__codelineno-0-2050>2050</a></span>
<span class=normal><a href=#__codelineno-0-2051>2051</a></span>
<span class=normal><a href=#__codelineno-0-2052>2052</a></span>
<span class=normal><a href=#__codelineno-0-2053>2053</a></span>
<span class=normal><a href=#__codelineno-0-2054>2054</a></span>
<span class=normal><a href=#__codelineno-0-2055>2055</a></span>
<span class=normal><a href=#__codelineno-0-2056>2056</a></span>
<span class=normal><a href=#__codelineno-0-2057>2057</a></span>
<span class=normal><a href=#__codelineno-0-2058>2058</a></span>
<span class=normal><a href=#__codelineno-0-2059>2059</a></span>
<span class=normal><a href=#__codelineno-0-2060>2060</a></span>
<span class=normal><a href=#__codelineno-0-2061>2061</a></span>
<span class=normal><a href=#__codelineno-0-2062>2062</a></span>
<span class=normal><a href=#__codelineno-0-2063>2063</a></span>
<span class=normal><a href=#__codelineno-0-2064>2064</a></span>
<span class=normal><a href=#__codelineno-0-2065>2065</a></span>
<span class=normal><a href=#__codelineno-0-2066>2066</a></span>
<span class=normal><a href=#__codelineno-0-2067>2067</a></span>
<span class=normal><a href=#__codelineno-0-2068>2068</a></span>
<span class=normal><a href=#__codelineno-0-2069>2069</a></span>
<span class=normal><a href=#__codelineno-0-2070>2070</a></span>
<span class=normal><a href=#__codelineno-0-2071>2071</a></span>
<span class=normal><a href=#__codelineno-0-2072>2072</a></span>
<span class=normal><a href=#__codelineno-0-2073>2073</a></span>
<span class=normal><a href=#__codelineno-0-2074>2074</a></span>
<span class=normal><a href=#__codelineno-0-2075>2075</a></span>
<span class=normal><a href=#__codelineno-0-2076>2076</a></span>
<span class=normal><a href=#__codelineno-0-2077>2077</a></span>
<span class=normal><a href=#__codelineno-0-2078>2078</a></span>
<span class=normal><a href=#__codelineno-0-2079>2079</a></span>
<span class=normal><a href=#__codelineno-0-2080>2080</a></span>
<span class=normal><a href=#__codelineno-0-2081>2081</a></span>
<span class=normal><a href=#__codelineno-0-2082>2082</a></span>
<span class=normal><a href=#__codelineno-0-2083>2083</a></span>
<span class=normal><a href=#__codelineno-0-2084>2084</a></span>
<span class=normal><a href=#__codelineno-0-2085>2085</a></span>
<span class=normal><a href=#__codelineno-0-2086>2086</a></span>
<span class=normal><a href=#__codelineno-0-2087>2087</a></span>
<span class=normal><a href=#__codelineno-0-2088>2088</a></span>
<span class=normal><a href=#__codelineno-0-2089>2089</a></span>
<span class=normal><a href=#__codelineno-0-2090>2090</a></span>
<span class=normal><a href=#__codelineno-0-2091>2091</a></span>
<span class=normal><a href=#__codelineno-0-2092>2092</a></span>
<span class=normal><a href=#__codelineno-0-2093>2093</a></span>
<span class=normal><a href=#__codelineno-0-2094>2094</a></span>
<span class=normal><a href=#__codelineno-0-2095>2095</a></span>
<span class=normal><a href=#__codelineno-0-2096>2096</a></span>
<span class=normal><a href=#__codelineno-0-2097>2097</a></span>
<span class=normal><a href=#__codelineno-0-2098>2098</a></span>
<span class=normal><a href=#__codelineno-0-2099>2099</a></span>
<span class=normal><a href=#__codelineno-0-2100>2100</a></span>
<span class=normal><a href=#__codelineno-0-2101>2101</a></span>
<span class=normal><a href=#__codelineno-0-2102>2102</a></span>
<span class=normal><a href=#__codelineno-0-2103>2103</a></span>
<span class=normal><a href=#__codelineno-0-2104>2104</a></span>
<span class=normal><a href=#__codelineno-0-2105>2105</a></span>
<span class=normal><a href=#__codelineno-0-2106>2106</a></span>
<span class=normal><a href=#__codelineno-0-2107>2107</a></span>
<span class=normal><a href=#__codelineno-0-2108>2108</a></span>
<span class=normal><a href=#__codelineno-0-2109>2109</a></span>
<span class=normal><a href=#__codelineno-0-2110>2110</a></span>
<span class=normal><a href=#__codelineno-0-2111>2111</a></span>
<span class=normal><a href=#__codelineno-0-2112>2112</a></span>
<span class=normal><a href=#__codelineno-0-2113>2113</a></span>
<span class=normal><a href=#__codelineno-0-2114>2114</a></span>
<span class=normal><a href=#__codelineno-0-2115>2115</a></span>
<span class=normal><a href=#__codelineno-0-2116>2116</a></span>
<span class=normal><a href=#__codelineno-0-2117>2117</a></span>
<span class=normal><a href=#__codelineno-0-2118>2118</a></span>
<span class=normal><a href=#__codelineno-0-2119>2119</a></span>
<span class=normal><a href=#__codelineno-0-2120>2120</a></span>
<span class=normal><a href=#__codelineno-0-2121>2121</a></span>
<span class=normal><a href=#__codelineno-0-2122>2122</a></span>
<span class=normal><a href=#__codelineno-0-2123>2123</a></span>
<span class=normal><a href=#__codelineno-0-2124>2124</a></span>
<span class=normal><a href=#__codelineno-0-2125>2125</a></span>
<span class=normal><a href=#__codelineno-0-2126>2126</a></span>
<span class=normal><a href=#__codelineno-0-2127>2127</a></span>
<span class=normal><a href=#__codelineno-0-2128>2128</a></span>
<span class=normal><a href=#__codelineno-0-2129>2129</a></span>
<span class=normal><a href=#__codelineno-0-2130>2130</a></span>
<span class=normal><a href=#__codelineno-0-2131>2131</a></span>
<span class=normal><a href=#__codelineno-0-2132>2132</a></span>
<span class=normal><a href=#__codelineno-0-2133>2133</a></span>
<span class=normal><a href=#__codelineno-0-2134>2134</a></span>
<span class=normal><a href=#__codelineno-0-2135>2135</a></span>
<span class=normal><a href=#__codelineno-0-2136>2136</a></span>
<span class=normal><a href=#__codelineno-0-2137>2137</a></span>
<span class=normal><a href=#__codelineno-0-2138>2138</a></span>
<span class=normal><a href=#__codelineno-0-2139>2139</a></span>
<span class=normal><a href=#__codelineno-0-2140>2140</a></span>
<span class=normal><a href=#__codelineno-0-2141>2141</a></span>
<span class=normal><a href=#__codelineno-0-2142>2142</a></span>
<span class=normal><a href=#__codelineno-0-2143>2143</a></span>
<span class=normal><a href=#__codelineno-0-2144>2144</a></span>
<span class=normal><a href=#__codelineno-0-2145>2145</a></span>
<span class=normal><a href=#__codelineno-0-2146>2146</a></span>
<span class=normal><a href=#__codelineno-0-2147>2147</a></span>
<span class=normal><a href=#__codelineno-0-2148>2148</a></span>
<span class=normal><a href=#__codelineno-0-2149>2149</a></span>
<span class=normal><a href=#__codelineno-0-2150>2150</a></span>
<span class=normal><a href=#__codelineno-0-2151>2151</a></span>
<span class=normal><a href=#__codelineno-0-2152>2152</a></span>
<span class=normal><a href=#__codelineno-0-2153>2153</a></span>
<span class=normal><a href=#__codelineno-0-2154>2154</a></span>
<span class=normal><a href=#__codelineno-0-2155>2155</a></span>
<span class=normal><a href=#__codelineno-0-2156>2156</a></span>
<span class=normal><a href=#__codelineno-0-2157>2157</a></span>
<span class=normal><a href=#__codelineno-0-2158>2158</a></span>
<span class=normal><a href=#__codelineno-0-2159>2159</a></span>
<span class=normal><a href=#__codelineno-0-2160>2160</a></span>
<span class=normal><a href=#__codelineno-0-2161>2161</a></span>
<span class=normal><a href=#__codelineno-0-2162>2162</a></span>
<span class=normal><a href=#__codelineno-0-2163>2163</a></span>
<span class=normal><a href=#__codelineno-0-2164>2164</a></span>
<span class=normal><a href=#__codelineno-0-2165>2165</a></span>
<span class=normal><a href=#__codelineno-0-2166>2166</a></span>
<span class=normal><a href=#__codelineno-0-2167>2167</a></span>
<span class=normal><a href=#__codelineno-0-2168>2168</a></span>
<span class=normal><a href=#__codelineno-0-2169>2169</a></span>
<span class=normal><a href=#__codelineno-0-2170>2170</a></span>
<span class=normal><a href=#__codelineno-0-2171>2171</a></span>
<span class=normal><a href=#__codelineno-0-2172>2172</a></span>
<span class=normal><a href=#__codelineno-0-2173>2173</a></span>
<span class=normal><a href=#__codelineno-0-2174>2174</a></span>
<span class=normal><a href=#__codelineno-0-2175>2175</a></span>
<span class=normal><a href=#__codelineno-0-2176>2176</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-2037 name=__codelineno-0-2037></a><span class=k>class</span><span class=w> </span><span class=nc>LeastSquaresMinimalResidual</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>):</span>
<a id=__codelineno-0-2038 name=__codelineno-0-2038></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Iterative solver for least-squares minimal residual problems.</span>
<a id=__codelineno-0-2039 name=__codelineno-0-2039></a>
<a id=__codelineno-0-2040 name=__codelineno-0-2040></a><span class=sd>    This is a wrapper class for the `scipy.sparse.linalg.lsmr` method.</span>
<a id=__codelineno-0-2041 name=__codelineno-0-2041></a>
<a id=__codelineno-0-2042 name=__codelineno-0-2042></a><span class=sd>    lsmr solves the system of linear equations ``Ax = b``. If the system</span>
<a id=__codelineno-0-2043 name=__codelineno-0-2043></a><span class=sd>    is inconsistent, it solves the least-squares problem ``min ||b - Ax||_2``.</span>
<a id=__codelineno-0-2044 name=__codelineno-0-2044></a><span class=sd>    ``A`` is a rectangular matrix of dimension m-by-n, where all cases are</span>
<a id=__codelineno-0-2045 name=__codelineno-0-2045></a><span class=sd>    allowed: m = n, m &gt; n, or m &lt; n. ``b`` is a vector of length m.</span>
<a id=__codelineno-0-2046 name=__codelineno-0-2046></a><span class=sd>    The matrix A may be dense or sparse (usually sparse).</span>
<a id=__codelineno-0-2047 name=__codelineno-0-2047></a>
<a id=__codelineno-0-2048 name=__codelineno-0-2048></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-2049 name=__codelineno-0-2049></a><span class=sd>    ----------</span>
<a id=__codelineno-0-2050 name=__codelineno-0-2050></a><span class=sd>    unbiased : bool, optional</span>
<a id=__codelineno-0-2051 name=__codelineno-0-2051></a><span class=sd>        If True, applies an unbiased estimator. Default is False.</span>
<a id=__codelineno-0-2052 name=__codelineno-0-2052></a><span class=sd>    uiter : int, optional</span>
<a id=__codelineno-0-2053 name=__codelineno-0-2053></a><span class=sd>        Number of iterations for the unbiased estimator. Default is 30.</span>
<a id=__codelineno-0-2054 name=__codelineno-0-2054></a>
<a id=__codelineno-0-2055 name=__codelineno-0-2055></a><span class=sd>    Attributes</span>
<a id=__codelineno-0-2056 name=__codelineno-0-2056></a><span class=sd>    ----------</span>
<a id=__codelineno-0-2057 name=__codelineno-0-2057></a><span class=sd>    unbiased : bool</span>
<a id=__codelineno-0-2058 name=__codelineno-0-2058></a><span class=sd>        Indicates whether an unbiased estimator is applied.</span>
<a id=__codelineno-0-2059 name=__codelineno-0-2059></a><span class=sd>    uiter : int</span>
<a id=__codelineno-0-2060 name=__codelineno-0-2060></a><span class=sd>        Number of iterations for the unbiased estimator.</span>
<a id=__codelineno-0-2061 name=__codelineno-0-2061></a><span class=sd>    damp : float</span>
<a id=__codelineno-0-2062 name=__codelineno-0-2062></a><span class=sd>        Damping factor for regularized least-squares. `lsmr` solves</span>
<a id=__codelineno-0-2063 name=__codelineno-0-2063></a><span class=sd>        the regularized least-squares problem::</span>
<a id=__codelineno-0-2064 name=__codelineno-0-2064></a>
<a id=__codelineno-0-2065 name=__codelineno-0-2065></a><span class=sd>         min ||(b) - (  A   )x||</span>
<a id=__codelineno-0-2066 name=__codelineno-0-2066></a><span class=sd>             ||(0)   (damp*I) ||_2</span>
<a id=__codelineno-0-2067 name=__codelineno-0-2067></a>
<a id=__codelineno-0-2068 name=__codelineno-0-2068></a><span class=sd>        where damp is a scalar.  If damp is None or 0, the system</span>
<a id=__codelineno-0-2069 name=__codelineno-0-2069></a><span class=sd>        is solved without regularization. Default is 0.</span>
<a id=__codelineno-0-2070 name=__codelineno-0-2070></a><span class=sd>    atol, btol : float, optional</span>
<a id=__codelineno-0-2071 name=__codelineno-0-2071></a><span class=sd>        Stopping tolerances. `lsmr` continues iterations until a</span>
<a id=__codelineno-0-2072 name=__codelineno-0-2072></a><span class=sd>        certain backward error estimate is smaller than some quantity</span>
<a id=__codelineno-0-2073 name=__codelineno-0-2073></a><span class=sd>        depending on atol and btol.  Let ``r = b - Ax`` be the</span>
<a id=__codelineno-0-2074 name=__codelineno-0-2074></a><span class=sd>        residual vector for the current approximate solution ``x``.</span>
<a id=__codelineno-0-2075 name=__codelineno-0-2075></a><span class=sd>        If ``Ax = b`` seems to be consistent, `lsmr` terminates</span>
<a id=__codelineno-0-2076 name=__codelineno-0-2076></a><span class=sd>        when ``norm(r) &lt;= atol * norm(A) * norm(x) + btol * norm(b)``.</span>
<a id=__codelineno-0-2077 name=__codelineno-0-2077></a><span class=sd>        Otherwise, `lsmr` terminates when ``norm(A^H r) &lt;=</span>
<a id=__codelineno-0-2078 name=__codelineno-0-2078></a><span class=sd>        atol * norm(A) * norm(r)``.  If both tolerances are 1.0e-6 (default),</span>
<a id=__codelineno-0-2079 name=__codelineno-0-2079></a><span class=sd>        the final ``norm(r)`` should be accurate to about 6</span>
<a id=__codelineno-0-2080 name=__codelineno-0-2080></a><span class=sd>        digits. (The final ``x`` will usually have fewer correct digits,</span>
<a id=__codelineno-0-2081 name=__codelineno-0-2081></a><span class=sd>        depending on ``cond(A)`` and the size of LAMBDA.)  If `atol`</span>
<a id=__codelineno-0-2082 name=__codelineno-0-2082></a><span class=sd>        or `btol` is None, a default value of 1.0e-6 will be used.</span>
<a id=__codelineno-0-2083 name=__codelineno-0-2083></a><span class=sd>        Ideally, they should be estimates of the relative error in the</span>
<a id=__codelineno-0-2084 name=__codelineno-0-2084></a><span class=sd>        entries of ``A`` and ``b`` respectively.  For example, if the entries</span>
<a id=__codelineno-0-2085 name=__codelineno-0-2085></a><span class=sd>        of ``A`` have 7 correct digits, set ``atol = 1e-7``. This prevents</span>
<a id=__codelineno-0-2086 name=__codelineno-0-2086></a><span class=sd>        the algorithm from doing unnecessary work beyond the</span>
<a id=__codelineno-0-2087 name=__codelineno-0-2087></a><span class=sd>        uncertainty of the input data.</span>
<a id=__codelineno-0-2088 name=__codelineno-0-2088></a><span class=sd>    conlim : float, optional</span>
<a id=__codelineno-0-2089 name=__codelineno-0-2089></a><span class=sd>        `lsmr` terminates if an estimate of ``cond(A)`` exceeds</span>
<a id=__codelineno-0-2090 name=__codelineno-0-2090></a><span class=sd>        `conlim`.  For compatible systems ``Ax = b``, conlim could be</span>
<a id=__codelineno-0-2091 name=__codelineno-0-2091></a><span class=sd>        as large as 1.0e+12 (say).  For least-squares problems,</span>
<a id=__codelineno-0-2092 name=__codelineno-0-2092></a><span class=sd>        `conlim` should be less than 1.0e+8. If `conlim` is None, the</span>
<a id=__codelineno-0-2093 name=__codelineno-0-2093></a><span class=sd>        default value is 1e+8.  Maximum precision can be obtained by</span>
<a id=__codelineno-0-2094 name=__codelineno-0-2094></a><span class=sd>        setting ``atol = btol = conlim = 0``, but the number of</span>
<a id=__codelineno-0-2095 name=__codelineno-0-2095></a><span class=sd>        iterations may then be excessive. Default is 1e8.</span>
<a id=__codelineno-0-2096 name=__codelineno-0-2096></a><span class=sd>    maxiter : int, optional</span>
<a id=__codelineno-0-2097 name=__codelineno-0-2097></a><span class=sd>        `lsmr` terminates if the number of iterations reaches</span>
<a id=__codelineno-0-2098 name=__codelineno-0-2098></a><span class=sd>        `maxiter`.  The default is ``maxiter = min(m, n)``.  For</span>
<a id=__codelineno-0-2099 name=__codelineno-0-2099></a><span class=sd>        ill-conditioned systems, a larger value of `maxiter` may be</span>
<a id=__codelineno-0-2100 name=__codelineno-0-2100></a><span class=sd>        needed. Default is False.</span>
<a id=__codelineno-0-2101 name=__codelineno-0-2101></a><span class=sd>    show : bool, optional</span>
<a id=__codelineno-0-2102 name=__codelineno-0-2102></a><span class=sd>        Print iterations logs if ``show=True``. Default is False.</span>
<a id=__codelineno-0-2103 name=__codelineno-0-2103></a><span class=sd>    x0 : array_like, shape (n,), optional</span>
<a id=__codelineno-0-2104 name=__codelineno-0-2104></a><span class=sd>        Initial guess of ``x``, if None zeros are used. Default is None.</span>
<a id=__codelineno-0-2105 name=__codelineno-0-2105></a>
<a id=__codelineno-0-2106 name=__codelineno-0-2106></a><span class=sd>    References</span>
<a id=__codelineno-0-2107 name=__codelineno-0-2107></a><span class=sd>    ----------</span>
<a id=__codelineno-0-2108 name=__codelineno-0-2108></a><span class=sd>    .. [1] D. C.-L. Fong and M. A. Saunders,</span>
<a id=__codelineno-0-2109 name=__codelineno-0-2109></a><span class=sd>           &quot;LSMR: An iterative algorithm for sparse least-squares problems&quot;,</span>
<a id=__codelineno-0-2110 name=__codelineno-0-2110></a><span class=sd>           SIAM J. Sci. Comput., vol. 33, pp. 2950-2971, 2011.</span>
<a id=__codelineno-0-2111 name=__codelineno-0-2111></a><span class=sd>           :arxiv:`1006.0758`</span>
<a id=__codelineno-0-2112 name=__codelineno-0-2112></a><span class=sd>    .. [2] LSMR Software, https://web.stanford.edu/group/SOL/software/lsmr/</span>
<a id=__codelineno-0-2113 name=__codelineno-0-2113></a>
<a id=__codelineno-0-2114 name=__codelineno-0-2114></a><span class=sd>    Notes</span>
<a id=__codelineno-0-2115 name=__codelineno-0-2115></a><span class=sd>    -----</span>
<a id=__codelineno-0-2116 name=__codelineno-0-2116></a><span class=sd>    This docstring is adapted from the `scipy.sparse.linalg.lsmr` method.</span>
<a id=__codelineno-0-2117 name=__codelineno-0-2117></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-2118 name=__codelineno-0-2118></a>
<a id=__codelineno-0-2119 name=__codelineno-0-2119></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span>
<a id=__codelineno-0-2120 name=__codelineno-0-2120></a>        <span class=bp>self</span><span class=p>,</span>
<a id=__codelineno-0-2121 name=__codelineno-0-2121></a>        <span class=o>*</span><span class=p>,</span>
<a id=__codelineno-0-2122 name=__codelineno-0-2122></a>        <span class=n>unbiased</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>
<a id=__codelineno-0-2123 name=__codelineno-0-2123></a>        <span class=n>uiter</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>30</span><span class=p>,</span>
<a id=__codelineno-0-2124 name=__codelineno-0-2124></a>        <span class=n>damp</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span>
<a id=__codelineno-0-2125 name=__codelineno-0-2125></a>        <span class=n>atol</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>,</span>
<a id=__codelineno-0-2126 name=__codelineno-0-2126></a>        <span class=n>btol</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>,</span>
<a id=__codelineno-0-2127 name=__codelineno-0-2127></a>        <span class=n>conlim</span><span class=o>=</span><span class=mf>1e8</span><span class=p>,</span>
<a id=__codelineno-0-2128 name=__codelineno-0-2128></a>        <span class=n>maxiter</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
<a id=__codelineno-0-2129 name=__codelineno-0-2129></a>        <span class=n>show</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
<a id=__codelineno-0-2130 name=__codelineno-0-2130></a>        <span class=n>x0</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
<a id=__codelineno-0-2131 name=__codelineno-0-2131></a>    <span class=p>):</span>
<a id=__codelineno-0-2132 name=__codelineno-0-2132></a>        <span class=bp>self</span><span class=o>.</span><span class=n>unbiased</span> <span class=o>=</span> <span class=n>unbiased</span>
<a id=__codelineno-0-2133 name=__codelineno-0-2133></a>        <span class=bp>self</span><span class=o>.</span><span class=n>uiter</span> <span class=o>=</span> <span class=n>uiter</span>
<a id=__codelineno-0-2134 name=__codelineno-0-2134></a>        <span class=bp>self</span><span class=o>.</span><span class=n>damp</span> <span class=o>=</span> <span class=n>damp</span>
<a id=__codelineno-0-2135 name=__codelineno-0-2135></a>        <span class=bp>self</span><span class=o>.</span><span class=n>atol</span> <span class=o>=</span> <span class=n>atol</span>
<a id=__codelineno-0-2136 name=__codelineno-0-2136></a>        <span class=bp>self</span><span class=o>.</span><span class=n>btol</span> <span class=o>=</span> <span class=n>btol</span>
<a id=__codelineno-0-2137 name=__codelineno-0-2137></a>        <span class=bp>self</span><span class=o>.</span><span class=n>conlim</span> <span class=o>=</span> <span class=n>conlim</span>
<a id=__codelineno-0-2138 name=__codelineno-0-2138></a>        <span class=bp>self</span><span class=o>.</span><span class=n>maxiter</span> <span class=o>=</span> <span class=n>maxiter</span>
<a id=__codelineno-0-2139 name=__codelineno-0-2139></a>        <span class=bp>self</span><span class=o>.</span><span class=n>show</span> <span class=o>=</span> <span class=n>show</span>
<a id=__codelineno-0-2140 name=__codelineno-0-2140></a>        <span class=bp>self</span><span class=o>.</span><span class=n>x0</span> <span class=o>=</span> <span class=n>x0</span>
<a id=__codelineno-0-2141 name=__codelineno-0-2141></a>
<a id=__codelineno-0-2142 name=__codelineno-0-2142></a>    <span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
<a id=__codelineno-0-2143 name=__codelineno-0-2143></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Mixed-norm LMS filter.</span>
<a id=__codelineno-0-2144 name=__codelineno-0-2144></a>
<a id=__codelineno-0-2145 name=__codelineno-0-2145></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-2146 name=__codelineno-0-2146></a><span class=sd>        ----------</span>
<a id=__codelineno-0-2147 name=__codelineno-0-2147></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-2148 name=__codelineno-0-2148></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-2149 name=__codelineno-0-2149></a><span class=sd>        y : ndarray of floats of shape (n_samples, 1)</span>
<a id=__codelineno-0-2150 name=__codelineno-0-2150></a><span class=sd>            The data used to train the model.</span>
<a id=__codelineno-0-2151 name=__codelineno-0-2151></a>
<a id=__codelineno-0-2152 name=__codelineno-0-2152></a><span class=sd>        Returns</span>
<a id=__codelineno-0-2153 name=__codelineno-0-2153></a><span class=sd>        -------</span>
<a id=__codelineno-0-2154 name=__codelineno-0-2154></a><span class=sd>        theta : array-like of shape = number_of_model_elements</span>
<a id=__codelineno-0-2155 name=__codelineno-0-2155></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-2156 name=__codelineno-0-2156></a>
<a id=__codelineno-0-2157 name=__codelineno-0-2157></a><span class=sd>        Notes</span>
<a id=__codelineno-0-2158 name=__codelineno-0-2158></a><span class=sd>        -----</span>
<a id=__codelineno-0-2159 name=__codelineno-0-2159></a><span class=sd>        This is a wrapper class for the `scipy.sparse.linalg.lsmr` method.</span>
<a id=__codelineno-0-2160 name=__codelineno-0-2160></a>
<a id=__codelineno-0-2161 name=__codelineno-0-2161></a><span class=sd>        References</span>
<a id=__codelineno-0-2162 name=__codelineno-0-2162></a><span class=sd>        ----------</span>
<a id=__codelineno-0-2163 name=__codelineno-0-2163></a><span class=sd>        .. [1] scipy, https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.lsmr.html</span>
<a id=__codelineno-0-2164 name=__codelineno-0-2164></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-2165 name=__codelineno-0-2165></a>        <span class=n>theta</span> <span class=o>=</span> <span class=n>lsmr</span><span class=p>(</span>
<a id=__codelineno-0-2166 name=__codelineno-0-2166></a>            <span class=n>psi</span><span class=p>,</span>
<a id=__codelineno-0-2167 name=__codelineno-0-2167></a>            <span class=n>y</span><span class=o>.</span><span class=n>ravel</span><span class=p>(),</span>
<a id=__codelineno-0-2168 name=__codelineno-0-2168></a>            <span class=n>damp</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>damp</span><span class=p>,</span>
<a id=__codelineno-0-2169 name=__codelineno-0-2169></a>            <span class=n>atol</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>atol</span><span class=p>,</span>
<a id=__codelineno-0-2170 name=__codelineno-0-2170></a>            <span class=n>btol</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>btol</span><span class=p>,</span>
<a id=__codelineno-0-2171 name=__codelineno-0-2171></a>            <span class=n>conlim</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>conlim</span><span class=p>,</span>
<a id=__codelineno-0-2172 name=__codelineno-0-2172></a>            <span class=n>maxiter</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>maxiter</span><span class=p>,</span>
<a id=__codelineno-0-2173 name=__codelineno-0-2173></a>            <span class=n>show</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>show</span><span class=p>,</span>
<a id=__codelineno-0-2174 name=__codelineno-0-2174></a>            <span class=n>x0</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>x0</span><span class=p>,</span>
<a id=__codelineno-0-2175 name=__codelineno-0-2175></a>        <span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-2176 name=__codelineno-0-2176></a>        <span class=k>return</span> <span class=n>theta</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.LeastSquaresMinimalResidual.optimize class="doc doc-heading"> <code class="highlight language-python"><span class=n>optimize</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.LeastSquaresMinimalResidual.optimize class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Parameter estimation using the Mixed-norm LMS filter.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>ndarray of floats of shape (n_samples, 1)</code> </td> <td> <div class=doc-md-description> <p>The data used to train the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>array-like of shape = number_of_model_elements</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=note open> <summary>Notes</summary> <p>This is a wrapper class for the <code>scipy.sparse.linalg.lsmr</code> method.</p> </details> <details class=references open> <summary>References</summary> <p>.. [1] scipy, <a href=https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.lsmr.html>https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.lsmr.html</a></p> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-2142>2142</a></span>
<span class=normal><a href=#__codelineno-0-2143>2143</a></span>
<span class=normal><a href=#__codelineno-0-2144>2144</a></span>
<span class=normal><a href=#__codelineno-0-2145>2145</a></span>
<span class=normal><a href=#__codelineno-0-2146>2146</a></span>
<span class=normal><a href=#__codelineno-0-2147>2147</a></span>
<span class=normal><a href=#__codelineno-0-2148>2148</a></span>
<span class=normal><a href=#__codelineno-0-2149>2149</a></span>
<span class=normal><a href=#__codelineno-0-2150>2150</a></span>
<span class=normal><a href=#__codelineno-0-2151>2151</a></span>
<span class=normal><a href=#__codelineno-0-2152>2152</a></span>
<span class=normal><a href=#__codelineno-0-2153>2153</a></span>
<span class=normal><a href=#__codelineno-0-2154>2154</a></span>
<span class=normal><a href=#__codelineno-0-2155>2155</a></span>
<span class=normal><a href=#__codelineno-0-2156>2156</a></span>
<span class=normal><a href=#__codelineno-0-2157>2157</a></span>
<span class=normal><a href=#__codelineno-0-2158>2158</a></span>
<span class=normal><a href=#__codelineno-0-2159>2159</a></span>
<span class=normal><a href=#__codelineno-0-2160>2160</a></span>
<span class=normal><a href=#__codelineno-0-2161>2161</a></span>
<span class=normal><a href=#__codelineno-0-2162>2162</a></span>
<span class=normal><a href=#__codelineno-0-2163>2163</a></span>
<span class=normal><a href=#__codelineno-0-2164>2164</a></span>
<span class=normal><a href=#__codelineno-0-2165>2165</a></span>
<span class=normal><a href=#__codelineno-0-2166>2166</a></span>
<span class=normal><a href=#__codelineno-0-2167>2167</a></span>
<span class=normal><a href=#__codelineno-0-2168>2168</a></span>
<span class=normal><a href=#__codelineno-0-2169>2169</a></span>
<span class=normal><a href=#__codelineno-0-2170>2170</a></span>
<span class=normal><a href=#__codelineno-0-2171>2171</a></span>
<span class=normal><a href=#__codelineno-0-2172>2172</a></span>
<span class=normal><a href=#__codelineno-0-2173>2173</a></span>
<span class=normal><a href=#__codelineno-0-2174>2174</a></span>
<span class=normal><a href=#__codelineno-0-2175>2175</a></span>
<span class=normal><a href=#__codelineno-0-2176>2176</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-2142 name=__codelineno-0-2142></a><span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
<a id=__codelineno-0-2143 name=__codelineno-0-2143></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Mixed-norm LMS filter.</span>
<a id=__codelineno-0-2144 name=__codelineno-0-2144></a>
<a id=__codelineno-0-2145 name=__codelineno-0-2145></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-2146 name=__codelineno-0-2146></a><span class=sd>    ----------</span>
<a id=__codelineno-0-2147 name=__codelineno-0-2147></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-2148 name=__codelineno-0-2148></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-2149 name=__codelineno-0-2149></a><span class=sd>    y : ndarray of floats of shape (n_samples, 1)</span>
<a id=__codelineno-0-2150 name=__codelineno-0-2150></a><span class=sd>        The data used to train the model.</span>
<a id=__codelineno-0-2151 name=__codelineno-0-2151></a>
<a id=__codelineno-0-2152 name=__codelineno-0-2152></a><span class=sd>    Returns</span>
<a id=__codelineno-0-2153 name=__codelineno-0-2153></a><span class=sd>    -------</span>
<a id=__codelineno-0-2154 name=__codelineno-0-2154></a><span class=sd>    theta : array-like of shape = number_of_model_elements</span>
<a id=__codelineno-0-2155 name=__codelineno-0-2155></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-2156 name=__codelineno-0-2156></a>
<a id=__codelineno-0-2157 name=__codelineno-0-2157></a><span class=sd>    Notes</span>
<a id=__codelineno-0-2158 name=__codelineno-0-2158></a><span class=sd>    -----</span>
<a id=__codelineno-0-2159 name=__codelineno-0-2159></a><span class=sd>    This is a wrapper class for the `scipy.sparse.linalg.lsmr` method.</span>
<a id=__codelineno-0-2160 name=__codelineno-0-2160></a>
<a id=__codelineno-0-2161 name=__codelineno-0-2161></a><span class=sd>    References</span>
<a id=__codelineno-0-2162 name=__codelineno-0-2162></a><span class=sd>    ----------</span>
<a id=__codelineno-0-2163 name=__codelineno-0-2163></a><span class=sd>    .. [1] scipy, https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.lsmr.html</span>
<a id=__codelineno-0-2164 name=__codelineno-0-2164></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-2165 name=__codelineno-0-2165></a>    <span class=n>theta</span> <span class=o>=</span> <span class=n>lsmr</span><span class=p>(</span>
<a id=__codelineno-0-2166 name=__codelineno-0-2166></a>        <span class=n>psi</span><span class=p>,</span>
<a id=__codelineno-0-2167 name=__codelineno-0-2167></a>        <span class=n>y</span><span class=o>.</span><span class=n>ravel</span><span class=p>(),</span>
<a id=__codelineno-0-2168 name=__codelineno-0-2168></a>        <span class=n>damp</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>damp</span><span class=p>,</span>
<a id=__codelineno-0-2169 name=__codelineno-0-2169></a>        <span class=n>atol</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>atol</span><span class=p>,</span>
<a id=__codelineno-0-2170 name=__codelineno-0-2170></a>        <span class=n>btol</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>btol</span><span class=p>,</span>
<a id=__codelineno-0-2171 name=__codelineno-0-2171></a>        <span class=n>conlim</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>conlim</span><span class=p>,</span>
<a id=__codelineno-0-2172 name=__codelineno-0-2172></a>        <span class=n>maxiter</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>maxiter</span><span class=p>,</span>
<a id=__codelineno-0-2173 name=__codelineno-0-2173></a>        <span class=n>show</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>show</span><span class=p>,</span>
<a id=__codelineno-0-2174 name=__codelineno-0-2174></a>        <span class=n>x0</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>x0</span><span class=p>,</span>
<a id=__codelineno-0-2175 name=__codelineno-0-2175></a>    <span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-2176 name=__codelineno-0-2176></a>    <span class=k>return</span> <span class=n>theta</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.NonNegativeLeastSquares class="doc doc-heading"> <code>NonNegativeLeastSquares</code> <a href=#sysidentpy.parameter_estimation.estimators.NonNegativeLeastSquares class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=sysidentpy.parameter_estimation.estimators_base.BaseEstimator>BaseEstimator</span></code></p> <p>Solve <code>argmin_x || Ax - b ||_2</code> for <code>x &gt;= 0</code>.</p> <p>This is a wrapper class for the <code>scipy.optimize.nnls</code> method.</p> <p>This problem, often called NonNegative Least Squares (NNLS), is a convex optimization problem with convex constraints. It typically arises when the <code>x</code> models quantities for which only nonnegative values are attainable; such as weights of ingredients, component costs, and so on.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>unbiased</code> </td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>If True, applies an unbiased estimator. Default is False.</p> </div> </td> <td> <code>False</code> </td> </tr> <tr class=doc-section-item> <td> <code>uiter</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of iterations for the unbiased estimator. Default is 30.</p> </div> </td> <td> <code>30</code> </td> </tr> <tr class=doc-section-item> <td> <code>maxiter</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Maximum number of iterations. Default value is <code>3 * n</code> where <code>n</code> is the number of features.</p> </div> </td> <td> <code>None</code> </td> </tr> <tr class=doc-section-item> <td> <code>atol</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>Tolerance value used in the algorithm to assess closeness to zero in the projected residual <code>(A.T @ (A x - b))</code> entries. Increasing this value relaxes the solution constraints. A typical relaxation value can be selected as <code>max(m, n) * np.linalg.norm(A, 1) * np.spacing(1.)</code>. Default is None.</p> </div> </td> <td> <code>None</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Attributes:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.NonNegativeLeastSquares.unbiased>unbiased</span></code></td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>Indicates whether an unbiased estimator is applied.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.NonNegativeLeastSquares.uiter>uiter</span></code></td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of iterations for the unbiased estimator.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.NonNegativeLeastSquares.maxiter>maxiter</span></code></td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Maximum number of iterations.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.NonNegativeLeastSquares.atol>atol</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>Tolerance value for the algorithm.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <p>Lawson C., Hanson R.J., "Solving Least Squares Problems", SIAM, 1995, :doi:<code>10.1137/1.9781611971217</code> Bro, Rasmus and de Jong, Sijmen, "A Fast Non-Negativity-Constrained Least Squares Algorithm", Journal Of Chemometrics, 1997, :doi:<code>10.1002/(SICI)1099-128X(199709/10)11:5&lt;393::AID-CEM483&gt;3.0.CO;2-L</code></p> </details> <p><span class=doc-section-title>Examples:</span></p> <div class=highlight><pre><span></span><code><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=gp>&gt;&gt;&gt; </span><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
<a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=gp>&gt;&gt;&gt; </span><span class=kn>from</span><span class=w> </span><span class=nn>sysidentpy.parameter_estimation</span><span class=w> </span><span class=kn>import</span> <span class=n>NonNegativeLeastSquares</span>
<a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=gp>...</span>
<a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=gp>&gt;&gt;&gt; </span><span class=n>A</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>]])</span>
<a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=gp>&gt;&gt;&gt; </span><span class=n>b</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>])</span>
<a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a><span class=gp>&gt;&gt;&gt; </span><span class=n>nnls_solver</span> <span class=o>=</span> <span class=n>NonNegativeLeastSquares</span><span class=p>()</span>
<a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a><span class=gp>&gt;&gt;&gt; </span><span class=n>x</span> <span class=o>=</span> <span class=n>nnls_solver</span><span class=o>.</span><span class=n>optimize</span><span class=p>(</span><span class=n>A</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>
<a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a><span class=gp>&gt;&gt;&gt; </span><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
<a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a><span class=go>[[1.5]</span>
<a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a><span class=go> [1. ]]</span>
</code></pre></div> <div class=highlight><pre><span></span><code><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=gp>&gt;&gt;&gt; </span><span class=n>b</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>])</span>
<a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=gp>&gt;&gt;&gt; </span><span class=n>x</span> <span class=o>=</span> <span class=n>nnls_solver</span><span class=o>.</span><span class=n>optimize</span><span class=p>(</span><span class=n>A</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>
<a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=gp>&gt;&gt;&gt; </span><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
<a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=go>[[0.]</span>
<a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=go> [0.]]</span>
</code></pre></div> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-1756>1756</a></span>
<span class=normal><a href=#__codelineno-0-1757>1757</a></span>
<span class=normal><a href=#__codelineno-0-1758>1758</a></span>
<span class=normal><a href=#__codelineno-0-1759>1759</a></span>
<span class=normal><a href=#__codelineno-0-1760>1760</a></span>
<span class=normal><a href=#__codelineno-0-1761>1761</a></span>
<span class=normal><a href=#__codelineno-0-1762>1762</a></span>
<span class=normal><a href=#__codelineno-0-1763>1763</a></span>
<span class=normal><a href=#__codelineno-0-1764>1764</a></span>
<span class=normal><a href=#__codelineno-0-1765>1765</a></span>
<span class=normal><a href=#__codelineno-0-1766>1766</a></span>
<span class=normal><a href=#__codelineno-0-1767>1767</a></span>
<span class=normal><a href=#__codelineno-0-1768>1768</a></span>
<span class=normal><a href=#__codelineno-0-1769>1769</a></span>
<span class=normal><a href=#__codelineno-0-1770>1770</a></span>
<span class=normal><a href=#__codelineno-0-1771>1771</a></span>
<span class=normal><a href=#__codelineno-0-1772>1772</a></span>
<span class=normal><a href=#__codelineno-0-1773>1773</a></span>
<span class=normal><a href=#__codelineno-0-1774>1774</a></span>
<span class=normal><a href=#__codelineno-0-1775>1775</a></span>
<span class=normal><a href=#__codelineno-0-1776>1776</a></span>
<span class=normal><a href=#__codelineno-0-1777>1777</a></span>
<span class=normal><a href=#__codelineno-0-1778>1778</a></span>
<span class=normal><a href=#__codelineno-0-1779>1779</a></span>
<span class=normal><a href=#__codelineno-0-1780>1780</a></span>
<span class=normal><a href=#__codelineno-0-1781>1781</a></span>
<span class=normal><a href=#__codelineno-0-1782>1782</a></span>
<span class=normal><a href=#__codelineno-0-1783>1783</a></span>
<span class=normal><a href=#__codelineno-0-1784>1784</a></span>
<span class=normal><a href=#__codelineno-0-1785>1785</a></span>
<span class=normal><a href=#__codelineno-0-1786>1786</a></span>
<span class=normal><a href=#__codelineno-0-1787>1787</a></span>
<span class=normal><a href=#__codelineno-0-1788>1788</a></span>
<span class=normal><a href=#__codelineno-0-1789>1789</a></span>
<span class=normal><a href=#__codelineno-0-1790>1790</a></span>
<span class=normal><a href=#__codelineno-0-1791>1791</a></span>
<span class=normal><a href=#__codelineno-0-1792>1792</a></span>
<span class=normal><a href=#__codelineno-0-1793>1793</a></span>
<span class=normal><a href=#__codelineno-0-1794>1794</a></span>
<span class=normal><a href=#__codelineno-0-1795>1795</a></span>
<span class=normal><a href=#__codelineno-0-1796>1796</a></span>
<span class=normal><a href=#__codelineno-0-1797>1797</a></span>
<span class=normal><a href=#__codelineno-0-1798>1798</a></span>
<span class=normal><a href=#__codelineno-0-1799>1799</a></span>
<span class=normal><a href=#__codelineno-0-1800>1800</a></span>
<span class=normal><a href=#__codelineno-0-1801>1801</a></span>
<span class=normal><a href=#__codelineno-0-1802>1802</a></span>
<span class=normal><a href=#__codelineno-0-1803>1803</a></span>
<span class=normal><a href=#__codelineno-0-1804>1804</a></span>
<span class=normal><a href=#__codelineno-0-1805>1805</a></span>
<span class=normal><a href=#__codelineno-0-1806>1806</a></span>
<span class=normal><a href=#__codelineno-0-1807>1807</a></span>
<span class=normal><a href=#__codelineno-0-1808>1808</a></span>
<span class=normal><a href=#__codelineno-0-1809>1809</a></span>
<span class=normal><a href=#__codelineno-0-1810>1810</a></span>
<span class=normal><a href=#__codelineno-0-1811>1811</a></span>
<span class=normal><a href=#__codelineno-0-1812>1812</a></span>
<span class=normal><a href=#__codelineno-0-1813>1813</a></span>
<span class=normal><a href=#__codelineno-0-1814>1814</a></span>
<span class=normal><a href=#__codelineno-0-1815>1815</a></span>
<span class=normal><a href=#__codelineno-0-1816>1816</a></span>
<span class=normal><a href=#__codelineno-0-1817>1817</a></span>
<span class=normal><a href=#__codelineno-0-1818>1818</a></span>
<span class=normal><a href=#__codelineno-0-1819>1819</a></span>
<span class=normal><a href=#__codelineno-0-1820>1820</a></span>
<span class=normal><a href=#__codelineno-0-1821>1821</a></span>
<span class=normal><a href=#__codelineno-0-1822>1822</a></span>
<span class=normal><a href=#__codelineno-0-1823>1823</a></span>
<span class=normal><a href=#__codelineno-0-1824>1824</a></span>
<span class=normal><a href=#__codelineno-0-1825>1825</a></span>
<span class=normal><a href=#__codelineno-0-1826>1826</a></span>
<span class=normal><a href=#__codelineno-0-1827>1827</a></span>
<span class=normal><a href=#__codelineno-0-1828>1828</a></span>
<span class=normal><a href=#__codelineno-0-1829>1829</a></span>
<span class=normal><a href=#__codelineno-0-1830>1830</a></span>
<span class=normal><a href=#__codelineno-0-1831>1831</a></span>
<span class=normal><a href=#__codelineno-0-1832>1832</a></span>
<span class=normal><a href=#__codelineno-0-1833>1833</a></span>
<span class=normal><a href=#__codelineno-0-1834>1834</a></span>
<span class=normal><a href=#__codelineno-0-1835>1835</a></span>
<span class=normal><a href=#__codelineno-0-1836>1836</a></span>
<span class=normal><a href=#__codelineno-0-1837>1837</a></span>
<span class=normal><a href=#__codelineno-0-1838>1838</a></span>
<span class=normal><a href=#__codelineno-0-1839>1839</a></span>
<span class=normal><a href=#__codelineno-0-1840>1840</a></span>
<span class=normal><a href=#__codelineno-0-1841>1841</a></span>
<span class=normal><a href=#__codelineno-0-1842>1842</a></span>
<span class=normal><a href=#__codelineno-0-1843>1843</a></span>
<span class=normal><a href=#__codelineno-0-1844>1844</a></span>
<span class=normal><a href=#__codelineno-0-1845>1845</a></span>
<span class=normal><a href=#__codelineno-0-1846>1846</a></span>
<span class=normal><a href=#__codelineno-0-1847>1847</a></span>
<span class=normal><a href=#__codelineno-0-1848>1848</a></span>
<span class=normal><a href=#__codelineno-0-1849>1849</a></span>
<span class=normal><a href=#__codelineno-0-1850>1850</a></span>
<span class=normal><a href=#__codelineno-0-1851>1851</a></span>
<span class=normal><a href=#__codelineno-0-1852>1852</a></span>
<span class=normal><a href=#__codelineno-0-1853>1853</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-1756 name=__codelineno-0-1756></a><span class=k>class</span><span class=w> </span><span class=nc>NonNegativeLeastSquares</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>):</span>
<a id=__codelineno-0-1757 name=__codelineno-0-1757></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Solve ``argmin_x || Ax - b ||_2`` for ``x &gt;= 0``.</span>
<a id=__codelineno-0-1758 name=__codelineno-0-1758></a>
<a id=__codelineno-0-1759 name=__codelineno-0-1759></a><span class=sd>    This is a wrapper class for the `scipy.optimize.nnls` method.</span>
<a id=__codelineno-0-1760 name=__codelineno-0-1760></a>
<a id=__codelineno-0-1761 name=__codelineno-0-1761></a><span class=sd>    This problem, often called NonNegative Least Squares (NNLS), is a convex</span>
<a id=__codelineno-0-1762 name=__codelineno-0-1762></a><span class=sd>    optimization problem with convex constraints. It typically arises when</span>
<a id=__codelineno-0-1763 name=__codelineno-0-1763></a><span class=sd>    the ``x`` models quantities for which only nonnegative values are</span>
<a id=__codelineno-0-1764 name=__codelineno-0-1764></a><span class=sd>    attainable; such as weights of ingredients, component costs, and so on.</span>
<a id=__codelineno-0-1765 name=__codelineno-0-1765></a>
<a id=__codelineno-0-1766 name=__codelineno-0-1766></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-1767 name=__codelineno-0-1767></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1768 name=__codelineno-0-1768></a><span class=sd>    unbiased : bool, optional</span>
<a id=__codelineno-0-1769 name=__codelineno-0-1769></a><span class=sd>        If True, applies an unbiased estimator. Default is False.</span>
<a id=__codelineno-0-1770 name=__codelineno-0-1770></a><span class=sd>    uiter : int, optional</span>
<a id=__codelineno-0-1771 name=__codelineno-0-1771></a><span class=sd>        Number of iterations for the unbiased estimator. Default is 30.</span>
<a id=__codelineno-0-1772 name=__codelineno-0-1772></a><span class=sd>    maxiter : int, optional</span>
<a id=__codelineno-0-1773 name=__codelineno-0-1773></a><span class=sd>        Maximum number of iterations. Default value is ``3 * n`` where ``n``</span>
<a id=__codelineno-0-1774 name=__codelineno-0-1774></a><span class=sd>        is the number of features.</span>
<a id=__codelineno-0-1775 name=__codelineno-0-1775></a><span class=sd>    atol : float, optional</span>
<a id=__codelineno-0-1776 name=__codelineno-0-1776></a><span class=sd>        Tolerance value used in the algorithm to assess closeness to zero in</span>
<a id=__codelineno-0-1777 name=__codelineno-0-1777></a><span class=sd>        the projected residual ``(A.T @ (A x - b))`` entries. Increasing this</span>
<a id=__codelineno-0-1778 name=__codelineno-0-1778></a><span class=sd>        value relaxes the solution constraints. A typical relaxation value can</span>
<a id=__codelineno-0-1779 name=__codelineno-0-1779></a><span class=sd>        be selected as ``max(m, n) * np.linalg.norm(A, 1) * np.spacing(1.)``.</span>
<a id=__codelineno-0-1780 name=__codelineno-0-1780></a><span class=sd>        Default is None.</span>
<a id=__codelineno-0-1781 name=__codelineno-0-1781></a>
<a id=__codelineno-0-1782 name=__codelineno-0-1782></a><span class=sd>    Attributes</span>
<a id=__codelineno-0-1783 name=__codelineno-0-1783></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1784 name=__codelineno-0-1784></a><span class=sd>    unbiased : bool</span>
<a id=__codelineno-0-1785 name=__codelineno-0-1785></a><span class=sd>        Indicates whether an unbiased estimator is applied.</span>
<a id=__codelineno-0-1786 name=__codelineno-0-1786></a><span class=sd>    uiter : int</span>
<a id=__codelineno-0-1787 name=__codelineno-0-1787></a><span class=sd>        Number of iterations for the unbiased estimator.</span>
<a id=__codelineno-0-1788 name=__codelineno-0-1788></a><span class=sd>    maxiter : int</span>
<a id=__codelineno-0-1789 name=__codelineno-0-1789></a><span class=sd>        Maximum number of iterations.</span>
<a id=__codelineno-0-1790 name=__codelineno-0-1790></a><span class=sd>    atol : float</span>
<a id=__codelineno-0-1791 name=__codelineno-0-1791></a><span class=sd>        Tolerance value for the algorithm.</span>
<a id=__codelineno-0-1792 name=__codelineno-0-1792></a>
<a id=__codelineno-0-1793 name=__codelineno-0-1793></a><span class=sd>    References</span>
<a id=__codelineno-0-1794 name=__codelineno-0-1794></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1795 name=__codelineno-0-1795></a><span class=sd>    Lawson C., Hanson R.J., &quot;Solving Least Squares Problems&quot;, SIAM,</span>
<a id=__codelineno-0-1796 name=__codelineno-0-1796></a><span class=sd>       1995, :doi:`10.1137/1.9781611971217`</span>
<a id=__codelineno-0-1797 name=__codelineno-0-1797></a><span class=sd>    Bro, Rasmus and de Jong, Sijmen, &quot;A Fast Non-Negativity-Constrained Least</span>
<a id=__codelineno-0-1798 name=__codelineno-0-1798></a><span class=sd>        Squares Algorithm&quot;, Journal Of Chemometrics, 1997,</span>
<a id=__codelineno-0-1799 name=__codelineno-0-1799></a><span class=sd>        :doi:`10.1002/(SICI)1099-128X(199709/10)11:5&lt;393::AID-CEM483&gt;3.0.CO;2-L`</span>
<a id=__codelineno-0-1800 name=__codelineno-0-1800></a>
<a id=__codelineno-0-1801 name=__codelineno-0-1801></a><span class=sd>    Examples</span>
<a id=__codelineno-0-1802 name=__codelineno-0-1802></a><span class=sd>    --------</span>
<a id=__codelineno-0-1803 name=__codelineno-0-1803></a><span class=sd>    &gt;&gt;&gt; import numpy as np</span>
<a id=__codelineno-0-1804 name=__codelineno-0-1804></a><span class=sd>    &gt;&gt;&gt; from sysidentpy.parameter_estimation import NonNegativeLeastSquares</span>
<a id=__codelineno-0-1805 name=__codelineno-0-1805></a><span class=sd>    ...</span>
<a id=__codelineno-0-1806 name=__codelineno-0-1806></a><span class=sd>    &gt;&gt;&gt; A = np.array([[1, 0], [1, 0], [0, 1]])</span>
<a id=__codelineno-0-1807 name=__codelineno-0-1807></a><span class=sd>    &gt;&gt;&gt; b = np.array([2, 1, 1])</span>
<a id=__codelineno-0-1808 name=__codelineno-0-1808></a><span class=sd>    &gt;&gt;&gt; nnls_solver = NonNegativeLeastSquares()</span>
<a id=__codelineno-0-1809 name=__codelineno-0-1809></a><span class=sd>    &gt;&gt;&gt; x = nnls_solver.optimize(A, b)</span>
<a id=__codelineno-0-1810 name=__codelineno-0-1810></a><span class=sd>    &gt;&gt;&gt; print(x)</span>
<a id=__codelineno-0-1811 name=__codelineno-0-1811></a><span class=sd>    [[1.5]</span>
<a id=__codelineno-0-1812 name=__codelineno-0-1812></a><span class=sd>     [1. ]]</span>
<a id=__codelineno-0-1813 name=__codelineno-0-1813></a>
<a id=__codelineno-0-1814 name=__codelineno-0-1814></a><span class=sd>    &gt;&gt;&gt; b = np.array([-1, -1, -1])</span>
<a id=__codelineno-0-1815 name=__codelineno-0-1815></a><span class=sd>    &gt;&gt;&gt; x = nnls_solver.optimize(A, b)</span>
<a id=__codelineno-0-1816 name=__codelineno-0-1816></a><span class=sd>    &gt;&gt;&gt; print(x)</span>
<a id=__codelineno-0-1817 name=__codelineno-0-1817></a><span class=sd>    [[0.]</span>
<a id=__codelineno-0-1818 name=__codelineno-0-1818></a><span class=sd>     [0.]]</span>
<a id=__codelineno-0-1819 name=__codelineno-0-1819></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-1820 name=__codelineno-0-1820></a>
<a id=__codelineno-0-1821 name=__codelineno-0-1821></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span>
<a id=__codelineno-0-1822 name=__codelineno-0-1822></a>        <span class=bp>self</span><span class=p>,</span> <span class=n>unbiased</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span> <span class=n>uiter</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>30</span><span class=p>,</span> <span class=n>maxiter</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>atol</span><span class=o>=</span><span class=kc>None</span>
<a id=__codelineno-0-1823 name=__codelineno-0-1823></a>    <span class=p>):</span>
<a id=__codelineno-0-1824 name=__codelineno-0-1824></a>        <span class=bp>self</span><span class=o>.</span><span class=n>unbiased</span> <span class=o>=</span> <span class=n>unbiased</span>
<a id=__codelineno-0-1825 name=__codelineno-0-1825></a>        <span class=bp>self</span><span class=o>.</span><span class=n>uiter</span> <span class=o>=</span> <span class=n>uiter</span>
<a id=__codelineno-0-1826 name=__codelineno-0-1826></a>        <span class=bp>self</span><span class=o>.</span><span class=n>maxiter</span> <span class=o>=</span> <span class=n>maxiter</span>
<a id=__codelineno-0-1827 name=__codelineno-0-1827></a>        <span class=bp>self</span><span class=o>.</span><span class=n>atol</span> <span class=o>=</span> <span class=n>atol</span>
<a id=__codelineno-0-1828 name=__codelineno-0-1828></a>
<a id=__codelineno-0-1829 name=__codelineno-0-1829></a>    <span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
<a id=__codelineno-0-1830 name=__codelineno-0-1830></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Parameter estimation using the NonNegativeLeastSquares algorithm.</span>
<a id=__codelineno-0-1831 name=__codelineno-0-1831></a>
<a id=__codelineno-0-1832 name=__codelineno-0-1832></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-1833 name=__codelineno-0-1833></a><span class=sd>        ----------</span>
<a id=__codelineno-0-1834 name=__codelineno-0-1834></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-1835 name=__codelineno-0-1835></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-1836 name=__codelineno-0-1836></a><span class=sd>        y : ndarray of floats of shape (n_samples, 1)</span>
<a id=__codelineno-0-1837 name=__codelineno-0-1837></a><span class=sd>            The data used to train the model.</span>
<a id=__codelineno-0-1838 name=__codelineno-0-1838></a>
<a id=__codelineno-0-1839 name=__codelineno-0-1839></a><span class=sd>        Returns</span>
<a id=__codelineno-0-1840 name=__codelineno-0-1840></a><span class=sd>        -------</span>
<a id=__codelineno-0-1841 name=__codelineno-0-1841></a><span class=sd>        theta : array-like of shape = number_of_model_elements</span>
<a id=__codelineno-0-1842 name=__codelineno-0-1842></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-1843 name=__codelineno-0-1843></a>
<a id=__codelineno-0-1844 name=__codelineno-0-1844></a><span class=sd>        Notes</span>
<a id=__codelineno-0-1845 name=__codelineno-0-1845></a><span class=sd>        -----</span>
<a id=__codelineno-0-1846 name=__codelineno-0-1846></a><span class=sd>        This is a wrapper class for the `scipy.optimize.nnls` method.</span>
<a id=__codelineno-0-1847 name=__codelineno-0-1847></a>
<a id=__codelineno-0-1848 name=__codelineno-0-1848></a><span class=sd>        References</span>
<a id=__codelineno-0-1849 name=__codelineno-0-1849></a><span class=sd>        ----------</span>
<a id=__codelineno-0-1850 name=__codelineno-0-1850></a><span class=sd>        .. [1] scipy, https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.nnls.html</span>
<a id=__codelineno-0-1851 name=__codelineno-0-1851></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-1852 name=__codelineno-0-1852></a>        <span class=n>theta</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>nnls</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=o>.</span><span class=n>ravel</span><span class=p>(),</span> <span class=n>maxiter</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>maxiter</span><span class=p>,</span> <span class=n>atol</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>atol</span><span class=p>)</span>
<a id=__codelineno-0-1853 name=__codelineno-0-1853></a>        <span class=k>return</span> <span class=n>theta</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.NonNegativeLeastSquares.optimize class="doc doc-heading"> <code class="highlight language-python"><span class=n>optimize</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.NonNegativeLeastSquares.optimize class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Parameter estimation using the NonNegativeLeastSquares algorithm.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>ndarray of floats of shape (n_samples, 1)</code> </td> <td> <div class=doc-md-description> <p>The data used to train the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>array-like of shape = number_of_model_elements</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=note open> <summary>Notes</summary> <p>This is a wrapper class for the <code>scipy.optimize.nnls</code> method.</p> </details> <details class=references open> <summary>References</summary> <p>.. [1] scipy, <a href=https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.nnls.html>https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.nnls.html</a></p> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-1829>1829</a></span>
<span class=normal><a href=#__codelineno-0-1830>1830</a></span>
<span class=normal><a href=#__codelineno-0-1831>1831</a></span>
<span class=normal><a href=#__codelineno-0-1832>1832</a></span>
<span class=normal><a href=#__codelineno-0-1833>1833</a></span>
<span class=normal><a href=#__codelineno-0-1834>1834</a></span>
<span class=normal><a href=#__codelineno-0-1835>1835</a></span>
<span class=normal><a href=#__codelineno-0-1836>1836</a></span>
<span class=normal><a href=#__codelineno-0-1837>1837</a></span>
<span class=normal><a href=#__codelineno-0-1838>1838</a></span>
<span class=normal><a href=#__codelineno-0-1839>1839</a></span>
<span class=normal><a href=#__codelineno-0-1840>1840</a></span>
<span class=normal><a href=#__codelineno-0-1841>1841</a></span>
<span class=normal><a href=#__codelineno-0-1842>1842</a></span>
<span class=normal><a href=#__codelineno-0-1843>1843</a></span>
<span class=normal><a href=#__codelineno-0-1844>1844</a></span>
<span class=normal><a href=#__codelineno-0-1845>1845</a></span>
<span class=normal><a href=#__codelineno-0-1846>1846</a></span>
<span class=normal><a href=#__codelineno-0-1847>1847</a></span>
<span class=normal><a href=#__codelineno-0-1848>1848</a></span>
<span class=normal><a href=#__codelineno-0-1849>1849</a></span>
<span class=normal><a href=#__codelineno-0-1850>1850</a></span>
<span class=normal><a href=#__codelineno-0-1851>1851</a></span>
<span class=normal><a href=#__codelineno-0-1852>1852</a></span>
<span class=normal><a href=#__codelineno-0-1853>1853</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-1829 name=__codelineno-0-1829></a><span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
<a id=__codelineno-0-1830 name=__codelineno-0-1830></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Parameter estimation using the NonNegativeLeastSquares algorithm.</span>
<a id=__codelineno-0-1831 name=__codelineno-0-1831></a>
<a id=__codelineno-0-1832 name=__codelineno-0-1832></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-1833 name=__codelineno-0-1833></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1834 name=__codelineno-0-1834></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-1835 name=__codelineno-0-1835></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-1836 name=__codelineno-0-1836></a><span class=sd>    y : ndarray of floats of shape (n_samples, 1)</span>
<a id=__codelineno-0-1837 name=__codelineno-0-1837></a><span class=sd>        The data used to train the model.</span>
<a id=__codelineno-0-1838 name=__codelineno-0-1838></a>
<a id=__codelineno-0-1839 name=__codelineno-0-1839></a><span class=sd>    Returns</span>
<a id=__codelineno-0-1840 name=__codelineno-0-1840></a><span class=sd>    -------</span>
<a id=__codelineno-0-1841 name=__codelineno-0-1841></a><span class=sd>    theta : array-like of shape = number_of_model_elements</span>
<a id=__codelineno-0-1842 name=__codelineno-0-1842></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-1843 name=__codelineno-0-1843></a>
<a id=__codelineno-0-1844 name=__codelineno-0-1844></a><span class=sd>    Notes</span>
<a id=__codelineno-0-1845 name=__codelineno-0-1845></a><span class=sd>    -----</span>
<a id=__codelineno-0-1846 name=__codelineno-0-1846></a><span class=sd>    This is a wrapper class for the `scipy.optimize.nnls` method.</span>
<a id=__codelineno-0-1847 name=__codelineno-0-1847></a>
<a id=__codelineno-0-1848 name=__codelineno-0-1848></a><span class=sd>    References</span>
<a id=__codelineno-0-1849 name=__codelineno-0-1849></a><span class=sd>    ----------</span>
<a id=__codelineno-0-1850 name=__codelineno-0-1850></a><span class=sd>    .. [1] scipy, https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.nnls.html</span>
<a id=__codelineno-0-1851 name=__codelineno-0-1851></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-1852 name=__codelineno-0-1852></a>    <span class=n>theta</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>nnls</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=o>.</span><span class=n>ravel</span><span class=p>(),</span> <span class=n>maxiter</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>maxiter</span><span class=p>,</span> <span class=n>atol</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>atol</span><span class=p>)</span>
<a id=__codelineno-0-1853 name=__codelineno-0-1853></a>    <span class=k>return</span> <span class=n>theta</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquares class="doc doc-heading"> <code>NormalizedLeastMeanSquares</code> <a href=#sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquares class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=sysidentpy.parameter_estimation.estimators_base.BaseEstimator>BaseEstimator</span></code></p> <p>Normalized Least Mean Squares (NLMS) filter for parameter estimation.</p> <p>The NLMS algorithm is an adaptive filter used to estimate the parameters of a model by minimizing the mean square error between the observed and predicted values. The normalization is used to avoid numerical instability when updating the estimated parameters.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>mu</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> <td> <code>0.01</code> </td> </tr> <tr class=doc-section-item> <td> <code>eps</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>Normalization factor of the normalized filters.</p> </div> </td> <td> <code>np.finfo(np.float64).eps</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Attributes:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquares.mu>mu</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquares.eps>eps</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>Normalization factor of the normalized filters.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquares.xi>xi</span></code></td> <td> <code><span title=numpy.ndarray>ndarray</span> or None</code> </td> <td> <div class=doc-md-description> <p>The estimation error at each iteration. Initialized as None and updated during optimization.</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Methods:</span></p> <table> <thead> <tr> <th>Name</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><a class="autorefs autorefs-internal" title="<code>sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquares.optimize</code>" href=../../../../user-guide/API/parameter-estimation/#sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquares.optimize>optimize</a></code></td> <td> <div class=doc-md-description> <p>Estimate the model parameters using the NLMS filter.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Hayes, M. H. (2009). Statistical digital signal processing and modeling. John Wiley &amp; Sons.</li> <li>Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de algoritmos LMS de passo variável.</li> <li>Wikipedia entry on Least Mean Squares: <a href=https://en.wikipedia.org/wiki/Least_mean_squares_filter>https://en.wikipedia.org/wiki/Least_mean_squares_filter</a></li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-731>731</a></span>
<span class=normal><a href=#__codelineno-0-732>732</a></span>
<span class=normal><a href=#__codelineno-0-733>733</a></span>
<span class=normal><a href=#__codelineno-0-734>734</a></span>
<span class=normal><a href=#__codelineno-0-735>735</a></span>
<span class=normal><a href=#__codelineno-0-736>736</a></span>
<span class=normal><a href=#__codelineno-0-737>737</a></span>
<span class=normal><a href=#__codelineno-0-738>738</a></span>
<span class=normal><a href=#__codelineno-0-739>739</a></span>
<span class=normal><a href=#__codelineno-0-740>740</a></span>
<span class=normal><a href=#__codelineno-0-741>741</a></span>
<span class=normal><a href=#__codelineno-0-742>742</a></span>
<span class=normal><a href=#__codelineno-0-743>743</a></span>
<span class=normal><a href=#__codelineno-0-744>744</a></span>
<span class=normal><a href=#__codelineno-0-745>745</a></span>
<span class=normal><a href=#__codelineno-0-746>746</a></span>
<span class=normal><a href=#__codelineno-0-747>747</a></span>
<span class=normal><a href=#__codelineno-0-748>748</a></span>
<span class=normal><a href=#__codelineno-0-749>749</a></span>
<span class=normal><a href=#__codelineno-0-750>750</a></span>
<span class=normal><a href=#__codelineno-0-751>751</a></span>
<span class=normal><a href=#__codelineno-0-752>752</a></span>
<span class=normal><a href=#__codelineno-0-753>753</a></span>
<span class=normal><a href=#__codelineno-0-754>754</a></span>
<span class=normal><a href=#__codelineno-0-755>755</a></span>
<span class=normal><a href=#__codelineno-0-756>756</a></span>
<span class=normal><a href=#__codelineno-0-757>757</a></span>
<span class=normal><a href=#__codelineno-0-758>758</a></span>
<span class=normal><a href=#__codelineno-0-759>759</a></span>
<span class=normal><a href=#__codelineno-0-760>760</a></span>
<span class=normal><a href=#__codelineno-0-761>761</a></span>
<span class=normal><a href=#__codelineno-0-762>762</a></span>
<span class=normal><a href=#__codelineno-0-763>763</a></span>
<span class=normal><a href=#__codelineno-0-764>764</a></span>
<span class=normal><a href=#__codelineno-0-765>765</a></span>
<span class=normal><a href=#__codelineno-0-766>766</a></span>
<span class=normal><a href=#__codelineno-0-767>767</a></span>
<span class=normal><a href=#__codelineno-0-768>768</a></span>
<span class=normal><a href=#__codelineno-0-769>769</a></span>
<span class=normal><a href=#__codelineno-0-770>770</a></span>
<span class=normal><a href=#__codelineno-0-771>771</a></span>
<span class=normal><a href=#__codelineno-0-772>772</a></span>
<span class=normal><a href=#__codelineno-0-773>773</a></span>
<span class=normal><a href=#__codelineno-0-774>774</a></span>
<span class=normal><a href=#__codelineno-0-775>775</a></span>
<span class=normal><a href=#__codelineno-0-776>776</a></span>
<span class=normal><a href=#__codelineno-0-777>777</a></span>
<span class=normal><a href=#__codelineno-0-778>778</a></span>
<span class=normal><a href=#__codelineno-0-779>779</a></span>
<span class=normal><a href=#__codelineno-0-780>780</a></span>
<span class=normal><a href=#__codelineno-0-781>781</a></span>
<span class=normal><a href=#__codelineno-0-782>782</a></span>
<span class=normal><a href=#__codelineno-0-783>783</a></span>
<span class=normal><a href=#__codelineno-0-784>784</a></span>
<span class=normal><a href=#__codelineno-0-785>785</a></span>
<span class=normal><a href=#__codelineno-0-786>786</a></span>
<span class=normal><a href=#__codelineno-0-787>787</a></span>
<span class=normal><a href=#__codelineno-0-788>788</a></span>
<span class=normal><a href=#__codelineno-0-789>789</a></span>
<span class=normal><a href=#__codelineno-0-790>790</a></span>
<span class=normal><a href=#__codelineno-0-791>791</a></span>
<span class=normal><a href=#__codelineno-0-792>792</a></span>
<span class=normal><a href=#__codelineno-0-793>793</a></span>
<span class=normal><a href=#__codelineno-0-794>794</a></span>
<span class=normal><a href=#__codelineno-0-795>795</a></span>
<span class=normal><a href=#__codelineno-0-796>796</a></span>
<span class=normal><a href=#__codelineno-0-797>797</a></span>
<span class=normal><a href=#__codelineno-0-798>798</a></span>
<span class=normal><a href=#__codelineno-0-799>799</a></span>
<span class=normal><a href=#__codelineno-0-800>800</a></span>
<span class=normal><a href=#__codelineno-0-801>801</a></span>
<span class=normal><a href=#__codelineno-0-802>802</a></span>
<span class=normal><a href=#__codelineno-0-803>803</a></span>
<span class=normal><a href=#__codelineno-0-804>804</a></span>
<span class=normal><a href=#__codelineno-0-805>805</a></span>
<span class=normal><a href=#__codelineno-0-806>806</a></span>
<span class=normal><a href=#__codelineno-0-807>807</a></span>
<span class=normal><a href=#__codelineno-0-808>808</a></span>
<span class=normal><a href=#__codelineno-0-809>809</a></span>
<span class=normal><a href=#__codelineno-0-810>810</a></span>
<span class=normal><a href=#__codelineno-0-811>811</a></span>
<span class=normal><a href=#__codelineno-0-812>812</a></span>
<span class=normal><a href=#__codelineno-0-813>813</a></span>
<span class=normal><a href=#__codelineno-0-814>814</a></span>
<span class=normal><a href=#__codelineno-0-815>815</a></span>
<span class=normal><a href=#__codelineno-0-816>816</a></span>
<span class=normal><a href=#__codelineno-0-817>817</a></span>
<span class=normal><a href=#__codelineno-0-818>818</a></span>
<span class=normal><a href=#__codelineno-0-819>819</a></span>
<span class=normal><a href=#__codelineno-0-820>820</a></span>
<span class=normal><a href=#__codelineno-0-821>821</a></span>
<span class=normal><a href=#__codelineno-0-822>822</a></span>
<span class=normal><a href=#__codelineno-0-823>823</a></span>
<span class=normal><a href=#__codelineno-0-824>824</a></span>
<span class=normal><a href=#__codelineno-0-825>825</a></span>
<span class=normal><a href=#__codelineno-0-826>826</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-731 name=__codelineno-0-731></a><span class=k>class</span><span class=w> </span><span class=nc>NormalizedLeastMeanSquares</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>):</span>
<a id=__codelineno-0-732 name=__codelineno-0-732></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Normalized Least Mean Squares (NLMS) filter for parameter estimation.</span>
<a id=__codelineno-0-733 name=__codelineno-0-733></a>
<a id=__codelineno-0-734 name=__codelineno-0-734></a><span class=sd>    The NLMS algorithm is an adaptive filter used to estimate the parameters of a model</span>
<a id=__codelineno-0-735 name=__codelineno-0-735></a><span class=sd>    by minimizing the mean square error between the observed and predicted values. The</span>
<a id=__codelineno-0-736 name=__codelineno-0-736></a><span class=sd>    normalization is used to avoid numerical instability when updating the estimated</span>
<a id=__codelineno-0-737 name=__codelineno-0-737></a><span class=sd>    parameters.</span>
<a id=__codelineno-0-738 name=__codelineno-0-738></a>
<a id=__codelineno-0-739 name=__codelineno-0-739></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-740 name=__codelineno-0-740></a><span class=sd>    ----------</span>
<a id=__codelineno-0-741 name=__codelineno-0-741></a><span class=sd>    mu : float, default=0.01</span>
<a id=__codelineno-0-742 name=__codelineno-0-742></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-743 name=__codelineno-0-743></a><span class=sd>    eps : float, default=np.finfo(np.float64).eps</span>
<a id=__codelineno-0-744 name=__codelineno-0-744></a><span class=sd>        Normalization factor of the normalized filters.</span>
<a id=__codelineno-0-745 name=__codelineno-0-745></a>
<a id=__codelineno-0-746 name=__codelineno-0-746></a><span class=sd>    Attributes</span>
<a id=__codelineno-0-747 name=__codelineno-0-747></a><span class=sd>    ----------</span>
<a id=__codelineno-0-748 name=__codelineno-0-748></a><span class=sd>    mu : float</span>
<a id=__codelineno-0-749 name=__codelineno-0-749></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-750 name=__codelineno-0-750></a><span class=sd>    eps : float</span>
<a id=__codelineno-0-751 name=__codelineno-0-751></a><span class=sd>        Normalization factor of the normalized filters.</span>
<a id=__codelineno-0-752 name=__codelineno-0-752></a><span class=sd>    xi : np.ndarray or None</span>
<a id=__codelineno-0-753 name=__codelineno-0-753></a><span class=sd>        The estimation error at each iteration. Initialized as None and updated during</span>
<a id=__codelineno-0-754 name=__codelineno-0-754></a><span class=sd>        optimization.</span>
<a id=__codelineno-0-755 name=__codelineno-0-755></a>
<a id=__codelineno-0-756 name=__codelineno-0-756></a><span class=sd>    Methods</span>
<a id=__codelineno-0-757 name=__codelineno-0-757></a><span class=sd>    -------</span>
<a id=__codelineno-0-758 name=__codelineno-0-758></a><span class=sd>    optimize(psi: np.ndarray, y: np.ndarray) -&gt; np.ndarray</span>
<a id=__codelineno-0-759 name=__codelineno-0-759></a><span class=sd>        Estimate the model parameters using the NLMS filter.</span>
<a id=__codelineno-0-760 name=__codelineno-0-760></a>
<a id=__codelineno-0-761 name=__codelineno-0-761></a><span class=sd>    References</span>
<a id=__codelineno-0-762 name=__codelineno-0-762></a><span class=sd>    ----------</span>
<a id=__codelineno-0-763 name=__codelineno-0-763></a><span class=sd>    - Hayes, M. H. (2009). Statistical digital signal processing and modeling.</span>
<a id=__codelineno-0-764 name=__codelineno-0-764></a><span class=sd>      John Wiley &amp; Sons.</span>
<a id=__codelineno-0-765 name=__codelineno-0-765></a><span class=sd>    - Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de</span>
<a id=__codelineno-0-766 name=__codelineno-0-766></a><span class=sd>      algoritmos LMS de passo variável.</span>
<a id=__codelineno-0-767 name=__codelineno-0-767></a><span class=sd>    - Wikipedia entry on Least Mean Squares: https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>
<a id=__codelineno-0-768 name=__codelineno-0-768></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-769 name=__codelineno-0-769></a>
<a id=__codelineno-0-770 name=__codelineno-0-770></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span>
<a id=__codelineno-0-771 name=__codelineno-0-771></a>        <span class=bp>self</span><span class=p>,</span>
<a id=__codelineno-0-772 name=__codelineno-0-772></a>        <span class=o>*</span><span class=p>,</span>
<a id=__codelineno-0-773 name=__codelineno-0-773></a>        <span class=n>mu</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.01</span><span class=p>,</span>
<a id=__codelineno-0-774 name=__codelineno-0-774></a>        <span class=n>eps</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>float64</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>finfo</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float64</span><span class=p>)</span><span class=o>.</span><span class=n>eps</span><span class=p>,</span>
<a id=__codelineno-0-775 name=__codelineno-0-775></a>        <span class=n>unbiased</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>
<a id=__codelineno-0-776 name=__codelineno-0-776></a>        <span class=n>uiter</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>30</span><span class=p>,</span>
<a id=__codelineno-0-777 name=__codelineno-0-777></a>    <span class=p>):</span>
<a id=__codelineno-0-778 name=__codelineno-0-778></a>        <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>=</span> <span class=n>mu</span>
<a id=__codelineno-0-779 name=__codelineno-0-779></a>        <span class=bp>self</span><span class=o>.</span><span class=n>eps</span> <span class=o>=</span> <span class=n>eps</span>
<a id=__codelineno-0-780 name=__codelineno-0-780></a>        <span class=bp>self</span><span class=o>.</span><span class=n>unbiased</span> <span class=o>=</span> <span class=n>unbiased</span>
<a id=__codelineno-0-781 name=__codelineno-0-781></a>        <span class=bp>self</span><span class=o>.</span><span class=n>uiter</span> <span class=o>=</span> <span class=n>uiter</span>
<a id=__codelineno-0-782 name=__codelineno-0-782></a>        <span class=n>_validate_params</span><span class=p>(</span><span class=nb>vars</span><span class=p>(</span><span class=bp>self</span><span class=p>))</span>
<a id=__codelineno-0-783 name=__codelineno-0-783></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
<a id=__codelineno-0-784 name=__codelineno-0-784></a>
<a id=__codelineno-0-785 name=__codelineno-0-785></a>    <span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-786 name=__codelineno-0-786></a><span class=w>        </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Normalized Least Mean Squares filter.</span>
<a id=__codelineno-0-787 name=__codelineno-0-787></a>
<a id=__codelineno-0-788 name=__codelineno-0-788></a><span class=sd>        The NLMS algorithm updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-789 name=__codelineno-0-789></a>
<a id=__codelineno-0-790 name=__codelineno-0-790></a><span class=sd>        1. Compute the estimation error:</span>
<a id=__codelineno-0-791 name=__codelineno-0-791></a>
<a id=__codelineno-0-792 name=__codelineno-0-792></a><span class=sd>           $$</span>
<a id=__codelineno-0-793 name=__codelineno-0-793></a><span class=sd>           \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-794 name=__codelineno-0-794></a><span class=sd>           $$</span>
<a id=__codelineno-0-795 name=__codelineno-0-795></a>
<a id=__codelineno-0-796 name=__codelineno-0-796></a><span class=sd>        2. Update the parameter vector:</span>
<a id=__codelineno-0-797 name=__codelineno-0-797></a>
<a id=__codelineno-0-798 name=__codelineno-0-798></a><span class=sd>           $$</span>
<a id=__codelineno-0-799 name=__codelineno-0-799></a><span class=sd>           \theta_i = \theta_{i-1} + 2 \mu \xi_i \frac{\psi_i}{\epsilon +</span>
<a id=__codelineno-0-800 name=__codelineno-0-800></a><span class=sd>           \psi_i^T \psi_i}</span>
<a id=__codelineno-0-801 name=__codelineno-0-801></a><span class=sd>           $$</span>
<a id=__codelineno-0-802 name=__codelineno-0-802></a>
<a id=__codelineno-0-803 name=__codelineno-0-803></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-804 name=__codelineno-0-804></a><span class=sd>        ----------</span>
<a id=__codelineno-0-805 name=__codelineno-0-805></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-806 name=__codelineno-0-806></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-807 name=__codelineno-0-807></a><span class=sd>        y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-808 name=__codelineno-0-808></a><span class=sd>            The data used to train the model.</span>
<a id=__codelineno-0-809 name=__codelineno-0-809></a>
<a id=__codelineno-0-810 name=__codelineno-0-810></a><span class=sd>        Returns</span>
<a id=__codelineno-0-811 name=__codelineno-0-811></a><span class=sd>        -------</span>
<a id=__codelineno-0-812 name=__codelineno-0-812></a><span class=sd>        theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-813 name=__codelineno-0-813></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-814 name=__codelineno-0-814></a>
<a id=__codelineno-0-815 name=__codelineno-0-815></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-816 name=__codelineno-0-816></a>        <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-817 name=__codelineno-0-817></a>
<a id=__codelineno-0-818 name=__codelineno-0-818></a>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-819 name=__codelineno-0-819></a>            <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-820 name=__codelineno-0-820></a>            <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-821 name=__codelineno-0-821></a>            <span class=n>tmp_list</span> <span class=o>=</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=mi>2</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=p>(</span>
<a id=__codelineno-0-822 name=__codelineno-0-822></a>                <span class=n>psi_tmp</span> <span class=o>/</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>eps</span> <span class=o>+</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>psi_tmp</span><span class=p>))</span>
<a id=__codelineno-0-823 name=__codelineno-0-823></a>            <span class=p>)</span>
<a id=__codelineno-0-824 name=__codelineno-0-824></a>            <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-825 name=__codelineno-0-825></a>
<a id=__codelineno-0-826 name=__codelineno-0-826></a>        <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquares.optimize class="doc doc-heading"> <code class="highlight language-python"><span class=n>optimize</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquares.optimize class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Parameter estimation using the Normalized Least Mean Squares filter.</p> <p>The NLMS algorithm updates the parameter estimates recursively as follows:</p> <ol> <li>Compute the estimation error:</li> </ol> <p>$$ \xi_i = y_i - \psi_i^T \theta_{i-1} $$</p> <ol> <li>Update the parameter vector:</li> </ol> <p>$$ \theta_i = \theta_{i-1} + 2 \mu \xi_i \frac{\psi_i}{\epsilon + \psi_i^T \psi_i} $$</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>array-like of shape (n_samples, 1)</code> </td> <td> <div class=doc-md-description> <p>The data used to train the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>array-like of shape (n_features, 1)</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-785>785</a></span>
<span class=normal><a href=#__codelineno-0-786>786</a></span>
<span class=normal><a href=#__codelineno-0-787>787</a></span>
<span class=normal><a href=#__codelineno-0-788>788</a></span>
<span class=normal><a href=#__codelineno-0-789>789</a></span>
<span class=normal><a href=#__codelineno-0-790>790</a></span>
<span class=normal><a href=#__codelineno-0-791>791</a></span>
<span class=normal><a href=#__codelineno-0-792>792</a></span>
<span class=normal><a href=#__codelineno-0-793>793</a></span>
<span class=normal><a href=#__codelineno-0-794>794</a></span>
<span class=normal><a href=#__codelineno-0-795>795</a></span>
<span class=normal><a href=#__codelineno-0-796>796</a></span>
<span class=normal><a href=#__codelineno-0-797>797</a></span>
<span class=normal><a href=#__codelineno-0-798>798</a></span>
<span class=normal><a href=#__codelineno-0-799>799</a></span>
<span class=normal><a href=#__codelineno-0-800>800</a></span>
<span class=normal><a href=#__codelineno-0-801>801</a></span>
<span class=normal><a href=#__codelineno-0-802>802</a></span>
<span class=normal><a href=#__codelineno-0-803>803</a></span>
<span class=normal><a href=#__codelineno-0-804>804</a></span>
<span class=normal><a href=#__codelineno-0-805>805</a></span>
<span class=normal><a href=#__codelineno-0-806>806</a></span>
<span class=normal><a href=#__codelineno-0-807>807</a></span>
<span class=normal><a href=#__codelineno-0-808>808</a></span>
<span class=normal><a href=#__codelineno-0-809>809</a></span>
<span class=normal><a href=#__codelineno-0-810>810</a></span>
<span class=normal><a href=#__codelineno-0-811>811</a></span>
<span class=normal><a href=#__codelineno-0-812>812</a></span>
<span class=normal><a href=#__codelineno-0-813>813</a></span>
<span class=normal><a href=#__codelineno-0-814>814</a></span>
<span class=normal><a href=#__codelineno-0-815>815</a></span>
<span class=normal><a href=#__codelineno-0-816>816</a></span>
<span class=normal><a href=#__codelineno-0-817>817</a></span>
<span class=normal><a href=#__codelineno-0-818>818</a></span>
<span class=normal><a href=#__codelineno-0-819>819</a></span>
<span class=normal><a href=#__codelineno-0-820>820</a></span>
<span class=normal><a href=#__codelineno-0-821>821</a></span>
<span class=normal><a href=#__codelineno-0-822>822</a></span>
<span class=normal><a href=#__codelineno-0-823>823</a></span>
<span class=normal><a href=#__codelineno-0-824>824</a></span>
<span class=normal><a href=#__codelineno-0-825>825</a></span>
<span class=normal><a href=#__codelineno-0-826>826</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-785 name=__codelineno-0-785></a><span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-786 name=__codelineno-0-786></a><span class=w>    </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Normalized Least Mean Squares filter.</span>
<a id=__codelineno-0-787 name=__codelineno-0-787></a>
<a id=__codelineno-0-788 name=__codelineno-0-788></a><span class=sd>    The NLMS algorithm updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-789 name=__codelineno-0-789></a>
<a id=__codelineno-0-790 name=__codelineno-0-790></a><span class=sd>    1. Compute the estimation error:</span>
<a id=__codelineno-0-791 name=__codelineno-0-791></a>
<a id=__codelineno-0-792 name=__codelineno-0-792></a><span class=sd>       $$</span>
<a id=__codelineno-0-793 name=__codelineno-0-793></a><span class=sd>       \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-794 name=__codelineno-0-794></a><span class=sd>       $$</span>
<a id=__codelineno-0-795 name=__codelineno-0-795></a>
<a id=__codelineno-0-796 name=__codelineno-0-796></a><span class=sd>    2. Update the parameter vector:</span>
<a id=__codelineno-0-797 name=__codelineno-0-797></a>
<a id=__codelineno-0-798 name=__codelineno-0-798></a><span class=sd>       $$</span>
<a id=__codelineno-0-799 name=__codelineno-0-799></a><span class=sd>       \theta_i = \theta_{i-1} + 2 \mu \xi_i \frac{\psi_i}{\epsilon +</span>
<a id=__codelineno-0-800 name=__codelineno-0-800></a><span class=sd>       \psi_i^T \psi_i}</span>
<a id=__codelineno-0-801 name=__codelineno-0-801></a><span class=sd>       $$</span>
<a id=__codelineno-0-802 name=__codelineno-0-802></a>
<a id=__codelineno-0-803 name=__codelineno-0-803></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-804 name=__codelineno-0-804></a><span class=sd>    ----------</span>
<a id=__codelineno-0-805 name=__codelineno-0-805></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-806 name=__codelineno-0-806></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-807 name=__codelineno-0-807></a><span class=sd>    y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-808 name=__codelineno-0-808></a><span class=sd>        The data used to train the model.</span>
<a id=__codelineno-0-809 name=__codelineno-0-809></a>
<a id=__codelineno-0-810 name=__codelineno-0-810></a><span class=sd>    Returns</span>
<a id=__codelineno-0-811 name=__codelineno-0-811></a><span class=sd>    -------</span>
<a id=__codelineno-0-812 name=__codelineno-0-812></a><span class=sd>    theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-813 name=__codelineno-0-813></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-814 name=__codelineno-0-814></a>
<a id=__codelineno-0-815 name=__codelineno-0-815></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-816 name=__codelineno-0-816></a>    <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-817 name=__codelineno-0-817></a>
<a id=__codelineno-0-818 name=__codelineno-0-818></a>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-819 name=__codelineno-0-819></a>        <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-820 name=__codelineno-0-820></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-821 name=__codelineno-0-821></a>        <span class=n>tmp_list</span> <span class=o>=</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=mi>2</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=p>(</span>
<a id=__codelineno-0-822 name=__codelineno-0-822></a>            <span class=n>psi_tmp</span> <span class=o>/</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>eps</span> <span class=o>+</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>psi_tmp</span><span class=p>))</span>
<a id=__codelineno-0-823 name=__codelineno-0-823></a>        <span class=p>)</span>
<a id=__codelineno-0-824 name=__codelineno-0-824></a>        <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-825 name=__codelineno-0-825></a>
<a id=__codelineno-0-826 name=__codelineno-0-826></a>    <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquaresSignError class="doc doc-heading"> <code>NormalizedLeastMeanSquaresSignError</code> <a href=#sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquaresSignError class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=sysidentpy.parameter_estimation.estimators_base.BaseEstimator>BaseEstimator</span></code></p> <p>Normalized Least Mean Squares SignError (NLMSSE) filter for parameter estimation.</p> <p>The NLMSSE algorithm updates the parameter estimates recursively by normalizing the input signal to avoid numerical instability and using the sign of the error vector to adjust the filter coefficients.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>mu</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> <td> <code>0.01</code> </td> </tr> <tr class=doc-section-item> <td> <code>eps</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>Normalization factor of the normalized filters.</p> </div> </td> <td> <code>np.finfo(np.float64).eps</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Attributes:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquaresSignError.mu>mu</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>The learning rate or step size for the LMS algorithm.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquaresSignError.eps>eps</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>Normalization factor of the normalized filters.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquaresSignError.xi>xi</span></code></td> <td> <code><span title=numpy.ndarray>ndarray</span> or None</code> </td> <td> <div class=doc-md-description> <p>The estimation error at each iteration. Initialized as None and updated during optimization.</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Methods:</span></p> <table> <thead> <tr> <th>Name</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><a class="autorefs autorefs-internal" title="<code>sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquaresSignError.optimize</code>" href=../../../../user-guide/API/parameter-estimation/#sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquaresSignError.optimize>optimize</a></code></td> <td> <div class=doc-md-description> <p>Estimate the model parameters using the NLMSSE filter.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Hayes, M. H. (2009). Statistical digital signal processing and modeling. John Wiley &amp; Sons.</li> <li>Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de algoritmos LMS de passo variável.</li> <li>Wikipedia entry on Least Mean Squares: <a href=https://en.wikipedia.org/wiki/Least_mean_squares_filter>https://en.wikipedia.org/wiki/Least_mean_squares_filter</a></li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-829>829</a></span>
<span class=normal><a href=#__codelineno-0-830>830</a></span>
<span class=normal><a href=#__codelineno-0-831>831</a></span>
<span class=normal><a href=#__codelineno-0-832>832</a></span>
<span class=normal><a href=#__codelineno-0-833>833</a></span>
<span class=normal><a href=#__codelineno-0-834>834</a></span>
<span class=normal><a href=#__codelineno-0-835>835</a></span>
<span class=normal><a href=#__codelineno-0-836>836</a></span>
<span class=normal><a href=#__codelineno-0-837>837</a></span>
<span class=normal><a href=#__codelineno-0-838>838</a></span>
<span class=normal><a href=#__codelineno-0-839>839</a></span>
<span class=normal><a href=#__codelineno-0-840>840</a></span>
<span class=normal><a href=#__codelineno-0-841>841</a></span>
<span class=normal><a href=#__codelineno-0-842>842</a></span>
<span class=normal><a href=#__codelineno-0-843>843</a></span>
<span class=normal><a href=#__codelineno-0-844>844</a></span>
<span class=normal><a href=#__codelineno-0-845>845</a></span>
<span class=normal><a href=#__codelineno-0-846>846</a></span>
<span class=normal><a href=#__codelineno-0-847>847</a></span>
<span class=normal><a href=#__codelineno-0-848>848</a></span>
<span class=normal><a href=#__codelineno-0-849>849</a></span>
<span class=normal><a href=#__codelineno-0-850>850</a></span>
<span class=normal><a href=#__codelineno-0-851>851</a></span>
<span class=normal><a href=#__codelineno-0-852>852</a></span>
<span class=normal><a href=#__codelineno-0-853>853</a></span>
<span class=normal><a href=#__codelineno-0-854>854</a></span>
<span class=normal><a href=#__codelineno-0-855>855</a></span>
<span class=normal><a href=#__codelineno-0-856>856</a></span>
<span class=normal><a href=#__codelineno-0-857>857</a></span>
<span class=normal><a href=#__codelineno-0-858>858</a></span>
<span class=normal><a href=#__codelineno-0-859>859</a></span>
<span class=normal><a href=#__codelineno-0-860>860</a></span>
<span class=normal><a href=#__codelineno-0-861>861</a></span>
<span class=normal><a href=#__codelineno-0-862>862</a></span>
<span class=normal><a href=#__codelineno-0-863>863</a></span>
<span class=normal><a href=#__codelineno-0-864>864</a></span>
<span class=normal><a href=#__codelineno-0-865>865</a></span>
<span class=normal><a href=#__codelineno-0-866>866</a></span>
<span class=normal><a href=#__codelineno-0-867>867</a></span>
<span class=normal><a href=#__codelineno-0-868>868</a></span>
<span class=normal><a href=#__codelineno-0-869>869</a></span>
<span class=normal><a href=#__codelineno-0-870>870</a></span>
<span class=normal><a href=#__codelineno-0-871>871</a></span>
<span class=normal><a href=#__codelineno-0-872>872</a></span>
<span class=normal><a href=#__codelineno-0-873>873</a></span>
<span class=normal><a href=#__codelineno-0-874>874</a></span>
<span class=normal><a href=#__codelineno-0-875>875</a></span>
<span class=normal><a href=#__codelineno-0-876>876</a></span>
<span class=normal><a href=#__codelineno-0-877>877</a></span>
<span class=normal><a href=#__codelineno-0-878>878</a></span>
<span class=normal><a href=#__codelineno-0-879>879</a></span>
<span class=normal><a href=#__codelineno-0-880>880</a></span>
<span class=normal><a href=#__codelineno-0-881>881</a></span>
<span class=normal><a href=#__codelineno-0-882>882</a></span>
<span class=normal><a href=#__codelineno-0-883>883</a></span>
<span class=normal><a href=#__codelineno-0-884>884</a></span>
<span class=normal><a href=#__codelineno-0-885>885</a></span>
<span class=normal><a href=#__codelineno-0-886>886</a></span>
<span class=normal><a href=#__codelineno-0-887>887</a></span>
<span class=normal><a href=#__codelineno-0-888>888</a></span>
<span class=normal><a href=#__codelineno-0-889>889</a></span>
<span class=normal><a href=#__codelineno-0-890>890</a></span>
<span class=normal><a href=#__codelineno-0-891>891</a></span>
<span class=normal><a href=#__codelineno-0-892>892</a></span>
<span class=normal><a href=#__codelineno-0-893>893</a></span>
<span class=normal><a href=#__codelineno-0-894>894</a></span>
<span class=normal><a href=#__codelineno-0-895>895</a></span>
<span class=normal><a href=#__codelineno-0-896>896</a></span>
<span class=normal><a href=#__codelineno-0-897>897</a></span>
<span class=normal><a href=#__codelineno-0-898>898</a></span>
<span class=normal><a href=#__codelineno-0-899>899</a></span>
<span class=normal><a href=#__codelineno-0-900>900</a></span>
<span class=normal><a href=#__codelineno-0-901>901</a></span>
<span class=normal><a href=#__codelineno-0-902>902</a></span>
<span class=normal><a href=#__codelineno-0-903>903</a></span>
<span class=normal><a href=#__codelineno-0-904>904</a></span>
<span class=normal><a href=#__codelineno-0-905>905</a></span>
<span class=normal><a href=#__codelineno-0-906>906</a></span>
<span class=normal><a href=#__codelineno-0-907>907</a></span>
<span class=normal><a href=#__codelineno-0-908>908</a></span>
<span class=normal><a href=#__codelineno-0-909>909</a></span>
<span class=normal><a href=#__codelineno-0-910>910</a></span>
<span class=normal><a href=#__codelineno-0-911>911</a></span>
<span class=normal><a href=#__codelineno-0-912>912</a></span>
<span class=normal><a href=#__codelineno-0-913>913</a></span>
<span class=normal><a href=#__codelineno-0-914>914</a></span>
<span class=normal><a href=#__codelineno-0-915>915</a></span>
<span class=normal><a href=#__codelineno-0-916>916</a></span>
<span class=normal><a href=#__codelineno-0-917>917</a></span>
<span class=normal><a href=#__codelineno-0-918>918</a></span>
<span class=normal><a href=#__codelineno-0-919>919</a></span>
<span class=normal><a href=#__codelineno-0-920>920</a></span>
<span class=normal><a href=#__codelineno-0-921>921</a></span>
<span class=normal><a href=#__codelineno-0-922>922</a></span>
<span class=normal><a href=#__codelineno-0-923>923</a></span>
<span class=normal><a href=#__codelineno-0-924>924</a></span>
<span class=normal><a href=#__codelineno-0-925>925</a></span>
<span class=normal><a href=#__codelineno-0-926>926</a></span>
<span class=normal><a href=#__codelineno-0-927>927</a></span>
<span class=normal><a href=#__codelineno-0-928>928</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-829 name=__codelineno-0-829></a><span class=k>class</span><span class=w> </span><span class=nc>NormalizedLeastMeanSquaresSignError</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>):</span>
<a id=__codelineno-0-830 name=__codelineno-0-830></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Normalized Least Mean Squares SignError (NLMSSE) filter for parameter estimation.</span>
<a id=__codelineno-0-831 name=__codelineno-0-831></a>
<a id=__codelineno-0-832 name=__codelineno-0-832></a><span class=sd>    The NLMSSE algorithm updates the parameter estimates recursively by normalizing</span>
<a id=__codelineno-0-833 name=__codelineno-0-833></a><span class=sd>    the input signal to avoid numerical instability and using the sign of the error</span>
<a id=__codelineno-0-834 name=__codelineno-0-834></a><span class=sd>    vector to adjust the filter coefficients.</span>
<a id=__codelineno-0-835 name=__codelineno-0-835></a>
<a id=__codelineno-0-836 name=__codelineno-0-836></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-837 name=__codelineno-0-837></a><span class=sd>    ----------</span>
<a id=__codelineno-0-838 name=__codelineno-0-838></a><span class=sd>    mu : float, default=0.01</span>
<a id=__codelineno-0-839 name=__codelineno-0-839></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-840 name=__codelineno-0-840></a><span class=sd>    eps : float, default=np.finfo(np.float64).eps</span>
<a id=__codelineno-0-841 name=__codelineno-0-841></a><span class=sd>        Normalization factor of the normalized filters.</span>
<a id=__codelineno-0-842 name=__codelineno-0-842></a>
<a id=__codelineno-0-843 name=__codelineno-0-843></a><span class=sd>    Attributes</span>
<a id=__codelineno-0-844 name=__codelineno-0-844></a><span class=sd>    ----------</span>
<a id=__codelineno-0-845 name=__codelineno-0-845></a><span class=sd>    mu : float</span>
<a id=__codelineno-0-846 name=__codelineno-0-846></a><span class=sd>        The learning rate or step size for the LMS algorithm.</span>
<a id=__codelineno-0-847 name=__codelineno-0-847></a><span class=sd>    eps : float</span>
<a id=__codelineno-0-848 name=__codelineno-0-848></a><span class=sd>        Normalization factor of the normalized filters.</span>
<a id=__codelineno-0-849 name=__codelineno-0-849></a><span class=sd>    xi : np.ndarray or None</span>
<a id=__codelineno-0-850 name=__codelineno-0-850></a><span class=sd>        The estimation error at each iteration. Initialized as None and updated during</span>
<a id=__codelineno-0-851 name=__codelineno-0-851></a><span class=sd>        optimization.</span>
<a id=__codelineno-0-852 name=__codelineno-0-852></a>
<a id=__codelineno-0-853 name=__codelineno-0-853></a><span class=sd>    Methods</span>
<a id=__codelineno-0-854 name=__codelineno-0-854></a><span class=sd>    -------</span>
<a id=__codelineno-0-855 name=__codelineno-0-855></a><span class=sd>    optimize(psi: np.ndarray, y: np.ndarray) -&gt; np.ndarray</span>
<a id=__codelineno-0-856 name=__codelineno-0-856></a><span class=sd>        Estimate the model parameters using the NLMSSE filter.</span>
<a id=__codelineno-0-857 name=__codelineno-0-857></a>
<a id=__codelineno-0-858 name=__codelineno-0-858></a><span class=sd>    References</span>
<a id=__codelineno-0-859 name=__codelineno-0-859></a><span class=sd>    ----------</span>
<a id=__codelineno-0-860 name=__codelineno-0-860></a><span class=sd>    - Hayes, M. H. (2009). Statistical digital signal processing and modeling.</span>
<a id=__codelineno-0-861 name=__codelineno-0-861></a><span class=sd>      John Wiley &amp; Sons.</span>
<a id=__codelineno-0-862 name=__codelineno-0-862></a><span class=sd>    - Zipf, J. G. F. (2011). Classificação, análise estatística e novas estratégias de</span>
<a id=__codelineno-0-863 name=__codelineno-0-863></a><span class=sd>      algoritmos LMS de passo variável.</span>
<a id=__codelineno-0-864 name=__codelineno-0-864></a><span class=sd>    - Wikipedia entry on Least Mean Squares: https://en.wikipedia.org/wiki/Least_mean_squares_filter</span>
<a id=__codelineno-0-865 name=__codelineno-0-865></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-866 name=__codelineno-0-866></a>
<a id=__codelineno-0-867 name=__codelineno-0-867></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span>
<a id=__codelineno-0-868 name=__codelineno-0-868></a>        <span class=bp>self</span><span class=p>,</span>
<a id=__codelineno-0-869 name=__codelineno-0-869></a>        <span class=o>*</span><span class=p>,</span>
<a id=__codelineno-0-870 name=__codelineno-0-870></a>        <span class=n>mu</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.01</span><span class=p>,</span>
<a id=__codelineno-0-871 name=__codelineno-0-871></a>        <span class=n>eps</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>float64</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>finfo</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float64</span><span class=p>)</span><span class=o>.</span><span class=n>eps</span><span class=p>,</span>
<a id=__codelineno-0-872 name=__codelineno-0-872></a>        <span class=n>unbiased</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>
<a id=__codelineno-0-873 name=__codelineno-0-873></a>        <span class=n>uiter</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>30</span><span class=p>,</span>
<a id=__codelineno-0-874 name=__codelineno-0-874></a>    <span class=p>):</span>
<a id=__codelineno-0-875 name=__codelineno-0-875></a>        <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>=</span> <span class=n>mu</span>
<a id=__codelineno-0-876 name=__codelineno-0-876></a>        <span class=bp>self</span><span class=o>.</span><span class=n>eps</span> <span class=o>=</span> <span class=n>eps</span>
<a id=__codelineno-0-877 name=__codelineno-0-877></a>        <span class=bp>self</span><span class=o>.</span><span class=n>unbiased</span> <span class=o>=</span> <span class=n>unbiased</span>
<a id=__codelineno-0-878 name=__codelineno-0-878></a>        <span class=bp>self</span><span class=o>.</span><span class=n>uiter</span> <span class=o>=</span> <span class=n>uiter</span>
<a id=__codelineno-0-879 name=__codelineno-0-879></a>        <span class=n>_validate_params</span><span class=p>(</span><span class=nb>vars</span><span class=p>(</span><span class=bp>self</span><span class=p>))</span>
<a id=__codelineno-0-880 name=__codelineno-0-880></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
<a id=__codelineno-0-881 name=__codelineno-0-881></a>
<a id=__codelineno-0-882 name=__codelineno-0-882></a>    <span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-883 name=__codelineno-0-883></a><span class=w>        </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Normalized Sign-Error LMS filter.</span>
<a id=__codelineno-0-884 name=__codelineno-0-884></a>
<a id=__codelineno-0-885 name=__codelineno-0-885></a><span class=sd>        The NLMSSE algorithm updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-886 name=__codelineno-0-886></a>
<a id=__codelineno-0-887 name=__codelineno-0-887></a><span class=sd>        1. Compute the estimation error:</span>
<a id=__codelineno-0-888 name=__codelineno-0-888></a>
<a id=__codelineno-0-889 name=__codelineno-0-889></a><span class=sd>           $$</span>
<a id=__codelineno-0-890 name=__codelineno-0-890></a><span class=sd>           \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-891 name=__codelineno-0-891></a><span class=sd>           $$</span>
<a id=__codelineno-0-892 name=__codelineno-0-892></a>
<a id=__codelineno-0-893 name=__codelineno-0-893></a><span class=sd>        2. Update the parameter vector:</span>
<a id=__codelineno-0-894 name=__codelineno-0-894></a>
<a id=__codelineno-0-895 name=__codelineno-0-895></a><span class=sd>           $$</span>
<a id=__codelineno-0-896 name=__codelineno-0-896></a><span class=sd>           \theta_i = \theta_{i-1} + 2 \mu \cdot \text{sign}(\xi_i) \cdot</span>
<a id=__codelineno-0-897 name=__codelineno-0-897></a><span class=sd>           \frac{\psi_i}{\epsilon + \psi_i^T \psi_i}</span>
<a id=__codelineno-0-898 name=__codelineno-0-898></a><span class=sd>           $$</span>
<a id=__codelineno-0-899 name=__codelineno-0-899></a>
<a id=__codelineno-0-900 name=__codelineno-0-900></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-901 name=__codelineno-0-901></a><span class=sd>        ----------</span>
<a id=__codelineno-0-902 name=__codelineno-0-902></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-903 name=__codelineno-0-903></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-904 name=__codelineno-0-904></a><span class=sd>        y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-905 name=__codelineno-0-905></a><span class=sd>            The data used to train the model.</span>
<a id=__codelineno-0-906 name=__codelineno-0-906></a>
<a id=__codelineno-0-907 name=__codelineno-0-907></a><span class=sd>        Returns</span>
<a id=__codelineno-0-908 name=__codelineno-0-908></a><span class=sd>        -------</span>
<a id=__codelineno-0-909 name=__codelineno-0-909></a><span class=sd>        theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-910 name=__codelineno-0-910></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-911 name=__codelineno-0-911></a>
<a id=__codelineno-0-912 name=__codelineno-0-912></a><span class=sd>        Notes</span>
<a id=__codelineno-0-913 name=__codelineno-0-913></a><span class=sd>        -----</span>
<a id=__codelineno-0-914 name=__codelineno-0-914></a><span class=sd>        The normalization is used to avoid numerical instability when updating</span>
<a id=__codelineno-0-915 name=__codelineno-0-915></a><span class=sd>        the estimated parameters and the sign of the error vector is used to</span>
<a id=__codelineno-0-916 name=__codelineno-0-916></a><span class=sd>        change the filter coefficients.</span>
<a id=__codelineno-0-917 name=__codelineno-0-917></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-918 name=__codelineno-0-918></a>        <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-919 name=__codelineno-0-919></a>
<a id=__codelineno-0-920 name=__codelineno-0-920></a>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-921 name=__codelineno-0-921></a>            <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-922 name=__codelineno-0-922></a>            <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-923 name=__codelineno-0-923></a>            <span class=n>tmp_list</span> <span class=o>=</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=mi>2</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>sign</span><span class=p>(</span>
<a id=__codelineno-0-924 name=__codelineno-0-924></a>                <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-925 name=__codelineno-0-925></a>            <span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=n>psi_tmp</span> <span class=o>/</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>eps</span> <span class=o>+</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>psi_tmp</span><span class=p>)))</span>
<a id=__codelineno-0-926 name=__codelineno-0-926></a>            <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-927 name=__codelineno-0-927></a>
<a id=__codelineno-0-928 name=__codelineno-0-928></a>        <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquaresSignError.optimize class="doc doc-heading"> <code class="highlight language-python"><span class=n>optimize</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.NormalizedLeastMeanSquaresSignError.optimize class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Parameter estimation using the Normalized Sign-Error LMS filter.</p> <p>The NLMSSE algorithm updates the parameter estimates recursively as follows:</p> <ol> <li>Compute the estimation error:</li> </ol> <p>$$ \xi_i = y_i - \psi_i^T \theta_{i-1} $$</p> <ol> <li>Update the parameter vector:</li> </ol> <p>$$ \theta_i = \theta_{i-1} + 2 \mu \cdot \text{sign}(\xi_i) \cdot \frac{\psi_i}{\epsilon + \psi_i^T \psi_i} $$</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>array-like of shape (n_samples, 1)</code> </td> <td> <div class=doc-md-description> <p>The data used to train the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>array-like of shape (n_features, 1)</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=note open> <summary>Notes</summary> <p>The normalization is used to avoid numerical instability when updating the estimated parameters and the sign of the error vector is used to change the filter coefficients.</p> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-882>882</a></span>
<span class=normal><a href=#__codelineno-0-883>883</a></span>
<span class=normal><a href=#__codelineno-0-884>884</a></span>
<span class=normal><a href=#__codelineno-0-885>885</a></span>
<span class=normal><a href=#__codelineno-0-886>886</a></span>
<span class=normal><a href=#__codelineno-0-887>887</a></span>
<span class=normal><a href=#__codelineno-0-888>888</a></span>
<span class=normal><a href=#__codelineno-0-889>889</a></span>
<span class=normal><a href=#__codelineno-0-890>890</a></span>
<span class=normal><a href=#__codelineno-0-891>891</a></span>
<span class=normal><a href=#__codelineno-0-892>892</a></span>
<span class=normal><a href=#__codelineno-0-893>893</a></span>
<span class=normal><a href=#__codelineno-0-894>894</a></span>
<span class=normal><a href=#__codelineno-0-895>895</a></span>
<span class=normal><a href=#__codelineno-0-896>896</a></span>
<span class=normal><a href=#__codelineno-0-897>897</a></span>
<span class=normal><a href=#__codelineno-0-898>898</a></span>
<span class=normal><a href=#__codelineno-0-899>899</a></span>
<span class=normal><a href=#__codelineno-0-900>900</a></span>
<span class=normal><a href=#__codelineno-0-901>901</a></span>
<span class=normal><a href=#__codelineno-0-902>902</a></span>
<span class=normal><a href=#__codelineno-0-903>903</a></span>
<span class=normal><a href=#__codelineno-0-904>904</a></span>
<span class=normal><a href=#__codelineno-0-905>905</a></span>
<span class=normal><a href=#__codelineno-0-906>906</a></span>
<span class=normal><a href=#__codelineno-0-907>907</a></span>
<span class=normal><a href=#__codelineno-0-908>908</a></span>
<span class=normal><a href=#__codelineno-0-909>909</a></span>
<span class=normal><a href=#__codelineno-0-910>910</a></span>
<span class=normal><a href=#__codelineno-0-911>911</a></span>
<span class=normal><a href=#__codelineno-0-912>912</a></span>
<span class=normal><a href=#__codelineno-0-913>913</a></span>
<span class=normal><a href=#__codelineno-0-914>914</a></span>
<span class=normal><a href=#__codelineno-0-915>915</a></span>
<span class=normal><a href=#__codelineno-0-916>916</a></span>
<span class=normal><a href=#__codelineno-0-917>917</a></span>
<span class=normal><a href=#__codelineno-0-918>918</a></span>
<span class=normal><a href=#__codelineno-0-919>919</a></span>
<span class=normal><a href=#__codelineno-0-920>920</a></span>
<span class=normal><a href=#__codelineno-0-921>921</a></span>
<span class=normal><a href=#__codelineno-0-922>922</a></span>
<span class=normal><a href=#__codelineno-0-923>923</a></span>
<span class=normal><a href=#__codelineno-0-924>924</a></span>
<span class=normal><a href=#__codelineno-0-925>925</a></span>
<span class=normal><a href=#__codelineno-0-926>926</a></span>
<span class=normal><a href=#__codelineno-0-927>927</a></span>
<span class=normal><a href=#__codelineno-0-928>928</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-882 name=__codelineno-0-882></a><span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-883 name=__codelineno-0-883></a><span class=w>    </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Parameter estimation using the Normalized Sign-Error LMS filter.</span>
<a id=__codelineno-0-884 name=__codelineno-0-884></a>
<a id=__codelineno-0-885 name=__codelineno-0-885></a><span class=sd>    The NLMSSE algorithm updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-886 name=__codelineno-0-886></a>
<a id=__codelineno-0-887 name=__codelineno-0-887></a><span class=sd>    1. Compute the estimation error:</span>
<a id=__codelineno-0-888 name=__codelineno-0-888></a>
<a id=__codelineno-0-889 name=__codelineno-0-889></a><span class=sd>       $$</span>
<a id=__codelineno-0-890 name=__codelineno-0-890></a><span class=sd>       \xi_i = y_i - \psi_i^T \theta_{i-1}</span>
<a id=__codelineno-0-891 name=__codelineno-0-891></a><span class=sd>       $$</span>
<a id=__codelineno-0-892 name=__codelineno-0-892></a>
<a id=__codelineno-0-893 name=__codelineno-0-893></a><span class=sd>    2. Update the parameter vector:</span>
<a id=__codelineno-0-894 name=__codelineno-0-894></a>
<a id=__codelineno-0-895 name=__codelineno-0-895></a><span class=sd>       $$</span>
<a id=__codelineno-0-896 name=__codelineno-0-896></a><span class=sd>       \theta_i = \theta_{i-1} + 2 \mu \cdot \text{sign}(\xi_i) \cdot</span>
<a id=__codelineno-0-897 name=__codelineno-0-897></a><span class=sd>       \frac{\psi_i}{\epsilon + \psi_i^T \psi_i}</span>
<a id=__codelineno-0-898 name=__codelineno-0-898></a><span class=sd>       $$</span>
<a id=__codelineno-0-899 name=__codelineno-0-899></a>
<a id=__codelineno-0-900 name=__codelineno-0-900></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-901 name=__codelineno-0-901></a><span class=sd>    ----------</span>
<a id=__codelineno-0-902 name=__codelineno-0-902></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-903 name=__codelineno-0-903></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-904 name=__codelineno-0-904></a><span class=sd>    y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-905 name=__codelineno-0-905></a><span class=sd>        The data used to train the model.</span>
<a id=__codelineno-0-906 name=__codelineno-0-906></a>
<a id=__codelineno-0-907 name=__codelineno-0-907></a><span class=sd>    Returns</span>
<a id=__codelineno-0-908 name=__codelineno-0-908></a><span class=sd>    -------</span>
<a id=__codelineno-0-909 name=__codelineno-0-909></a><span class=sd>    theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-910 name=__codelineno-0-910></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-911 name=__codelineno-0-911></a>
<a id=__codelineno-0-912 name=__codelineno-0-912></a><span class=sd>    Notes</span>
<a id=__codelineno-0-913 name=__codelineno-0-913></a><span class=sd>    -----</span>
<a id=__codelineno-0-914 name=__codelineno-0-914></a><span class=sd>    The normalization is used to avoid numerical instability when updating</span>
<a id=__codelineno-0-915 name=__codelineno-0-915></a><span class=sd>    the estimated parameters and the sign of the error vector is used to</span>
<a id=__codelineno-0-916 name=__codelineno-0-916></a><span class=sd>    change the filter coefficients.</span>
<a id=__codelineno-0-917 name=__codelineno-0-917></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-918 name=__codelineno-0-918></a>    <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-919 name=__codelineno-0-919></a>
<a id=__codelineno-0-920 name=__codelineno-0-920></a>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-921 name=__codelineno-0-921></a>        <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-922 name=__codelineno-0-922></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-923 name=__codelineno-0-923></a>        <span class=n>tmp_list</span> <span class=o>=</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=mi>2</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>mu</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>sign</span><span class=p>(</span>
<a id=__codelineno-0-924 name=__codelineno-0-924></a>            <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-925 name=__codelineno-0-925></a>        <span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=n>psi_tmp</span> <span class=o>/</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>eps</span> <span class=o>+</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>psi_tmp</span><span class=p>)))</span>
<a id=__codelineno-0-926 name=__codelineno-0-926></a>        <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-927 name=__codelineno-0-927></a>
<a id=__codelineno-0-928 name=__codelineno-0-928></a>    <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.RecursiveLeastSquares class="doc doc-heading"> <code>RecursiveLeastSquares</code> <a href=#sysidentpy.parameter_estimation.estimators.RecursiveLeastSquares class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=sysidentpy.parameter_estimation.estimators_base.BaseEstimator>BaseEstimator</span></code></p> <p>Recursive Least Squares (RLS) filter for parameter estimation.</p> <p>The Recursive Least Squares method is used to estimate the parameters of a model by minimizing the sum of the squares of the differences between the observed and predicted values. This method incorporates a forgetting factor to give more weight to recent observations.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>lam</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>Forgetting factor of the Recursive Least Squares method.</p> </div> </td> <td> <code>0.98</code> </td> </tr> <tr class=doc-section-item> <td> <code>delta</code> </td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>Normalization factor of the P matrix.</p> </div> </td> <td> <code>0.01</code> </td> </tr> <tr class=doc-section-item> <td> <code>unbiased</code> </td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>If True, applies an unbiased estimator. Default is False.</p> </div> </td> <td> <code>False</code> </td> </tr> <tr class=doc-section-item> <td> <code>uiter</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of iterations for the unbiased estimator. Default is 30.</p> </div> </td> <td> <code>30</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Attributes:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.RecursiveLeastSquares.lam>lam</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>Forgetting factor of the Recursive Least Squares method.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.RecursiveLeastSquares.delta>delta</span></code></td> <td> <code><span title=float>float</span></code> </td> <td> <div class=doc-md-description> <p>Normalization factor of the P matrix.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.RecursiveLeastSquares.xi>xi</span></code></td> <td> <code><span title=numpy.ndarray>ndarray</span></code> </td> <td> <div class=doc-md-description> <p>The estimation error at each iteration.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.RecursiveLeastSquares.theta_evolution>theta_evolution</span></code></td> <td> <code><span title=numpy.ndarray>ndarray</span></code> </td> <td> <div class=doc-md-description> <p>Evolution of the estimated parameters over iterations.</p> </div> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Methods:</span></p> <table> <thead> <tr> <th>Name</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><a class="autorefs autorefs-internal" title="<code>sysidentpy.parameter_estimation.estimators.RecursiveLeastSquares.optimize</code>" href=../../../../user-guide/API/parameter-estimation/#sysidentpy.parameter_estimation.estimators.RecursiveLeastSquares.optimize>optimize</a></code></td> <td> <div class=doc-md-description> <p>Estimate the model parameters using the Recursive Least Squares method.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Book (Portuguese): Aguirre, L. A. (2007). Introdução identificação de sistemas: técnicas lineares e não-lineares aplicadas a sistemas reais. Editora da UFMG. 3a edição.</li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-317>317</a></span>
<span class=normal><a href=#__codelineno-0-318>318</a></span>
<span class=normal><a href=#__codelineno-0-319>319</a></span>
<span class=normal><a href=#__codelineno-0-320>320</a></span>
<span class=normal><a href=#__codelineno-0-321>321</a></span>
<span class=normal><a href=#__codelineno-0-322>322</a></span>
<span class=normal><a href=#__codelineno-0-323>323</a></span>
<span class=normal><a href=#__codelineno-0-324>324</a></span>
<span class=normal><a href=#__codelineno-0-325>325</a></span>
<span class=normal><a href=#__codelineno-0-326>326</a></span>
<span class=normal><a href=#__codelineno-0-327>327</a></span>
<span class=normal><a href=#__codelineno-0-328>328</a></span>
<span class=normal><a href=#__codelineno-0-329>329</a></span>
<span class=normal><a href=#__codelineno-0-330>330</a></span>
<span class=normal><a href=#__codelineno-0-331>331</a></span>
<span class=normal><a href=#__codelineno-0-332>332</a></span>
<span class=normal><a href=#__codelineno-0-333>333</a></span>
<span class=normal><a href=#__codelineno-0-334>334</a></span>
<span class=normal><a href=#__codelineno-0-335>335</a></span>
<span class=normal><a href=#__codelineno-0-336>336</a></span>
<span class=normal><a href=#__codelineno-0-337>337</a></span>
<span class=normal><a href=#__codelineno-0-338>338</a></span>
<span class=normal><a href=#__codelineno-0-339>339</a></span>
<span class=normal><a href=#__codelineno-0-340>340</a></span>
<span class=normal><a href=#__codelineno-0-341>341</a></span>
<span class=normal><a href=#__codelineno-0-342>342</a></span>
<span class=normal><a href=#__codelineno-0-343>343</a></span>
<span class=normal><a href=#__codelineno-0-344>344</a></span>
<span class=normal><a href=#__codelineno-0-345>345</a></span>
<span class=normal><a href=#__codelineno-0-346>346</a></span>
<span class=normal><a href=#__codelineno-0-347>347</a></span>
<span class=normal><a href=#__codelineno-0-348>348</a></span>
<span class=normal><a href=#__codelineno-0-349>349</a></span>
<span class=normal><a href=#__codelineno-0-350>350</a></span>
<span class=normal><a href=#__codelineno-0-351>351</a></span>
<span class=normal><a href=#__codelineno-0-352>352</a></span>
<span class=normal><a href=#__codelineno-0-353>353</a></span>
<span class=normal><a href=#__codelineno-0-354>354</a></span>
<span class=normal><a href=#__codelineno-0-355>355</a></span>
<span class=normal><a href=#__codelineno-0-356>356</a></span>
<span class=normal><a href=#__codelineno-0-357>357</a></span>
<span class=normal><a href=#__codelineno-0-358>358</a></span>
<span class=normal><a href=#__codelineno-0-359>359</a></span>
<span class=normal><a href=#__codelineno-0-360>360</a></span>
<span class=normal><a href=#__codelineno-0-361>361</a></span>
<span class=normal><a href=#__codelineno-0-362>362</a></span>
<span class=normal><a href=#__codelineno-0-363>363</a></span>
<span class=normal><a href=#__codelineno-0-364>364</a></span>
<span class=normal><a href=#__codelineno-0-365>365</a></span>
<span class=normal><a href=#__codelineno-0-366>366</a></span>
<span class=normal><a href=#__codelineno-0-367>367</a></span>
<span class=normal><a href=#__codelineno-0-368>368</a></span>
<span class=normal><a href=#__codelineno-0-369>369</a></span>
<span class=normal><a href=#__codelineno-0-370>370</a></span>
<span class=normal><a href=#__codelineno-0-371>371</a></span>
<span class=normal><a href=#__codelineno-0-372>372</a></span>
<span class=normal><a href=#__codelineno-0-373>373</a></span>
<span class=normal><a href=#__codelineno-0-374>374</a></span>
<span class=normal><a href=#__codelineno-0-375>375</a></span>
<span class=normal><a href=#__codelineno-0-376>376</a></span>
<span class=normal><a href=#__codelineno-0-377>377</a></span>
<span class=normal><a href=#__codelineno-0-378>378</a></span>
<span class=normal><a href=#__codelineno-0-379>379</a></span>
<span class=normal><a href=#__codelineno-0-380>380</a></span>
<span class=normal><a href=#__codelineno-0-381>381</a></span>
<span class=normal><a href=#__codelineno-0-382>382</a></span>
<span class=normal><a href=#__codelineno-0-383>383</a></span>
<span class=normal><a href=#__codelineno-0-384>384</a></span>
<span class=normal><a href=#__codelineno-0-385>385</a></span>
<span class=normal><a href=#__codelineno-0-386>386</a></span>
<span class=normal><a href=#__codelineno-0-387>387</a></span>
<span class=normal><a href=#__codelineno-0-388>388</a></span>
<span class=normal><a href=#__codelineno-0-389>389</a></span>
<span class=normal><a href=#__codelineno-0-390>390</a></span>
<span class=normal><a href=#__codelineno-0-391>391</a></span>
<span class=normal><a href=#__codelineno-0-392>392</a></span>
<span class=normal><a href=#__codelineno-0-393>393</a></span>
<span class=normal><a href=#__codelineno-0-394>394</a></span>
<span class=normal><a href=#__codelineno-0-395>395</a></span>
<span class=normal><a href=#__codelineno-0-396>396</a></span>
<span class=normal><a href=#__codelineno-0-397>397</a></span>
<span class=normal><a href=#__codelineno-0-398>398</a></span>
<span class=normal><a href=#__codelineno-0-399>399</a></span>
<span class=normal><a href=#__codelineno-0-400>400</a></span>
<span class=normal><a href=#__codelineno-0-401>401</a></span>
<span class=normal><a href=#__codelineno-0-402>402</a></span>
<span class=normal><a href=#__codelineno-0-403>403</a></span>
<span class=normal><a href=#__codelineno-0-404>404</a></span>
<span class=normal><a href=#__codelineno-0-405>405</a></span>
<span class=normal><a href=#__codelineno-0-406>406</a></span>
<span class=normal><a href=#__codelineno-0-407>407</a></span>
<span class=normal><a href=#__codelineno-0-408>408</a></span>
<span class=normal><a href=#__codelineno-0-409>409</a></span>
<span class=normal><a href=#__codelineno-0-410>410</a></span>
<span class=normal><a href=#__codelineno-0-411>411</a></span>
<span class=normal><a href=#__codelineno-0-412>412</a></span>
<span class=normal><a href=#__codelineno-0-413>413</a></span>
<span class=normal><a href=#__codelineno-0-414>414</a></span>
<span class=normal><a href=#__codelineno-0-415>415</a></span>
<span class=normal><a href=#__codelineno-0-416>416</a></span>
<span class=normal><a href=#__codelineno-0-417>417</a></span>
<span class=normal><a href=#__codelineno-0-418>418</a></span>
<span class=normal><a href=#__codelineno-0-419>419</a></span>
<span class=normal><a href=#__codelineno-0-420>420</a></span>
<span class=normal><a href=#__codelineno-0-421>421</a></span>
<span class=normal><a href=#__codelineno-0-422>422</a></span>
<span class=normal><a href=#__codelineno-0-423>423</a></span>
<span class=normal><a href=#__codelineno-0-424>424</a></span>
<span class=normal><a href=#__codelineno-0-425>425</a></span>
<span class=normal><a href=#__codelineno-0-426>426</a></span>
<span class=normal><a href=#__codelineno-0-427>427</a></span>
<span class=normal><a href=#__codelineno-0-428>428</a></span>
<span class=normal><a href=#__codelineno-0-429>429</a></span>
<span class=normal><a href=#__codelineno-0-430>430</a></span>
<span class=normal><a href=#__codelineno-0-431>431</a></span>
<span class=normal><a href=#__codelineno-0-432>432</a></span>
<span class=normal><a href=#__codelineno-0-433>433</a></span>
<span class=normal><a href=#__codelineno-0-434>434</a></span>
<span class=normal><a href=#__codelineno-0-435>435</a></span>
<span class=normal><a href=#__codelineno-0-436>436</a></span>
<span class=normal><a href=#__codelineno-0-437>437</a></span>
<span class=normal><a href=#__codelineno-0-438>438</a></span>
<span class=normal><a href=#__codelineno-0-439>439</a></span>
<span class=normal><a href=#__codelineno-0-440>440</a></span>
<span class=normal><a href=#__codelineno-0-441>441</a></span>
<span class=normal><a href=#__codelineno-0-442>442</a></span>
<span class=normal><a href=#__codelineno-0-443>443</a></span>
<span class=normal><a href=#__codelineno-0-444>444</a></span>
<span class=normal><a href=#__codelineno-0-445>445</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-317 name=__codelineno-0-317></a><span class=k>class</span><span class=w> </span><span class=nc>RecursiveLeastSquares</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>):</span>
<a id=__codelineno-0-318 name=__codelineno-0-318></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Recursive Least Squares (RLS) filter for parameter estimation.</span>
<a id=__codelineno-0-319 name=__codelineno-0-319></a>
<a id=__codelineno-0-320 name=__codelineno-0-320></a><span class=sd>    The Recursive Least Squares method is used to estimate the parameters of a model</span>
<a id=__codelineno-0-321 name=__codelineno-0-321></a><span class=sd>    by minimizing the sum of the squares of the differences between the observed and</span>
<a id=__codelineno-0-322 name=__codelineno-0-322></a><span class=sd>    predicted values. This method incorporates a forgetting factor to give more weight</span>
<a id=__codelineno-0-323 name=__codelineno-0-323></a><span class=sd>    to recent observations.</span>
<a id=__codelineno-0-324 name=__codelineno-0-324></a>
<a id=__codelineno-0-325 name=__codelineno-0-325></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-326 name=__codelineno-0-326></a><span class=sd>    ----------</span>
<a id=__codelineno-0-327 name=__codelineno-0-327></a><span class=sd>    lam : float, default=0.98</span>
<a id=__codelineno-0-328 name=__codelineno-0-328></a><span class=sd>        Forgetting factor of the Recursive Least Squares method.</span>
<a id=__codelineno-0-329 name=__codelineno-0-329></a><span class=sd>    delta : float, default=0.01</span>
<a id=__codelineno-0-330 name=__codelineno-0-330></a><span class=sd>        Normalization factor of the P matrix.</span>
<a id=__codelineno-0-331 name=__codelineno-0-331></a><span class=sd>    unbiased : bool, optional</span>
<a id=__codelineno-0-332 name=__codelineno-0-332></a><span class=sd>        If True, applies an unbiased estimator. Default is False.</span>
<a id=__codelineno-0-333 name=__codelineno-0-333></a><span class=sd>    uiter : int, optional</span>
<a id=__codelineno-0-334 name=__codelineno-0-334></a><span class=sd>        Number of iterations for the unbiased estimator. Default is 30.</span>
<a id=__codelineno-0-335 name=__codelineno-0-335></a>
<a id=__codelineno-0-336 name=__codelineno-0-336></a><span class=sd>    Attributes</span>
<a id=__codelineno-0-337 name=__codelineno-0-337></a><span class=sd>    ----------</span>
<a id=__codelineno-0-338 name=__codelineno-0-338></a><span class=sd>    lam : float</span>
<a id=__codelineno-0-339 name=__codelineno-0-339></a><span class=sd>        Forgetting factor of the Recursive Least Squares method.</span>
<a id=__codelineno-0-340 name=__codelineno-0-340></a><span class=sd>    delta : float</span>
<a id=__codelineno-0-341 name=__codelineno-0-341></a><span class=sd>        Normalization factor of the P matrix.</span>
<a id=__codelineno-0-342 name=__codelineno-0-342></a><span class=sd>    xi : np.ndarray</span>
<a id=__codelineno-0-343 name=__codelineno-0-343></a><span class=sd>        The estimation error at each iteration.</span>
<a id=__codelineno-0-344 name=__codelineno-0-344></a><span class=sd>    theta_evolution : np.ndarray</span>
<a id=__codelineno-0-345 name=__codelineno-0-345></a><span class=sd>        Evolution of the estimated parameters over iterations.</span>
<a id=__codelineno-0-346 name=__codelineno-0-346></a>
<a id=__codelineno-0-347 name=__codelineno-0-347></a><span class=sd>    Methods</span>
<a id=__codelineno-0-348 name=__codelineno-0-348></a><span class=sd>    -------</span>
<a id=__codelineno-0-349 name=__codelineno-0-349></a><span class=sd>    optimize(psi: np.ndarray, y: np.ndarray) -&gt; np.ndarray</span>
<a id=__codelineno-0-350 name=__codelineno-0-350></a><span class=sd>        Estimate the model parameters using the Recursive Least Squares method.</span>
<a id=__codelineno-0-351 name=__codelineno-0-351></a>
<a id=__codelineno-0-352 name=__codelineno-0-352></a><span class=sd>    References</span>
<a id=__codelineno-0-353 name=__codelineno-0-353></a><span class=sd>    ----------</span>
<a id=__codelineno-0-354 name=__codelineno-0-354></a><span class=sd>    - Book (Portuguese): Aguirre, L. A. (2007). Introdução identificação</span>
<a id=__codelineno-0-355 name=__codelineno-0-355></a><span class=sd>       de sistemas: técnicas lineares e não-lineares aplicadas a sistemas</span>
<a id=__codelineno-0-356 name=__codelineno-0-356></a><span class=sd>       reais. Editora da UFMG. 3a edição.</span>
<a id=__codelineno-0-357 name=__codelineno-0-357></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-358 name=__codelineno-0-358></a>
<a id=__codelineno-0-359 name=__codelineno-0-359></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span>
<a id=__codelineno-0-360 name=__codelineno-0-360></a>        <span class=bp>self</span><span class=p>,</span>
<a id=__codelineno-0-361 name=__codelineno-0-361></a>        <span class=o>*</span><span class=p>,</span>
<a id=__codelineno-0-362 name=__codelineno-0-362></a>        <span class=n>delta</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.01</span><span class=p>,</span>
<a id=__codelineno-0-363 name=__codelineno-0-363></a>        <span class=n>lam</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.98</span><span class=p>,</span>
<a id=__codelineno-0-364 name=__codelineno-0-364></a>        <span class=n>unbiased</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>
<a id=__codelineno-0-365 name=__codelineno-0-365></a>        <span class=n>uiter</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>30</span><span class=p>,</span>
<a id=__codelineno-0-366 name=__codelineno-0-366></a>    <span class=p>):</span>
<a id=__codelineno-0-367 name=__codelineno-0-367></a>        <span class=bp>self</span><span class=o>.</span><span class=n>delta</span> <span class=o>=</span> <span class=n>delta</span>
<a id=__codelineno-0-368 name=__codelineno-0-368></a>        <span class=bp>self</span><span class=o>.</span><span class=n>lam</span> <span class=o>=</span> <span class=n>lam</span>
<a id=__codelineno-0-369 name=__codelineno-0-369></a>        <span class=bp>self</span><span class=o>.</span><span class=n>unbiased</span> <span class=o>=</span> <span class=n>unbiased</span>
<a id=__codelineno-0-370 name=__codelineno-0-370></a>        <span class=bp>self</span><span class=o>.</span><span class=n>uiter</span> <span class=o>=</span> <span class=n>uiter</span>
<a id=__codelineno-0-371 name=__codelineno-0-371></a>        <span class=n>_validate_params</span><span class=p>(</span><span class=nb>vars</span><span class=p>(</span><span class=bp>self</span><span class=p>))</span>
<a id=__codelineno-0-372 name=__codelineno-0-372></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
<a id=__codelineno-0-373 name=__codelineno-0-373></a>        <span class=bp>self</span><span class=o>.</span><span class=n>theta_evolution</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
<a id=__codelineno-0-374 name=__codelineno-0-374></a>
<a id=__codelineno-0-375 name=__codelineno-0-375></a>    <span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-376 name=__codelineno-0-376></a><span class=w>        </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Estimate the model parameters using the Recursive Least Squares method.</span>
<a id=__codelineno-0-377 name=__codelineno-0-377></a>
<a id=__codelineno-0-378 name=__codelineno-0-378></a><span class=sd>        The implementation considers the forgetting factor.</span>
<a id=__codelineno-0-379 name=__codelineno-0-379></a>
<a id=__codelineno-0-380 name=__codelineno-0-380></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-381 name=__codelineno-0-381></a><span class=sd>        ----------</span>
<a id=__codelineno-0-382 name=__codelineno-0-382></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-383 name=__codelineno-0-383></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-384 name=__codelineno-0-384></a><span class=sd>        y : array-like of shape = y_training</span>
<a id=__codelineno-0-385 name=__codelineno-0-385></a><span class=sd>            The data used to train the model.</span>
<a id=__codelineno-0-386 name=__codelineno-0-386></a>
<a id=__codelineno-0-387 name=__codelineno-0-387></a><span class=sd>        Returns</span>
<a id=__codelineno-0-388 name=__codelineno-0-388></a><span class=sd>        -------</span>
<a id=__codelineno-0-389 name=__codelineno-0-389></a><span class=sd>        theta : array-like of shape = number_of_model_elements</span>
<a id=__codelineno-0-390 name=__codelineno-0-390></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-391 name=__codelineno-0-391></a>
<a id=__codelineno-0-392 name=__codelineno-0-392></a><span class=sd>        Notes</span>
<a id=__codelineno-0-393 name=__codelineno-0-393></a><span class=sd>        -----</span>
<a id=__codelineno-0-394 name=__codelineno-0-394></a><span class=sd>        The RLS algorithm updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-395 name=__codelineno-0-395></a>
<a id=__codelineno-0-396 name=__codelineno-0-396></a><span class=sd>        1. Initialize the parameter vector `theta` and the covariance matrix `P`:</span>
<a id=__codelineno-0-397 name=__codelineno-0-397></a>
<a id=__codelineno-0-398 name=__codelineno-0-398></a><span class=sd>           $$</span>
<a id=__codelineno-0-399 name=__codelineno-0-399></a><span class=sd>           \\theta_0 = \\mathbf{0}, \\quad P_0 = \\frac{1}{\\delta} I</span>
<a id=__codelineno-0-400 name=__codelineno-0-400></a><span class=sd>           $$</span>
<a id=__codelineno-0-401 name=__codelineno-0-401></a>
<a id=__codelineno-0-402 name=__codelineno-0-402></a><span class=sd>        2. For each new observation `(psi_i, y_i)`, update the estimates:</span>
<a id=__codelineno-0-403 name=__codelineno-0-403></a>
<a id=__codelineno-0-404 name=__codelineno-0-404></a><span class=sd>           $$</span>
<a id=__codelineno-0-405 name=__codelineno-0-405></a><span class=sd>           k_i = \\frac{\\lambda^{-1} P_{i-1} \\psi_i}{1 +</span>
<a id=__codelineno-0-406 name=__codelineno-0-406></a><span class=sd>           \\lambda^{-1} \\psi_i^T P_{i-1} \\psi_i}</span>
<a id=__codelineno-0-407 name=__codelineno-0-407></a><span class=sd>           $$</span>
<a id=__codelineno-0-408 name=__codelineno-0-408></a>
<a id=__codelineno-0-409 name=__codelineno-0-409></a><span class=sd>           $$</span>
<a id=__codelineno-0-410 name=__codelineno-0-410></a><span class=sd>           \\theta_i = \\theta_{i-1} + k_i (y_i - \\psi_i^T \\theta_{i-1})</span>
<a id=__codelineno-0-411 name=__codelineno-0-411></a><span class=sd>           $$</span>
<a id=__codelineno-0-412 name=__codelineno-0-412></a>
<a id=__codelineno-0-413 name=__codelineno-0-413></a><span class=sd>           $$</span>
<a id=__codelineno-0-414 name=__codelineno-0-414></a><span class=sd>           P_i = \\lambda^{-1} (P_{i-1} - k_i \\psi_i^T P_{i-1})</span>
<a id=__codelineno-0-415 name=__codelineno-0-415></a><span class=sd>           $$</span>
<a id=__codelineno-0-416 name=__codelineno-0-416></a>
<a id=__codelineno-0-417 name=__codelineno-0-417></a><span class=sd>        References</span>
<a id=__codelineno-0-418 name=__codelineno-0-418></a><span class=sd>        ----------</span>
<a id=__codelineno-0-419 name=__codelineno-0-419></a><span class=sd>        - Book (Portuguese): Aguirre, L. A. (2007). Introdução identificação</span>
<a id=__codelineno-0-420 name=__codelineno-0-420></a><span class=sd>           de sistemas: técnicas lineares e não-lineares aplicadas a sistemas</span>
<a id=__codelineno-0-421 name=__codelineno-0-421></a><span class=sd>           reais. Editora da UFMG. 3a edição.</span>
<a id=__codelineno-0-422 name=__codelineno-0-422></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-423 name=__codelineno-0-423></a>        <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-424 name=__codelineno-0-424></a>        <span class=n>p</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>eye</span><span class=p>(</span><span class=n>n_theta</span><span class=p>)</span> <span class=o>/</span> <span class=bp>self</span><span class=o>.</span><span class=n>delta</span>
<a id=__codelineno-0-425 name=__codelineno-0-425></a>
<a id=__codelineno-0-426 name=__codelineno-0-426></a>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-427 name=__codelineno-0-427></a>            <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-428 name=__codelineno-0-428></a>            <span class=n>k_numerator</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>lam</span> <span class=o>**</span> <span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=n>p</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=p>)</span>
<a id=__codelineno-0-429 name=__codelineno-0-429></a>            <span class=n>k_denominator</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>lam</span> <span class=o>**</span> <span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>p</span><span class=p>)</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=p>)</span>
<a id=__codelineno-0-430 name=__codelineno-0-430></a>            <span class=n>k</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>divide</span><span class=p>(</span><span class=n>k_numerator</span><span class=p>,</span> <span class=n>k_denominator</span><span class=p>)</span>
<a id=__codelineno-0-431 name=__codelineno-0-431></a>            <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-432 name=__codelineno-0-432></a>            <span class=n>tmp_list</span> <span class=o>=</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=n>k</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>])</span>
<a id=__codelineno-0-433 name=__codelineno-0-433></a>            <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-434 name=__codelineno-0-434></a>
<a id=__codelineno-0-435 name=__codelineno-0-435></a>            <span class=n>p1</span> <span class=o>=</span> <span class=n>p</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>T</span><span class=p>)</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>p</span><span class=p>)</span>
<a id=__codelineno-0-436 name=__codelineno-0-436></a>            <span class=n>p2</span> <span class=o>=</span> <span class=p>(</span>
<a id=__codelineno-0-437 name=__codelineno-0-437></a>                <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>T</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>p</span><span class=p>)</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
<a id=__codelineno-0-438 name=__codelineno-0-438></a>                <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>lam</span>
<a id=__codelineno-0-439 name=__codelineno-0-439></a>            <span class=p>)</span>
<a id=__codelineno-0-440 name=__codelineno-0-440></a>
<a id=__codelineno-0-441 name=__codelineno-0-441></a>            <span class=n>p_numerator</span> <span class=o>=</span> <span class=n>p</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>divide</span><span class=p>(</span><span class=n>p1</span><span class=p>,</span> <span class=n>p2</span><span class=p>)</span>
<a id=__codelineno-0-442 name=__codelineno-0-442></a>            <span class=n>p</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>divide</span><span class=p>(</span><span class=n>p_numerator</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>lam</span><span class=p>)</span>
<a id=__codelineno-0-443 name=__codelineno-0-443></a>
<a id=__codelineno-0-444 name=__codelineno-0-444></a>        <span class=bp>self</span><span class=o>.</span><span class=n>theta_evolution</span> <span class=o>=</span> <span class=n>theta</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
<a id=__codelineno-0-445 name=__codelineno-0-445></a>        <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.RecursiveLeastSquares.optimize class="doc doc-heading"> <code class="highlight language-python"><span class=n>optimize</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.RecursiveLeastSquares.optimize class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Estimate the model parameters using the Recursive Least Squares method.</p> <p>The implementation considers the forgetting factor.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>array-like of shape = y_training</code> </td> <td> <div class=doc-md-description> <p>The data used to train the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>array-like of shape = number_of_model_elements</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=note open> <summary>Notes</summary> <p>The RLS algorithm updates the parameter estimates recursively as follows:</p> <ol> <li>Initialize the parameter vector <code>theta</code> and the covariance matrix <code>P</code>:</li> </ol> <p>$$ \theta_0 = \mathbf{0}, \quad P_0 = \frac{1}{\delta} I $$</p> <ol> <li>For each new observation <code>(psi_i, y_i)</code>, update the estimates:</li> </ol> <p>$$ k_i = \frac{\lambda^{-1} P_{i-1} \psi_i}{1 + \lambda^{-1} \psi_i^T P_{i-1} \psi_i} $$</p> <p>$$ \theta_i = \theta_{i-1} + k_i (y_i - \psi_i^T \theta_{i-1}) $$</p> <p>$$ P_i = \lambda^{-1} (P_{i-1} - k_i \psi_i^T P_{i-1}) $$</p> </details> <details class=references open> <summary>References</summary> <ul> <li>Book (Portuguese): Aguirre, L. A. (2007). Introdução identificação de sistemas: técnicas lineares e não-lineares aplicadas a sistemas reais. Editora da UFMG. 3a edição.</li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-375>375</a></span>
<span class=normal><a href=#__codelineno-0-376>376</a></span>
<span class=normal><a href=#__codelineno-0-377>377</a></span>
<span class=normal><a href=#__codelineno-0-378>378</a></span>
<span class=normal><a href=#__codelineno-0-379>379</a></span>
<span class=normal><a href=#__codelineno-0-380>380</a></span>
<span class=normal><a href=#__codelineno-0-381>381</a></span>
<span class=normal><a href=#__codelineno-0-382>382</a></span>
<span class=normal><a href=#__codelineno-0-383>383</a></span>
<span class=normal><a href=#__codelineno-0-384>384</a></span>
<span class=normal><a href=#__codelineno-0-385>385</a></span>
<span class=normal><a href=#__codelineno-0-386>386</a></span>
<span class=normal><a href=#__codelineno-0-387>387</a></span>
<span class=normal><a href=#__codelineno-0-388>388</a></span>
<span class=normal><a href=#__codelineno-0-389>389</a></span>
<span class=normal><a href=#__codelineno-0-390>390</a></span>
<span class=normal><a href=#__codelineno-0-391>391</a></span>
<span class=normal><a href=#__codelineno-0-392>392</a></span>
<span class=normal><a href=#__codelineno-0-393>393</a></span>
<span class=normal><a href=#__codelineno-0-394>394</a></span>
<span class=normal><a href=#__codelineno-0-395>395</a></span>
<span class=normal><a href=#__codelineno-0-396>396</a></span>
<span class=normal><a href=#__codelineno-0-397>397</a></span>
<span class=normal><a href=#__codelineno-0-398>398</a></span>
<span class=normal><a href=#__codelineno-0-399>399</a></span>
<span class=normal><a href=#__codelineno-0-400>400</a></span>
<span class=normal><a href=#__codelineno-0-401>401</a></span>
<span class=normal><a href=#__codelineno-0-402>402</a></span>
<span class=normal><a href=#__codelineno-0-403>403</a></span>
<span class=normal><a href=#__codelineno-0-404>404</a></span>
<span class=normal><a href=#__codelineno-0-405>405</a></span>
<span class=normal><a href=#__codelineno-0-406>406</a></span>
<span class=normal><a href=#__codelineno-0-407>407</a></span>
<span class=normal><a href=#__codelineno-0-408>408</a></span>
<span class=normal><a href=#__codelineno-0-409>409</a></span>
<span class=normal><a href=#__codelineno-0-410>410</a></span>
<span class=normal><a href=#__codelineno-0-411>411</a></span>
<span class=normal><a href=#__codelineno-0-412>412</a></span>
<span class=normal><a href=#__codelineno-0-413>413</a></span>
<span class=normal><a href=#__codelineno-0-414>414</a></span>
<span class=normal><a href=#__codelineno-0-415>415</a></span>
<span class=normal><a href=#__codelineno-0-416>416</a></span>
<span class=normal><a href=#__codelineno-0-417>417</a></span>
<span class=normal><a href=#__codelineno-0-418>418</a></span>
<span class=normal><a href=#__codelineno-0-419>419</a></span>
<span class=normal><a href=#__codelineno-0-420>420</a></span>
<span class=normal><a href=#__codelineno-0-421>421</a></span>
<span class=normal><a href=#__codelineno-0-422>422</a></span>
<span class=normal><a href=#__codelineno-0-423>423</a></span>
<span class=normal><a href=#__codelineno-0-424>424</a></span>
<span class=normal><a href=#__codelineno-0-425>425</a></span>
<span class=normal><a href=#__codelineno-0-426>426</a></span>
<span class=normal><a href=#__codelineno-0-427>427</a></span>
<span class=normal><a href=#__codelineno-0-428>428</a></span>
<span class=normal><a href=#__codelineno-0-429>429</a></span>
<span class=normal><a href=#__codelineno-0-430>430</a></span>
<span class=normal><a href=#__codelineno-0-431>431</a></span>
<span class=normal><a href=#__codelineno-0-432>432</a></span>
<span class=normal><a href=#__codelineno-0-433>433</a></span>
<span class=normal><a href=#__codelineno-0-434>434</a></span>
<span class=normal><a href=#__codelineno-0-435>435</a></span>
<span class=normal><a href=#__codelineno-0-436>436</a></span>
<span class=normal><a href=#__codelineno-0-437>437</a></span>
<span class=normal><a href=#__codelineno-0-438>438</a></span>
<span class=normal><a href=#__codelineno-0-439>439</a></span>
<span class=normal><a href=#__codelineno-0-440>440</a></span>
<span class=normal><a href=#__codelineno-0-441>441</a></span>
<span class=normal><a href=#__codelineno-0-442>442</a></span>
<span class=normal><a href=#__codelineno-0-443>443</a></span>
<span class=normal><a href=#__codelineno-0-444>444</a></span>
<span class=normal><a href=#__codelineno-0-445>445</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-375 name=__codelineno-0-375></a><span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-376 name=__codelineno-0-376></a><span class=w>    </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Estimate the model parameters using the Recursive Least Squares method.</span>
<a id=__codelineno-0-377 name=__codelineno-0-377></a>
<a id=__codelineno-0-378 name=__codelineno-0-378></a><span class=sd>    The implementation considers the forgetting factor.</span>
<a id=__codelineno-0-379 name=__codelineno-0-379></a>
<a id=__codelineno-0-380 name=__codelineno-0-380></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-381 name=__codelineno-0-381></a><span class=sd>    ----------</span>
<a id=__codelineno-0-382 name=__codelineno-0-382></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-383 name=__codelineno-0-383></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-384 name=__codelineno-0-384></a><span class=sd>    y : array-like of shape = y_training</span>
<a id=__codelineno-0-385 name=__codelineno-0-385></a><span class=sd>        The data used to train the model.</span>
<a id=__codelineno-0-386 name=__codelineno-0-386></a>
<a id=__codelineno-0-387 name=__codelineno-0-387></a><span class=sd>    Returns</span>
<a id=__codelineno-0-388 name=__codelineno-0-388></a><span class=sd>    -------</span>
<a id=__codelineno-0-389 name=__codelineno-0-389></a><span class=sd>    theta : array-like of shape = number_of_model_elements</span>
<a id=__codelineno-0-390 name=__codelineno-0-390></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-391 name=__codelineno-0-391></a>
<a id=__codelineno-0-392 name=__codelineno-0-392></a><span class=sd>    Notes</span>
<a id=__codelineno-0-393 name=__codelineno-0-393></a><span class=sd>    -----</span>
<a id=__codelineno-0-394 name=__codelineno-0-394></a><span class=sd>    The RLS algorithm updates the parameter estimates recursively as follows:</span>
<a id=__codelineno-0-395 name=__codelineno-0-395></a>
<a id=__codelineno-0-396 name=__codelineno-0-396></a><span class=sd>    1. Initialize the parameter vector `theta` and the covariance matrix `P`:</span>
<a id=__codelineno-0-397 name=__codelineno-0-397></a>
<a id=__codelineno-0-398 name=__codelineno-0-398></a><span class=sd>       $$</span>
<a id=__codelineno-0-399 name=__codelineno-0-399></a><span class=sd>       \\theta_0 = \\mathbf{0}, \\quad P_0 = \\frac{1}{\\delta} I</span>
<a id=__codelineno-0-400 name=__codelineno-0-400></a><span class=sd>       $$</span>
<a id=__codelineno-0-401 name=__codelineno-0-401></a>
<a id=__codelineno-0-402 name=__codelineno-0-402></a><span class=sd>    2. For each new observation `(psi_i, y_i)`, update the estimates:</span>
<a id=__codelineno-0-403 name=__codelineno-0-403></a>
<a id=__codelineno-0-404 name=__codelineno-0-404></a><span class=sd>       $$</span>
<a id=__codelineno-0-405 name=__codelineno-0-405></a><span class=sd>       k_i = \\frac{\\lambda^{-1} P_{i-1} \\psi_i}{1 +</span>
<a id=__codelineno-0-406 name=__codelineno-0-406></a><span class=sd>       \\lambda^{-1} \\psi_i^T P_{i-1} \\psi_i}</span>
<a id=__codelineno-0-407 name=__codelineno-0-407></a><span class=sd>       $$</span>
<a id=__codelineno-0-408 name=__codelineno-0-408></a>
<a id=__codelineno-0-409 name=__codelineno-0-409></a><span class=sd>       $$</span>
<a id=__codelineno-0-410 name=__codelineno-0-410></a><span class=sd>       \\theta_i = \\theta_{i-1} + k_i (y_i - \\psi_i^T \\theta_{i-1})</span>
<a id=__codelineno-0-411 name=__codelineno-0-411></a><span class=sd>       $$</span>
<a id=__codelineno-0-412 name=__codelineno-0-412></a>
<a id=__codelineno-0-413 name=__codelineno-0-413></a><span class=sd>       $$</span>
<a id=__codelineno-0-414 name=__codelineno-0-414></a><span class=sd>       P_i = \\lambda^{-1} (P_{i-1} - k_i \\psi_i^T P_{i-1})</span>
<a id=__codelineno-0-415 name=__codelineno-0-415></a><span class=sd>       $$</span>
<a id=__codelineno-0-416 name=__codelineno-0-416></a>
<a id=__codelineno-0-417 name=__codelineno-0-417></a><span class=sd>    References</span>
<a id=__codelineno-0-418 name=__codelineno-0-418></a><span class=sd>    ----------</span>
<a id=__codelineno-0-419 name=__codelineno-0-419></a><span class=sd>    - Book (Portuguese): Aguirre, L. A. (2007). Introdução identificação</span>
<a id=__codelineno-0-420 name=__codelineno-0-420></a><span class=sd>       de sistemas: técnicas lineares e não-lineares aplicadas a sistemas</span>
<a id=__codelineno-0-421 name=__codelineno-0-421></a><span class=sd>       reais. Editora da UFMG. 3a edição.</span>
<a id=__codelineno-0-422 name=__codelineno-0-422></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-423 name=__codelineno-0-423></a>    <span class=n>n_theta</span><span class=p>,</span> <span class=n>n</span><span class=p>,</span> <span class=n>theta</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>xi</span> <span class=o>=</span> <span class=n>_initial_values</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-424 name=__codelineno-0-424></a>    <span class=n>p</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>eye</span><span class=p>(</span><span class=n>n_theta</span><span class=p>)</span> <span class=o>/</span> <span class=bp>self</span><span class=o>.</span><span class=n>delta</span>
<a id=__codelineno-0-425 name=__codelineno-0-425></a>
<a id=__codelineno-0-426 name=__codelineno-0-426></a>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
<a id=__codelineno-0-427 name=__codelineno-0-427></a>        <span class=n>psi_tmp</span> <span class=o>=</span> <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<a id=__codelineno-0-428 name=__codelineno-0-428></a>        <span class=n>k_numerator</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>lam</span> <span class=o>**</span> <span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=n>p</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=p>)</span>
<a id=__codelineno-0-429 name=__codelineno-0-429></a>        <span class=n>k_denominator</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>lam</span> <span class=o>**</span> <span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>p</span><span class=p>)</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=p>)</span>
<a id=__codelineno-0-430 name=__codelineno-0-430></a>        <span class=n>k</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>divide</span><span class=p>(</span><span class=n>k_numerator</span><span class=p>,</span> <span class=n>k_denominator</span><span class=p>)</span>
<a id=__codelineno-0-431 name=__codelineno-0-431></a>        <span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>y</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi_tmp</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])[</span><span class=mi>0</span><span class=p>]</span>
<a id=__codelineno-0-432 name=__codelineno-0-432></a>        <span class=n>tmp_list</span> <span class=o>=</span> <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=n>k</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>xi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>])</span>
<a id=__codelineno-0-433 name=__codelineno-0-433></a>        <span class=n>theta</span><span class=p>[:,</span> <span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp_list</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
<a id=__codelineno-0-434 name=__codelineno-0-434></a>
<a id=__codelineno-0-435 name=__codelineno-0-435></a>        <span class=n>p1</span> <span class=o>=</span> <span class=n>p</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>T</span><span class=p>)</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>p</span><span class=p>)</span>
<a id=__codelineno-0-436 name=__codelineno-0-436></a>        <span class=n>p2</span> <span class=o>=</span> <span class=p>(</span>
<a id=__codelineno-0-437 name=__codelineno-0-437></a>            <span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>T</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>p</span><span class=p>)</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>psi</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
<a id=__codelineno-0-438 name=__codelineno-0-438></a>            <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>lam</span>
<a id=__codelineno-0-439 name=__codelineno-0-439></a>        <span class=p>)</span>
<a id=__codelineno-0-440 name=__codelineno-0-440></a>
<a id=__codelineno-0-441 name=__codelineno-0-441></a>        <span class=n>p_numerator</span> <span class=o>=</span> <span class=n>p</span> <span class=o>-</span> <span class=n>np</span><span class=o>.</span><span class=n>divide</span><span class=p>(</span><span class=n>p1</span><span class=p>,</span> <span class=n>p2</span><span class=p>)</span>
<a id=__codelineno-0-442 name=__codelineno-0-442></a>        <span class=n>p</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>divide</span><span class=p>(</span><span class=n>p_numerator</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>lam</span><span class=p>)</span>
<a id=__codelineno-0-443 name=__codelineno-0-443></a>
<a id=__codelineno-0-444 name=__codelineno-0-444></a>    <span class=bp>self</span><span class=o>.</span><span class=n>theta_evolution</span> <span class=o>=</span> <span class=n>theta</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
<a id=__codelineno-0-445 name=__codelineno-0-445></a>    <span class=k>return</span> <span class=n>theta</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.RidgeRegression class="doc doc-heading"> <code>RidgeRegression</code> <a href=#sysidentpy.parameter_estimation.estimators.RidgeRegression class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=sysidentpy.parameter_estimation.estimators_base.BaseEstimator>BaseEstimator</span></code></p> <p>Ridge Regression estimator using classic and SVD methods.</p> <p>This class implements Ridge Regression, a type of linear regression that includes an L2 penalty to prevent overfitting. The implementation offers two methods for parameter estimation: a classic approach and an approach based on Singular Value Decomposition (SVD).</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>alpha</code> </td> <td> <code>(<span title=numpy.float64>float64</span>, <span title=optional>optional</span>(default=<span title=eps>eps</span>))</code> </td> <td> <div class=doc-md-description> <p>Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. If the input is a noisy signal, the ridge parameter is likely to be set close to the noise level, at least as a starting point. Entered through the self data structure.</p> </div> </td> <td> <code><span title=eps>eps</span></code> </td> </tr> <tr class=doc-section-item> <td> <code>solver</code> </td> <td> <code>(<span title=str>str</span>, <span title=optional>optional</span>(default=<span title=svd>svd</span>))</code> </td> <td> <div class=doc-md-description> <p>Solver to use in the parameter estimation procedure.</p> </div> </td> <td> <code>&#39;svd&#39;</code> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Methods:</span></p> <table> <thead> <tr> <th>Name</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code><a class="autorefs autorefs-internal" title="<code>sysidentpy.parameter_estimation.estimators.RidgeRegression.ridge_regression_classic</code>" href=../../../../user-guide/API/parameter-estimation/#sysidentpy.parameter_estimation.estimators.RidgeRegression.ridge_regression_classic>ridge_regression_classic</a></code></td> <td> <div class=doc-md-description> <p>Estimate the model parameters using the classic ridge regression method.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><a class="autorefs autorefs-internal" title="<code>sysidentpy.parameter_estimation.estimators.RidgeRegression.ridge_regression</code>" href=../../../../user-guide/API/parameter-estimation/#sysidentpy.parameter_estimation.estimators.RidgeRegression.ridge_regression>ridge_regression</a></code></td> <td> <div class=doc-md-description> <p>Estimate the model parameters using the SVD-based ridge regression method.</p> </div> </td> </tr> <tr class=doc-section-item> <td><code><span title=sysidentpy.parameter_estimation.estimators.RidgeRegression.optimize>optimize</span></code></td> <td> <div class=doc-md-description> <p>Optimize the model parameters using the chosen method (SVD or classic).</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Wikipedia entry on ridge regression <a href=https://en.wikipedia.org/wiki/Ridge_regression>https://en.wikipedia.org/wiki/Ridge_regression</a></li> <li>D. J. Gauthier, E. Bollt, A. Griffith, W. A. S. Barbosa, 'Next generation reservoir computing,' Nat. Commun. 12, 5564 (2021). <a href=https://www.nature.com/articles/s41467-021-25801-2>https://www.nature.com/articles/s41467-021-25801-2</a></li> <li>Hoerl, A. E.; Kennard, R. W. Ridge regression: applications to nonorthogonal problems. Technometrics, Taylor &amp; Francis, v. 12, n. 1, p. 69-82, 1970.</li> <li>StackExchange: whuber. The proof of shrinking coefficients using ridge regression through "spectral decomposition". Cross Validated, accessed 21 September 2023, <a href=https://stats.stackexchange.com/q/220324>https://stats.stackexchange.com/q/220324</a></li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-100>100</a></span>
<span class=normal><a href=#__codelineno-0-101>101</a></span>
<span class=normal><a href=#__codelineno-0-102>102</a></span>
<span class=normal><a href=#__codelineno-0-103>103</a></span>
<span class=normal><a href=#__codelineno-0-104>104</a></span>
<span class=normal><a href=#__codelineno-0-105>105</a></span>
<span class=normal><a href=#__codelineno-0-106>106</a></span>
<span class=normal><a href=#__codelineno-0-107>107</a></span>
<span class=normal><a href=#__codelineno-0-108>108</a></span>
<span class=normal><a href=#__codelineno-0-109>109</a></span>
<span class=normal><a href=#__codelineno-0-110>110</a></span>
<span class=normal><a href=#__codelineno-0-111>111</a></span>
<span class=normal><a href=#__codelineno-0-112>112</a></span>
<span class=normal><a href=#__codelineno-0-113>113</a></span>
<span class=normal><a href=#__codelineno-0-114>114</a></span>
<span class=normal><a href=#__codelineno-0-115>115</a></span>
<span class=normal><a href=#__codelineno-0-116>116</a></span>
<span class=normal><a href=#__codelineno-0-117>117</a></span>
<span class=normal><a href=#__codelineno-0-118>118</a></span>
<span class=normal><a href=#__codelineno-0-119>119</a></span>
<span class=normal><a href=#__codelineno-0-120>120</a></span>
<span class=normal><a href=#__codelineno-0-121>121</a></span>
<span class=normal><a href=#__codelineno-0-122>122</a></span>
<span class=normal><a href=#__codelineno-0-123>123</a></span>
<span class=normal><a href=#__codelineno-0-124>124</a></span>
<span class=normal><a href=#__codelineno-0-125>125</a></span>
<span class=normal><a href=#__codelineno-0-126>126</a></span>
<span class=normal><a href=#__codelineno-0-127>127</a></span>
<span class=normal><a href=#__codelineno-0-128>128</a></span>
<span class=normal><a href=#__codelineno-0-129>129</a></span>
<span class=normal><a href=#__codelineno-0-130>130</a></span>
<span class=normal><a href=#__codelineno-0-131>131</a></span>
<span class=normal><a href=#__codelineno-0-132>132</a></span>
<span class=normal><a href=#__codelineno-0-133>133</a></span>
<span class=normal><a href=#__codelineno-0-134>134</a></span>
<span class=normal><a href=#__codelineno-0-135>135</a></span>
<span class=normal><a href=#__codelineno-0-136>136</a></span>
<span class=normal><a href=#__codelineno-0-137>137</a></span>
<span class=normal><a href=#__codelineno-0-138>138</a></span>
<span class=normal><a href=#__codelineno-0-139>139</a></span>
<span class=normal><a href=#__codelineno-0-140>140</a></span>
<span class=normal><a href=#__codelineno-0-141>141</a></span>
<span class=normal><a href=#__codelineno-0-142>142</a></span>
<span class=normal><a href=#__codelineno-0-143>143</a></span>
<span class=normal><a href=#__codelineno-0-144>144</a></span>
<span class=normal><a href=#__codelineno-0-145>145</a></span>
<span class=normal><a href=#__codelineno-0-146>146</a></span>
<span class=normal><a href=#__codelineno-0-147>147</a></span>
<span class=normal><a href=#__codelineno-0-148>148</a></span>
<span class=normal><a href=#__codelineno-0-149>149</a></span>
<span class=normal><a href=#__codelineno-0-150>150</a></span>
<span class=normal><a href=#__codelineno-0-151>151</a></span>
<span class=normal><a href=#__codelineno-0-152>152</a></span>
<span class=normal><a href=#__codelineno-0-153>153</a></span>
<span class=normal><a href=#__codelineno-0-154>154</a></span>
<span class=normal><a href=#__codelineno-0-155>155</a></span>
<span class=normal><a href=#__codelineno-0-156>156</a></span>
<span class=normal><a href=#__codelineno-0-157>157</a></span>
<span class=normal><a href=#__codelineno-0-158>158</a></span>
<span class=normal><a href=#__codelineno-0-159>159</a></span>
<span class=normal><a href=#__codelineno-0-160>160</a></span>
<span class=normal><a href=#__codelineno-0-161>161</a></span>
<span class=normal><a href=#__codelineno-0-162>162</a></span>
<span class=normal><a href=#__codelineno-0-163>163</a></span>
<span class=normal><a href=#__codelineno-0-164>164</a></span>
<span class=normal><a href=#__codelineno-0-165>165</a></span>
<span class=normal><a href=#__codelineno-0-166>166</a></span>
<span class=normal><a href=#__codelineno-0-167>167</a></span>
<span class=normal><a href=#__codelineno-0-168>168</a></span>
<span class=normal><a href=#__codelineno-0-169>169</a></span>
<span class=normal><a href=#__codelineno-0-170>170</a></span>
<span class=normal><a href=#__codelineno-0-171>171</a></span>
<span class=normal><a href=#__codelineno-0-172>172</a></span>
<span class=normal><a href=#__codelineno-0-173>173</a></span>
<span class=normal><a href=#__codelineno-0-174>174</a></span>
<span class=normal><a href=#__codelineno-0-175>175</a></span>
<span class=normal><a href=#__codelineno-0-176>176</a></span>
<span class=normal><a href=#__codelineno-0-177>177</a></span>
<span class=normal><a href=#__codelineno-0-178>178</a></span>
<span class=normal><a href=#__codelineno-0-179>179</a></span>
<span class=normal><a href=#__codelineno-0-180>180</a></span>
<span class=normal><a href=#__codelineno-0-181>181</a></span>
<span class=normal><a href=#__codelineno-0-182>182</a></span>
<span class=normal><a href=#__codelineno-0-183>183</a></span>
<span class=normal><a href=#__codelineno-0-184>184</a></span>
<span class=normal><a href=#__codelineno-0-185>185</a></span>
<span class=normal><a href=#__codelineno-0-186>186</a></span>
<span class=normal><a href=#__codelineno-0-187>187</a></span>
<span class=normal><a href=#__codelineno-0-188>188</a></span>
<span class=normal><a href=#__codelineno-0-189>189</a></span>
<span class=normal><a href=#__codelineno-0-190>190</a></span>
<span class=normal><a href=#__codelineno-0-191>191</a></span>
<span class=normal><a href=#__codelineno-0-192>192</a></span>
<span class=normal><a href=#__codelineno-0-193>193</a></span>
<span class=normal><a href=#__codelineno-0-194>194</a></span>
<span class=normal><a href=#__codelineno-0-195>195</a></span>
<span class=normal><a href=#__codelineno-0-196>196</a></span>
<span class=normal><a href=#__codelineno-0-197>197</a></span>
<span class=normal><a href=#__codelineno-0-198>198</a></span>
<span class=normal><a href=#__codelineno-0-199>199</a></span>
<span class=normal><a href=#__codelineno-0-200>200</a></span>
<span class=normal><a href=#__codelineno-0-201>201</a></span>
<span class=normal><a href=#__codelineno-0-202>202</a></span>
<span class=normal><a href=#__codelineno-0-203>203</a></span>
<span class=normal><a href=#__codelineno-0-204>204</a></span>
<span class=normal><a href=#__codelineno-0-205>205</a></span>
<span class=normal><a href=#__codelineno-0-206>206</a></span>
<span class=normal><a href=#__codelineno-0-207>207</a></span>
<span class=normal><a href=#__codelineno-0-208>208</a></span>
<span class=normal><a href=#__codelineno-0-209>209</a></span>
<span class=normal><a href=#__codelineno-0-210>210</a></span>
<span class=normal><a href=#__codelineno-0-211>211</a></span>
<span class=normal><a href=#__codelineno-0-212>212</a></span>
<span class=normal><a href=#__codelineno-0-213>213</a></span>
<span class=normal><a href=#__codelineno-0-214>214</a></span>
<span class=normal><a href=#__codelineno-0-215>215</a></span>
<span class=normal><a href=#__codelineno-0-216>216</a></span>
<span class=normal><a href=#__codelineno-0-217>217</a></span>
<span class=normal><a href=#__codelineno-0-218>218</a></span>
<span class=normal><a href=#__codelineno-0-219>219</a></span>
<span class=normal><a href=#__codelineno-0-220>220</a></span>
<span class=normal><a href=#__codelineno-0-221>221</a></span>
<span class=normal><a href=#__codelineno-0-222>222</a></span>
<span class=normal><a href=#__codelineno-0-223>223</a></span>
<span class=normal><a href=#__codelineno-0-224>224</a></span>
<span class=normal><a href=#__codelineno-0-225>225</a></span>
<span class=normal><a href=#__codelineno-0-226>226</a></span>
<span class=normal><a href=#__codelineno-0-227>227</a></span>
<span class=normal><a href=#__codelineno-0-228>228</a></span>
<span class=normal><a href=#__codelineno-0-229>229</a></span>
<span class=normal><a href=#__codelineno-0-230>230</a></span>
<span class=normal><a href=#__codelineno-0-231>231</a></span>
<span class=normal><a href=#__codelineno-0-232>232</a></span>
<span class=normal><a href=#__codelineno-0-233>233</a></span>
<span class=normal><a href=#__codelineno-0-234>234</a></span>
<span class=normal><a href=#__codelineno-0-235>235</a></span>
<span class=normal><a href=#__codelineno-0-236>236</a></span>
<span class=normal><a href=#__codelineno-0-237>237</a></span>
<span class=normal><a href=#__codelineno-0-238>238</a></span>
<span class=normal><a href=#__codelineno-0-239>239</a></span>
<span class=normal><a href=#__codelineno-0-240>240</a></span>
<span class=normal><a href=#__codelineno-0-241>241</a></span>
<span class=normal><a href=#__codelineno-0-242>242</a></span>
<span class=normal><a href=#__codelineno-0-243>243</a></span>
<span class=normal><a href=#__codelineno-0-244>244</a></span>
<span class=normal><a href=#__codelineno-0-245>245</a></span>
<span class=normal><a href=#__codelineno-0-246>246</a></span>
<span class=normal><a href=#__codelineno-0-247>247</a></span>
<span class=normal><a href=#__codelineno-0-248>248</a></span>
<span class=normal><a href=#__codelineno-0-249>249</a></span>
<span class=normal><a href=#__codelineno-0-250>250</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-100 name=__codelineno-0-100></a><span class=nd>@deprecated</span><span class=p>(</span>
<a id=__codelineno-0-101 name=__codelineno-0-101></a>    <span class=n>version</span><span class=o>=</span><span class=s2>&quot;v0.6.0&quot;</span><span class=p>,</span>
<a id=__codelineno-0-102 name=__codelineno-0-102></a>    <span class=n>future_version</span><span class=o>=</span><span class=s2>&quot;v1.0.0&quot;</span><span class=p>,</span>
<a id=__codelineno-0-103 name=__codelineno-0-103></a>    <span class=n>message</span><span class=o>=</span><span class=p>(</span>
<a id=__codelineno-0-104 name=__codelineno-0-104></a>        <span class=s2>&quot; `solver` is deprecated in v0.5.4 and will be removed in v1.0.0.&quot;</span>
<a id=__codelineno-0-105 name=__codelineno-0-105></a>        <span class=s2>&quot; A single solver option will be retained moving forward.&quot;</span>
<a id=__codelineno-0-106 name=__codelineno-0-106></a>    <span class=p>),</span>
<a id=__codelineno-0-107 name=__codelineno-0-107></a><span class=p>)</span>
<a id=__codelineno-0-108 name=__codelineno-0-108></a><span class=k>class</span><span class=w> </span><span class=nc>RidgeRegression</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>):</span>
<a id=__codelineno-0-109 name=__codelineno-0-109></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Ridge Regression estimator using classic and SVD methods.</span>
<a id=__codelineno-0-110 name=__codelineno-0-110></a>
<a id=__codelineno-0-111 name=__codelineno-0-111></a><span class=sd>    This class implements Ridge Regression, a type of linear regression that includes</span>
<a id=__codelineno-0-112 name=__codelineno-0-112></a><span class=sd>    an L2 penalty to prevent overfitting. The implementation offers two methods for</span>
<a id=__codelineno-0-113 name=__codelineno-0-113></a><span class=sd>    parameter estimation: a classic approach and an approach based on Singular Value</span>
<a id=__codelineno-0-114 name=__codelineno-0-114></a><span class=sd>    Decomposition (SVD).</span>
<a id=__codelineno-0-115 name=__codelineno-0-115></a>
<a id=__codelineno-0-116 name=__codelineno-0-116></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-117 name=__codelineno-0-117></a><span class=sd>    ----------</span>
<a id=__codelineno-0-118 name=__codelineno-0-118></a><span class=sd>    alpha : np.float64, optional (default=np.finfo(np.float64).eps)</span>
<a id=__codelineno-0-119 name=__codelineno-0-119></a><span class=sd>        Regularization strength; must be a positive float. Regularization improves the</span>
<a id=__codelineno-0-120 name=__codelineno-0-120></a><span class=sd>        conditioning of the problem and reduces the variance of the estimates. Larger</span>
<a id=__codelineno-0-121 name=__codelineno-0-121></a><span class=sd>        values specify stronger regularization. If the input is a noisy signal,</span>
<a id=__codelineno-0-122 name=__codelineno-0-122></a><span class=sd>        the ridge parameter is likely to be set close to the noise level, at least as</span>
<a id=__codelineno-0-123 name=__codelineno-0-123></a><span class=sd>        a starting point. Entered through the self data structure.</span>
<a id=__codelineno-0-124 name=__codelineno-0-124></a><span class=sd>    solver : str, optional (default=&quot;svd&quot;)</span>
<a id=__codelineno-0-125 name=__codelineno-0-125></a><span class=sd>        Solver to use in the parameter estimation procedure.</span>
<a id=__codelineno-0-126 name=__codelineno-0-126></a>
<a id=__codelineno-0-127 name=__codelineno-0-127></a><span class=sd>    Methods</span>
<a id=__codelineno-0-128 name=__codelineno-0-128></a><span class=sd>    -------</span>
<a id=__codelineno-0-129 name=__codelineno-0-129></a><span class=sd>    ridge_regression_classic(psi, y)</span>
<a id=__codelineno-0-130 name=__codelineno-0-130></a><span class=sd>        Estimate the model parameters using the classic ridge regression method.</span>
<a id=__codelineno-0-131 name=__codelineno-0-131></a><span class=sd>    ridge_regression(psi, y)</span>
<a id=__codelineno-0-132 name=__codelineno-0-132></a><span class=sd>        Estimate the model parameters using the SVD-based ridge regression method.</span>
<a id=__codelineno-0-133 name=__codelineno-0-133></a><span class=sd>    optimize(psi, y)</span>
<a id=__codelineno-0-134 name=__codelineno-0-134></a><span class=sd>        Optimize the model parameters using the chosen method (SVD or classic).</span>
<a id=__codelineno-0-135 name=__codelineno-0-135></a>
<a id=__codelineno-0-136 name=__codelineno-0-136></a><span class=sd>    References</span>
<a id=__codelineno-0-137 name=__codelineno-0-137></a><span class=sd>    ----------</span>
<a id=__codelineno-0-138 name=__codelineno-0-138></a><span class=sd>    - Wikipedia entry on ridge regression</span>
<a id=__codelineno-0-139 name=__codelineno-0-139></a><span class=sd>      https://en.wikipedia.org/wiki/Ridge_regression</span>
<a id=__codelineno-0-140 name=__codelineno-0-140></a><span class=sd>    - D. J. Gauthier, E. Bollt, A. Griffith, W. A. S. Barbosa, &#39;Next generation</span>
<a id=__codelineno-0-141 name=__codelineno-0-141></a><span class=sd>      reservoir computing,&#39; Nat. Commun. 12, 5564 (2021).</span>
<a id=__codelineno-0-142 name=__codelineno-0-142></a><span class=sd>      https://www.nature.com/articles/s41467-021-25801-2</span>
<a id=__codelineno-0-143 name=__codelineno-0-143></a><span class=sd>    - Hoerl, A. E.; Kennard, R. W. Ridge regression: applications to nonorthogonal</span>
<a id=__codelineno-0-144 name=__codelineno-0-144></a><span class=sd>      problems. Technometrics, Taylor &amp; Francis, v. 12, n. 1, p. 69-82, 1970.</span>
<a id=__codelineno-0-145 name=__codelineno-0-145></a><span class=sd>    - StackExchange: whuber. The proof of shrinking coefficients using ridge regression</span>
<a id=__codelineno-0-146 name=__codelineno-0-146></a><span class=sd>      through &quot;spectral decomposition&quot;.</span>
<a id=__codelineno-0-147 name=__codelineno-0-147></a><span class=sd>      Cross Validated, accessed 21 September 2023,</span>
<a id=__codelineno-0-148 name=__codelineno-0-148></a><span class=sd>      https://stats.stackexchange.com/q/220324</span>
<a id=__codelineno-0-149 name=__codelineno-0-149></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-150 name=__codelineno-0-150></a>
<a id=__codelineno-0-151 name=__codelineno-0-151></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span>
<a id=__codelineno-0-152 name=__codelineno-0-152></a>        <span class=bp>self</span><span class=p>,</span>
<a id=__codelineno-0-153 name=__codelineno-0-153></a>        <span class=o>*</span><span class=p>,</span>
<a id=__codelineno-0-154 name=__codelineno-0-154></a>        <span class=n>alpha</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>float64</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>finfo</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float64</span><span class=p>)</span><span class=o>.</span><span class=n>eps</span><span class=p>,</span>
<a id=__codelineno-0-155 name=__codelineno-0-155></a>        <span class=n>solver</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>&quot;svd&quot;</span><span class=p>,</span>
<a id=__codelineno-0-156 name=__codelineno-0-156></a>        <span class=n>unbiased</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>
<a id=__codelineno-0-157 name=__codelineno-0-157></a>        <span class=n>uiter</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>30</span><span class=p>,</span>
<a id=__codelineno-0-158 name=__codelineno-0-158></a>    <span class=p>):</span>
<a id=__codelineno-0-159 name=__codelineno-0-159></a>        <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span> <span class=o>=</span> <span class=n>alpha</span>
<a id=__codelineno-0-160 name=__codelineno-0-160></a>        <span class=bp>self</span><span class=o>.</span><span class=n>solver</span> <span class=o>=</span> <span class=n>solver</span>
<a id=__codelineno-0-161 name=__codelineno-0-161></a>        <span class=bp>self</span><span class=o>.</span><span class=n>uiter</span> <span class=o>=</span> <span class=n>uiter</span>
<a id=__codelineno-0-162 name=__codelineno-0-162></a>        <span class=bp>self</span><span class=o>.</span><span class=n>unbiased</span> <span class=o>=</span> <span class=n>unbiased</span>
<a id=__codelineno-0-163 name=__codelineno-0-163></a>        <span class=n>_validate_params</span><span class=p>(</span><span class=nb>vars</span><span class=p>(</span><span class=bp>self</span><span class=p>))</span>
<a id=__codelineno-0-164 name=__codelineno-0-164></a>
<a id=__codelineno-0-165 name=__codelineno-0-165></a>    <span class=k>def</span><span class=w> </span><span class=nf>ridge_regression_classic</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-166 name=__codelineno-0-166></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Estimate the model parameters using ridge regression.</span>
<a id=__codelineno-0-167 name=__codelineno-0-167></a>
<a id=__codelineno-0-168 name=__codelineno-0-168></a><span class=sd>           Based on the least_squares module and uses the same data format but you need</span>
<a id=__codelineno-0-169 name=__codelineno-0-169></a><span class=sd>           to pass alpha in the call to FROLS.</span>
<a id=__codelineno-0-170 name=__codelineno-0-170></a>
<a id=__codelineno-0-171 name=__codelineno-0-171></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-172 name=__codelineno-0-172></a><span class=sd>        ----------</span>
<a id=__codelineno-0-173 name=__codelineno-0-173></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-174 name=__codelineno-0-174></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-175 name=__codelineno-0-175></a><span class=sd>        y : array-like of shape = y_training</span>
<a id=__codelineno-0-176 name=__codelineno-0-176></a><span class=sd>            The data used to training the model.</span>
<a id=__codelineno-0-177 name=__codelineno-0-177></a>
<a id=__codelineno-0-178 name=__codelineno-0-178></a><span class=sd>        Returns</span>
<a id=__codelineno-0-179 name=__codelineno-0-179></a><span class=sd>        -------</span>
<a id=__codelineno-0-180 name=__codelineno-0-180></a><span class=sd>        theta : array-like of shape = number_of_model_elements</span>
<a id=__codelineno-0-181 name=__codelineno-0-181></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-182 name=__codelineno-0-182></a>
<a id=__codelineno-0-183 name=__codelineno-0-183></a><span class=sd>        References</span>
<a id=__codelineno-0-184 name=__codelineno-0-184></a><span class=sd>        ----------</span>
<a id=__codelineno-0-185 name=__codelineno-0-185></a><span class=sd>        - Wikipedia entry on ridge regression</span>
<a id=__codelineno-0-186 name=__codelineno-0-186></a><span class=sd>          https://en.wikipedia.org/wiki/Ridge_regression</span>
<a id=__codelineno-0-187 name=__codelineno-0-187></a>
<a id=__codelineno-0-188 name=__codelineno-0-188></a><span class=sd>        alpha multiplied by the identity matrix (np.eye) favors models (theta) that</span>
<a id=__codelineno-0-189 name=__codelineno-0-189></a><span class=sd>        have small size using an L2 norm.  This prevents over fitting of the model.</span>
<a id=__codelineno-0-190 name=__codelineno-0-190></a><span class=sd>        For applications where preventing overfitting is important, see, for example,</span>
<a id=__codelineno-0-191 name=__codelineno-0-191></a><span class=sd>        D. J. Gauthier, E. Bollt, A. Griffith, W. A. S. Barbosa, &#39;Next generation</span>
<a id=__codelineno-0-192 name=__codelineno-0-192></a><span class=sd>        reservoir computing,&#39; Nat. Commun. 12, 5564 (2021).</span>
<a id=__codelineno-0-193 name=__codelineno-0-193></a><span class=sd>        https://www.nature.com/articles/s41467-021-25801-2</span>
<a id=__codelineno-0-194 name=__codelineno-0-194></a>
<a id=__codelineno-0-195 name=__codelineno-0-195></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-196 name=__codelineno-0-196></a>        <span class=n>check_linear_dependence_rows</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-197 name=__codelineno-0-197></a>
<a id=__codelineno-0-198 name=__codelineno-0-198></a>        <span class=n>theta</span> <span class=o>=</span> <span class=p>(</span>
<a id=__codelineno-0-199 name=__codelineno-0-199></a>            <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>pinv</span><span class=p>(</span><span class=n>psi</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>psi</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>eye</span><span class=p>(</span><span class=n>psi</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]))</span> <span class=o>@</span> <span class=n>psi</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>y</span>
<a id=__codelineno-0-200 name=__codelineno-0-200></a>        <span class=p>)</span>
<a id=__codelineno-0-201 name=__codelineno-0-201></a>        <span class=k>return</span> <span class=n>theta</span>
<a id=__codelineno-0-202 name=__codelineno-0-202></a>
<a id=__codelineno-0-203 name=__codelineno-0-203></a>    <span class=k>def</span><span class=w> </span><span class=nf>ridge_regression</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-204 name=__codelineno-0-204></a><span class=w>        </span><span class=sd>&quot;&quot;&quot;Estimate the model parameters using SVD and Ridge Regression method.</span>
<a id=__codelineno-0-205 name=__codelineno-0-205></a>
<a id=__codelineno-0-206 name=__codelineno-0-206></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-207 name=__codelineno-0-207></a><span class=sd>        ----------</span>
<a id=__codelineno-0-208 name=__codelineno-0-208></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-209 name=__codelineno-0-209></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-210 name=__codelineno-0-210></a><span class=sd>        y : array-like of shape = y_training</span>
<a id=__codelineno-0-211 name=__codelineno-0-211></a><span class=sd>            The data used to training the model.</span>
<a id=__codelineno-0-212 name=__codelineno-0-212></a>
<a id=__codelineno-0-213 name=__codelineno-0-213></a><span class=sd>        Returns</span>
<a id=__codelineno-0-214 name=__codelineno-0-214></a><span class=sd>        -------</span>
<a id=__codelineno-0-215 name=__codelineno-0-215></a><span class=sd>        theta : array-like of shape = number_of_model_elements</span>
<a id=__codelineno-0-216 name=__codelineno-0-216></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-217 name=__codelineno-0-217></a>
<a id=__codelineno-0-218 name=__codelineno-0-218></a><span class=sd>        References</span>
<a id=__codelineno-0-219 name=__codelineno-0-219></a><span class=sd>        ----------</span>
<a id=__codelineno-0-220 name=__codelineno-0-220></a><span class=sd>        - Manuscript: Hoerl, A. E.; Kennard, R. W. Ridge regression:</span>
<a id=__codelineno-0-221 name=__codelineno-0-221></a><span class=sd>                      applications to nonorthogonal problems. Technometrics,</span>
<a id=__codelineno-0-222 name=__codelineno-0-222></a><span class=sd>                      Taylor &amp; Francis, v. 12, n. 1, p. 69-82, 1970.</span>
<a id=__codelineno-0-223 name=__codelineno-0-223></a>
<a id=__codelineno-0-224 name=__codelineno-0-224></a><span class=sd>        - StackExchange: whuber. The proof of shrinking coefficients using ridge</span>
<a id=__codelineno-0-225 name=__codelineno-0-225></a><span class=sd>                         regression through &quot;spectral decomposition&quot;.</span>
<a id=__codelineno-0-226 name=__codelineno-0-226></a><span class=sd>                         Cross Validated, accessed 21 September 2023,</span>
<a id=__codelineno-0-227 name=__codelineno-0-227></a><span class=sd>                         https://stats.stackexchange.com/q/220324</span>
<a id=__codelineno-0-228 name=__codelineno-0-228></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-229 name=__codelineno-0-229></a>        <span class=n>check_linear_dependence_rows</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-230 name=__codelineno-0-230></a>        <span class=k>try</span><span class=p>:</span>
<a id=__codelineno-0-231 name=__codelineno-0-231></a>            <span class=n>U</span><span class=p>,</span> <span class=n>S</span><span class=p>,</span> <span class=n>Vh</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>svd</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>full_matrices</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
<a id=__codelineno-0-232 name=__codelineno-0-232></a>            <span class=n>S</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>diag</span><span class=p>(</span><span class=n>S</span><span class=p>)</span>
<a id=__codelineno-0-233 name=__codelineno-0-233></a>            <span class=n>i</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>identity</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>S</span><span class=p>))</span>
<a id=__codelineno-0-234 name=__codelineno-0-234></a>            <span class=n>theta</span> <span class=o>=</span> <span class=n>Vh</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>inv</span><span class=p>(</span><span class=n>S</span><span class=o>**</span><span class=mi>2</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span> <span class=o>*</span> <span class=n>i</span><span class=p>)</span> <span class=o>@</span> <span class=n>S</span> <span class=o>@</span> <span class=n>U</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>y</span>
<a id=__codelineno-0-235 name=__codelineno-0-235></a>        <span class=k>except</span> <span class=n>EstimatorError</span><span class=p>:</span>
<a id=__codelineno-0-236 name=__codelineno-0-236></a>            <span class=n>warnings</span><span class=o>.</span><span class=n>warn</span><span class=p>(</span>
<a id=__codelineno-0-237 name=__codelineno-0-237></a>                <span class=s2>&quot;The SVD computation did not converge.&quot;</span>
<a id=__codelineno-0-238 name=__codelineno-0-238></a>                <span class=s2>&quot;Theta values will be calculated with the classic algorithm.&quot;</span><span class=p>,</span>
<a id=__codelineno-0-239 name=__codelineno-0-239></a>                <span class=n>stacklevel</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-0-240 name=__codelineno-0-240></a>            <span class=p>)</span>
<a id=__codelineno-0-241 name=__codelineno-0-241></a>
<a id=__codelineno-0-242 name=__codelineno-0-242></a>            <span class=n>theta</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ridge_regression_classic</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
<a id=__codelineno-0-243 name=__codelineno-0-243></a>
<a id=__codelineno-0-244 name=__codelineno-0-244></a>        <span class=k>return</span> <span class=n>theta</span>
<a id=__codelineno-0-245 name=__codelineno-0-245></a>
<a id=__codelineno-0-246 name=__codelineno-0-246></a>    <span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>):</span>
<a id=__codelineno-0-247 name=__codelineno-0-247></a>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>solver</span> <span class=o>==</span> <span class=s2>&quot;svd&quot;</span><span class=p>:</span>
<a id=__codelineno-0-248 name=__codelineno-0-248></a>            <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>ridge_regression</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
<a id=__codelineno-0-249 name=__codelineno-0-249></a>
<a id=__codelineno-0-250 name=__codelineno-0-250></a>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>ridge_regression_classic</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.RidgeRegression.ridge_regression class="doc doc-heading"> <code class="highlight language-python"><span class=n>ridge_regression</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.RidgeRegression.ridge_regression class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Estimate the model parameters using SVD and Ridge Regression method.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>array-like of shape = y_training</code> </td> <td> <div class=doc-md-description> <p>The data used to training the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>array-like of shape = number_of_model_elements</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li> <p>Manuscript: Hoerl, A. E.; Kennard, R. W. Ridge regression: applications to nonorthogonal problems. Technometrics, Taylor &amp; Francis, v. 12, n. 1, p. 69-82, 1970.</p> </li> <li> <p>StackExchange: whuber. The proof of shrinking coefficients using ridge regression through "spectral decomposition". Cross Validated, accessed 21 September 2023, <a href=https://stats.stackexchange.com/q/220324>https://stats.stackexchange.com/q/220324</a></p> </li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-203>203</a></span>
<span class=normal><a href=#__codelineno-0-204>204</a></span>
<span class=normal><a href=#__codelineno-0-205>205</a></span>
<span class=normal><a href=#__codelineno-0-206>206</a></span>
<span class=normal><a href=#__codelineno-0-207>207</a></span>
<span class=normal><a href=#__codelineno-0-208>208</a></span>
<span class=normal><a href=#__codelineno-0-209>209</a></span>
<span class=normal><a href=#__codelineno-0-210>210</a></span>
<span class=normal><a href=#__codelineno-0-211>211</a></span>
<span class=normal><a href=#__codelineno-0-212>212</a></span>
<span class=normal><a href=#__codelineno-0-213>213</a></span>
<span class=normal><a href=#__codelineno-0-214>214</a></span>
<span class=normal><a href=#__codelineno-0-215>215</a></span>
<span class=normal><a href=#__codelineno-0-216>216</a></span>
<span class=normal><a href=#__codelineno-0-217>217</a></span>
<span class=normal><a href=#__codelineno-0-218>218</a></span>
<span class=normal><a href=#__codelineno-0-219>219</a></span>
<span class=normal><a href=#__codelineno-0-220>220</a></span>
<span class=normal><a href=#__codelineno-0-221>221</a></span>
<span class=normal><a href=#__codelineno-0-222>222</a></span>
<span class=normal><a href=#__codelineno-0-223>223</a></span>
<span class=normal><a href=#__codelineno-0-224>224</a></span>
<span class=normal><a href=#__codelineno-0-225>225</a></span>
<span class=normal><a href=#__codelineno-0-226>226</a></span>
<span class=normal><a href=#__codelineno-0-227>227</a></span>
<span class=normal><a href=#__codelineno-0-228>228</a></span>
<span class=normal><a href=#__codelineno-0-229>229</a></span>
<span class=normal><a href=#__codelineno-0-230>230</a></span>
<span class=normal><a href=#__codelineno-0-231>231</a></span>
<span class=normal><a href=#__codelineno-0-232>232</a></span>
<span class=normal><a href=#__codelineno-0-233>233</a></span>
<span class=normal><a href=#__codelineno-0-234>234</a></span>
<span class=normal><a href=#__codelineno-0-235>235</a></span>
<span class=normal><a href=#__codelineno-0-236>236</a></span>
<span class=normal><a href=#__codelineno-0-237>237</a></span>
<span class=normal><a href=#__codelineno-0-238>238</a></span>
<span class=normal><a href=#__codelineno-0-239>239</a></span>
<span class=normal><a href=#__codelineno-0-240>240</a></span>
<span class=normal><a href=#__codelineno-0-241>241</a></span>
<span class=normal><a href=#__codelineno-0-242>242</a></span>
<span class=normal><a href=#__codelineno-0-243>243</a></span>
<span class=normal><a href=#__codelineno-0-244>244</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-203 name=__codelineno-0-203></a><span class=k>def</span><span class=w> </span><span class=nf>ridge_regression</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-204 name=__codelineno-0-204></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Estimate the model parameters using SVD and Ridge Regression method.</span>
<a id=__codelineno-0-205 name=__codelineno-0-205></a>
<a id=__codelineno-0-206 name=__codelineno-0-206></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-207 name=__codelineno-0-207></a><span class=sd>    ----------</span>
<a id=__codelineno-0-208 name=__codelineno-0-208></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-209 name=__codelineno-0-209></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-210 name=__codelineno-0-210></a><span class=sd>    y : array-like of shape = y_training</span>
<a id=__codelineno-0-211 name=__codelineno-0-211></a><span class=sd>        The data used to training the model.</span>
<a id=__codelineno-0-212 name=__codelineno-0-212></a>
<a id=__codelineno-0-213 name=__codelineno-0-213></a><span class=sd>    Returns</span>
<a id=__codelineno-0-214 name=__codelineno-0-214></a><span class=sd>    -------</span>
<a id=__codelineno-0-215 name=__codelineno-0-215></a><span class=sd>    theta : array-like of shape = number_of_model_elements</span>
<a id=__codelineno-0-216 name=__codelineno-0-216></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-217 name=__codelineno-0-217></a>
<a id=__codelineno-0-218 name=__codelineno-0-218></a><span class=sd>    References</span>
<a id=__codelineno-0-219 name=__codelineno-0-219></a><span class=sd>    ----------</span>
<a id=__codelineno-0-220 name=__codelineno-0-220></a><span class=sd>    - Manuscript: Hoerl, A. E.; Kennard, R. W. Ridge regression:</span>
<a id=__codelineno-0-221 name=__codelineno-0-221></a><span class=sd>                  applications to nonorthogonal problems. Technometrics,</span>
<a id=__codelineno-0-222 name=__codelineno-0-222></a><span class=sd>                  Taylor &amp; Francis, v. 12, n. 1, p. 69-82, 1970.</span>
<a id=__codelineno-0-223 name=__codelineno-0-223></a>
<a id=__codelineno-0-224 name=__codelineno-0-224></a><span class=sd>    - StackExchange: whuber. The proof of shrinking coefficients using ridge</span>
<a id=__codelineno-0-225 name=__codelineno-0-225></a><span class=sd>                     regression through &quot;spectral decomposition&quot;.</span>
<a id=__codelineno-0-226 name=__codelineno-0-226></a><span class=sd>                     Cross Validated, accessed 21 September 2023,</span>
<a id=__codelineno-0-227 name=__codelineno-0-227></a><span class=sd>                     https://stats.stackexchange.com/q/220324</span>
<a id=__codelineno-0-228 name=__codelineno-0-228></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-229 name=__codelineno-0-229></a>    <span class=n>check_linear_dependence_rows</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-230 name=__codelineno-0-230></a>    <span class=k>try</span><span class=p>:</span>
<a id=__codelineno-0-231 name=__codelineno-0-231></a>        <span class=n>U</span><span class=p>,</span> <span class=n>S</span><span class=p>,</span> <span class=n>Vh</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>svd</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>full_matrices</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
<a id=__codelineno-0-232 name=__codelineno-0-232></a>        <span class=n>S</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>diag</span><span class=p>(</span><span class=n>S</span><span class=p>)</span>
<a id=__codelineno-0-233 name=__codelineno-0-233></a>        <span class=n>i</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>identity</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>S</span><span class=p>))</span>
<a id=__codelineno-0-234 name=__codelineno-0-234></a>        <span class=n>theta</span> <span class=o>=</span> <span class=n>Vh</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>inv</span><span class=p>(</span><span class=n>S</span><span class=o>**</span><span class=mi>2</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span> <span class=o>*</span> <span class=n>i</span><span class=p>)</span> <span class=o>@</span> <span class=n>S</span> <span class=o>@</span> <span class=n>U</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>y</span>
<a id=__codelineno-0-235 name=__codelineno-0-235></a>    <span class=k>except</span> <span class=n>EstimatorError</span><span class=p>:</span>
<a id=__codelineno-0-236 name=__codelineno-0-236></a>        <span class=n>warnings</span><span class=o>.</span><span class=n>warn</span><span class=p>(</span>
<a id=__codelineno-0-237 name=__codelineno-0-237></a>            <span class=s2>&quot;The SVD computation did not converge.&quot;</span>
<a id=__codelineno-0-238 name=__codelineno-0-238></a>            <span class=s2>&quot;Theta values will be calculated with the classic algorithm.&quot;</span><span class=p>,</span>
<a id=__codelineno-0-239 name=__codelineno-0-239></a>            <span class=n>stacklevel</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
<a id=__codelineno-0-240 name=__codelineno-0-240></a>        <span class=p>)</span>
<a id=__codelineno-0-241 name=__codelineno-0-241></a>
<a id=__codelineno-0-242 name=__codelineno-0-242></a>        <span class=n>theta</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ridge_regression_classic</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
<a id=__codelineno-0-243 name=__codelineno-0-243></a>
<a id=__codelineno-0-244 name=__codelineno-0-244></a>    <span class=k>return</span> <span class=n>theta</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.RidgeRegression.ridge_regression_classic class="doc doc-heading"> <code class="highlight language-python"><span class=n>ridge_regression_classic</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.RidgeRegression.ridge_regression_classic class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Estimate the model parameters using ridge regression.</p> <p>Based on the least_squares module and uses the same data format but you need to pass alpha in the call to FROLS.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>array-like of shape = y_training</code> </td> <td> <div class=doc-md-description> <p>The data used to training the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>array-like of shape = number_of_model_elements</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Wikipedia entry on ridge regression <a href=https://en.wikipedia.org/wiki/Ridge_regression>https://en.wikipedia.org/wiki/Ridge_regression</a></li> </ul> <p>alpha multiplied by the identity matrix (np.eye) favors models (theta) that have small size using an L2 norm. This prevents over fitting of the model. For applications where preventing overfitting is important, see, for example, D. J. Gauthier, E. Bollt, A. Griffith, W. A. S. Barbosa, 'Next generation reservoir computing,' Nat. Commun. 12, 5564 (2021). <a href=https://www.nature.com/articles/s41467-021-25801-2>https://www.nature.com/articles/s41467-021-25801-2</a></p> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-165>165</a></span>
<span class=normal><a href=#__codelineno-0-166>166</a></span>
<span class=normal><a href=#__codelineno-0-167>167</a></span>
<span class=normal><a href=#__codelineno-0-168>168</a></span>
<span class=normal><a href=#__codelineno-0-169>169</a></span>
<span class=normal><a href=#__codelineno-0-170>170</a></span>
<span class=normal><a href=#__codelineno-0-171>171</a></span>
<span class=normal><a href=#__codelineno-0-172>172</a></span>
<span class=normal><a href=#__codelineno-0-173>173</a></span>
<span class=normal><a href=#__codelineno-0-174>174</a></span>
<span class=normal><a href=#__codelineno-0-175>175</a></span>
<span class=normal><a href=#__codelineno-0-176>176</a></span>
<span class=normal><a href=#__codelineno-0-177>177</a></span>
<span class=normal><a href=#__codelineno-0-178>178</a></span>
<span class=normal><a href=#__codelineno-0-179>179</a></span>
<span class=normal><a href=#__codelineno-0-180>180</a></span>
<span class=normal><a href=#__codelineno-0-181>181</a></span>
<span class=normal><a href=#__codelineno-0-182>182</a></span>
<span class=normal><a href=#__codelineno-0-183>183</a></span>
<span class=normal><a href=#__codelineno-0-184>184</a></span>
<span class=normal><a href=#__codelineno-0-185>185</a></span>
<span class=normal><a href=#__codelineno-0-186>186</a></span>
<span class=normal><a href=#__codelineno-0-187>187</a></span>
<span class=normal><a href=#__codelineno-0-188>188</a></span>
<span class=normal><a href=#__codelineno-0-189>189</a></span>
<span class=normal><a href=#__codelineno-0-190>190</a></span>
<span class=normal><a href=#__codelineno-0-191>191</a></span>
<span class=normal><a href=#__codelineno-0-192>192</a></span>
<span class=normal><a href=#__codelineno-0-193>193</a></span>
<span class=normal><a href=#__codelineno-0-194>194</a></span>
<span class=normal><a href=#__codelineno-0-195>195</a></span>
<span class=normal><a href=#__codelineno-0-196>196</a></span>
<span class=normal><a href=#__codelineno-0-197>197</a></span>
<span class=normal><a href=#__codelineno-0-198>198</a></span>
<span class=normal><a href=#__codelineno-0-199>199</a></span>
<span class=normal><a href=#__codelineno-0-200>200</a></span>
<span class=normal><a href=#__codelineno-0-201>201</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-165 name=__codelineno-0-165></a><span class=k>def</span><span class=w> </span><span class=nf>ridge_regression_classic</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-166 name=__codelineno-0-166></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Estimate the model parameters using ridge regression.</span>
<a id=__codelineno-0-167 name=__codelineno-0-167></a>
<a id=__codelineno-0-168 name=__codelineno-0-168></a><span class=sd>       Based on the least_squares module and uses the same data format but you need</span>
<a id=__codelineno-0-169 name=__codelineno-0-169></a><span class=sd>       to pass alpha in the call to FROLS.</span>
<a id=__codelineno-0-170 name=__codelineno-0-170></a>
<a id=__codelineno-0-171 name=__codelineno-0-171></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-172 name=__codelineno-0-172></a><span class=sd>    ----------</span>
<a id=__codelineno-0-173 name=__codelineno-0-173></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-174 name=__codelineno-0-174></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-175 name=__codelineno-0-175></a><span class=sd>    y : array-like of shape = y_training</span>
<a id=__codelineno-0-176 name=__codelineno-0-176></a><span class=sd>        The data used to training the model.</span>
<a id=__codelineno-0-177 name=__codelineno-0-177></a>
<a id=__codelineno-0-178 name=__codelineno-0-178></a><span class=sd>    Returns</span>
<a id=__codelineno-0-179 name=__codelineno-0-179></a><span class=sd>    -------</span>
<a id=__codelineno-0-180 name=__codelineno-0-180></a><span class=sd>    theta : array-like of shape = number_of_model_elements</span>
<a id=__codelineno-0-181 name=__codelineno-0-181></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-182 name=__codelineno-0-182></a>
<a id=__codelineno-0-183 name=__codelineno-0-183></a><span class=sd>    References</span>
<a id=__codelineno-0-184 name=__codelineno-0-184></a><span class=sd>    ----------</span>
<a id=__codelineno-0-185 name=__codelineno-0-185></a><span class=sd>    - Wikipedia entry on ridge regression</span>
<a id=__codelineno-0-186 name=__codelineno-0-186></a><span class=sd>      https://en.wikipedia.org/wiki/Ridge_regression</span>
<a id=__codelineno-0-187 name=__codelineno-0-187></a>
<a id=__codelineno-0-188 name=__codelineno-0-188></a><span class=sd>    alpha multiplied by the identity matrix (np.eye) favors models (theta) that</span>
<a id=__codelineno-0-189 name=__codelineno-0-189></a><span class=sd>    have small size using an L2 norm.  This prevents over fitting of the model.</span>
<a id=__codelineno-0-190 name=__codelineno-0-190></a><span class=sd>    For applications where preventing overfitting is important, see, for example,</span>
<a id=__codelineno-0-191 name=__codelineno-0-191></a><span class=sd>    D. J. Gauthier, E. Bollt, A. Griffith, W. A. S. Barbosa, &#39;Next generation</span>
<a id=__codelineno-0-192 name=__codelineno-0-192></a><span class=sd>    reservoir computing,&#39; Nat. Commun. 12, 5564 (2021).</span>
<a id=__codelineno-0-193 name=__codelineno-0-193></a><span class=sd>    https://www.nature.com/articles/s41467-021-25801-2</span>
<a id=__codelineno-0-194 name=__codelineno-0-194></a>
<a id=__codelineno-0-195 name=__codelineno-0-195></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-196 name=__codelineno-0-196></a>    <span class=n>check_linear_dependence_rows</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-197 name=__codelineno-0-197></a>
<a id=__codelineno-0-198 name=__codelineno-0-198></a>    <span class=n>theta</span> <span class=o>=</span> <span class=p>(</span>
<a id=__codelineno-0-199 name=__codelineno-0-199></a>        <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>pinv</span><span class=p>(</span><span class=n>psi</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>psi</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>eye</span><span class=p>(</span><span class=n>psi</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]))</span> <span class=o>@</span> <span class=n>psi</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>y</span>
<a id=__codelineno-0-200 name=__codelineno-0-200></a>    <span class=p>)</span>
<a id=__codelineno-0-201 name=__codelineno-0-201></a>    <span class=k>return</span> <span class=n>theta</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> <div class="doc doc-object doc-class"> <h2 id=sysidentpy.parameter_estimation.estimators.TotalLeastSquares class="doc doc-heading"> <code>TotalLeastSquares</code> <a href=#sysidentpy.parameter_estimation.estimators.TotalLeastSquares class=headerlink title="Permanent link">&para;</a></h2> <div class="doc doc-contents "> <p class="doc doc-class-bases"> Bases: <code><span title=sysidentpy.parameter_estimation.estimators_base.BaseEstimator>BaseEstimator</span></code></p> <p>Estimate the model parameters using the Total Least Squares (TLS) method.</p> <p>The Total Least Squares method is used to solve the problem of fitting a model to data when both the independent variables (psi) and the dependent variable (y) are subject to errors. This method minimizes the orthogonal distances from the data points to the fitted model, which is more appropriate when errors are present in all variables.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>unbiased</code> </td> <td> <code><span title=bool>bool</span></code> </td> <td> <div class=doc-md-description> <p>If True, applies an unbiased estimator. Default is False.</p> </div> </td> <td> <code>False</code> </td> </tr> <tr class=doc-section-item> <td> <code>uiter</code> </td> <td> <code><span title=int>int</span></code> </td> <td> <div class=doc-md-description> <p>Number of iterations for the unbiased estimator. Default is 30.</p> </div> </td> <td> <code>30</code> </td> </tr> </tbody> </table> <details class=references open> <summary>References</summary> <ul> <li>Golub, G. H., &amp; Van Loan, C. F. (1980). An analysis of the total least squares problem. SIAM journal on numerical analysis, 17(6), 883-893.</li> <li>Markovsky, I., &amp; Van Huffel, S. (2007). Overview of total least-squares methods. Signal processing, 87(10), 2283-2302. <a href=https://eprints.soton.ac.uk/263855/1/tls_overview.pdf>https://eprints.soton.ac.uk/263855/1/tls_overview.pdf</a></li> <li>Wikipedia entry on Total Least Squares: <a href=https://en.wikipedia.org/wiki/Total_least_squares>https://en.wikipedia.org/wiki/Total_least_squares</a></li> </ul> </details> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-253>253</a></span>
<span class=normal><a href=#__codelineno-0-254>254</a></span>
<span class=normal><a href=#__codelineno-0-255>255</a></span>
<span class=normal><a href=#__codelineno-0-256>256</a></span>
<span class=normal><a href=#__codelineno-0-257>257</a></span>
<span class=normal><a href=#__codelineno-0-258>258</a></span>
<span class=normal><a href=#__codelineno-0-259>259</a></span>
<span class=normal><a href=#__codelineno-0-260>260</a></span>
<span class=normal><a href=#__codelineno-0-261>261</a></span>
<span class=normal><a href=#__codelineno-0-262>262</a></span>
<span class=normal><a href=#__codelineno-0-263>263</a></span>
<span class=normal><a href=#__codelineno-0-264>264</a></span>
<span class=normal><a href=#__codelineno-0-265>265</a></span>
<span class=normal><a href=#__codelineno-0-266>266</a></span>
<span class=normal><a href=#__codelineno-0-267>267</a></span>
<span class=normal><a href=#__codelineno-0-268>268</a></span>
<span class=normal><a href=#__codelineno-0-269>269</a></span>
<span class=normal><a href=#__codelineno-0-270>270</a></span>
<span class=normal><a href=#__codelineno-0-271>271</a></span>
<span class=normal><a href=#__codelineno-0-272>272</a></span>
<span class=normal><a href=#__codelineno-0-273>273</a></span>
<span class=normal><a href=#__codelineno-0-274>274</a></span>
<span class=normal><a href=#__codelineno-0-275>275</a></span>
<span class=normal><a href=#__codelineno-0-276>276</a></span>
<span class=normal><a href=#__codelineno-0-277>277</a></span>
<span class=normal><a href=#__codelineno-0-278>278</a></span>
<span class=normal><a href=#__codelineno-0-279>279</a></span>
<span class=normal><a href=#__codelineno-0-280>280</a></span>
<span class=normal><a href=#__codelineno-0-281>281</a></span>
<span class=normal><a href=#__codelineno-0-282>282</a></span>
<span class=normal><a href=#__codelineno-0-283>283</a></span>
<span class=normal><a href=#__codelineno-0-284>284</a></span>
<span class=normal><a href=#__codelineno-0-285>285</a></span>
<span class=normal><a href=#__codelineno-0-286>286</a></span>
<span class=normal><a href=#__codelineno-0-287>287</a></span>
<span class=normal><a href=#__codelineno-0-288>288</a></span>
<span class=normal><a href=#__codelineno-0-289>289</a></span>
<span class=normal><a href=#__codelineno-0-290>290</a></span>
<span class=normal><a href=#__codelineno-0-291>291</a></span>
<span class=normal><a href=#__codelineno-0-292>292</a></span>
<span class=normal><a href=#__codelineno-0-293>293</a></span>
<span class=normal><a href=#__codelineno-0-294>294</a></span>
<span class=normal><a href=#__codelineno-0-295>295</a></span>
<span class=normal><a href=#__codelineno-0-296>296</a></span>
<span class=normal><a href=#__codelineno-0-297>297</a></span>
<span class=normal><a href=#__codelineno-0-298>298</a></span>
<span class=normal><a href=#__codelineno-0-299>299</a></span>
<span class=normal><a href=#__codelineno-0-300>300</a></span>
<span class=normal><a href=#__codelineno-0-301>301</a></span>
<span class=normal><a href=#__codelineno-0-302>302</a></span>
<span class=normal><a href=#__codelineno-0-303>303</a></span>
<span class=normal><a href=#__codelineno-0-304>304</a></span>
<span class=normal><a href=#__codelineno-0-305>305</a></span>
<span class=normal><a href=#__codelineno-0-306>306</a></span>
<span class=normal><a href=#__codelineno-0-307>307</a></span>
<span class=normal><a href=#__codelineno-0-308>308</a></span>
<span class=normal><a href=#__codelineno-0-309>309</a></span>
<span class=normal><a href=#__codelineno-0-310>310</a></span>
<span class=normal><a href=#__codelineno-0-311>311</a></span>
<span class=normal><a href=#__codelineno-0-312>312</a></span>
<span class=normal><a href=#__codelineno-0-313>313</a></span>
<span class=normal><a href=#__codelineno-0-314>314</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-253 name=__codelineno-0-253></a><span class=k>class</span><span class=w> </span><span class=nc>TotalLeastSquares</span><span class=p>(</span><span class=n>BaseEstimator</span><span class=p>):</span>
<a id=__codelineno-0-254 name=__codelineno-0-254></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Estimate the model parameters using the Total Least Squares (TLS) method.</span>
<a id=__codelineno-0-255 name=__codelineno-0-255></a>
<a id=__codelineno-0-256 name=__codelineno-0-256></a><span class=sd>    The Total Least Squares method is used to solve the problem of fitting a model</span>
<a id=__codelineno-0-257 name=__codelineno-0-257></a><span class=sd>    to data when both the independent variables (psi) and the dependent variable (y)</span>
<a id=__codelineno-0-258 name=__codelineno-0-258></a><span class=sd>    are subject to errors. This method minimizes the orthogonal distances from the</span>
<a id=__codelineno-0-259 name=__codelineno-0-259></a><span class=sd>    data points to the fitted model, which is more appropriate when errors are present</span>
<a id=__codelineno-0-260 name=__codelineno-0-260></a><span class=sd>    in all variables.</span>
<a id=__codelineno-0-261 name=__codelineno-0-261></a>
<a id=__codelineno-0-262 name=__codelineno-0-262></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-263 name=__codelineno-0-263></a><span class=sd>    ----------</span>
<a id=__codelineno-0-264 name=__codelineno-0-264></a><span class=sd>    unbiased : bool, optional</span>
<a id=__codelineno-0-265 name=__codelineno-0-265></a><span class=sd>        If True, applies an unbiased estimator. Default is False.</span>
<a id=__codelineno-0-266 name=__codelineno-0-266></a><span class=sd>    uiter : int, optional</span>
<a id=__codelineno-0-267 name=__codelineno-0-267></a><span class=sd>        Number of iterations for the unbiased estimator. Default is 30.</span>
<a id=__codelineno-0-268 name=__codelineno-0-268></a>
<a id=__codelineno-0-269 name=__codelineno-0-269></a><span class=sd>    References</span>
<a id=__codelineno-0-270 name=__codelineno-0-270></a><span class=sd>    ----------</span>
<a id=__codelineno-0-271 name=__codelineno-0-271></a><span class=sd>    - Golub, G. H., &amp; Van Loan, C. F. (1980). An analysis of the total least squares</span>
<a id=__codelineno-0-272 name=__codelineno-0-272></a><span class=sd>    problem.</span>
<a id=__codelineno-0-273 name=__codelineno-0-273></a><span class=sd>      SIAM journal on numerical analysis, 17(6), 883-893.</span>
<a id=__codelineno-0-274 name=__codelineno-0-274></a><span class=sd>    - Markovsky, I., &amp; Van Huffel, S. (2007). Overview of total least-squares methods.</span>
<a id=__codelineno-0-275 name=__codelineno-0-275></a><span class=sd>      Signal processing, 87(10), 2283-2302. https://eprints.soton.ac.uk/263855/1/tls_overview.pdf</span>
<a id=__codelineno-0-276 name=__codelineno-0-276></a><span class=sd>    - Wikipedia entry on Total Least Squares: https://en.wikipedia.org/wiki/Total_least_squares</span>
<a id=__codelineno-0-277 name=__codelineno-0-277></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-278 name=__codelineno-0-278></a>
<a id=__codelineno-0-279 name=__codelineno-0-279></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=o>*</span><span class=p>,</span> <span class=n>unbiased</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span> <span class=n>uiter</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>30</span><span class=p>):</span>
<a id=__codelineno-0-280 name=__codelineno-0-280></a>        <span class=bp>self</span><span class=o>.</span><span class=n>unbiased</span> <span class=o>=</span> <span class=n>unbiased</span>
<a id=__codelineno-0-281 name=__codelineno-0-281></a>        <span class=bp>self</span><span class=o>.</span><span class=n>uiter</span> <span class=o>=</span> <span class=n>uiter</span>
<a id=__codelineno-0-282 name=__codelineno-0-282></a>        <span class=n>_validate_params</span><span class=p>(</span><span class=nb>vars</span><span class=p>(</span><span class=bp>self</span><span class=p>))</span>
<a id=__codelineno-0-283 name=__codelineno-0-283></a>
<a id=__codelineno-0-284 name=__codelineno-0-284></a>    <span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-285 name=__codelineno-0-285></a><span class=w>        </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Estimate the model parameters using the Total Least Squares method.</span>
<a id=__codelineno-0-286 name=__codelineno-0-286></a>
<a id=__codelineno-0-287 name=__codelineno-0-287></a><span class=sd>        The TLS method solves the following problem:</span>
<a id=__codelineno-0-288 name=__codelineno-0-288></a>
<a id=__codelineno-0-289 name=__codelineno-0-289></a><span class=sd>        $$</span>
<a id=__codelineno-0-290 name=__codelineno-0-290></a><span class=sd>            \min_{E, f} \| [E, f] \|_F \quad \text{subject to}</span>
<a id=__codelineno-0-291 name=__codelineno-0-291></a><span class=sd>            \quad (psi + E) \theta = y + f</span>
<a id=__codelineno-0-292 name=__codelineno-0-292></a><span class=sd>        $$</span>
<a id=__codelineno-0-293 name=__codelineno-0-293></a>
<a id=__codelineno-0-294 name=__codelineno-0-294></a><span class=sd>        where $E$ and $f$ are the error matrices for $psi$ and $y$ respectively,</span>
<a id=__codelineno-0-295 name=__codelineno-0-295></a><span class=sd>        and $\| \cdot \|_F$ denotes the Frobenius norm.</span>
<a id=__codelineno-0-296 name=__codelineno-0-296></a>
<a id=__codelineno-0-297 name=__codelineno-0-297></a><span class=sd>        Parameters</span>
<a id=__codelineno-0-298 name=__codelineno-0-298></a><span class=sd>        ----------</span>
<a id=__codelineno-0-299 name=__codelineno-0-299></a><span class=sd>        psi : ndarray of floats</span>
<a id=__codelineno-0-300 name=__codelineno-0-300></a><span class=sd>            The information matrix of the model.</span>
<a id=__codelineno-0-301 name=__codelineno-0-301></a><span class=sd>        y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-302 name=__codelineno-0-302></a><span class=sd>            The data used to train the model.</span>
<a id=__codelineno-0-303 name=__codelineno-0-303></a>
<a id=__codelineno-0-304 name=__codelineno-0-304></a><span class=sd>        Returns</span>
<a id=__codelineno-0-305 name=__codelineno-0-305></a><span class=sd>        -------</span>
<a id=__codelineno-0-306 name=__codelineno-0-306></a><span class=sd>        theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-307 name=__codelineno-0-307></a><span class=sd>            The estimated parameters of the model.</span>
<a id=__codelineno-0-308 name=__codelineno-0-308></a><span class=sd>        &quot;&quot;&quot;</span>
<a id=__codelineno-0-309 name=__codelineno-0-309></a>        <span class=n>check_linear_dependence_rows</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-310 name=__codelineno-0-310></a>        <span class=n>full</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>hstack</span><span class=p>((</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>))</span>
<a id=__codelineno-0-311 name=__codelineno-0-311></a>        <span class=n>n</span> <span class=o>=</span> <span class=n>psi</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
<a id=__codelineno-0-312 name=__codelineno-0-312></a>        <span class=n>_</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=n>v</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>svd</span><span class=p>(</span><span class=n>full</span><span class=p>,</span> <span class=n>full_matrices</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<a id=__codelineno-0-313 name=__codelineno-0-313></a>        <span class=n>theta</span> <span class=o>=</span> <span class=o>-</span><span class=n>v</span><span class=o>.</span><span class=n>T</span><span class=p>[:</span><span class=n>n</span><span class=p>,</span> <span class=n>n</span><span class=p>:]</span> <span class=o>/</span> <span class=n>v</span><span class=o>.</span><span class=n>T</span><span class=p>[</span><span class=n>n</span><span class=p>:,</span> <span class=n>n</span><span class=p>:]</span>
<a id=__codelineno-0-314 name=__codelineno-0-314></a>        <span class=k>return</span> <span class=n>theta</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> <div class="doc doc-children"> <div class="doc doc-object doc-function"> <h3 id=sysidentpy.parameter_estimation.estimators.TotalLeastSquares.optimize class="doc doc-heading"> <code class="highlight language-python"><span class=n>optimize</span><span class=p>(</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span></code> <a href=#sysidentpy.parameter_estimation.estimators.TotalLeastSquares.optimize class=headerlink title="Permanent link">&para;</a></h3> <div class="doc doc-contents "> <p>Estimate the model parameters using the Total Least Squares method.</p> <p>The TLS method solves the following problem:</p> <div class=arithmatex>\[ \min_{E, f} \| [E, f] \|_F \quad \text{subject to} \quad (psi + E) \theta = y + f \]</div> <p>where <span class=arithmatex>\(E\)</span> and <span class=arithmatex>\(f\)</span> are the error matrices for <span class=arithmatex>\(psi\)</span> and <span class=arithmatex>\(y\)</span> respectively, and <span class=arithmatex>\(\| \cdot \|_F\)</span> denotes the Frobenius norm.</p> <p><span class=doc-section-title>Parameters:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> <th>Default</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td> <code>psi</code> </td> <td> <code>ndarray of floats</code> </td> <td> <div class=doc-md-description> <p>The information matrix of the model.</p> </div> </td> <td> <em>required</em> </td> </tr> <tr class=doc-section-item> <td> <code>y</code> </td> <td> <code>array-like of shape (n_samples, 1)</code> </td> <td> <div class=doc-md-description> <p>The data used to train the model.</p> </div> </td> <td> <em>required</em> </td> </tr> </tbody> </table> <p><span class=doc-section-title>Returns:</span></p> <table> <thead> <tr> <th>Name</th> <th>Type</th> <th>Description</th> </tr> </thead> <tbody> <tr class=doc-section-item> <td><code>theta</code></td> <td> <code>array-like of shape (n_features, 1)</code> </td> <td> <div class=doc-md-description> <p>The estimated parameters of the model.</p> </div> </td> </tr> </tbody> </table> <details class=quote> <summary>Source code in <code>sysidentpy/parameter_estimation/estimators.py</code></summary> <div class=highlight><table class=highlighttable><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-284>284</a></span>
<span class=normal><a href=#__codelineno-0-285>285</a></span>
<span class=normal><a href=#__codelineno-0-286>286</a></span>
<span class=normal><a href=#__codelineno-0-287>287</a></span>
<span class=normal><a href=#__codelineno-0-288>288</a></span>
<span class=normal><a href=#__codelineno-0-289>289</a></span>
<span class=normal><a href=#__codelineno-0-290>290</a></span>
<span class=normal><a href=#__codelineno-0-291>291</a></span>
<span class=normal><a href=#__codelineno-0-292>292</a></span>
<span class=normal><a href=#__codelineno-0-293>293</a></span>
<span class=normal><a href=#__codelineno-0-294>294</a></span>
<span class=normal><a href=#__codelineno-0-295>295</a></span>
<span class=normal><a href=#__codelineno-0-296>296</a></span>
<span class=normal><a href=#__codelineno-0-297>297</a></span>
<span class=normal><a href=#__codelineno-0-298>298</a></span>
<span class=normal><a href=#__codelineno-0-299>299</a></span>
<span class=normal><a href=#__codelineno-0-300>300</a></span>
<span class=normal><a href=#__codelineno-0-301>301</a></span>
<span class=normal><a href=#__codelineno-0-302>302</a></span>
<span class=normal><a href=#__codelineno-0-303>303</a></span>
<span class=normal><a href=#__codelineno-0-304>304</a></span>
<span class=normal><a href=#__codelineno-0-305>305</a></span>
<span class=normal><a href=#__codelineno-0-306>306</a></span>
<span class=normal><a href=#__codelineno-0-307>307</a></span>
<span class=normal><a href=#__codelineno-0-308>308</a></span>
<span class=normal><a href=#__codelineno-0-309>309</a></span>
<span class=normal><a href=#__codelineno-0-310>310</a></span>
<span class=normal><a href=#__codelineno-0-311>311</a></span>
<span class=normal><a href=#__codelineno-0-312>312</a></span>
<span class=normal><a href=#__codelineno-0-313>313</a></span>
<span class=normal><a href=#__codelineno-0-314>314</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-284 name=__codelineno-0-284></a><span class=k>def</span><span class=w> </span><span class=nf>optimize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>psi</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>y</span><span class=p>:</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>np</span><span class=o>.</span><span class=n>ndarray</span><span class=p>:</span>
<a id=__codelineno-0-285 name=__codelineno-0-285></a><span class=w>    </span><span class=sa>r</span><span class=sd>&quot;&quot;&quot;Estimate the model parameters using the Total Least Squares method.</span>
<a id=__codelineno-0-286 name=__codelineno-0-286></a>
<a id=__codelineno-0-287 name=__codelineno-0-287></a><span class=sd>    The TLS method solves the following problem:</span>
<a id=__codelineno-0-288 name=__codelineno-0-288></a>
<a id=__codelineno-0-289 name=__codelineno-0-289></a><span class=sd>    $$</span>
<a id=__codelineno-0-290 name=__codelineno-0-290></a><span class=sd>        \min_{E, f} \| [E, f] \|_F \quad \text{subject to}</span>
<a id=__codelineno-0-291 name=__codelineno-0-291></a><span class=sd>        \quad (psi + E) \theta = y + f</span>
<a id=__codelineno-0-292 name=__codelineno-0-292></a><span class=sd>    $$</span>
<a id=__codelineno-0-293 name=__codelineno-0-293></a>
<a id=__codelineno-0-294 name=__codelineno-0-294></a><span class=sd>    where $E$ and $f$ are the error matrices for $psi$ and $y$ respectively,</span>
<a id=__codelineno-0-295 name=__codelineno-0-295></a><span class=sd>    and $\| \cdot \|_F$ denotes the Frobenius norm.</span>
<a id=__codelineno-0-296 name=__codelineno-0-296></a>
<a id=__codelineno-0-297 name=__codelineno-0-297></a><span class=sd>    Parameters</span>
<a id=__codelineno-0-298 name=__codelineno-0-298></a><span class=sd>    ----------</span>
<a id=__codelineno-0-299 name=__codelineno-0-299></a><span class=sd>    psi : ndarray of floats</span>
<a id=__codelineno-0-300 name=__codelineno-0-300></a><span class=sd>        The information matrix of the model.</span>
<a id=__codelineno-0-301 name=__codelineno-0-301></a><span class=sd>    y : array-like of shape (n_samples, 1)</span>
<a id=__codelineno-0-302 name=__codelineno-0-302></a><span class=sd>        The data used to train the model.</span>
<a id=__codelineno-0-303 name=__codelineno-0-303></a>
<a id=__codelineno-0-304 name=__codelineno-0-304></a><span class=sd>    Returns</span>
<a id=__codelineno-0-305 name=__codelineno-0-305></a><span class=sd>    -------</span>
<a id=__codelineno-0-306 name=__codelineno-0-306></a><span class=sd>    theta : array-like of shape (n_features, 1)</span>
<a id=__codelineno-0-307 name=__codelineno-0-307></a><span class=sd>        The estimated parameters of the model.</span>
<a id=__codelineno-0-308 name=__codelineno-0-308></a><span class=sd>    &quot;&quot;&quot;</span>
<a id=__codelineno-0-309 name=__codelineno-0-309></a>    <span class=n>check_linear_dependence_rows</span><span class=p>(</span><span class=n>psi</span><span class=p>)</span>
<a id=__codelineno-0-310 name=__codelineno-0-310></a>    <span class=n>full</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>hstack</span><span class=p>((</span><span class=n>psi</span><span class=p>,</span> <span class=n>y</span><span class=p>))</span>
<a id=__codelineno-0-311 name=__codelineno-0-311></a>    <span class=n>n</span> <span class=o>=</span> <span class=n>psi</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
<a id=__codelineno-0-312 name=__codelineno-0-312></a>    <span class=n>_</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=n>v</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>svd</span><span class=p>(</span><span class=n>full</span><span class=p>,</span> <span class=n>full_matrices</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<a id=__codelineno-0-313 name=__codelineno-0-313></a>    <span class=n>theta</span> <span class=o>=</span> <span class=o>-</span><span class=n>v</span><span class=o>.</span><span class=n>T</span><span class=p>[:</span><span class=n>n</span><span class=p>,</span> <span class=n>n</span><span class=p>:]</span> <span class=o>/</span> <span class=n>v</span><span class=o>.</span><span class=n>T</span><span class=p>[</span><span class=n>n</span><span class=p>:,</span> <span class=n>n</span><span class=p>:]</span>
<a id=__codelineno-0-314 name=__codelineno-0-314></a>    <span class=k>return</span> <span class=n>theta</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</code></pre></div></td></tr></table></div> </details> </div> </div> </div> </div> </div> </div> </div> </div> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Volver al principio </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Pie> <a href=../general-estimators/ class="md-footer__link md-footer__link--prev" aria-label="Anterior: General Estimators"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Anterior </span> <div class=md-ellipsis> General Estimators </div> </div> </a> <a href=../multiobjective-parameter-estimation/ class="md-footer__link md-footer__link--next" aria-label="Siguiente: Multiobjective Parameter Estimation"> <div class=md-footer__title> <span class=md-footer__direction> Siguiente </span> <div class=md-ellipsis> Multiobjective Parameter Estimation </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2016 - 2025 Wilson Rocha </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/wilsonrljr target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://pypi.org/project/sysidentpy/ target=_blank rel=noopener title=pypi.org class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3"/></svg> </a> <a href=https://twitter.com/wilsonrljr target=_blank rel=noopener title=twitter.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../../..", "features": ["content.code.copy", "content.action.edit", "content.action.view", "navigation.footer", "content.code.annotate", "content.tabs.link", "content.tooltips", "navigation.indexes", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copiado al portapapeles", "clipboard.copy": "Copiar al portapapeles", "search.result.more.one": "1 m\u00e1s en esta p\u00e1gina", "search.result.more.other": "# m\u00e1s en esta p\u00e1gina", "search.result.none": "No se encontraron documentos", "search.result.one": "1 documento encontrado", "search.result.other": "# documentos encontrados", "search.result.placeholder": "Teclee para comenzar b\u00fasqueda", "search.result.term.missing": "Falta", "select.version": "Seleccionar versi\u00f3n"}}</script> <script src=../../../../assets/javascripts/bundle.c8b220af.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=../../../../overrides/assets/js/katex.js></script> <script src=https://unpkg.com/katex@0/dist/katex.min.js></script> <script src=https://unpkg.com/katex@0/dist/contrib/auto-render.min.js></script> <script src=https://cdn.jsdelivr.net/npm/swiper@11/swiper-bundle.min.js></script> <script src=../../../../overrides/assets/vendor/js/prism.js></script> <script src=https://cdn.jsdelivr.net/npm/apexcharts></script> <script src=../../../../overrides/assets/js/chart-example.js></script> <script src=../../../../overrides/assets/js/scripts.js></script> <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body> </html>